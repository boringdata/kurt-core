# Pre-extracted claims - grep for keywords to find relevant facts
# Generated from motherduck database
# Total claims: 3337

claims:
- statement: '#databs is a hashtag used for posts related to data management and streaming.'
  type: definition
  entity: '#databs'
  keywords:
  - definition
  - databs
  - hashtag
  - used
  - posts
  - related
  - data
  - management
  - streaming
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: A hashtag used for posts related to data management and streaming.
    char_start: 0
    char_end: 66
- statement: 'Hashtags #datasky and #databs can be used to filter posts.'
  type: definition
  entity: '#datasky'
  keywords:
  - definition
  - hashtags
  - datasky
  - databs
  - used
  - filter
  - posts
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: 'If you want a stream dedicated to hashtags, for instance, #datasky and
      #databs.'
    char_start: 0
    char_end: 79
- statement: You should add .env to your .gitignore file.
  type: definition
  entity: .env
  keywords:
  - definition
  - add
  - env
  - gitignore
  - file
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: Add .env to your .gitignore file.
    char_start: 0
    char_end: 33
- statement: 7-Zip is a free and open-source file archiver and compression utility.
  type: definition
  entity: 7-Zip
  keywords:
  - definition
  - zip
  - free
  - open
  - source
  - file
  - archiver
  - compression
  - utility
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: 7-Zip is a free and open-source file archiver and compression utility.
    char_start: 0
    char_end: 70
- statement: 7-Zip is widely used in data engineering workflows to compress large
    datasets or extract compressed files.
  type: definition
  entity: 7-Zip
  keywords:
  - definition
  - zip
  - widely
  - used
  - data
  - engineering
  - workflows
  - compress
  - large
  - datasets
  - extract
  - compressed
  - files
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: It's widely used in data engineering workflows to compress large datasets
      or extract compressed files.
    char_start: 0
    char_end: 102
- statement: Data professionals often use 7-Zip to reduce file sizes for storage or
    transmission.
  type: definition
  entity: 7-Zip
  keywords:
  - definition
  - data
  - professionals
  - often
  - use
  - zip
  - reduce
  - file
  - sizes
  - storage
  - transmission
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: Data professionals often use 7-Zip to reduce file sizes for storage or
      transmission.
    char_start: 0
    char_end: 84
- statement: The command-line version of 7-Zip is particularly useful for automating
    compression and decompression tasks in data pipelines.
  type: definition
  entity: 7-Zip
  keywords:
  - definition
  - command
  - line
  - version
  - zip
  - particularly
  - useful
  - automating
  - compression
  - decompression
  - tasks
  - data
  - pipelines
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: The command-line version of 7-Zip is particularly useful for automating
      compression and decompression tasks in data pipelines.
    char_start: 0
    char_end: 126
- statement: Access Logs monitor who is accessing data systems.
  type: definition
  entity: Access Logs
  keywords:
  - definition
  - access
  - logs
  - monitor
  - who
  - accessing
  - data
  - systems
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: 'Access Logs: Monitor who''s accessing data systems and when.'
    char_start: 0
    char_end: 59
- statement: The account id account:::7017 was the one least recently updated.
  type: definition
  entity: account:::7017
  keywords:
  - definition
  - account
  - id
  - '7017'
  - one
  - least
  - recently
  - updated
  source:
    doc: motherduck.com/blog/sql-keyboard-shortcuts-for-joyful-querying.md
    quote: Now we know that the account id `account:::7017` was the one least recently
      updated.
    char_start: 0
    char_end: 84
- statement: The top-5 viewed accounts among the 2-hop followers of account:::7017
    were retrieved.
  type: definition
  entity: account:::7017
  keywords:
  - definition
  - top
  - viewed
  - accounts
  - among
  - hop
  - followers
  - account
  - '7017'
  - retrieved
  source:
    doc: motherduck.com/blog/sql-keyboard-shortcuts-for-joyful-querying.md
    quote: Specifically, the following gremlin query checks top-5 viewed accounts
      among the 2-hop followers (followers of followers) of the account.
    char_start: 0
    char_end: 137
- statement: Atomicity guarantees you won't end up in a state where A is debited but
    B never gets credited.
  type: definition
  entity: Accounts
  keywords:
  - definition
  - atomicity
  - guarantees
  - won
  - end
  - up
  - state
  - debited
  - never
  - gets
  - credited
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part1.md
    quote: Atomicity guarantees you won't end up in a state where A is debited but
      B never gets credited if something goes wrong midway.
    char_start: 0
    char_end: 125
- statement: The Accounts table is used for storing account information.
  type: definition
  entity: Accounts
  keywords:
  - definition
  - accounts
  - table
  - used
  - storing
  - account
  - information
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: CREATE TABLE Accounts (AccountID INTEGER PRIMARY KEY, Balance DECIMAL(10,2)
      CHECK (Balance >= 0));
    char_start: 0
    char_end: 98
- statement: activity_count is calculated based on user_id.
  type: definition
  entity: activity_count
  keywords:
  - definition
  - activity
  - count
  - calculated
  - based
  - user
  - id
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: The activity_count is calculated based on the user_id.
    char_start: 0
    char_end: 54
- statement: ALP has already been incorporated into DuckDB 0.10.
  type: definition
  entity: Adaptive Lossless Floating-Point Compression (ALP)
  keywords:
  - definition
  - alp
  - already
  - incorporated
  - duckdb
  - '0.10'
  source:
    doc: motherduck.com/blog/motherduck-window-functions-in-sql.md
    quote: it has already been incorporated into DuckDB 0.10.
    char_start: 0
    char_end: 50
- statement: ALP outperforms existing codecs in both compression and decompression
    speeds and compression ratio.
  type: definition
  entity: Adaptive Lossless Floating-Point Compression (ALP)
  keywords:
  - definition
  - alp
  - outperforms
  - existing
  - codecs
  - both
  - compression
  - decompression
  - speeds
  - ratio
  source:
    doc: motherduck.com/blog/motherduck-window-functions-in-sql.md
    quote: Notably, ALP outperforms these codecs in both compression and decompression
      speeds and compression ratio.
    char_start: 0
    char_end: 105
- statement: The algorithm was first published in SIGMOD 2024.
  type: definition
  entity: Adaptive Lossless Floating-Point Compression (ALP)
  keywords:
  - definition
  - algorithm
  - first
  - published
  - sigmod
  - '2024'
  source:
    doc: motherduck.com/blog/motherduck-window-functions-in-sql.md
    quote: The algorithm was first published in SIGMOD 2024.
    char_start: 0
    char_end: 49
- statement: The CWI research group presented a new floating-point compression method.
  type: definition
  entity: Adaptive Lossless Floating-Point Compression (ALP)
  keywords:
  - definition
  - cwi
  - research
  - group
  - presented
  - new
  - floating
  - point
  - compression
  - method
  source:
    doc: motherduck.com/blog/perf-is-not-enough.md
    quote: The CWI research group, the origin of DuckDB, presented a new floating-point
      compression method.
    char_start: 0
    char_end: 96
- statement: Adi Polak is the author of O'Reilly's 'Scaling Machine Learning with
    Spark'.
  type: definition
  entity: Adi Polak
  keywords:
  - definition
  - adi
  - polak
  - author
  - reilly
  - scaling
  - machine
  - learning
  - spark
  source:
    doc: motherduck.com/blog/announcing-small-data-sf-2025.md
    quote: Adi brings deep expertise in distributed systems and machine learning,
      having literally written the book on scaling ML.
    char_start: 0
    char_end: 119
- statement: Advent of Code provides daily coding challenges.
  type: definition
  entity: Advent of Code
  keywords:
  - definition
  - advent
  - code
  - provides
  - daily
  - coding
  - challenges
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2024.md
    quote: An annual event in December that provides daily coding challenges.
    char_start: 0
    char_end: 66
- statement: Recursive CTEs are essential for many of the more challenging AoC problems.
  type: definition
  entity: Advent of Code
  keywords:
  - definition
  - recursive
  - ctes
  - essential
  - many
  - challenging
  - aoc
  - problems
  source:
    doc: motherduck.com/blog/solving-advent-code-duckdb-dbt.md
    quote: Recursive CTEs are essential for many of the more challenging AoC problems.
    char_start: 0
    char_end: 75
- statement: The author decided to use SQL for AoC.
  type: definition
  entity: Advent of Code
  keywords:
  - definition
  - author
  - decided
  - use
  - sql
  - aoc
  source:
    doc: motherduck.com/blog/getting-started-ducklake-table-format.md
    quote: In November 2022 with AoC approaching I decided I would commit myself to
      using SQL for AoC.
    char_start: 0
    char_end: 91
- statement: The author used Python for AoC.
  type: definition
  entity: Advent of Code
  keywords:
  - definition
  - author
  - used
  - python
  - aoc
  source:
    doc: motherduck.com/blog/getting-started-ducklake-table-format.md
    quote: In 2022 I used Python.
    char_start: 0
    char_end: 22
- statement: The puzzle input contains 300 lines of varying length random-looking
    text strings.
  type: definition
  entity: Advent of Code
  keywords:
  - definition
  - puzzle
  - input
  - contains
  - '300'
  - lines
  - varying
  - length
  - random
  - looking
  - text
  - strings
  source:
    doc: motherduck.com/blog/pushing-geo-boundaries-with-motherduck-geobase.md
    quote: The puzzle input contains 300 lines of varying length random-looking text
      strings.
    char_start: 0
    char_end: 82
- statement: Agentic Data Engineering is a concept related to data engineering practices.
  type: definition
  entity: Agentic Data Engineering
  keywords:
  - definition
  - agentic
  - data
  - engineering
  - concept
  - related
  - practices
  source:
    doc: motherduck.com/learn-more/duckdb-struct-nested-data.md
    quote: Lessons from Building MotherDuck with MotherDuck
    char_start: 0
    char_end: 48
- statement: AI includes Machine Learning and Large Language Models.
  type: definition
  entity: AI
  keywords:
  - definition
  - ai
  - includes
  - machine
  - learning
  - large
  - language
  - models
  source:
    doc: motherduck.com/videos.md
    quote: AI, ML and LLMs
    char_start: 0
    char_end: 15
- statement: AI is the simulation of human intelligence in machines.
  type: definition
  entity: AI
  keywords:
  - definition
  - ai
  - simulation
  - human
  - intelligence
  - machines
  source:
    doc: motherduck.com/videos.md
    quote: Artificial Intelligence, the simulation of human intelligence in machines.
    char_start: 0
    char_end: 74
- statement: The AI updates the Python script to add a new layer to the Folium map.
  type: definition
  entity: AI
  keywords:
  - definition
  - ai
  - updates
  - python
  - script
  - add
  - new
  - layer
  - folium
  - map
  source:
    doc: motherduck.com/blog/streaming-oracle-to-motherduck.md
    quote: The AI updates the Python script one more time, adding a new layer to our
      Folium map.
    char_start: 0
    char_end: 85
- statement: AI agents can perform tasks autonomously.
  type: definition
  entity: AI agents/LLMs
  keywords:
  - definition
  - ai
  - agents
  - perform
  - tasks
  - autonomously
  source:
    doc: motherduck.com/videos/bringing-duckdb-to-the-cloud-dual-execution-explained.md
    quote: Artificial intelligence systems that can perform tasks autonomously.
    char_start: 0
    char_end: 68
- statement: The AI Native Summit 2025 will feature discussions on enterprise AI.
  type: definition
  entity: AI Native Summit 2025
  keywords:
  - definition
  - ai
  - native
  - summit
  - '2025'
  - feature
  - discussions
  - enterprise
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: This event brings together AI leaders across research, startups and global
      companies for a day of discussion about the state of enterprise AI.
    char_start: 0
    char_end: 142
- statement: AI in BI represents augmentation.
  type: definition
  entity: AI Powered BI
  keywords:
  - definition
  - ai
  - bi
  - represents
  - augmentation
  source:
    doc: motherduck.com/videos/a-new-paradigm-for-data-visualization-with-just-sql-markdown.md
    quote: Rather than replacement, AI in BI represents augmentation.
    char_start: 0
    char_end: 58
- statement: AI Powered BI can generate dashboards using LLMs.
  type: feature
  entity: AI Powered BI
  keywords:
  - feature
  - ai
  - powered
  - bi
  - generate
  - dashboards
  - using
  - llms
  source:
    doc: motherduck.com/videos/is-bi-too-big-for-small-data.md
    quote: 'AI Powered BI: Can LLMs REALLY Generate Your Dashboards? ft. Michael Driscoll'
    char_start: 0
    char_end: 77
- statement: Business intelligence is evolving from drag-and-drop tools to code-based,
    AI-powered workflows.
  type: definition
  entity: AI Powered BI
  keywords:
  - definition
  - business
  - intelligence
  - evolving
  - drag
  - drop
  - tools
  - code
  - based
  - ai
  - powered
  - workflows
  source:
    doc: motherduck.com/videos.md
    quote: Discover how business intelligence is evolving from drag-and-drop tools
      to code-based, AI-powered workflows.
    char_start: 0
    char_end: 108
- statement: LLMs can generate dashboards in business intelligence.
  type: definition
  entity: AI Powered BI
  keywords:
  - definition
  - llms
  - generate
  - dashboards
  - business
  - intelligence
  source:
    doc: motherduck.com/learn-more/partitioned-writes-parquet-ducklake.md
    quote: Can LLMs REALLY Generate Your Dashboards?
    char_start: 0
    char_end: 41
- statement: AI tools are transforming data workflows by eliminating routine tasks
    and accelerating development cycles.
  type: definition
  entity: AI tools
  keywords:
  - definition
  - ai
  - tools
  - transforming
  - data
  - workflows
  - eliminating
  - routine
  - tasks
  - accelerating
  - development
  - cycles
  source:
    doc: motherduck.com/videos.md
    quote: 'The consensus among panelists: AI tools are transforming data workflows
      by eliminating routine tasks and accelerating development cycles.'
    char_start: 0
    char_end: 137
- statement: Success requires thoughtful implementation, continuous validation, and
    a clear understanding that these tools augment rather than replace human expertise.
  type: definition
  entity: AI tools
  keywords:
  - definition
  - success
  - requires
  - thoughtful
  - implementation
  - continuous
  - validation
  - clear
  - understanding
  - tools
  - augment
  - rather
  - replace
  - human
  - expertise
  source:
    doc: motherduck.com/videos.md
    quote: However, success requires thoughtful implementation, continuous validation,
      and a clear understanding that these tools augment rather than replace human
      expertise.
    char_start: 0
    char_end: 163
- statement: AI-Driven Optimization incorporates machine learning for automated query
    optimization, data placement, and resource allocation.
  type: definition
  entity: AI-Driven Optimization
  keywords:
  - definition
  - ai
  - driven
  - optimization
  - incorporates
  - machine
  - learning
  - automated
  - query
  - data
  - placement
  - resource
  - allocation
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: AI-Driven Optimization Incorporating machine learning for automated query
      optimization, data placement, and resource allocation.
    char_start: 0
    char_end: 128
- statement: AI-generated SQL refers to SQL queries generated by artificial intelligence
    systems.
  type: definition
  entity: AI-generated SQL
  keywords:
  - definition
  - ai
  - generated
  - sql
  - refers
  - queries
  - artificial
  - intelligence
  - systems
  source:
    doc: motherduck.com/blog/just-enough-sql-for-ai.md
    quote: SQL queries that are generated by artificial intelligence systems.
    char_start: 0
    char_end: 66
- statement: AI features improve the SQL query workflow.
  type: definition
  entity: AI-powered edit suggestions
  keywords:
  - definition
  - ai
  - features
  - improve
  - sql
  - query
  - workflow
  source:
    doc: motherduck.com/blog/motherduck-kestra-etl-pipelines.md
    quote: All of these workflow improvements are great for humans, but they're even
      better when you throw AI features into the mix.
    char_start: 0
    char_end: 121
- statement: Airbyte and Fivetran are managed ELT services that simplify data ingestion.
  type: definition
  entity: Airbyte
  keywords:
  - definition
  - airbyte
  - fivetran
  - managed
  - elt
  - services
  - simplify
  - data
  - ingestion
  source:
    doc: motherduck.com/videos/duckfooding-at-motherduck.md
    quote: These managed ELT (Extract, Load, Transform) services offer extensive libraries
      of pre-built connectors.
    char_start: 0
    char_end: 104
- statement: Airbyte integrates with DuckDB for data solutions.
  type: definition
  entity: Airbyte
  keywords:
  - definition
  - airbyte
  - integrates
  - duckdb
  - data
  - solutions
  source:
    doc: motherduck.com/blog/announcing-duckdb-141-motherduck.md
    quote: Airbyte and MotherDuck to solve the needs of delivering modern data integration.
    char_start: 0
    char_end: 80
- statement: AirByte serves as the data ingestion and orchestration platform.
  type: definition
  entity: Airbyte
  keywords:
  - definition
  - airbyte
  - serves
  - data
  - ingestion
  - orchestration
  - platform
  source:
    doc: motherduck.com/blog/simplifying-iot-analytics-motherduck.md
    quote: AirByte serves as the data ingestion and orchestration platform.
    char_start: 0
    char_end: 64
- statement: Airflow is an open-source tool to programmatically author, schedule,
    and monitor workflows.
  type: definition
  entity: Airflow
  keywords:
  - definition
  - airflow
  - open
  - source
  - tool
  - programmatically
  - author
  - schedule
  - monitor
  - workflows
  source:
    doc: motherduck.com/blog/data-engineer-highlights-PyConDE-2023.md
    quote: Airflow is an open-source tool to programmatically author, schedule, and
      monitor workflows.
    char_start: 0
    char_end: 91
- statement: Alex transitioned from an industrial engineer to a data scientist at
    Intel.
  type: definition
  entity: Alex
  keywords:
  - definition
  - alex
  - transitioned
  - industrial
  - engineer
  - data
  - scientist
  - intel
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Moreover, delve into Alex's transition from an industrial engineer to a
      data scientist at Intel.
    char_start: 0
    char_end: 96
- statement: Alex's path from industrial engineering to data science was propelled
    by his intrigue for DuckDB.
  type: definition
  entity: Alex
  keywords:
  - definition
  - alex
  - path
  - industrial
  - engineering
  - data
  - science
  - propelled
  - intrigue
  - duckdb
  source:
    doc: motherduck.com/videos/from-core-to-custom-unlocking-new-possibilities-with-duckdb-extensions.md
    quote: Similarly, Alex's path from industrial engineering to data science, propelled
      by his intrigue for DuckDB, underscores the importance of innovative tools in
      career evolution and the execution of data p
    char_start: 0
    char_end: 208
- statement: Alex Monahan is a data scientist at Intel and works on DuckDB.
  type: definition
  entity: Alex Monahan
  keywords:
  - definition
  - alex
  - monahan
  - data
  - scientist
  - intel
  - works
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-two.md
    quote: He's a data scientist at Intel, but also works on documentation, tutorials
      and training at DuckDB Labs.
    char_start: 0
    char_end: 103
- statement: Alex Monahan is a featured community member in the DuckDB ecosystem.
  type: definition
  entity: Alex Monahan
  keywords:
  - definition
  - alex
  - monahan
  - featured
  - community
  - member
  - duckdb
  - ecosystem
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-two.md
    quote: If you've s...]
    char_start: 0
    char_end: 15
- statement: Altair is a declarative statistical visualization library for Python.
  type: definition
  entity: Altair
  keywords:
  - definition
  - altair
  - declarative
  - statistical
  - visualization
  - library
  - python
  source:
    doc: motherduck.com/blog/big-data-is-dead.md
    quote: Altair is a declarative statistical visualization library for Python.
    char_start: 0
    char_end: 69
- statement: Amazon Redshift includes new optimization techniques for intelligent
    scaling.
  type: definition
  entity: Amazon Redshift
  keywords:
  - definition
  - amazon
  - redshift
  - includes
  - new
  - optimization
  - techniques
  - intelligent
  - scaling
  source:
    doc: motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md
    quote: Redshift’s next-generation AI-powered Scaling, which includes new optimization
      techniques for intelligent scaling in Amazon Redshift.
    char_start: 0
    char_end: 133
- statement: Amazon Redshift pioneered the cloud data warehouse category.
  type: definition
  entity: Amazon Redshift
  keywords:
  - definition
  - amazon
  - redshift
  - pioneered
  - cloud
  - data
  - warehouse
  - category
  source:
    doc: motherduck.com/blog/unstructured-analysis-tensorlake-motherduck.md
    quote: Amazon Redshift pioneered the cloud data warehouse category, offering organizations
      a way to analyze large datasets without managing physical infrastructure.
    char_start: 0
    char_end: 157
- statement: Amazon Redshift provides insights into query patterns and workload distributions.
  type: definition
  entity: Amazon Redshift
  keywords:
  - definition
  - amazon
  - redshift
  - provides
  - insights
  - query
  - patterns
  - workload
  - distributions
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-2.md
    quote: His analysis of the Redset dataset from Amazon Redshift customers provides
      insights into query patterns and workload distributions.
    char_start: 0
    char_end: 131
- statement: Amazon Redshift significantly lowered the barrier to entry by replacing
    hardware procurement with a managed, pay-as-you-go service.
  type: definition
  entity: Amazon Redshift
  keywords:
  - definition
  - amazon
  - redshift
  - significantly
  - lowered
  - barrier
  - entry
  - replacing
  - hardware
  - procurement
  - managed
  - pay
  - go
  - service
  source:
    doc: motherduck.com/videos/whats-new-in-data-small-data-big-impact.md
    quote: Services like Amazon Redshift (2012) significantly lowered the barrier
      to entry by replacing hardware procurement with a managed, pay-as-you-go service.
    char_start: 0
    char_end: 152
- statement: Amazon Redshift traditionally requires the most hands-on management.
  type: definition
  entity: Amazon Redshift
  keywords:
  - definition
  - amazon
  - redshift
  - traditionally
  - requires
  - hands
  - management
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part1.md
    quote: Amazon Redshift traditionally requires the most hands-on management.
    char_start: 0
    char_end: 68
- statement: Modern cloud data warehouses offer incredible scalability.
  type: definition
  entity: Amazon Redshift
  keywords:
  - definition
  - modern
  - cloud
  - data
  - warehouses
  - offer
  - incredible
  - scalability
  source:
    doc: motherduck.com/learn-more/star-schema-data-warehouse-guide.md
    quote: Modern cloud data warehouses (like Amazon Redshift, Google BigQuery, Snowflake,
      Azure Synapse Analytics) offer incredible scalability.
    char_start: 0
    char_end: 134
- statement: Redshift's TCO is often rooted in its provisioned cluster model, where
    you pay per hour for a fixed set of resources.
  type: definition
  entity: Amazon Redshift
  keywords:
  - definition
  - redshift
  - tco
  - often
  - rooted
  - provisioned
  - cluster
  - model
  - pay
  - per
  - hour
  - fixed
  - set
  - resources
  source:
    doc: motherduck.com/blog/why-everybody-hates-databases.md
    quote: Redshift's TCO is often rooted in its provisioned cluster model, where
      you pay per hour for a fixed set of resources.
    char_start: 0
    char_end: 117
- statement: A practical and cost-effective DR plan can be built by using cloud object
    storage like AWS S3.
  type: definition
  entity: Amazon S3
  keywords:
  - definition
  - practical
  - cost
  - effective
  - dr
  - plan
  - built
  - using
  - cloud
  - object
  - storage
  - like
  - aws
  - s3
  source:
    doc: motherduck.com/videos/where-data-science-meets-shrek-how-buzzfeed-uses-ai.md
    quote: A practical and cost-effective DR plan can be built by using cloud object
      storage like AWS S3.
    char_start: 0
    char_end: 94
- statement: A single Graviton3 instance delivers 300 gigabytes per second of aggregate
    memory bandwidth.
  type: definition
  entity: Amazon S3
  keywords:
  - definition
  - single
  - graviton3
  - instance
  - delivers
  - '300'
  - gigabytes
  - per
  - second
  - aggregate
  - memory
  - bandwidth
  source:
    doc: motherduck.com/videos/whats-new-in-data-small-data-big-impact.md
    quote: A single Graviton3 instance at $1.30 per hour delivers 300 gigabytes per
      second of aggregate memory bandwidth.
    char_start: 0
    char_end: 110
- statement: AWS S3 is used as a staging bucket for MotherDuck.
  type: definition
  entity: Amazon S3
  keywords:
  - definition
  - aws
  - s3
  - used
  - staging
  - bucket
  - motherduck
  source:
    doc: motherduck.com/blog/tableau-cloud-motherduck.md
    quote: 'S3 Staging Bucket: The name of your AWS S3 bucket.'
    char_start: 0
    char_end: 50
- statement: Keeping a warehouse warm for related analytical queries can be beneficial.
  type: definition
  entity: Amazon S3
  keywords:
  - definition
  - keeping
  - warehouse
  - warm
  - related
  - analytical
  - queries
  - beneficial
  source:
    doc: motherduck.com/videos/sql-ide-safari-harlequin-in-your-terminal.md
    quote: Keeping a warehouse warm for related analytical queries can be beneficial.
    char_start: 0
    char_end: 74
- statement: Network latency creates a slow feedback loop for modern developers.
  type: definition
  entity: Amazon S3
  keywords:
  - definition
  - network
  - latency
  - creates
  - slow
  - feedback
  - loop
  - modern
  - developers
  source:
    doc: motherduck.com/videos/duckdb-vs-pandas-vs-polars-for-python-devs.md
    quote: This network latency creates a slow feedback loop.
    char_start: 0
    char_end: 50
- statement: Pandas is a library that requires Python to function.
  type: definition
  entity: Amazon S3
  keywords:
  - definition
  - pandas
  - library
  - requires
  - python
  - function
  source:
    doc: motherduck.com/videos/motherduck-in-100-seconds-by-a-duck.md
    quote: Pandas is a library that requires Python to function.
    char_start: 0
    char_end: 53
- statement: Popular cloud storage providers include Amazon S3, Google Cloud Storage,
    and Microsoft Azure Blob Storage.
  type: definition
  entity: Amazon S3
  keywords:
  - definition
  - popular
  - cloud
  - storage
  - providers
  - include
  - amazon
  - s3
  - google
  - microsoft
  - azure
  - blob
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: Popular cloud storage providers include Amazon S3, Google Cloud Storage,
      and Microsoft Azure Blob Storage.
    char_start: 0
    char_end: 106
- statement: PostgreSQL was named DBMS of the Year in 2023.
  type: definition
  entity: Amazon S3
  keywords:
  - definition
  - postgresql
  - named
  - dbms
  - year
  - '2023'
  source:
    doc: motherduck.com/videos/pg_duckdb-postgres-analytics-just-got-faster-with-duckdb.md
    quote: PostgreSQL is on a roll. It was named DBMS of the Year in 2023.
    char_start: 0
    char_end: 63
- statement: Reading data from cloud object storage like Amazon S3 is the slowest
    part of any query.
  type: definition
  entity: Amazon S3
  keywords:
  - definition
  - reading
  - data
  - cloud
  - object
  - storage
  - like
  - amazon
  - s3
  - slowest
  - part
  - any
  - query
  source:
    doc: motherduck.com/learn-more.md
    quote: Reading data from cloud object storage like Amazon S3 is the slowest part
      of any query.
    char_start: 0
    char_end: 87
- statement: S3 organizes data into 'buckets' which act as containers for objects.
  type: definition
  entity: Amazon S3
  keywords:
  - definition
  - s3
  - organizes
  - data
  - buckets
  - which
  - act
  - containers
  - objects
  source:
    doc: motherduck.com/blog/streaming-data-to-motherduck.md
    quote: S3 organizes data into 'buckets' which act as containers for objects (files),
      and each object is identified by a unique key within its bucket.
    char_start: 0
    char_end: 142
- statement: The df_engineers DataFrame contains columns for Engineer, Specialty,
    YearsExp, and HourlyRate.
  type: definition
  entity: Amazon S3
  keywords:
  - definition
  - df
  - engineers
  - dataframe
  - contains
  - columns
  - engineer
  - specialty
  - yearsexp
  - hourlyrate
  source:
    doc: motherduck.com/videos/whats-new-in-duckdb-motherduck.md
    quote: The df_engineers DataFrame contains columns for Engineer, Specialty, YearsExp,
      and HourlyRate.
    char_start: 0
    char_end: 94
- statement: The next step is to move your analytical workloads from a row-oriented
    (OLTP) database like Postgres to a purpose-built columnar (OLAP) engine like DuckDB.
  type: definition
  entity: Amazon S3
  keywords:
  - definition
  - next
  - step
  - move
  - analytical
  - workloads
  - row
  - oriented
  - oltp
  - database
  - like
  - postgres
  - purpose
  - built
  - columnar
  - olap
  - engine
  - duckdb
  source:
    doc: motherduck.com/videos/ducklake-big-data-small-coalesce-2025.md
    quote: The next step is to move your analytical workloads from a row-oriented
      (OLTP) database like Postgres to a purpose-built columnar (OLAP) engine like
      DuckDB.
    char_start: 0
    char_end: 155
- statement: The original pipeline was built on Hadoop and was slow and difficult
    to work with.
  type: performance
  entity: Amazon S3
  keywords:
  - performance
  - original
  - pipeline
  - built
  - hadoop
  - slow
  - difficult
  - work
  source:
    doc: motherduck.com/videos/duckdb-run-dbt-build-with-sub-second-execution-times.md
    quote: The original pipeline was built on Hadoop. It was slow and incredibly difficult
      to work with.
    char_start: 0
    char_end: 93
- statement: The struct_pack function is used to create STRUCTs in DuckDB.
  type: definition
  entity: Amazon S3
  keywords:
  - definition
  - struct
  - pack
  - function
  - used
  - create
  - structs
  - duckdb
  source:
    doc: motherduck.com/webinar/data-discoverability-secoda-motherduck.md
    quote: The most explicit way is using the struct_pack function.
    char_start: 0
    char_end: 56
- statement: Usage-based billing eliminates guesswork about capacity planning and
    associated expenses.
  type: definition
  entity: Amazon S3
  keywords:
  - definition
  - usage
  - based
  - billing
  - eliminates
  - guesswork
  - about
  - capacity
  - planning
  - associated
  - expenses
  source:
    doc: motherduck.com/videos/a-duck-in-the-hand-is-worth-two-in-the-cloud.md
    quote: Usage-based billing eliminates guesswork about capacity planning and associated
      expenses.
    char_start: 0
    char_end: 89
- statement: Using open data formats allows you to store your data in a simple, cost-effective
    object store.
  type: definition
  entity: Amazon S3
  keywords:
  - definition
  - using
  - open
  - data
  - formats
  - allows
  - store
  - simple
  - cost
  - effective
  - object
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: This commitment allows you to store your data in a simple, cost-effective
      object store like Amazon S3 or Google Cloud Storage in a vendor-neutral format.
    char_start: 0
    char_end: 153
- statement: Using open formats on commodity object storage avoids vendor lock-in
    and significantly reduces storage costs.
  type: definition
  entity: Amazon S3
  keywords:
  - definition
  - using
  - open
  - formats
  - commodity
  - object
  - storage
  - avoids
  - vendor
  - lock
  - significantly
  - reduces
  - costs
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: Using open formats on commodity object storage avoids vendor lock-in and
      significantly reduces storage costs.
    char_start: 0
    char_end: 109
- statement: Serverless catalogs simplify setup and maintenance by integrating the
    catalog with the storage layer.
  type: definition
  entity: Amazon S3 Tables
  keywords:
  - definition
  - serverless
  - catalogs
  - simplify
  - setup
  - maintenance
  - integrating
  - catalog
  - storage
  - layer
  source:
    doc: motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse.md
    quote: these are a 'great innovation because they bundle the catalog _with the
      storage_, simplifying setup and maintenance'.
    char_start: 0
    char_end: 117
- statement: DuckDB offers extensions that simplify authentication and read/write
    operations to AWS S3.
  type: definition
  entity: Amazon Simple Storage Service
  keywords:
  - definition
  - duckdb
  - offers
  - extensions
  - simplify
  - authentication
  - read
  - write
  - operations
  - aws
  - s3
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: DuckDB offers extensions that simplify authentication and read/write operations
      to AWS S3.
    char_start: 0
    char_end: 90
- statement: S3 can be used as a database, but it has significant limitations.
  type: definition
  entity: Amazon Simple Storage Service
  keywords:
  - definition
  - s3
  - used
  - database
  - significant
  - limitations
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-2.md
    quote: You can, of course, use S3 as a database.
    char_start: 0
    char_end: 41
- statement: S3 is a cloud storage service provided by Amazon Web Services.
  type: definition
  entity: Amazon Simple Storage Service
  keywords:
  - definition
  - s3
  - cloud
  - storage
  - service
  - provided
  - amazon
  - web
  - services
  source:
    doc: motherduck.com/blog/motherduck-congratulates-duckdb-1.0-release.md
    quote: Just because it stores data doesn’t make it a database.
    char_start: 0
    char_end: 55
- statement: S3 is used for storing data.
  type: definition
  entity: Amazon Simple Storage Service
  keywords:
  - definition
  - s3
  - used
  - storing
  - data
  source:
    doc: motherduck.com/blog/redshift-files-hunt-for-big-data.md
    quote: Alternatively, you can load the data from S3 yourself.
    char_start: 0
    char_end: 54
- statement: The AWS S3 path is set as an environment variable.
  type: definition
  entity: Amazon Simple Storage Service
  keywords:
  - definition
  - aws
  - s3
  - path
  - set
  - environment
  - variable
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: The AWS S3 path is set as an environment variable.
    char_start: 0
    char_end: 50
- statement: Using S3 as a database can lead to high latency and inconsistency.
  type: definition
  entity: Amazon Simple Storage Service
  keywords:
  - definition
  - using
  - s3
  - database
  - lead
  - high
  - latency
  - inconsistency
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-2.md
    quote: Latency can be very high, and variance can be higher.
    char_start: 0
    char_end: 53
- statement: We have some sample raw data available in a public AWS S3 bucket.
  type: definition
  entity: Amazon Simple Storage Service
  keywords:
  - definition
  - sample
  - raw
  - data
  - available
  - public
  - aws
  - s3
  - bucket
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: we have some sample raw data available in a public AWS S3 bucket that you
      can use as input for the transformation pipeline.
    char_start: 0
    char_end: 123
- statement: The heart of a data application is its analysis engine.
  type: definition
  entity: Analysis Engine
  keywords:
  - definition
  - heart
  - data
  - application
  - analysis
  - engine
  source:
    doc: motherduck.com/ecosystem.md
    quote: The heart of a data application is its analysis engine.
    char_start: 0
    char_end: 55
- statement: Analytical databases are designed for querying and analyzing large datasets.
  type: definition
  entity: analytical databases
  keywords:
  - definition
  - analytical
  - databases
  - designed
  - querying
  - analyzing
  - large
  - datasets
  source:
    doc: motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md
    quote: Analytical databases, or OLAP (Online Analytical Processing) databases,
      are designed for querying and analyzing large datasets.
    char_start: 0
    char_end: 127
- statement: Analytical databases unlock a world of possibilities for web developers.
  type: definition
  entity: analytical databases
  keywords:
  - definition
  - analytical
  - databases
  - unlock
  - world
  - possibilities
  - web
  - developers
  source:
    doc: motherduck.com/blog/why-web-developers-should-care-about-analytical-databases.md
    quote: To wrap up, analytical databases unlock a world of possibilities for web
      developers.
    char_start: 0
    char_end: 84
- statement: Setting up analytical workflows has never been easier with modern tools
    and SQL.
  type: definition
  entity: analytical databases
  keywords:
  - definition
  - setting
  - up
  - analytical
  - workflows
  - never
  - easier
  - modern
  - tools
  - sql
  source:
    doc: motherduck.com/blog/why-web-developers-should-care-about-analytical-databases.md
    quote: With modern tools and SQL as a common language, setting up these workflows
      has never been easier.
    char_start: 0
    char_end: 97
- statement: The analytics team needs reliable and performant access to up-to-date
    copies without impacting production performance.
  type: definition
  entity: analytics team
  keywords:
  - definition
  - analytics
  - team
  - needs
  - reliable
  - performant
  - access
  - up
  - date
  - copies
  - without
  - impacting
  - production
  - performance
  source:
    doc: motherduck.com/blog/small-data-sf-workshops-agenda.md
    quote: The analytics team needs reliable and performant access to up-to-date copies
      without impacting production performance.
    char_start: 0
    char_end: 118
- statement: Andreas Kretz created The Data Engineering Cookbook.
  type: definition
  entity: Andreas Kretz
  keywords:
  - definition
  - andreas
  - kretz
  - created
  - data
  - engineering
  - cookbook
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: He's the creator of The Data Engineering Cookbook.
    char_start: 0
    char_end: 50
- statement: Andreas Kretz is a data engineering educator and the founder of Learn
    Data Engineering Academy.
  type: definition
  entity: Andreas Kretz
  keywords:
  - definition
  - andreas
  - kretz
  - data
  - engineering
  - educator
  - founder
  - learn
  - academy
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: Andreas Kretz is a data engineering educator and the founder of Learn Data
      Engineering Academy.
    char_start: 0
    char_end: 95
- statement: Anna Geller appreciates some randomly generated datasets for analyzing
    real-world things.
  type: definition
  entity: Anna Geller
  keywords:
  - definition
  - anna
  - geller
  - appreciates
  - randomly
  - generated
  - datasets
  - analyzing
  - real
  - world
  - things
  source:
    doc: motherduck.com/blog/pg-mooncake-columnstore.md
    quote: As a user, I would appreciate some randomly generated datasets where folks
      can analyze real world things like costs and revenue rather than petal lengths.
    char_start: 0
    char_end: 154
- statement: Answers are posts that can be linked to questions.
  type: definition
  entity: Answers
  keywords:
  - definition
  - answers
  - posts
  - linked
  - questions
  source:
    doc: motherduck.com/blog/pg-duckdb-release.md
    quote: The Answers (Post with postTypeId=2) with their own ownerUserId, upvotes,
      downvotes, comments.
    char_start: 0
    char_end: 94
- statement: Apache Airflow is a platform to programmatically author, schedule, and
    monitor workflows.
  type: definition
  entity: Apache Airflow
  keywords:
  - definition
  - apache
  - airflow
  - platform
  - programmatically
  - author
  - schedule
  - monitor
  - workflows
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: A platform to programmatically author, schedule, and monitor workflows.
    char_start: 0
    char_end: 71
- statement: Modern data pipelines often incorporate tools like Apache Airflow for
    orchestration, dbt for transformation, and Fivetran for data extraction.
  type: definition
  entity: Apache Airflow
  keywords:
  - definition
  - modern
  - data
  - pipelines
  - often
  - incorporate
  - tools
  - like
  - apache
  - airflow
  - orchestration
  - dbt
  - transformation
  - fivetran
  - extraction
  source:
    doc: motherduck.com/case-studies/dosomething-non-profit-tco-cost-savings.md
    quote: Modern data pipelines often incorporate tools like Apache Airflow for orchestration,
      dbt for transformation, and Fivetran for data extraction.
    char_start: 0
    char_end: 142
- statement: Modern data pipelines often leverage tools like Apache Airflow, Dagster,
    or Prefect to orchestrate these workflows.
  type: definition
  entity: Apache Airflow
  keywords:
  - definition
  - modern
  - data
  - pipelines
  - often
  - leverage
  - tools
  - like
  - apache
  - airflow
  - dagster
  - prefect
  - orchestrate
  - workflows
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: Modern data pipelines often leverage tools like Apache Airflow, Dagster,
      or Prefect to orchestrate these workflows.
    char_start: 0
    char_end: 115
- statement: Apache Arrow is optimized for ML inference through its vector-ready design.
  type: definition
  entity: Apache Arrow
  keywords:
  - definition
  - apache
  - arrow
  - optimized
  - ml
  - inference
  - vector
  - ready
  - design
  source:
    doc: motherduck.com/blog/duckdb-text2sql-llm.md
    quote: Perfect for batching, scanning, and ML inference.
    char_start: 0
    char_end: 49
- statement: Apache Arrow's column-first layout is designed to be SIMD-friendly.
  type: definition
  entity: Apache Arrow
  keywords:
  - definition
  - apache
  - arrow
  - column
  - first
  - layout
  - designed
  - simd
  - friendly
  source:
    doc: motherduck.com/blog/duckdb-text2sql-llm.md
    quote: Column-first layout → SIMD-friendly (Single Instruction, Multiple Data),
      enabling parallel processing at the CPU level.
    char_start: 0
    char_end: 119
- statement: Arrow facilitates fast analytics on big data by leveraging modern hardware
    through techniques like SIMD operations.
  type: definition
  entity: Apache Arrow
  keywords:
  - definition
  - arrow
  - facilitates
  - fast
  - analytics
  - big
  - data
  - leveraging
  - modern
  - hardware
  - techniques
  - like
  - simd
  - operations
  source:
    doc: motherduck.com/ecosystem.md
    quote: Arrow facilitates fast analytics on big data by leveraging modern hardware
      through techniques like SIMD (Single Instruction, Multiple Data) operations.
    char_start: 0
    char_end: 151
- statement: Arrow is widely adopted in the data ecosystem, with integrations in popular
    tools like pandas, DuckDB, and Apache Spark.
  type: definition
  entity: Apache Arrow
  keywords:
  - definition
  - arrow
  - widely
  - adopted
  - data
  - ecosystem
  - integrations
  - popular
  - tools
  - like
  - pandas
  - duckdb
  - apache
  - spark
  source:
    doc: motherduck.com/ecosystem.md
    quote: It's widely adopted in the data ecosystem, with integrations in popular
      tools like pandas, DuckDB, and Apache Spark.
    char_start: 0
    char_end: 116
- statement: Thanks to Apache Arrow, we can actually use one or more of these frameworks
    together.
  type: definition
  entity: Apache Arrow
  keywords:
  - definition
  - thanks
  - apache
  - arrow
  - actually
  - use
  - one
  - frameworks
  - together
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: Thanks to Apache Arrow, we can actually use one or more of these frameworks
      together.
    char_start: 0
    char_end: 85
- statement: Zero-copy or data virtualization technologies enable data sharing without
    serialization overhead.
  type: definition
  entity: Apache Arrow
  keywords:
  - definition
  - zero
  - copy
  - data
  - virtualization
  - technologies
  - enable
  - sharing
  - without
  - serialization
  - overhead
  source:
    doc: motherduck.com/blog/git-for-data-part-1.md
    quote: The next best approach is zero-copy or data virtualization technologies.
    char_start: 0
    char_end: 72
- statement: Apache Arrow Flight enables multiple writers to send data while simultaneously
    executing queries.
  type: definition
  entity: Apache Arrow Flight
  keywords:
  - definition
  - apache
  - arrow
  - flight
  - enables
  - multiple
  - writers
  - send
  - data
  - simultaneously
  - executing
  - queries
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-essential-tools.md
    quote: Ritchie introduces a solution by leveraging Apache Arrow Flight, enabling
      multiple writers to send data while simultaneously executing queries.
    char_start: 0
    char_end: 143
- statement: Apache Avro offers a flexible, row-based format that emphasizes efficient
    data serialization and schema evolution.
  type: definition
  entity: Apache Avro
  keywords:
  - definition
  - apache
  - avro
  - offers
  - flexible
  - row
  - based
  - format
  - emphasizes
  - efficient
  - data
  - serialization
  - schema
  - evolution
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Apache Avro offers a flexible, row-based format that emphasizes efficient
      data serialization and schema evolution.
    char_start: 0
    char_end: 114
- statement: Apache Flink and Storm make real-time analytics possible.
  type: definition
  entity: Apache Flink
  keywords:
  - definition
  - apache
  - flink
  - storm
  - make
  - real
  - time
  - analytics
  - possible
  source:
    doc: motherduck.com/blog/unstructured-analysis-tensorlake-motherduck.md
    quote: Apache Flink and Storm emerged to process these streams of data, making
      real-time analytics possible for organizations of all sizes.
    char_start: 0
    char_end: 132
- statement: Apache Flink supports stateful stream processing.
  type: definition
  entity: Apache Flink
  keywords:
  - definition
  - apache
  - flink
  - supports
  - stateful
  - stream
  - processing
  source:
    doc: motherduck.com/case-studies/layers-multi-tenant-data-warehouse.md
    quote: Apache Flink supports stateful stream processing.
    char_start: 0
    char_end: 49
- statement: Apache Hadoop is an open-source software framework for storing and processing
    large datasets in a distributed computing environment.
  type: definition
  entity: Apache Hadoop
  keywords:
  - definition
  - apache
  - hadoop
  - open
  - source
  - software
  - framework
  - storing
  - processing
  - large
  - datasets
  - distributed
  - computing
  - environment
  source:
    doc: motherduck.com/privacy-policy.md
    quote: Apache Hadoop is an open-source software framework for storing and processing
      large datasets in a distributed computing environment.
    char_start: 0
    char_end: 132
- statement: Apache Hudi is well-suited for update-heavy workloads.
  type: definition
  entity: Apache Hudi
  keywords:
  - definition
  - apache
  - hudi
  - well
  - suited
  - update
  - heavy
  - workloads
  source:
    doc: motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md
    quote: Hudi differentiates itself with native primary key support, making it particularly
      well-suited for update-heavy workloads.
    char_start: 0
    char_end: 122
- statement: Apache Iceberg is a middle ground for building a data stack.
  type: definition
  entity: Apache Iceberg
  keywords:
  - definition
  - apache
  - iceberg
  - middle
  - ground
  - building
  - data
  - stack
  source:
    doc: motherduck.com/videos/local-dev-cloud-prod-with-dagster-and-motherduck.md
    quote: Apache Iceberg is a middle ground, but its catalog is a hurdle.
    char_start: 0
    char_end: 63
- statement: Apache Iceberg is becoming the industry standard for open table formats.
  type: definition
  entity: Apache Iceberg
  keywords:
  - definition
  - apache
  - iceberg
  - becoming
  - industry
  - standard
  - open
  - table
  - formats
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: Apache Iceberg is becoming the industry standard, with Delta Lake and Apache
      Hudi also available.
    char_start: 0
    char_end: 97
- statement: Data lakehouse formats are re-learning some of the lessons of the past
    regarding database semantics.
  type: definition
  entity: Apache Iceberg
  keywords:
  - definition
  - data
  - lakehouse
  - formats
  - re
  - learning
  - lessons
  - past
  - regarding
  - database
  - semantics
  source:
    doc: motherduck.com/blog/introducing-instant-sql.md
    quote: Seeing the rise of data lakehouse formats feels like déjà vu all over again...
    char_start: 0
    char_end: 78
- statement: DuckLake is more portable than Iceberg because it is easier to implement.
  type: comparison
  entity: Apache Iceberg
  keywords:
  - comparison
  - ducklake
  - portable
  - iceberg
  - easier
  - implement
  source:
    doc: motherduck.com/blog/duckdb-the-great-federator.md
    quote: DuckLake is actually more portable than Iceberg because it is easier to
      implement.
    char_start: 0
    char_end: 82
- statement: Iceberg allows for large-scale data management.
  type: definition
  entity: Apache Iceberg
  keywords:
  - definition
  - iceberg
  - allows
  - large
  - scale
  - data
  - management
  source:
    doc: motherduck.com/blog/motherduck-congratulates-duckdb-1.0-release.md
    quote: open table formats like Iceberg power ...
    char_start: 0
    char_end: 41
- statement: Iceberg and Delta Lake are part of the table format wars.
  type: definition
  entity: Apache Iceberg
  keywords:
  - definition
  - iceberg
  - delta
  - lake
  - part
  - table
  - format
  - wars
  source:
    doc: motherduck.com/blog/semantic-layer-duckdb-tutorial.md
    quote: If you work with data, you’ve probably heard about the 'table format wars'—
      Iceberg and Delta Lake.
    char_start: 0
    char_end: 99
- statement: Iceberg is a table format for large analytic datasets that provides features
    like snapshot isolation and time travel.
  type: definition
  entity: Apache Iceberg
  keywords:
  - definition
  - iceberg
  - table
  - format
  - large
  - analytic
  - datasets
  - provides
  - features
  - like
  - snapshot
  - isolation
  - time
  - travel
  source:
    doc: motherduck.com/blog/motherduck-dbt-pipelines.md
    quote: Now that everyone seems to have stopped squabbling about whether to use
      Iceberg or Hudi.
    char_start: 0
    char_end: 88
- statement: Iceberg provides built-in time travel capabilities.
  type: definition
  entity: Apache Iceberg
  keywords:
  - definition
  - iceberg
  - provides
  - built
  - time
  - travel
  - capabilities
  source:
    doc: motherduck.com/blog/motherduck-union-orchestration.md
    quote: open table formats (Iceberg/Delta Lake) for their built-in time travel
      capabilities.
    char_start: 0
    char_end: 84
- statement: Iceberg support is still important in DuckDB and MotherDuck.
  type: definition
  entity: Apache Iceberg
  keywords:
  - definition
  - iceberg
  - support
  - still
  - important
  - duckdb
  - motherduck
  source:
    doc: motherduck.com/blog/duckdb-the-great-federator.md
    quote: But Iceberg support is still important in DuckDB and MotherDuck.
    char_start: 0
    char_end: 64
- statement: 'Iceberg, Delta Lake, and Hudi were all created with a unifying constraint:
    everything has to be stored in S3.'
  type: definition
  entity: Apache Iceberg
  keywords:
  - definition
  - iceberg
  - delta
  - lake
  - hudi
  - created
  - unifying
  - constraint
  - everything
  - stored
  - s3
  source:
    doc: motherduck.com/blog/effortless-etl-unstructured-data-unstructuredio-motherduck.md
    quote: 'The main data lakehouse formats, Iceberg, Delta Lake, and Hudi, were all
      created with a unifying constraint: everything has to be stored in S3.'
    char_start: 0
    char_end: 143
- statement: Open table formats provide database-like features on top of distributed
    files.
  type: definition
  entity: Apache Iceberg
  keywords:
  - definition
  - open
  - table
  - formats
  - provide
  - database
  - like
  - features
  - top
  - distributed
  - files
  source:
    doc: motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md
    quote: Data lakes with affordable storage and an open table format (Iceberg, Delta,
      Hudi, Lance) are here to provide database-like features on top of distributed
      files.
    char_start: 0
    char_end: 161
- statement: Technologies like Apache Iceberg are integral to modern Kappa architectures.
  type: definition
  entity: Apache Iceberg
  keywords:
  - definition
  - technologies
  - like
  - apache
  - iceberg
  - integral
  - modern
  - kappa
  - architectures
  source:
    doc: motherduck.com/case-studies/layers-multi-tenant-data-warehouse.md
    quote: Technologies like Apache Iceberg are also integral to modern Kappa architectures.
    char_start: 0
    char_end: 81
- statement: The latest prominent open-source table formats are Iceberg, Delta Lake,
    Hudi, Paimon, and Lance.
  type: definition
  entity: Apache Iceberg
  keywords:
  - definition
  - latest
  - prominent
  - open
  - source
  - table
  - formats
  - iceberg
  - delta
  - lake
  - hudi
  - paimon
  - lance
  source:
    doc: motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md
    quote: The latest prominent open-source table formats are Iceberg, Delta Lake,
      Hudi, Paimon, and Lance.
    char_start: 0
    char_end: 96
- statement: Writing, updating, and managing Iceberg tables allows for a fully interoperable
    data ecosystem.
  type: definition
  entity: Apache Iceberg
  keywords:
  - definition
  - writing
  - updating
  - managing
  - iceberg
  - tables
  - allows
  - fully
  - interoperable
  - data
  - ecosystem
  source:
    doc: motherduck.com/blog/how-to-extract-analytics-from-bluesky.md
    quote: That's where the real power of composable data platforms becomes fully
      apparent; by reading and materializing on top of Iceberg, we're getting closer
      to a fully interoperable data ecosystem.
    char_start: 0
    char_end: 190
- statement: Apache Kafka enables real-time data pipelines at scale.
  type: definition
  entity: Apache Kafka
  keywords:
  - definition
  - apache
  - kafka
  - enables
  - real
  - time
  - data
  - pipelines
  - scale
  source:
    doc: motherduck.com/blog/unstructured-analysis-tensorlake-motherduck.md
    quote: LinkedIn developed Apache Kafka to handle high-throughput message queuing,
      enabling real-time data pipelines at scale.
    char_start: 0
    char_end: 118
- statement: Apache Kafka serves as the central event bus.
  type: definition
  entity: Apache Kafka
  keywords:
  - definition
  - apache
  - kafka
  - serves
  - central
  - event
  - bus
  source:
    doc: motherduck.com/case-studies/layers-multi-tenant-data-warehouse.md
    quote: Apache Kafka serves as the central event bus.
    char_start: 0
    char_end: 45
- statement: Event-driven approaches or integrating your data as a stream is sometimes
    a must and business-critical.
  type: definition
  entity: Apache Kafka
  keywords:
  - definition
  - event
  - driven
  - approaches
  - integrating
  - data
  - stream
  - sometimes
  - business
  - critical
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part1.md
    quote: Event-driven approaches or integrating your data as a stream, end-to-end
      from source to your analytics, is sometimes a must and business-critical.
    char_start: 0
    char_end: 146
- statement: The Tributary DuckDB extension provides Apache Kafka integration.
  type: definition
  entity: Apache Kafka
  keywords:
  - definition
  - tributary
  - duckdb
  - extension
  - provides
  - apache
  - kafka
  - integration
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2024.md
    quote: The Tributary DuckDB extension provides Apache Kafka integration.
    char_start: 0
    char_end: 65
- statement: Apache ORC stands out with its columnar storage capabilities, optimized
    for high-performance data processing tasks.
  type: definition
  entity: Apache ORC
  keywords:
  - definition
  - apache
  - orc
  - stands
  - out
  - columnar
  - storage
  - capabilities
  - optimized
  - high
  - performance
  - data
  - processing
  - tasks
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Apache ORC stands out with its columnar storage capabilities, optimized
      for high-performance data processing tasks.
    char_start: 0
    char_end: 115
- statement: Apache Paimon is optimized for real-time lakehouse architecture.
  type: definition
  entity: Apache Paimon
  keywords:
  - definition
  - apache
  - paimon
  - optimized
  - real
  - time
  - lakehouse
  - architecture
  source:
    doc: motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md
    quote: Apache Paimon is emerging as a format specifically optimized for real-time
      lakehouse architecture.
    char_start: 0
    char_end: 98
- statement: Files are divided into row groups (e.g., 128 MB chunks), and the file
    footer contains min/max statistics for every column in each row group.
  type: definition
  entity: Apache Parquet
  keywords:
  - definition
  - files
  - divided
  - row
  - groups
  - '128'
  - mb
  - chunks
  - file
  - footer
  - contains
  - min
  - max
  - statistics
  - every
  - column
  - group
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: Files are divided into row groups (e.g., 128 MB chunks), and the file footer
      contains min/max statistics for every column in each row group.
    char_start: 0
    char_end: 140
- statement: Parquet files store rich metadata and statistics for each column chunk.
  type: definition
  entity: Apache Parquet
  keywords:
  - definition
  - parquet
  - files
  - store
  - rich
  - metadata
  - statistics
  - column
  - chunk
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part2.md
    quote: Parquet files also store rich metadata and statistics—min/max values, null
      counts—for each column chunk.
    char_start: 0
    char_end: 104
- statement: This can reduce storage footprints by up to 75% compared to raw formats.
  type: definition
  entity: Apache Parquet
  keywords:
  - definition
  - reduce
  - storage
  - footprints
  - up
  - '75'
  - compared
  - raw
  - formats
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: This can reduce storage footprints by up to 75% compared to raw formats.
    char_start: 0
    char_end: 72
- statement: Apache Spark can provide an ecosystem for data processing needs.
  type: definition
  entity: Apache Spark
  keywords:
  - definition
  - apache
  - spark
  - provide
  - ecosystem
  - data
  - processing
  - needs
  source:
    doc: motherduck.com/blog/spark-ducklake-getting-started.md
    quote: what if your data processing needs require ecosystem that only Apache Spark
      can provide?
    char_start: 0
    char_end: 88
- statement: Apache Spark is designed to work on a cluster.
  type: definition
  entity: Apache Spark
  keywords:
  - definition
  - apache
  - spark
  - designed
  - work
  - cluster
  source:
    doc: motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md
    quote: Apache Spark has been designed to work on a cluster.
    char_start: 0
    char_end: 52
- statement: Apache Spark provides a faster and more flexible alternative to MapReduce.
  type: definition
  entity: Apache Spark
  keywords:
  - definition
  - apache
  - spark
  - provides
  - faster
  - flexible
  - alternative
  - mapreduce
  source:
    doc: motherduck.com/blog/unstructured-analysis-tensorlake-motherduck.md
    quote: The introduction of Apache Spark from UC Berkeley marked another milestone,
      providing a faster and more flexible alternative to MapReduce that would eventually
      become the industry standard.
    char_start: 0
    char_end: 189
- statement: Apache Spark's reliance on the JVM leads to a cold start delay.
  type: definition
  entity: Apache Spark
  keywords:
  - definition
  - apache
  - spark
  - reliance
  - jvm
  - leads
  - cold
  - start
  - delay
  source:
    doc: motherduck.com/blog/local-duckdb-ui-visual-data-analysis.md
    quote: Apache Spark's reliance on the JVM leads to a cold start delay, usually
      under 5 seconds.
    char_start: 0
    char_end: 88
- statement: Apache Spark’s scale combined with DuckLake’s simplicity allows for building
    a lakehouse with ACID, time travel, and schema evolution.
  type: definition
  entity: Apache Spark
  keywords:
  - definition
  - apache
  - spark
  - scale
  - combined
  - ducklake
  - simplicity
  - allows
  - building
  - lakehouse
  - acid
  - time
  - travel
  - schema
  - evolution
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2024.md
    quote: Learn how to combine Apache Spark’s scale with DuckLake’s simplicity to
      build a lakehouse with ACID, time travel, and schema evolution
    char_start: 0
    char_end: 134
- statement: The integration of Apache Spark and DuckLake is showing promise for teams
    that want the best of both worlds.
  type: definition
  entity: Apache Spark
  keywords:
  - definition
  - integration
  - apache
  - spark
  - ducklake
  - showing
  - promise
  - teams
  - want
  - best
  - both
  - worlds
  source:
    doc: motherduck.com/blog/python-duckdb-vs-dataframe-libraries.md
    quote: While the marriage between Apache Spark and DuckLake is still in its honeymoon
      phase, it's already showing promise for teams that want the best of both worlds.
    char_start: 0
    char_end: 159
- statement: Apache Superset is an original open-source BI tool.
  type: definition
  entity: Apache Superset
  keywords:
  - definition
  - apache
  - superset
  - original
  - open
  - source
  - bi
  - tool
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: 'Apache Superset: Original open-source BI tool.'
    char_start: 0
    char_end: 46
- statement: Apache.log is a log file generated by the Apache web server.
  type: definition
  entity: Apache.log
  keywords:
  - definition
  - apache
  - log
  - file
  - generated
  - web
  - server
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2024.md
    quote: A log file generated by the Apache web server.
    char_start: 0
    char_end: 46
- statement: The SQL query extracts timestamp, error status, client IP, and message
    from the log.
  type: definition
  entity: Apache.log
  keywords:
  - definition
  - sql
  - query
  - extracts
  - timestamp
  - error
  - status
  - client
  - ip
  - message
  - log
  source:
    doc: motherduck.com/blog/flight-sql-vs-rest-vs-jdbc.md
    quote: SELECT regexp_extract(line, '\[(.*?)\]', 1) AS timestamp, ...
    char_start: 0
    char_end: 61
- statement: The top 10 client IP addresses with the highest error counts are retrieved
    from the apache_errors table.
  type: definition
  entity: apache_errors
  keywords:
  - definition
  - top
  - '10'
  - client
  - ip
  - addresses
  - highest
  - error
  - counts
  - retrieved
  - apache
  - errors
  - table
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: 'The result in a couple of seconds: ...'
    char_start: 0
    char_end: 38
- statement: Apartamentos el Coritu is one of the apartment complexes listed in the
    dataset.
  type: definition
  entity: Apartamentos el Coritu
  keywords:
  - definition
  - apartamentos
  - el
  - coritu
  - one
  - apartment
  - complexes
  - listed
  - dataset
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: │ 265109 │ POINT (-5.112427896960327 43.33982803064052)  │ Apartamentos
      el Coritu                        │
    char_start: 0
    char_end: 106
- statement: API Gateway Authentication is critical for validating user sessions before
    any query is run.
  type: definition
  entity: API Gateway Authentication
  keywords:
  - definition
  - api
  - gateway
  - authentication
  - critical
  - validating
  - user
  - sessions
  - any
  - query
  - run
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-use-cases.md
    quote: First, API Gateway Authentication is critical. Before any query is run,
      the backend must validate the user's session.
    char_start: 0
    char_end: 117
- statement: Application Logs track events within data processing applications.
  type: definition
  entity: Application Logs
  keywords:
  - definition
  - application
  - logs
  - track
  - events
  - within
  - data
  - processing
  - applications
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: 'Application Logs: Track events within data processing applications, ETL
      tools, and analytics platforms, capturing pipeline execution details, transformations,
      and failures.'
    char_start: 0
    char_end: 172
- statement: ArcGIS is a traditional GIS solution with limitations.
  type: definition
  entity: ArcGIS
  keywords:
  - definition
  - arcgis
  - traditional
  - gis
  - solution
  - limitations
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: In the past, you needed very expensive tools for doing GIS applications,
      tools like ArcGIS.
    char_start: 0
    char_end: 91
- statement: Traditional GIS tools like ArcGIS and QGIS add a high barrier to getting
    started.
  type: definition
  entity: ArcGIS
  keywords:
  - definition
  - traditional
  - gis
  - tools
  - like
  - arcgis
  - qgis
  - add
  - high
  - barrier
  - getting
  - started
  source:
    doc: motherduck.com/blog/read-scaling-preview.md
    quote: these tools obviously do much more, but it added a high barrier to getting
      started.
    char_start: 0
    char_end: 83
- statement: Archie Sarre Wood is Head of community at Evidence.
  type: definition
  entity: Archie Sarre Wood
  keywords:
  - definition
  - archie
  - sarre
  - wood
  - head
  - community
  - evidence
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md
    quote: Archie Sarre Wood is Head of community at Evidence.
    char_start: 0
    char_end: 51
- statement: arg_max() uses Radix sort, which leverages SQL group by to identify the
    groups in which to find the max.
  type: explanation
  entity: arg_max()
  keywords:
  - explanation
  - arg
  - max
  - uses
  - radix
  - sort
  - which
  - leverages
  - sql
  - group
  - identify
  - groups
  - find
  source:
    doc: motherduck.com/blog/faster-ducks.md
    quote: The short answer is that arg_max() uses Radix sort, which leverages SQL
      group by to identify the groups in which to find the max.
    char_start: 0
    char_end: 129
- statement: DuckDB specific querys like arg_min and arg_max are available.
  type: definition
  entity: arg_min and arg_max
  keywords:
  - definition
  - duckdb
  - specific
  - querys
  - like
  - arg
  - min
  - max
  - available
  source:
    doc: motherduck.com/blog/preswald-health-data-analysis.md
    quote: DuckDB specific querys like arg_min and arg_max
    char_start: 0
    char_end: 47
- statement: Argo Workflows is an open-source container-native workflow engine for
    Kubernetes.
  type: definition
  entity: Argo Workflows
  keywords:
  - definition
  - argo
  - workflows
  - open
  - source
  - container
  - native
  - workflow
  - engine
  - kubernetes
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: An open-source container-native workflow engine for Kubernetes.
    char_start: 0
    char_end: 63
- statement: array_agg() is used to turn a table column into a list.
  type: definition
  entity: array_agg
  keywords:
  - definition
  - array
  - agg
  - used
  - turn
  - table
  - column
  - list
  source:
    doc: motherduck.com/blog/motherduck-kestra-etl-pipelines.md
    quote: array_agg() which is used to turn a table column into a list.
    char_start: 0
    char_end: 61
- statement: Using Arrow results can be significantly faster, as they enable zero-copy
    interaction with DuckDB.
  type: definition
  entity: Arrow
  keywords:
  - definition
  - using
  - arrow
  - results
  - significantly
  - faster
  - enable
  - zero
  - copy
  - interaction
  - duckdb
  source:
    doc: motherduck.com/blog/bigquery-to-duckdb-motherduck.md
    quote: Using Arrow results can be significantly faster, as they enable zero-copy
      interaction with DuckDB.
    char_start: 0
    char_end: 98
- statement: Arrow Flight is the network protocol that makes Arrow feel like it's
    teleporting.
  type: definition
  entity: Arrow Flight
  keywords:
  - definition
  - arrow
  - flight
  - network
  - protocol
  - makes
  - feel
  - like
  - teleporting
  source:
    doc: motherduck.com/blog/duckdb-text2sql-llm.md
    quote: Arrow Flight is the network protocol that makes Arrow feel like it's teleporting.
    char_start: 0
    char_end: 81
- statement: Arrow Flight streams Arrow batches over gRPC like a data wizard slinging
    spells.
  type: definition
  entity: Arrow Flight
  keywords:
  - definition
  - arrow
  - flight
  - streams
  - batches
  - over
  - grpc
  - like
  - data
  - wizard
  - slinging
  - spells
  source:
    doc: motherduck.com/blog/six-reasons-duckdb-slaps.md
    quote: Flight streams Arrow batches over gRPC like a data wizard slinging spells.
    char_start: 0
    char_end: 74
- statement: Arrow Flight SQL is a framework for high-performance data transfer using
    Apache Arrow.
  type: definition
  entity: Arrow Flight SQL
  keywords:
  - definition
  - arrow
  - flight
  - sql
  - framework
  - high
  - performance
  - data
  - transfer
  - using
  - apache
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: Arrow Flight SQL is a framework for high-performance data transfer using
      Apache Arrow.
    char_start: 0
    char_end: 86
- statement: Artefact collaborates with MotherDuck in a webinar.
  type: definition
  entity: Artefact
  keywords:
  - definition
  - artefact
  - collaborates
  - motherduck
  - webinar
  source:
    doc: motherduck.com/videos.md
    quote: Watch this webinar with MotherDuck and Artefact.
    char_start: 0
    char_end: 48
- statement: Artie automates the entire ingestion lifecycle with zero engineering
    maintenance.
  type: definition
  entity: Artie
  keywords:
  - definition
  - artie
  - automates
  - entire
  - ingestion
  - lifecycle
  - zero
  - engineering
  - maintenance
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: Artie automates the entire ingestion lifecycle — change capture, merges,
      backfills, and observability — with zero engineering maintenance and deploys
      in minutes.
    char_start: 0
    char_end: 161
- statement: Companies like Substack, ClickUp, and Alloy use Artie to solve pipeline
    issues.
  type: definition
  entity: Artie
  keywords:
  - definition
  - companies
  - like
  - substack
  - clickup
  - alloy
  - use
  - artie
  - solve
  - pipeline
  - issues
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: Leaders like Substack, ClickUp, and Alloy use Artie not just to solve today's
      pipeline issues, but to future-proof their data stack as their AI strategy accelerates.
    char_start: 0
    char_end: 165
- statement: AI can be used to automate data cleaning, enhance data quality, or provide
    insights through natural language processing.
  type: definition
  entity: Artificial Intelligence
  keywords:
  - definition
  - ai
  - used
  - automate
  - data
  - cleaning
  - enhance
  - quality
  - provide
  - insights
  - natural
  - language
  - processing
  source:
    doc: motherduck.com/case-studies/dosomething-non-profit-tco-cost-savings.md
    quote: In the context of data pipelines, AI can be used to automate data cleaning,
      enhance data quality, or provide insights through natural language processing.
    char_start: 0
    char_end: 154
- statement: An AI-equipped platform can translate plain English questions into SQL.
  type: definition
  entity: Artificial Intelligence
  keywords:
  - definition
  - ai
  - equipped
  - platform
  - translate
  - plain
  - english
  - questions
  - sql
  source:
    doc: motherduck.com/videos/from-curiosity-to-impact-how-dosomething-democratized-data.md
    quote: An AI-equipped platform can translate plain English questions into SQL.
    char_start: 0
    char_end: 71
- statement: Artificial Intelligence refers to computer systems designed to perform
    tasks that typically require human intelligence.
  type: definition
  entity: Artificial Intelligence
  keywords:
  - definition
  - artificial
  - intelligence
  - refers
  - computer
  - systems
  - designed
  - perform
  - tasks
  - typically
  - require
  - human
  source:
    doc: motherduck.com/case-studies/dosomething-non-profit-tco-cost-savings.md
    quote: Artificial Intelligence (AI) refers to computer systems designed to perform
      tasks that typically require human intelligence.
    char_start: 0
    char_end: 124
- statement: Using AI can enhance the experience of using keyboard shortcuts.
  type: definition
  entity: Artificial Intelligence
  keywords:
  - definition
  - using
  - ai
  - enhance
  - experience
  - keyboard
  - shortcuts
  source:
    doc: motherduck.com/blog.md
    quote: Learn to run queries, comment, format, and even use AI without leaving
      your keyboard.
    char_start: 0
    char_end: 85
- statement: Ascend is participating in the hands-on lab event.
  type: definition
  entity: Ascend
  keywords:
  - definition
  - ascend
  - participating
  - hands
  - lab
  - event
  source:
    doc: motherduck.com/learn-more/fix-slow-bi-dashboards.md
    quote: 'Hands-on Lab: Agentic Data Engineering with MotherDuck and Ascend'
    char_start: 0
    char_end: 65
- statement: Ascend provides data engineering solutions.
  type: definition
  entity: Ascend
  keywords:
  - definition
  - ascend
  - provides
  - data
  - engineering
  - solutions
  source:
    doc: motherduck.com/videos/simple-way-to-convert-csv-and-parquet-files.md
    quote: Ascend
    char_start: 0
    char_end: 6
- statement: Ascend.io integrates with MotherDuck by enabling seamless data pipeline
    automation.
  type: definition
  entity: Ascend.io
  keywords:
  - definition
  - ascend
  - io
  - integrates
  - motherduck
  - enabling
  - seamless
  - data
  - pipeline
  - automation
  source:
    doc: motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md
    quote: Ascend.io integrates with MotherDuck by enabling seamless data pipeline
      automation.
    char_start: 0
    char_end: 83
- statement: The ord function returns the ASCII character code for the character passed
    in.
  type: definition
  entity: ASCII
  keywords:
  - definition
  - ord
  - function
  - returns
  - ascii
  - character
  - code
  - passed
  source:
    doc: motherduck.com/blog/pushing-geo-boundaries-with-motherduck-geobase.md
    quote: The ord function returns the ASCII character code for the character passed
      in.
    char_start: 0
    char_end: 78
- statement: Astrodata, MotherDuck, and Cube’s combined data stack can build embedded
    analytics.
  type: definition
  entity: Astrodata
  keywords:
  - definition
  - astrodata
  - motherduck
  - cube
  - combined
  - data
  - stack
  - build
  - embedded
  - analytics
  source:
    doc: motherduck.com/quacking-around-the-web.md
    quote: Explore how to use Astrodata, MotherDuck, and Cube’s combined data stack
      to build embedded analytics.
    char_start: 0
    char_end: 101
- statement: Astronomer is a platform for building and managing data workflows with
    Apache Airflow.
  type: definition
  entity: Astronomer
  keywords:
  - definition
  - astronomer
  - platform
  - building
  - managing
  - data
  - workflows
  - apache
  - airflow
  source:
    doc: motherduck.com/blog/data-engineer-highlights-PyConDE-2023.md
    quote: Astronomer is a platform for building and managing data workflows with
      Apache Airflow.
    char_start: 0
    char_end: 86
- statement: The AT Protocol allows streaming of posts.
  type: definition
  entity: AT Protocol
  keywords:
  - definition
  - protocol
  - allows
  - streaming
  - posts
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: 'It will stream everything and looks like this:'
    char_start: 0
    char_end: 46
- statement: The AT Protocol is used for decentralized social networking.
  type: definition
  entity: AT Protocol
  keywords:
  - definition
  - protocol
  - used
  - decentralized
  - social
  - networking
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: Using Python for interacting with the AT Protocol
    char_start: 0
    char_end: 49
- statement: The Python SDK is used to interact with the AT Protocol.
  type: definition
  entity: AT Protocol
  keywords:
  - definition
  - python
  - sdk
  - used
  - interact
  - protocol
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: The Python SDK is used to interact with the AT Protocol.
    char_start: 0
    char_end: 56
- statement: ATM.com cuts analytics costs by 65% while gaining SQL expressibility.
  type: definition
  entity: ATM.com
  keywords:
  - definition
  - atm
  - com
  - cuts
  - analytics
  - costs
  - '65'
  - gaining
  - sql
  - expressibility
  source:
    doc: motherduck.com/case-studies/layers-multi-tenant-data-warehouse.md
    quote: Even with a few big backfills, we're still looking at costs that are 35
      to 40% of what we're paying with SingleStore.
    char_start: 0
    char_end: 117
- statement: ATM.com has evolved from its initial focus on data monetization to become
    a comprehensive financial platform.
  type: definition
  entity: ATM.com
  keywords:
  - definition
  - atm
  - com
  - evolved
  - initial
  - focus
  - data
  - monetization
  - become
  - comprehensive
  - financial
  - platform
  source:
    doc: motherduck.com/case-studies/layers-multi-tenant-data-warehouse.md
    quote: Founded in 2019, the Irvine-based fintech has evolved from its initial
      focus on data monetization to become a comprehensive financial platform serving
      millions of users with microtransactions daily.
    char_start: 0
    char_end: 198
- statement: ATM.com is migrating to a new data infrastructure.
  type: definition
  entity: ATM.com
  keywords:
  - definition
  - atm
  - com
  - migrating
  - new
  - data
  - infrastructure
  source:
    doc: motherduck.com/learn-more/big-data.md
    quote: As ATM.com completes their migration...
    char_start: 0
    char_end: 39
- statement: ATM.com uses SQLMesh for transformations.
  type: definition
  entity: ATM.com
  keywords:
  - definition
  - atm
  - com
  - uses
  - sqlmesh
  - transformations
  source:
    doc: motherduck.com/learn-more/big-data.md
    quote: The team uses SQLMesh for transformations...
    char_start: 0
    char_end: 44
- statement: Costs already down 65% and performance dramatically improved.
  type: definition
  entity: ATM.com
  keywords:
  - definition
  - costs
  - already
  - down
  - '65'
  - performance
  - dramatically
  - improved
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: 'With costs already down 65% and performance dramatically improved, the
      team can focus on what matters: building better financial products for their
      users.'
    char_start: 0
    char_end: 154
- statement: Even with a few big backfills, we're still looking at costs that are
    35 to 40% of what we're paying with SingleStore.
  type: definition
  entity: ATM.com
  keywords:
  - definition
  - even
  - big
  - backfills
  - re
  - still
  - looking
  - costs
  - '35'
  - '40'
  - what
  - paying
  - singlestore
  source:
    doc: motherduck.com/learn-more/data-application-architecture.md
    quote: Even with a few big backfills, we're still looking at costs that are 35
      to 40% of what we're paying with SingleStore.
    char_start: 0
    char_end: 117
- statement: The migration to MotherDuck is happening incrementally, using Sling for
    data movement from RDS Postgres.
  type: definition
  entity: ATM.com
  keywords:
  - definition
  - migration
  - motherduck
  - happening
  - incrementally
  - using
  - sling
  - data
  - movement
  - rds
  - postgres
  source:
    doc: motherduck.com/learn-more/data-application-architecture.md
    quote: The migration to MotherDuck is happening incrementally, using Sling for
      data movement from RDS Postgres.
    char_start: 0
    char_end: 104
- statement: The performance improvements extend beyond cost savings.
  type: definition
  entity: ATM.com
  keywords:
  - definition
  - performance
  - improvements
  - extend
  - beyond
  - cost
  - savings
  source:
    doc: motherduck.com/learn-more/data-application-architecture.md
    quote: The performance improvements extend beyond cost savings.
    char_start: 0
    char_end: 56
- statement: Atomicity ensures that a transaction is treated as a single, indivisible
    unit.
  type: definition
  entity: Atomicity
  keywords:
  - definition
  - atomicity
  - ensures
  - transaction
  - treated
  - single
  - indivisible
  - unit
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part1.md
    quote: Atomicity ensures that a transaction is treated as a single, indivisible
      unit.
    char_start: 0
    char_end: 78
- statement: If any part fails due to errors or crashes, the entire transaction rolls
    back.
  type: definition
  entity: Atomicity
  keywords:
  - definition
  - any
  - part
  - fails
  - due
  - errors
  - crashes
  - entire
  - transaction
  - rolls
  - back
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part1.md
    quote: If any part fails due to errors or crashes, the entire transaction rolls
      back.
    char_start: 0
    char_end: 78
- statement: 'Two alternative UIs are already built on top of ATProto: Frontpage and
    Smoke Signal.'
  type: definition
  entity: ATProto
  keywords:
  - definition
  - two
  - alternative
  - uis
  - already
  - built
  - top
  - atproto
  - frontpage
  - smoke
  - signal
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: 'Two alternative UIs are already built on top of ATProto: Frontpage, an
      alternative Hackernews, and Smoke Signal, an RSVP management app.'
    char_start: 0
    char_end: 136
- statement: Audit Logs document changes to data schemas.
  type: definition
  entity: Audit Logs
  keywords:
  - definition
  - audit
  - logs
  - document
  - changes
  - data
  - schemas
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: 'Audit Logs: Document changes to data schemas, permissions, and configurations.'
    char_start: 0
    char_end: 78
- statement: Augmented Analytics makes advanced analytics accessible to a broader
    audience.
  type: definition
  entity: Augmented Analytics
  keywords:
  - definition
  - augmented
  - analytics
  - makes
  - advanced
  - accessible
  - broader
  - audience
  source:
    doc: motherduck.com/learn-more/data-application.md
    quote: Incorporating AI and machine learning to automate data preparation and
      insight discovery, making advanced analytics accessible to a broader audience.
    char_start: 0
    char_end: 149
- statement: Auto inference applies to more complex data structures, such as nested
    JSON objects.
  type: definition
  entity: auto inference
  keywords:
  - definition
  - auto
  - inference
  - applies
  - complex
  - data
  - structures
  - nested
  - json
  - objects
  source:
    doc: motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md
    quote: Auto inference also applies to more complex data structures, such as nested
      JSON objects.
    char_start: 0
    char_end: 89
- statement: Auto Update allows database shares to automatically sync with the latest
    changes within five minutes.
  type: definition
  entity: Auto Update
  keywords:
  - definition
  - auto
  - update
  - allows
  - database
  - shares
  - automatically
  - sync
  - latest
  - changes
  - within
  - five
  - minutes
  source:
    doc: motherduck.com/blog/data-warehouse-feature-roundup-oct-2024.md
    quote: With the introduction of Auto Update, you can now set your database shares
      to automatically sync with the latest changes—both DDL and DML—within five minutes
      of any completed writes.
    char_start: 0
    char_end: 182
- statement: Setting the AUTO_SUSPEND parameter can help reduce costs significantly.
  type: definition
  entity: AUTO_SUSPEND
  keywords:
  - definition
  - setting
  - auto
  - suspend
  - parameter
  - help
  - reduce
  - costs
  - significantly
  source:
    doc: motherduck.com/learn-more/product-analytics-motherduck-duckdb.md
    quote: Set aggressive yet intelligent warehouse timeouts. For most workloads,
      set the AUTO_SUSPEND parameter.
    char_start: 0
    char_end: 102
- statement: AutoCAD has been brought to the web using WebAssembly.
  type: definition
  entity: AutoCAD
  keywords:
  - definition
  - autocad
  - brought
  - web
  - using
  - webassembly
  source:
    doc: motherduck.com/learn-more/pandas-dataframes-guide.md
    quote: Autodesk brought their massive CAD application to the web using Wasm.
    char_start: 0
    char_end: 69
- statement: Automated maintenance operations layer captures essential automated processes.
  type: definition
  entity: automated maintenance operations layer
  keywords:
  - definition
  - automated
  - maintenance
  - operations
  - layer
  - captures
  - essential
  - processes
  source:
    doc: motherduck.com/blog/how-to-extract-analytics-from-bluesky.md
    quote: which captures automated processes like compaction, snapshot management,
      and unreferenced file removal that are essential for operational efficiency.
    char_start: 0
    char_end: 149
- statement: Avenida de los Picos de Europa is a location mentioned in the dataset.
  type: definition
  entity: Avenida de los Picos de Europa
  keywords:
  - definition
  - avenida
  - de
  - los
  - picos
  - europa
  - location
  - mentioned
  - dataset
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: │ 117706 │ POINT (-5.12532666805556 43.35258395)         │ Avenida de los
      Picos de Europa                │
    char_start: 0
    char_end: 106
- statement: Avro is a row-oriented remote procedure call and data serialization framework.
  type: definition
  entity: Avro
  keywords:
  - definition
  - avro
  - row
  - oriented
  - remote
  - procedure
  - call
  - data
  - serialization
  - framework
  source:
    doc: motherduck.com/blog/estuary-streaming-cdc-replication.md
    quote: To understand table formats, we need to start with file formats like Parquet
      and Avro.
    char_start: 0
    char_end: 86
- statement: A standard instance on AWS uses a physical server with 64 cores and 256
    GB of RAM.
  type: definition
  entity: AWS
  keywords:
  - definition
  - standard
  - instance
  - aws
  - uses
  - physical
  - server
  - '64'
  - cores
  - '256'
  - gb
  - ram
  source:
    doc: motherduck.com/blog/dosomething-motherduck-data-warehouse-ROI.md
    quote: Today, however, a standard instance on AWS uses a physical server with
      64 cores and 256 GB of RAM.
    char_start: 0
    char_end: 98
- statement: Amazon Web Services provides on-demand cloud computing platforms.
  type: definition
  entity: AWS
  keywords:
  - definition
  - amazon
  - web
  - services
  - provides
  - demand
  - cloud
  - computing
  - platforms
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-seven.md
    quote: Amazon Web Services, a subsidiary of Amazon providing on-demand cloud computing
      platforms.
    char_start: 0
    char_end: 90
- statement: AWS and Cloudflare are providing managed Iceberg services.
  type: definition
  entity: AWS
  keywords:
  - definition
  - aws
  - cloudflare
  - providing
  - managed
  - iceberg
  - services
  source:
    doc: motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md
    quote: the addition of managed Iceberg services by AWS, Cloudflare, and other
      hyperscalers.
    char_start: 0
    char_end: 84
- statement: AWS and Google Cloud can be used with DuckDB for managing secrets.
  type: definition
  entity: AWS
  keywords:
  - definition
  - aws
  - google
  - cloud
  - used
  - duckdb
  - managing
  - secrets
  source:
    doc: motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md
    quote: it also works with private buckets, requiring the reader to have the correct
      IAM role to access them.
    char_start: 0
    char_end: 101
- statement: AWS will respawn your workload in a new machine if your server crashes.
  type: definition
  entity: AWS
  keywords:
  - definition
  - aws
  - respawn
  - workload
  - new
  - machine
  - server
  - crashes
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: If your server crashes, AWS will respawn your workload in a new machine.
    char_start: 0
    char_end: 72
- statement: Many workloads do not require the extensive resources of distributed
    systems.
  type: definition
  entity: AWS
  keywords:
  - definition
  - many
  - workloads
  - require
  - extensive
  - resources
  - distributed
  - systems
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: If you don’t have 'Big Data,' then you almost certainly don’t need scale-out
      architectures.
    char_start: 0
    char_end: 91
- statement: Understanding major cloud platforms can enhance employability.
  type: definition
  entity: AWS
  keywords:
  - definition
  - understanding
  - major
  - cloud
  - platforms
  - enhance
  - employability
  source:
    doc: motherduck.com/blog/streaming-oracle-to-motherduck.md
    quote: Getting to know major cloud platform providers can save you a significant
      amount of time and enhance your employability.
    char_start: 0
    char_end: 120
- statement: Container-as-a-Service platforms offer a middle ground.
  type: definition
  entity: AWS Fargate
  keywords:
  - definition
  - container
  - service
  - platforms
  - offer
  - middle
  - ground
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: Container-as-a-Service (CaaS) platforms, such as Google Cloud Run, AWS
      Fargate, or Azure Container Instances, offer a middle ground.
    char_start: 0
    char_end: 132
- statement: AWS Glue authorizes a minimum configuration of 2 DPUs.
  type: definition
  entity: AWS Glue
  keywords:
  - definition
  - aws
  - glue
  - authorizes
  - minimum
  - configuration
  - dpus
  source:
    doc: motherduck.com/blog/local-duckdb-ui-visual-data-analysis.md
    quote: AWS Glue authorize a minimum configuration of 2 DPUs.
    char_start: 0
    char_end: 53
- statement: Managed REST catalogs provide a central endpoint to manage table state
    and handle concurrent writes.
  type: definition
  entity: AWS Glue Catalog
  keywords:
  - definition
  - managed
  - rest
  - catalogs
  - provide
  - central
  - endpoint
  - manage
  - table
  - state
  - handle
  - concurrent
  - writes
  source:
    doc: motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse.md
    quote: They provide a central endpoint to manage table state and handle concurrent
      writes.
    char_start: 0
    char_end: 83
- statement: AWS Kinesis is a platform on AWS to collect, process, and analyze real-time,
    streaming data.
  type: definition
  entity: AWS Kinesis
  keywords:
  - definition
  - aws
  - kinesis
  - platform
  - collect
  - process
  - analyze
  - real
  - time
  - streaming
  - data
  source:
    doc: motherduck.com/blog/vibe-coding-sql-cursor.md
    quote: A platform on AWS to collect, process, and analyze real-time, streaming
      data.
    char_start: 0
    char_end: 77
- statement: Serverless and Managed Services represent the highest abstraction level.
  type: definition
  entity: AWS Lambda
  keywords:
  - definition
  - serverless
  - managed
  - services
  - represent
  - highest
  - abstraction
  - level
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: Serverless and Managed Services represent the highest abstraction level,
      where you focus purely on your data logic while the platform handles infrastructure
      concerns.
    char_start: 0
    char_end: 166
- statement: Amazon EC2 can be used to generate large datasets efficiently.
  type: definition
  entity: AWS S3
  keywords:
  - definition
  - amazon
  - ec2
  - used
  - generate
  - large
  - datasets
  - efficiently
  source:
    doc: motherduck.com/blog/python-faker-duckdb-exploration.md
    quote: I used the GNU Parallel technique discussed above with a hefty m6i.32xlarge
      instance on Amazon EC2.
    char_start: 0
    char_end: 99
- statement: AWS RDS supports logical replication with specific output plugins.
  type: definition
  entity: AWS S3
  keywords:
  - definition
  - aws
  - rds
  - supports
  - logical
  - replication
  - specific
  - output
  - plugins
  source:
    doc: motherduck.com/blog/motherduck-union-orchestration.md
    quote: AWS RDS supports logical replication with specific output plugins.
    char_start: 0
    char_end: 66
- statement: Azure Data Warehouse was the fastest by far, followed by Redshift.
  type: performance
  entity: Azure Data Warehouse
  keywords:
  - performance
  - azure
  - data
  - warehouse
  - fastest
  - far
  - followed
  - redshift
  source:
    doc: motherduck.com/blog/duckdb-enterprise-5-key-categories.md
    quote: In 2019 GigaOm released a benchmark comparing cloud data warehouses. They
      ran both TPC-H and TPC-DS across the three major cloud vendors plus Snowflake.
      The results? Azure Data Warehouse was the faste
    char_start: 0
    char_end: 232
- statement: Microsoft presented its proactive resource allocation strategies for
    millions of serverless Azure SQL databases.
  type: definition
  entity: Azure SQL databases
  keywords:
  - definition
  - microsoft
  - presented
  - proactive
  - resource
  - allocation
  - strategies
  - millions
  - serverless
  - azure
  - sql
  - databases
  source:
    doc: motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md
    quote: Microsoft presented its proactive resource allocation strategies for millions
      of serverless Azure SQL databases.
    char_start: 0
    char_end: 112
- statement: The BAAI/bge-small-en-v1.5 model generates a vector embedding of 384
    dimensions with a maximum input tokens limit of 512.
  type: definition
  entity: BAAI/bge-small-en-v1.5
  keywords:
  - definition
  - baai
  - bge
  - small
  - en
  - v1.5
  - model
  - generates
  - vector
  - embedding
  - '384'
  - dimensions
  - maximum
  - input
  - tokens
  - limit
  - '512'
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-one.md
    quote: This means that the maximum chunk size of the text will be 512 tokens.
    char_start: 0
    char_end: 70
- statement: The model generates vector embeddings of dimension size 384.
  type: definition
  entity: BAAI/bge-small-en-v1.5
  keywords:
  - definition
  - model
  - generates
  - vector
  - embeddings
  - dimension
  - size
  - '384'
  source:
    doc: motherduck.com/blog/flight-sql-vs-rest-vs-jdbc.md
    quote: When we print the length of the generated embeddings, we get 384, the dimension
      size of the vector for this model that we mentioned above.
    char_start: 0
    char_end: 138
- statement: Bacalhau allows distributed queries to run on every machine.
  type: definition
  entity: Bacalhau
  keywords:
  - definition
  - bacalhau
  - allows
  - distributed
  - queries
  - run
  - every
  - machine
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-four.md
    quote: And just like that, the distributed query runs on every machine, with the
      results seamlessly integrating into MotherDuck.
    char_start: 0
    char_end: 121
- statement: Bacalhau dispatches queries to relevant machines.
  type: definition
  entity: Bacalhau
  keywords:
  - definition
  - bacalhau
  - dispatches
  - queries
  - relevant
  - machines
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-four.md
    quote: Bacalhau, a distributed compute platform, directly meets this need by dispatching
      your queries to the relevant machines.
    char_start: 0
    char_end: 120
- statement: Bacalhau enables executing remote queries directly on existing data.
  type: definition
  entity: Bacalhau
  keywords:
  - definition
  - bacalhau
  - enables
  - executing
  - remote
  - queries
  - directly
  - existing
  - data
  source:
    doc: motherduck.com/blog/motherduck-window-functions-in-sql.md
    quote: Bacalhau enables you to execute remote queries directly on your existing
      data.
    char_start: 0
    char_end: 78
- statement: Bacalhau is a platform for running data processing jobs in a distributed
    manner.
  type: definition
  entity: Bacalhau
  keywords:
  - definition
  - bacalhau
  - platform
  - running
  - data
  - processing
  - jobs
  - distributed
  - manner
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-four.md
    quote: aggregate your DuckDB logs with MotherDuck and Bacalhau
    char_start: 0
    char_end: 55
- statement: Bacalhau is great for running containers.
  type: definition
  entity: Bacalhau
  keywords:
  - definition
  - bacalhau
  - great
  - running
  - containers
  source:
    doc: motherduck.com/blog/log-processing-savings-bacalhau-motherduck.md
    quote: In our example, we're using Bacalhau, which is great for running containers.
    char_start: 0
    char_end: 76
- statement: We saved 95% on log processing costs by using Bacalhau and MotherDuck.
  type: definition
  entity: Bacalhau
  keywords:
  - definition
  - saved
  - '95'
  - log
  - processing
  - costs
  - using
  - bacalhau
  - motherduck
  source:
    doc: motherduck.com/blog/duckdb-wasm-in-browser.md
    quote: We stopped sifting our log data and started generating speedy logging insights
      to realize 95% in cost savings by pre-processing logs with Bacalhau and MotherDuck.
    char_start: 0
    char_end: 162
- statement: Users can earn badges for their contributions.
  type: definition
  entity: Badges
  keywords:
  - definition
  - users
  - earn
  - badges
  - contributions
  source:
    doc: motherduck.com/blog/pg-duckdb-release.md
    quote: There are also Badges with class columns that users can earn for their
      contributions.
    char_start: 0
    char_end: 85
- statement: Bamboo is Atlassian's CI/CD tool with tight integration to Jira and Bitbucket
    for teams already using the Atlassian ecosystem.
  type: definition
  entity: Bamboo
  keywords:
  - definition
  - bamboo
  - atlassian
  - ci
  - cd
  - tool
  - tight
  - integration
  - jira
  - bitbucket
  - teams
  - already
  - using
  - ecosystem
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: Atlassian's CI/CD tool with tight integration to Jira and Bitbucket for
      teams already using the Atlassian ecosystem
    char_start: 0
    char_end: 115
- statement: Bash scripting is essential for working in a Linux environment.
  type: definition
  entity: Bash
  keywords:
  - definition
  - bash
  - scripting
  - essential
  - working
  - linux
  - environment
  source:
    doc: motherduck.com/learn-more/bigquery-alternative-motherduck.md
    quote: Bash scripting essentials, starting with the basics of bash scripting,
      including variables, commands, inputs/outputs, and debugging.
    char_start: 0
    char_end: 132
- statement: Bauplan is an AI-focused and closed-source option in the data architecture
    landscape.
  type: definition
  entity: Bauplan
  keywords:
  - definition
  - bauplan
  - ai
  - focused
  - closed
  - source
  - option
  - data
  - architecture
  - landscape
  source:
    doc: motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md
    quote: Another, more AI-focused and closed-source option to keep an eye on is
      Bauplan.
    char_start: 0
    char_end: 79
- statement: Creating a study plan helps track preparation progress.
  type: definition
  entity: Ben (Topic)
  keywords:
  - definition
  - creating
  - study
  - plan
  - helps
  - track
  - preparation
  - progress
  source:
    doc: motherduck.com/blog/big-data-is-dead.md
    quote: Step zero is to create a study plan.
    char_start: 0
    char_end: 36
- statement: Benn Stancil is a thought leader in modern data practices.
  type: definition
  entity: Benn Stancil
  keywords:
  - definition
  - benn
  - stancil
  - thought
  - leader
  - modern
  - data
  - practices
  source:
    doc: motherduck.com/blog/announcing-series-seed-and-a.md
    quote: A thought leader in modern data practices, Benn has been vocal about rethinking
      how we approach data infrastructure.
    char_start: 0
    char_end: 116
- statement: Benn Stancil is the co-founder and CTO at Mode.
  type: definition
  entity: Benn Stancil
  keywords:
  - definition
  - benn
  - stancil
  - co
  - founder
  - cto
  - mode
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2024.md
    quote: Benn Stancil, co-founder and CTO at Mode
    char_start: 0
    char_end: 40
- statement: Interpretation of data is often a lot harder than exploration.
  type: definition
  entity: Benn Stancil
  keywords:
  - definition
  - interpretation
  - data
  - often
  - lot
  - harder
  - exploration
  source:
    doc: motherduck.com/videos/duckdb-tutorial-for-beginners.md
    quote: '"interpretation of data is often a lot harder than exploration."'
    char_start: 0
    char_end: 64
- statement: Bern is last in this measurement.
  type: definition
  entity: Bern
  keywords:
  - definition
  - bern
  - last
  - measurement
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Unfortunately, my favorite city, Bern, is last in this measurement 🙂.
    char_start: 0
    char_end: 69
- statement: BI-as-Code integrates Business Intelligence processes with code-based
    tools.
  type: definition
  entity: BI-as-Code
  keywords:
  - definition
  - bi
  - code
  - integrates
  - business
  - intelligence
  - processes
  - based
  - tools
  source:
    doc: motherduck.com/blog/duckdb-versus-pandas-versus-polars.md
    quote: A methodology that integrates Business Intelligence processes with code-based
      tools.
    char_start: 0
    char_end: 84
- statement: The query selects clusters of shops within a 2km radius of Biel, Switzerland.
  type: definition
  entity: Biel, Switzerland
  keywords:
  - definition
  - query
  - selects
  - clusters
  - shops
  - within
  - 2km
  - radius
  - biel
  - switzerland
  source:
    doc: motherduck.com/blog/pg_duckdb-postgresql-extension-for-duckdb-motherduck.md
    quote: The below query selects clusters of shops within a 2km radius of Biel,
      Switzerland...
    char_start: 0
    char_end: 85
- statement: 95% of databases don’t qualify as Big Data.
  type: definition
  entity: Big Data
  keywords:
  - definition
  - '95'
  - databases
  - don
  - qualify
  - big
  - data
  source:
    doc: motherduck.com/blog/python-faker-duckdb-exploration.md
    quote: 95% of databases don’t qualify as Big Data and 99.98% of user...
    char_start: 0
    char_end: 64
- statement: 'Big Data is often defined by the ''three Vs'': Volume, Velocity, and
    Variety.'
  type: definition
  entity: Big Data
  keywords:
  - definition
  - big
  - data
  - often
  - defined
  - three
  - vs
  - volume
  - velocity
  - variety
  source:
    doc: motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md
    quote: 'It is often defined by the ''three Vs'': Volume, Velocity, and Variety.'
    char_start: 0
    char_end: 69
- statement: Big data refers to extremely large and complex datasets that traditional
    data processing systems cannot handle efficiently.
  type: definition
  entity: Big Data
  keywords:
  - definition
  - big
  - data
  - refers
  - extremely
  - large
  - complex
  - datasets
  - traditional
  - processing
  - systems
  - cannot
  - handle
  - efficiently
  source:
    doc: motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md
    quote: Big data refers to extremely large and complex datasets that traditional
      data processing systems cannot handle efficiently.
    char_start: 0
    char_end: 123
- statement: Big data systems are often overengineered to meet the needs of most businesses.
  type: definition
  entity: Big Data
  keywords:
  - definition
  - big
  - data
  - systems
  - often
  - overengineered
  - meet
  - needs
  - businesses
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-2.md
    quote: the inefficiencies of big data infrastructure that have sparked a shift
      toward more cost-efficient solutions.
    char_start: 0
    char_end: 109
- statement: Big Data was everywhere over the last decade.
  type: definition
  entity: Big Data
  keywords:
  - definition
  - big
  - data
  - everywhere
  - over
  - last
  - decade
  source:
    doc: motherduck.com/videos.md
    quote: Over the last decade, Big Data was everywhere.
    char_start: 0
    char_end: 46
- statement: Data size wasn’t really the problem at all.
  type: definition
  entity: Big Data
  keywords:
  - definition
  - data
  - size
  - wasn
  - really
  - problem
  source:
    doc: motherduck.com/blog/announcing-small-data-sf-2025.md
    quote: they still were having trouble making sense of their data. They also may
      have noticed, if they were really paying attention, that data size wasn’t really
      the problem at all.
    char_start: 0
    char_end: 173
- statement: Most applications do not need to process massive amounts of data.
  type: definition
  entity: Big Data
  keywords:
  - definition
  - applications
  - need
  - process
  - massive
  - amounts
  - data
  source:
    doc: motherduck.com/blog/announcing-small-data-sf-2025.md
    quote: Most applications do not need to process massive amounts of data.
    char_start: 0
    char_end: 65
- statement: Organizations use big data to gain insights, make data-driven decisions,
    and drive innovation.
  type: definition
  entity: Big Data
  keywords:
  - definition
  - organizations
  - use
  - big
  - data
  - gain
  - insights
  - make
  - driven
  - decisions
  - drive
  - innovation
  source:
    doc: motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md
    quote: Organizations use big data to gain insights, make data-driven decisions,
      and drive innovation.
    char_start: 0
    char_end: 94
- statement: The acceleration of data generation was going to leave the data systems
    of yesteryear stuck in the mud.
  type: definition
  entity: Big Data
  keywords:
  - definition
  - acceleration
  - data
  - generation
  - going
  - leave
  - systems
  - yesteryear
  - stuck
  - mud
  source:
    doc: motherduck.com/blog/announcing-small-data-sf-2025.md
    quote: The acceleration of data generation was going to leave the data systems
      of yesteryear stuck in the mud.
    char_start: 0
    char_end: 103
- statement: The amount of data queried when big data tables are queried is significant.
  type: definition
  entity: Big Data
  keywords:
  - definition
  - amount
  - data
  - queried
  - big
  - tables
  - significant
  source:
    doc: motherduck.com/blog/python-faker-duckdb-exploration.md
    quote: Now, assuming we are querying huge tables, how much data do we actually
      read?
    char_start: 0
    char_end: 77
- statement: The cost of keeping data around is less than the cost of figuring out
    what to throw away.
  type: definition
  entity: Big Data
  keywords:
  - definition
  - cost
  - keeping
  - data
  - around
  - less
  - figuring
  - out
  - what
  - throw
  - away
  source:
    doc: motherduck.com/blog/dosomething-motherduck-data-warehouse-ROI.md
    quote: An alternate definition of Big Data is 'when the cost of keeping data around
      is less than the cost of figuring out what to throw away.'
    char_start: 0
    char_end: 135
- statement: The median and 90th percentile of usage are computed for big data queries.
  type: definition
  entity: Big Data
  keywords:
  - definition
  - median
  - 90th
  - percentile
  - usage
  - computed
  - big
  - data
  - queries
  source:
    doc: motherduck.com/blog/python-faker-duckdb-exploration.md
    quote: We compute for each scan size bucket the percentages of queries that are
      within that bucket...
    char_start: 0
    char_end: 94
- statement: The term 'big data' emerged in the mid-1990s as organizations began grappling
    with datasets that exceeded the capabilities of traditional database systems.
  type: definition
  entity: Big Data
  keywords:
  - definition
  - term
  - big
  - data
  - emerged
  - mid
  - 1990s
  - organizations
  - began
  - grappling
  - datasets
  - exceeded
  - capabilities
  - traditional
  - database
  - systems
  source:
    doc: motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md
    quote: The term 'big data' emerged in the mid-1990s as organizations began grappling
      with datasets that exceeded the capabilities of traditional database systems.
    char_start: 0
    char_end: 155
- statement: The world in 2023 looks different from when the Big Data alarm bells
    started going off.
  type: definition
  entity: Big Data
  keywords:
  - definition
  - world
  - '2023'
  - looks
  - different
  - big
  - data
  - alarm
  - bells
  - started
  - going
  - 'off'
  source:
    doc: motherduck.com/blog/announcing-small-data-sf-2025.md
    quote: The world in 2023 looks different from when the Big Data alarm bells started
      going off.
    char_start: 0
    char_end: 87
- statement: Bigeye provides ML-driven automatic threshold tests and alerts.
  type: definition
  entity: Bigeye
  keywords:
  - definition
  - bigeye
  - provides
  - ml
  - driven
  - automatic
  - threshold
  - tests
  - alerts
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: ML-driven automatic threshold tests and alerts
    char_start: 0
    char_end: 46
- statement: BigQuery can be combined with DuckDB.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - bigquery
  - combined
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md
    quote: A fascinating article about how to combine the power of GCP’s BigQuery
      and MotherDuck.
    char_start: 0
    char_end: 86
- statement: BigQuery can be surprisingly expensive for medium-sized data.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - bigquery
  - surprisingly
  - expensive
  - medium
  - sized
  - data
  source:
    doc: motherduck.com/blog/streaming-data-to-motherduck.md
    quote: Why BigQuery can be surprisingly expensive for medium-sized data by deconstructing
      its pricing model.
    char_start: 0
    char_end: 101
- statement: BigQuery can be used for querying data in Iceberg format.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - bigquery
  - used
  - querying
  - data
  - iceberg
  - format
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: Use Snowflake or BigQuery for massive, ad-hoc interactive queries when
      you need the horsepower.
    char_start: 0
    char_end: 95
- statement: BigQuery enables scalable analysis over petabytes of data.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - bigquery
  - enables
  - scalable
  - analysis
  - over
  - petabytes
  - data
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: A fully-managed, serverless data warehouse that enables scalable analysis
      over petabytes of data.
    char_start: 0
    char_end: 97
- statement: BigQuery had separation of storage and compute, but was missing important
    database features like transactions and atomic updates.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - bigquery
  - separation
  - storage
  - compute
  - missing
  - important
  - database
  - features
  - like
  - transactions
  - atomic
  - updates
  source:
    doc: motherduck.com/blog/introducing-instant-sql.md
    quote: BigQuery had separation of storage and compute, but we were missing important
      database features like transactions, atomic updates...
    char_start: 0
    char_end: 132
- statement: BigQuery has been a cornerstone OLAP database for over a decade.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - bigquery
  - cornerstone
  - olap
  - database
  - over
  - decade
  source:
    doc: motherduck.com/blog/dosomething-motherduck-data-warehouse-ROI.md
    quote: BigQuery has been a cornerstone OLAP database for over a decade.
    char_start: 0
    char_end: 64
- statement: BigQuery is part of Google Cloud.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - bigquery
  - part
  - google
  - cloud
  source:
    doc: motherduck.com/blog/announcing-ducklake-support-motherduck-preview.md
    quote: BigQuery, a serverless, highly scalable, and cost-effective multi-cloud
      data warehouse.
    char_start: 0
    char_end: 87
- statement: BigQuery is used for large-scale, batch ETL/ELT workloads.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - bigquery
  - used
  - large
  - scale
  - batch
  - etl
  - elt
  - workloads
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: Your primary workload is large-scale, batch ETL/ELT that can take minutes
      or hours to run.
    char_start: 0
    char_end: 90
- statement: BigQuery operates on a different cost model compared to DuckDB.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - bigquery
  - operates
  - different
  - cost
  - model
  - compared
  - duckdb
  source:
    doc: motherduck.com/blog/vibe-coding-sql-cursor.md
    quote: Traditional data warehouses like BigQuery operate on a princ...
    char_start: 0
    char_end: 63
- statement: 'BigQuery primarily offers two models: On-Demand and Flat-Rate.'
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - bigquery
  - primarily
  - offers
  - two
  - models
  - demand
  - flat
  - rate
  source:
    doc: motherduck.com/learn-more/bigquery-alternative-motherduck.md
    quote: 'BigQuery primarily offers two models: On-Demand and Flat-Rate.'
    char_start: 0
    char_end: 62
- statement: BigQuery shows up very poorly in benchmarks, but the actual experience
    of many people is that the performance is magical.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - bigquery
  - shows
  - up
  - poorly
  - benchmarks
  - actual
  - experience
  - many
  - people
  - performance
  - magical
  source:
    doc: motherduck.com/blog/duckdb-enterprise-5-key-categories.md
    quote: For example, BigQuery shows up very poorly in benchmarks, but the actual
      experience of many people is that the performance is magical.
    char_start: 0
    char_end: 134
- statement: BigQuery uses Colossus for data and Spanner for metadata.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - bigquery
  - uses
  - colossus
  - data
  - spanner
  - metadata
  source:
    doc: motherduck.com/blog/effortless-etl-unstructured-data-unstructuredio-motherduck.md
    quote: BigQuery uses Colossus, an internal Google object store, for data and Spanner
      for metadata.
    char_start: 0
    char_end: 91
- statement: BigQuery's on-demand pricing model can lead to large, unexpected bills
    from a single inefficient query.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - bigquery
  - demand
  - pricing
  - model
  - lead
  - large
  - unexpected
  - bills
  - single
  - inefficient
  - query
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: 'BigQuery''s on-demand pricing model presents a different kind of financial
      risk: the ''scan-based pricing trap.'''
    char_start: 0
    char_end: 110
- statement: BigQuery's on-demand pricing model presents a different kind of financial
    risk.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - bigquery
  - demand
  - pricing
  - model
  - presents
  - different
  - kind
  - financial
  - risk
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: 'BigQuery''s on-demand pricing model presents a different kind of financial
      risk: the ''scan-based pricing trap.'''
    char_start: 0
    char_end: 110
- statement: BigQuery's performance could improve with slight adjustments to benchmarking
    methods.
  type: performance
  entity: BigQuery
  keywords:
  - bigquery
  - performance
  - improve
  - slight
  - adjustments
  - benchmarking
  - methods
  source:
    doc: motherduck.com/blog/llm-data-pipelines-prompt-motherduck-dbt.md
    quote: my guess is that if someone from the BigQuery team updated the method of
      running the benchmark slightly, the results would look a lot better.
    char_start: 0
    char_end: 141
- statement: BigQuery's pricing model can be costly for typical startup data volumes.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - bigquery
  - pricing
  - model
  - costly
  - typical
  - startup
  - data
  - volumes
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: Like other massive-scale warehouses, BigQuery's pricing model can be costly
      for typical startup data volumes.
    char_start: 0
    char_end: 109
- statement: BigQuery's pricing model prioritizes throughput for enormous datasets
    over latency or cost-efficiency for smaller ones.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - bigquery
  - pricing
  - model
  - prioritizes
  - throughput
  - enormous
  - datasets
  - over
  - latency
  - cost
  - efficiency
  - smaller
  - ones
  source:
    doc: motherduck.com/case-studies/trunkrs-same-day-delivery-motherduck-from-redshift.md
    quote: BigQuery is a massively parallel processing (MPP) system built to scan
      petabytes of data. Its pricing model reflects this architecture, prioritizing
      throughput for enormous datasets over latency or co
    char_start: 0
    char_end: 231
- statement: BigQuery's TCO is most commonly driven by its on-demand model, where
    you pay for the terabytes of data your queries scan.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - bigquery
  - tco
  - commonly
  - driven
  - demand
  - model
  - pay
  - terabytes
  - data
  - queries
  - scan
  source:
    doc: motherduck.com/blog/why-everybody-hates-databases.md
    quote: BigQuery's TCO is most commonly driven by its on-demand model, where you
      pay for the terabytes of data your queries scan.
    char_start: 0
    char_end: 121
- statement: Costs can be controlled by enforcing query best practices.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - costs
  - controlled
  - enforcing
  - query
  - best
  - practices
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: Costs can be controlled by enforcing query best practices, such as always
      using a WHERE clause.
    char_start: 0
    char_end: 95
- statement: Customers ended up choosing BigQuery.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - customers
  - ended
  - up
  - choosing
  - bigquery
  source:
    doc: motherduck.com/blog/duckdb-enterprise-5-key-categories.md
    quote: However, the results didn’t match the impression we had from users. Every
      time a customer did a head-to-head evaluation of us vs Azure, they ended up
      choosing BigQuery.
    char_start: 0
    char_end: 168
- statement: Google BigQuery demands the least infrastructure administration.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - google
  - bigquery
  - demands
  - least
  - infrastructure
  - administration
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part1.md
    quote: Google BigQuery, as a fully serverless platform, demands the least infrastructure
      administration.
    char_start: 0
    char_end: 97
- statement: Google BigQuery eliminates the need to think about compute resources
    entirely.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - google
  - bigquery
  - eliminates
  - need
  - think
  - about
  - compute
  - resources
  - entirely
  source:
    doc: motherduck.com/blog/unstructured-analysis-tensorlake-motherduck.md
    quote: Google BigQuery followed with a serverless approach, eliminating the need
      to think about compute resources entirely.
    char_start: 0
    char_end: 116
- statement: Google BigQuery is optimized for high throughput and scanning massive
    volumes of data.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - google
  - bigquery
  - optimized
  - high
  - throughput
  - scanning
  - massive
  - volumes
  - data
  source:
    doc: motherduck.com/blog/streaming-oracle-to-motherduck.md
    quote: Optimized for high throughput and scanning massive volumes of data.
    char_start: 0
    char_end: 67
- statement: Google's Python SDK is used for interacting with BigQuery.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - google
  - python
  - sdk
  - used
  - interacting
  - bigquery
  source:
    doc: motherduck.com/blog/bigquery-to-duckdb-motherduck.md
    quote: Using Google's Python SDK for BigQuery.
    char_start: 0
    char_end: 39
- statement: Implementing platform-specific controls can prevent overages in data
    queries.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - implementing
  - platform
  - specific
  - controls
  - prevent
  - overages
  - data
  - queries
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part1.md
    quote: Key strategies include implementing platform-specific controls like setting
      user-level quotas in BigQuery or using resource monitors in Snowflake to prevent
      overages.
    char_start: 0
    char_end: 166
- statement: In BigQuery, we had a customer who was one of the largest retailers in
    the world.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - bigquery
  - customer
  - who
  - one
  - largest
  - retailers
  - world
  source:
    doc: motherduck.com/blog.md
    quote: In BigQuery, we had a customer who was one of the largest retailers in
      the world.
    char_start: 0
    char_end: 81
- statement: Most of the people using 'Big Query' don’t really have Big Data.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - people
  - using
  - big
  - query
  - don
  - really
  - data
  source:
    doc: motherduck.com/blog/MotherDuck-Visualize-Embeddings-Marimo.md
    quote: most of the people using 'Big Query' don’t really have Big Data.
    char_start: 0
    char_end: 64
- statement: OLAP databases like BigQuery, Snowflake, or MotherDuck fit the best for
    these use cases.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - olap
  - databases
  - like
  - bigquery
  - snowflake
  - motherduck
  - fit
  - best
  - use
  - cases
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-essential-tools.md
    quote: OLAP databases like BigQuery, Snowflake, or MotherDuck fit the best for
      these use cases.
    char_start: 0
    char_end: 88
- statement: Organizations can implement hard financial guardrails by setting project-level
    and user-level quotas.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - organizations
  - implement
  - hard
  - financial
  - guardrails
  - setting
  - project
  - level
  - user
  - quotas
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: Organizations can implement hard financial guardrails by setting project-level
      and user-level quotas.
    char_start: 0
    char_end: 101
- statement: The estimated monthly query cost for BigQuery is ~$192.10/month.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - estimated
  - monthly
  - query
  - cost
  - bigquery
  - '192.10'
  - month
  source:
    doc: motherduck.com/blog/vibe-coding-sql-cursor.md
    quote: 'Estimated monthly query cost: 30 TB * $6.25/TB = $187.50 - Storage cost
      (200GB): ~$4.60 Total: ~$192.10/month'
    char_start: 0
    char_end: 109
- statement: The first cloud data warehouse to separate storage and compute was BigQuery.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - first
  - cloud
  - data
  - warehouse
  - separate
  - storage
  - compute
  - bigquery
  source:
    doc: motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md
    quote: The first cloud data warehouse to separate storage and compute was BigQuery.
    char_start: 0
    char_end: 76
- statement: The most efficient way to get data out of BigQuery is to export it to
    a columnar format like Parquet.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - efficient
  - way
  - get
  - data
  - out
  - bigquery
  - export
  - columnar
  - format
  - like
  - parquet
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: The most efficient way to get data out of BigQuery is to export it to a
      columnar format like Parquet.
    char_start: 0
    char_end: 101
- statement: The vast majority of customers had less than a terabyte of data in total
    data storage.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - vast
  - majority
  - customers
  - less
  - terabyte
  - data
  - total
  - storage
  source:
    doc: motherduck.com/blog/dosomething-motherduck-data-warehouse-ROI.md
    quote: However, I can say that the vast majority of customers had less than a
      terabyte of data in total data storage.
    char_start: 0
    char_end: 110
- statement: To use the BigQuery extension, you'll need valid Google Cloud credentials.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - use
  - bigquery
  - extension
  - ll
  - need
  - valid
  - google
  - cloud
  - credentials
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: To use the BigQuery extension, you'll need valid Google Cloud credentials.
    char_start: 0
    char_end: 74
- statement: Using the partition column 'timestamp' and filtering on the project name
    can drastically reduce the data size of the query.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - using
  - partition
  - column
  - timestamp
  - filtering
  - project
  - name
  - drastically
  - reduce
  - data
  - size
  - query
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: Be aware! As the table is big, ALWAYS use the partition column 'timestamp'
      and filter on the project name; this will drastically reduce the data size of
      the query, and your compute bill.
    char_start: 0
    char_end: 186
- statement: When a data warehousing customer moves from an environment where they
    didn’t have separation of storage and compute into one where they do have it,
    their storage usage grows tremendously.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - data
  - warehousing
  - customer
  - moves
  - environment
  - didn
  - separation
  - storage
  - compute
  - one
  - usage
  - grows
  - tremendously
  source:
    doc: motherduck.com/blog.md
    quote: Very often when a data warehousing customer moves from an environment where
      they didn’t have separation of storage and compute into one where they do have
      it, their storage usage grows tremendously.
    char_start: 0
    char_end: 198
- statement: Your BigQuery bill is likely high due to the 'big data tax' inherent
    in its pricing model.
  type: definition
  entity: BigQuery
  keywords:
  - definition
  - bigquery
  - bill
  - likely
  - high
  - due
  - big
  - data
  - tax
  - inherent
  - pricing
  - model
  source:
    doc: motherduck.com/learn-more/bigquery-alternative-motherduck.md
    quote: Your BigQuery bill is likely high due to the ['big data tax'](https://motherduck.com/learn-more/modern-data-warehouse-playbook/)
      inherent in its pricing model.
    char_start: 0
    char_end: 159
- statement: The BigQuery community extension is one of the top 5 most downloaded
    community extensions last week with 21.7k downloads.
  type: definition
  entity: BigQuery community extension
  keywords:
  - definition
  - bigquery
  - community
  - extension
  - one
  - top
  - downloaded
  - extensions
  - last
  - week
  - '21.7'
  - downloads
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: one of the top 5 most downloaded community extensions last week with 21.7k
      downloads.
    char_start: 0
    char_end: 85
- statement: Bill Inmon defined data warehousing as a 'subject-oriented, integrated,
    time-variant, and non-volatile collection of data.'
  type: definition
  entity: Bill Inmon
  keywords:
  - definition
  - bill
  - inmon
  - defined
  - data
  - warehousing
  - subject
  - oriented
  - integrated
  - time
  - variant
  - non
  - volatile
  - collection
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: The 'godfather' of data warehousing, Bill Inmon, defined it as a 'subject-oriented,
      integrated, time-variant, and non-volatile collection of data in support of
      management's decision-making process.'
    char_start: 0
    char_end: 198
- statement: The average beak dimensions can be calculated for each species using
    SQL.
  type: definition
  entity: birds
  keywords:
  - definition
  - average
  - beak
  - dimensions
  - calculated
  - species
  - using
  - sql
  source:
    doc: motherduck.com/blog/just-enough-sql-for-ai.md
    quote: let's find the average beak measurements by species
    char_start: 0
    char_end: 51
- statement: Bluesky is an open-source social network with fully open APIs.
  type: definition
  entity: Bluesky
  keywords:
  - definition
  - bluesky
  - open
  - source
  - social
  - network
  - fully
  - apis
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: Bluesky, the open source social network with fully open APIs.
    char_start: 0
    char_end: 61
- statement: Bluesky is growing by 1 million new users daily.
  type: definition
  entity: Bluesky
  keywords:
  - definition
  - bluesky
  - growing
  - million
  - new
  - users
  - daily
  source:
    doc: motherduck.com/blog/from-data-lake-to-lakehouse-duckdb-portable-catalog.md
    quote: It is growing by 1 million new users daily.
    char_start: 0
    char_end: 43
- statement: Bluesky revolutionized social media with the ATProto.
  type: definition
  entity: Bluesky
  keywords:
  - definition
  - bluesky
  - revolutionized
  - social
  - media
  - atproto
  source:
    doc: motherduck.com/blog/duckdb-versus-pandas-versus-polars.md
    quote: Bluesky revolutionized this with the ATProto.
    char_start: 0
    char_end: 45
- statement: Bluesky uses Decentralized Identifiers for user identification.
  type: definition
  entity: Bluesky
  keywords:
  - definition
  - bluesky
  - uses
  - decentralized
  - identifiers
  - user
  - identification
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: To find the unique Bluesky-ID, aka the Decentralized Identifier (DID) that
      you need for the above query...
    char_start: 0
    char_end: 106
- statement: Bluesky works based on people and feeds instead of one colossal algorithm.
  type: definition
  entity: Bluesky
  keywords:
  - definition
  - bluesky
  - works
  - based
  - people
  - feeds
  - instead
  - one
  - colossal
  - algorithm
  source:
    doc: motherduck.com/blog/from-data-lake-to-lakehouse-duckdb-portable-catalog.md
    quote: Instead of one colossal algorithm deciding what we see and what not, Bluesky
      works based on people and feeds.
    char_start: 0
    char_end: 109
- statement: If Bluesky goes down, the protocol and your posts/data stay, and the
    new UI can be rebuilt.
  type: definition
  entity: Bluesky
  keywords:
  - definition
  - bluesky
  - goes
  - down
  - protocol
  - posts
  - data
  - stay
  - new
  - ui
  - rebuilt
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: If Bluesky goes down, the protocol and your posts/data stay, and the new
      UI can be rebuilt.
    char_start: 0
    char_end: 91
- statement: The APIs and Jetstreams can also be queried for free.
  type: definition
  entity: Bluesky
  keywords:
  - definition
  - apis
  - jetstreams
  - also
  - queried
  - free
  source:
    doc: motherduck.com/blog/from-data-lake-to-lakehouse-duckdb-portable-catalog.md
    quote: Not only is everything open-source but the APIs and Jetstreams can also
      be queried for free.
    char_start: 0
    char_end: 92
- statement: The count of records in the Bluesky dataset is 1 million.
  type: definition
  entity: Bluesky
  keywords:
  - definition
  - count
  - records
  - bluesky
  - dataset
  - million
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: │    1000000     │
    char_start: 0
    char_end: 18
- statement: SQL is used to analyze logs from the bluesky_events dataset.
  type: definition
  entity: bluesky_events
  keywords:
  - definition
  - sql
  - used
  - analyze
  - logs
  - bluesky
  - events
  - dataset
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: The SQL queries are used to analyze the bluesky_events dataset.
    char_start: 0
    char_end: 63
- statement: Performance is the most common metric that database nerds like me use
    to measure our importance.
  type: definition
  entity: Boeing 737-MAX
  keywords:
  - definition
  - performance
  - common
  - metric
  - database
  - nerds
  - like
  - me
  - use
  - measure
  - importance
  source:
    doc: motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md
    quote: Performance is the most common metric that database nerds like me use to
      measure our importance.
    char_start: 0
    char_end: 96
- statement: Bokeh is an interactive visualization library with geospatial capabilities.
  type: definition
  entity: Bokeh
  keywords:
  - definition
  - bokeh
  - interactive
  - visualization
  - library
  - geospatial
  - capabilities
  source:
    doc: motherduck.com/blog/motherduck-duckdb-dbt.md
    quote: 'Bokeh: Interactive visualization library with geospatial capabilities.'
    char_start: 0
    char_end: 70
- statement: The Boring Semantic Layer uses Ibis for the execution layer.
  type: definition
  entity: Boring Semantic Layer
  keywords:
  - definition
  - boring
  - semantic
  - layer
  - uses
  - ibis
  - execution
  source:
    doc: motherduck.com/blog/solving-advent-code-duckdb-dbt.md
    quote: We use DuckDB as the query engine and Python with Ibis for the execution
      layer.
    char_start: 0
    char_end: 79
- statement: The BSL includes some visualization capabilities with a built-in wrapper
    around Vega-Lite.
  type: definition
  entity: Boring Semantic Layer
  keywords:
  - definition
  - bsl
  - includes
  - visualization
  - capabilities
  - built
  - wrapper
  - around
  - vega
  - lite
  source:
    doc: motherduck.com/blog/semantic-layer-duckdb-tutorial.md
    quote: Interestingly, the BSL also includes some visualization capabilities with
      a built-in wrapper around Vega-Lite.
    char_start: 0
    char_end: 110
- statement: Install boring-catalog using pip.
  type: instruction
  entity: boring-catalog
  keywords:
  - instruction
  - install
  - boring
  - catalog
  - using
  - pip
  source:
    doc: motherduck.com/learn-more/what-is-duckdb.md
    quote: First, install `boring-catalog` using pip.
    char_start: 0
    char_end: 42
- statement: grep is used to search AWS environment variables.
  type: definition
  entity: brew
  keywords:
  - definition
  - grep
  - used
  - search
  - aws
  - environment
  - variables
  source:
    doc: motherduck.com/blog/data-warehouse-feature-roundup-oct-2024.md
    quote: 'quickly search AWS env variables: env | grep AWS'
    char_start: 0
    char_end: 48
- statement: Broadcast Join is a join strategy that sends a smaller table to all nodes
    to avoid shuffling large datasets.
  type: definition
  entity: Broadcast Join
  keywords:
  - definition
  - broadcast
  - join
  - strategy
  - sends
  - smaller
  - table
  - nodes
  - avoid
  - shuffling
  - large
  - datasets
  source:
    doc: motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md
    quote: A join strategy that sends a smaller table to all nodes to avoid shuffling
      large datasets.
    char_start: 0
    char_end: 90
- statement: Bruin allows you to ensure your data is accurate on a regular basis.
  type: definition
  entity: Bruin
  keywords:
  - definition
  - bruin
  - allows
  - ensure
  - data
  - accurate
  - regular
  - basis
  source:
    doc: motherduck.com/ecosystem.md
    quote: Bruin allows you to ensure your data is accurate on a regular basis, whether
      it comes in externally or you built it.
    char_start: 0
    char_end: 116
- statement: Bruin is an end-to-end data platform that brings together data ingestion,
    transformation, data quality, and governance.
  type: definition
  entity: Bruin
  keywords:
  - definition
  - bruin
  - end
  - data
  - platform
  - brings
  - together
  - ingestion
  - transformation
  - quality
  - governance
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: Bruin is an end-to-end data platform that brings together data ingestion,
      transformation using SQL and Python, data quality and governance.
    char_start: 0
    char_end: 139
- statement: BI tools promise deep insights, but most teams only get noise.
  type: definition
  entity: Business Intelligence
  keywords:
  - definition
  - bi
  - tools
  - promise
  - deep
  - insights
  - teams
  - get
  - noise
  source:
    doc: motherduck.com/videos.md
    quote: BI tools promise deep insights, but most teams only get noise.
    char_start: 0
    char_end: 62
- statement: Business Intelligence involves technologies for the analysis of business
    information.
  type: definition
  entity: Business Intelligence
  keywords:
  - definition
  - business
  - intelligence
  - involves
  - technologies
  - analysis
  - information
  source:
    doc: motherduck.com/videos/ai-powered-bi-can-llms-really-generate-your-dashboards-ft-michael-driscoll.md
    quote: Business Intelligence
    char_start: 0
    char_end: 21
- statement: Data warehouses provide clean, consolidated, and historically rich data
    that powers dashboards, reports, and ad-hoc analyses.
  type: definition
  entity: Business Intelligence
  keywords:
  - definition
  - data
  - warehouses
  - provide
  - clean
  - consolidated
  - historically
  - rich
  - powers
  - dashboards
  - reports
  - ad
  - hoc
  - analyses
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Ultimately, a well-designed data warehouse serves as the foundational layer
      for most business intelligence activities. It provides clean, consolidated,
      and historically rich data that powers dashboard
    char_start: 0
    char_end: 232
- statement: Many teams are unhappy with their BI tools, leading to 'trashboards'
    that nobody uses.
  type: definition
  entity: Business Intelligence
  keywords:
  - definition
  - many
  - teams
  - unhappy
  - bi
  - tools
  - leading
  - trashboards
  - nobody
  - uses
  source:
    doc: motherduck.com/learn-more/what-is-duckdb.md
    quote: Why do our dashboards become 'trashboards' that nobody uses?
    char_start: 0
    char_end: 60
- statement: The future of business intelligence is not just about visualizing data,
    but about building interactive, maintainable, and trustworthy data applications.
  type: definition
  entity: Business Intelligence
  keywords:
  - definition
  - future
  - business
  - intelligence
  - about
  - visualizing
  - data
  - building
  - interactive
  - maintainable
  - trustworthy
  - applications
  source:
    doc: motherduck.com/videos.md
    quote: The future of business intelligence is not just about visualizing data,
      but about building interactive, maintainable, and trustworthy data applications.
    char_start: 0
    char_end: 152
- statement: The story of BI tools uncovering insights is a foundational misunderstanding
    of the data most companies have.
  type: definition
  entity: Business Intelligence
  keywords:
  - definition
  - story
  - bi
  - tools
  - uncovering
  - insights
  - foundational
  - misunderstanding
  - data
  - companies
  source:
    doc: motherduck.com/learn-more/what-is-duckdb.md
    quote: the entire 'intrepid analyst' fantasy is built on a lie.
    char_start: 0
    char_end: 56
- statement: This transformation promises to make data analytics more accessible while
    maintaining precision and version control benefits.
  type: definition
  entity: Business Intelligence
  keywords:
  - definition
  - transformation
  - promises
  - make
  - data
  - analytics
  - accessible
  - maintaining
  - precision
  - version
  - control
  - benefits
  source:
    doc: motherduck.com/videos/bringing-duckdb-to-the-cloud-dual-execution-explained.md
    quote: This transformation promises to make data analytics more accessible while
      maintaining the precision and version control benefits.
    char_start: 0
    char_end: 129
- statement: Traditional BI tools fail startups and a modern approach saves critical
    time and money.
  type: definition
  entity: Business Intelligence
  keywords:
  - definition
  - traditional
  - bi
  - tools
  - fail
  - startups
  - modern
  - approach
  - saves
  - critical
  - time
  - money
  source:
    doc: motherduck.com/videos.md
    quote: Why traditional BI tools fail startups and how a modern approach saves
      critical time and money.
    char_start: 0
    char_end: 95
- statement: BI applications focus on reporting, dashboarding, and ad-hoc analysis
    of business data.
  type: definition
  entity: Business Intelligence (BI) tools
  keywords:
  - definition
  - bi
  - applications
  - focus
  - reporting
  - dashboarding
  - ad
  - hoc
  - analysis
  - business
  - data
  source:
    doc: motherduck.com/learn-more/data-application.md
    quote: BI applications focus on reporting, dashboarding, and ad-hoc analysis of
      business data.
    char_start: 0
    char_end: 87
- statement: Business Intelligence tools typically share a single database connection.
  type: definition
  entity: Business Intelligence (BI) tools
  keywords:
  - definition
  - business
  - intelligence
  - tools
  - typically
  - share
  - single
  - database
  - connection
  source:
    doc: motherduck.com/blog/announcing-mega-giga-instance-sizes-huge-scale.md
    quote: For example, business intelligence (BI) tools typically share a single
      database connection but then may have dozens of users running queries at the
      same time.
    char_start: 0
    char_end: 158
- statement: A modern approach to analytics can empower non-technical users.
  type: definition
  entity: Business Intelligence tools
  keywords:
  - definition
  - modern
  - approach
  - analytics
  - empower
  - non
  - technical
  - users
  source:
    doc: motherduck.com/videos/a-new-paradigm-for-data-visualization-with-just-sql-markdown.md
    quote: How to empower non-technical users to perform their own ad-hoc queries
      and analyses.
    char_start: 0
    char_end: 84
- statement: Speed and interactivity are critical for interpreting ambiguous charts.
  type: definition
  entity: Business Intelligence tools
  keywords:
  - definition
  - speed
  - interactivity
  - critical
  - interpreting
  - ambiguous
  - charts
  source:
    doc: motherduck.com/videos/duckdb-tutorial-for-beginners.md
    quote: When you can test ideas as fast as you can think of them...
    char_start: 0
    char_end: 59
- statement: Traditional BI tools fail startups due to their design for large enterprises.
  type: definition
  entity: Business Intelligence tools
  keywords:
  - definition
  - traditional
  - bi
  - tools
  - fail
  - startups
  - due
  - design
  - large
  - enterprises
  source:
    doc: motherduck.com/videos/a-new-paradigm-for-data-visualization-with-just-sql-markdown.md
    quote: Why traditional BI tools fail startups and how a modern approach saves
      critical time and money.
    char_start: 0
    char_end: 95
- statement: The Business Plan allows users to configure read scaling replicas in
    a self-serve fashion.
  type: definition
  entity: Business Plan
  keywords:
  - definition
  - business
  - plan
  - allows
  - users
  - configure
  - read
  - scaling
  - replicas
  - self
  - serve
  - fashion
  source:
    doc: motherduck.com/blog/motherduck-open-for-all-with-series-b.md
    quote: With today’s launch of the Business Plan, users can also configure read
      scaling replicas in a self-serve fashion.
    char_start: 0
    char_end: 113
- statement: The Business Plan includes performance optimization and three new configurable
    instance types.
  type: definition
  entity: Business Plan
  keywords:
  - definition
  - business
  - plan
  - includes
  - performance
  - optimization
  - three
  - new
  - configurable
  - instance
  - types
  source:
    doc: motherduck.com/blog/motherduck-open-for-all-with-series-b.md
    quote: 'Highlights of the Business Plan include: Performance optimization and
      tuning with three new, configurable instance types...'
    char_start: 0
    char_end: 123
- statement: We are introducing a new Business Plan with unlimited Organization members.
  type: definition
  entity: Business Plan
  keywords:
  - definition
  - introducing
  - new
  - business
  - plan
  - unlimited
  - organization
  - members
  source:
    doc: motherduck.com/blog/pgduckdb-beta-release-duckdb-postgres.md
    quote: We are introducing a new Business Plan with unlimited Organization members.
    char_start: 0
    char_end: 75
- statement: BuzzFeed developed in-house capabilities using Stable Diffusion XL models.
  type: definition
  entity: Buzzfeed
  keywords:
  - definition
  - buzzfeed
  - developed
  - house
  - capabilities
  - using
  - stable
  - diffusion
  - xl
  - models
  source:
    doc: motherduck.com/videos/pg_duckdb-ducking-awesome-analytics-in-postgres.md
    quote: 'BuzzFeed developed in-house capabilities using: Stable Diffusion XL (SDXL)
      models'
    char_start: 0
    char_end: 81
- statement: BuzzFeed has collected years of A/B testing data from their Bayesian-based
    testing system.
  type: definition
  entity: Buzzfeed
  keywords:
  - definition
  - buzzfeed
  - collected
  - years
  - testing
  - data
  - bayesian
  - based
  - system
  source:
    doc: motherduck.com/videos/pg_duckdb-ducking-awesome-analytics-in-postgres.md
    quote: BuzzFeed has collected years of A/B testing data from their Bayesian-based
      testing system.
    char_start: 0
    char_end: 90
- statement: Buzzfeed integrates AI tools into their generative content systems.
  type: definition
  entity: Buzzfeed
  keywords:
  - definition
  - buzzfeed
  - integrates
  - ai
  - tools
  - generative
  - content
  - systems
  source:
    doc: motherduck.com/blog/duckdb-the-great-federator.md
    quote: Gilad Lotan showcased how LLMs and AI tools have been integrated into their
      generative content systems.
    char_start: 0
    char_end: 103
- statement: BuzzFeed transitioned from using Google's Universal Sentence Encoders
    and DistilBERT to modern embedding approaches.
  type: definition
  entity: Buzzfeed
  keywords:
  - definition
  - buzzfeed
  - transitioned
  - using
  - google
  - universal
  - sentence
  - encoders
  - distilbert
  - modern
  - embedding
  - approaches
  source:
    doc: motherduck.com/videos.md
    quote: BuzzFeed transitioned from using Google's Universal Sentence Encoders and
      DistilBERT to modern embedding approaches.
    char_start: 0
    char_end: 116
- statement: BuzzFeed views current AI applications as the beginning of a significant
    transformation in media creation and consumption.
  type: definition
  entity: Buzzfeed
  keywords:
  - definition
  - buzzfeed
  - views
  - current
  - ai
  - applications
  - beginning
  - significant
  - transformation
  - media
  - creation
  - consumption
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: BuzzFeed views current AI applications as the beginning of a significant
      transformation in media creation and consumption.
    char_start: 0
    char_end: 122
- statement: BuzzFeed's editorial team began experimenting with Midjourney to create
    images relevant to trending topics.
  type: definition
  entity: Buzzfeed
  keywords:
  - definition
  - buzzfeed
  - editorial
  - team
  - began
  - experimenting
  - midjourney
  - create
  - images
  - relevant
  - trending
  - topics
  source:
    doc: motherduck.com/videos.md
    quote: BuzzFeed's editorial team began experimenting with Midjourney to create
      images relevant to trending topics.
    char_start: 0
    char_end: 107
- statement: The post went viral organically on Instagram and TikTok, with one TikTok
    video alone garnering over 13 million views.
  type: definition
  entity: Buzzfeed
  keywords:
  - definition
  - post
  - went
  - viral
  - organically
  - instagram
  - tiktok
  - one
  - video
  - alone
  - garnering
  - over
  - '13'
  - million
  - views
  source:
    doc: motherduck.com/videos.md
    quote: The post went viral organically on Instagram and TikTok, with one TikTok
      video alone garnering over 13 million views.
    char_start: 0
    char_end: 117
- statement: The team's approach emphasizes continuous learning and testing, relentless
    iteration, and finding unique applications for AI technology.
  type: definition
  entity: Buzzfeed
  keywords:
  - definition
  - team
  - approach
  - emphasizes
  - continuous
  - learning
  - testing
  - relentless
  - iteration
  - finding
  - unique
  - applications
  - ai
  - technology
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: 'The team''s approach emphasizes: Continuous learning and testing, Relentless
      iteration, Finding unique applications for AI technology.'
    char_start: 0
    char_end: 133
- statement: Bytewax is an open-source framework for building streaming data pipelines.
  type: definition
  entity: Bytewax
  keywords:
  - definition
  - bytewax
  - open
  - source
  - framework
  - building
  - streaming
  - data
  - pipelines
  source:
    doc: motherduck.com/learn-more/columnar-storage-guide.md
    quote: 'Open source framework and distributed stream processing engine. Build
      streaming data pipelines and real-time apps with everything you need: recovery,
      scalability, windowing, aggregations, and connecto'
    char_start: 0
    char_end: 203
- statement: CaaSPER uses a combination of reactive and predictive approaches based
    on historical time-series data.
  type: definition
  entity: CaaSPER
  keywords:
  - definition
  - caasper
  - uses
  - combination
  - reactive
  - predictive
  - approaches
  - based
  - historical
  - time
  - series
  - data
  source:
    doc: motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md
    quote: CaaSPER uses a combination of reactive and predictive approaches based
      on historical time-series data.
    char_start: 0
    char_end: 102
- statement: Microsoft’s scalable Container-As-A-Service Performance Enhanced Resizing
    algorithm for the cloud is called CaaSPER.
  type: definition
  entity: CaaSPER
  keywords:
  - definition
  - microsoft
  - scalable
  - container
  - service
  - performance
  - enhanced
  - resizing
  - algorithm
  - cloud
  - called
  - caasper
  source:
    doc: motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md
    quote: Microsoft’s scalable Container-As-A-Service Performance Enhanced Resizing
      algorithm for the cloud is called CaaSPER.
    char_start: 0
    char_end: 116
- statement: Caleb Fahlgren is a Product ML Engineer at Hugging Face.
  type: definition
  entity: Caleb Fahlgren
  keywords:
  - definition
  - caleb
  - fahlgren
  - product
  - ml
  - engineer
  - hugging
  - face
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: Caleb Fahlgren is a Product ML Engineer at Hugging Face.
    char_start: 0
    char_end: 56
- statement: Cartopy is a specialized library for cartographic projections and geospatial
    visualization.
  type: definition
  entity: Cartopy
  keywords:
  - definition
  - cartopy
  - specialized
  - library
  - cartographic
  - projections
  - geospatial
  - visualization
  source:
    doc: motherduck.com/blog/motherduck-duckdb-dbt.md
    quote: 'Cartopy: Specialized library for cartographic projections and geospatial
      visualization.'
    char_start: 0
    char_end: 87
- statement: The Catalog & Database Explorer shows your connected data sources.
  type: definition
  entity: Catalog & Database Explorer
  keywords:
  - definition
  - catalog
  - database
  - explorer
  - shows
  - connected
  - data
  - sources
  source:
    doc: motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md
    quote: 'The Catalog & Database Explorer (Left Panel): Shows your connected data
      sources.'
    char_start: 0
    char_end: 80
- statement: CDC increases the WAL detail level, slightly increasing disk I/O and
    storage requirements.
  type: definition
  entity: CDC
  keywords:
  - definition
  - cdc
  - increases
  - wal
  - detail
  - level
  - slightly
  - increasing
  - disk
  - storage
  - requirements
  source:
    doc: motherduck.com/blog/motherduck-union-orchestration.md
    quote: CDC increases the WAL detail level, slightly increasing disk I/O and storage
      requirements.
    char_start: 0
    char_end: 90
- statement: The new cell preview UI allows you to view the full contents of selected
    cells.
  type: definition
  entity: cell preview UI
  keywords:
  - definition
  - new
  - cell
  - preview
  - ui
  - allows
  - view
  - full
  - contents
  - selected
  - cells
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: With the new cell preview UI, you can view the full contents of selected
      cells.
    char_start: 0
    char_end: 79
- statement: Census helps ensure that all teams have access to the most up-to-date,
    actionable data.
  type: definition
  entity: Census
  keywords:
  - definition
  - census
  - helps
  - ensure
  - teams
  - access
  - up
  - date
  - actionable
  - data
  source:
    doc: motherduck.com/ecosystem.md
    quote: Census is a reverse ETL tool that allows businesses to sync data from their
      data warehouse directly into the apps they use.
    char_start: 0
    char_end: 123
- statement: CDC excels at real-time data while batch is more along the lines of the
    'weekly reporting job' model.
  type: definition
  entity: Change Data Capture
  keywords:
  - definition
  - cdc
  - excels
  - real
  - time
  - data
  - batch
  - along
  - lines
  - weekly
  - reporting
  - job
  - model
  source:
    doc: motherduck.com/blog/summer-data-engineering-roadmap.md
    quote: In a nutshell, CDC excels at real-time data while batch is more along the
      lines of the 'weekly reporting job' model.
    char_start: 0
    char_end: 116
- statement: CDC is a technique for capturing changes in data.
  type: definition
  entity: Change Data Capture
  keywords:
  - definition
  - cdc
  - technique
  - capturing
  - changes
  - data
  source:
    doc: motherduck.com/blog/streaming-data-to-motherduck.md
    quote: Change Data Capture, a technique for capturing changes in data.
    char_start: 0
    char_end: 63
- statement: CDC tools like Debezium provide incremental updates with minimal load.
  type: definition
  entity: Change Data Capture
  keywords:
  - definition
  - cdc
  - tools
  - like
  - debezium
  - provide
  - incremental
  - updates
  - minimal
  - load
  source:
    doc: motherduck.com/case-studies/layers-multi-tenant-data-warehouse.md
    quote: CDC tools like Debezium provide incremental updates with minimal load.
    char_start: 0
    char_end: 70
- statement: Change Data Capture (CDC) is a technique used to identify and capture
    changes made to data.
  type: definition
  entity: Change Data Capture
  keywords:
  - definition
  - change
  - data
  - capture
  - cdc
  - technique
  - used
  - identify
  - changes
  - made
  source:
    doc: motherduck.com/blog/summer-data-engineering-roadmap.md
    quote: What is CDC?
    char_start: 0
    char_end: 12
- statement: Change Data Capture lets you track incremental changes as they occur
    rather than loading data in batches.
  type: definition
  entity: Change Data Capture
  keywords:
  - definition
  - change
  - data
  - capture
  - lets
  - track
  - incremental
  - changes
  - occur
  - rather
  - loading
  - batches
  source:
    doc: motherduck.com/blog/motherduck-union-orchestration.md
    quote: CDC lets you track incremental changes as they occur rather than loading
      data in batches.
    char_start: 0
    char_end: 89
- statement: The CDC process adds some CPU load.
  type: definition
  entity: Change Data Capture (CDC)
  keywords:
  - definition
  - cdc
  - process
  - adds
  - cpu
  - load
  source:
    doc: motherduck.com/blog/getting-started-ducklake-table-format.md
    quote: The CDC process adds some CPU load.
    char_start: 0
    char_end: 35
- statement: Chanin Natasenamat is a Developer Advocate at Streamlit.
  type: definition
  entity: Chanin Natasenamat
  keywords:
  - definition
  - chanin
  - natasenamat
  - developer
  - advocate
  - streamlit
  source:
    doc: motherduck.com/videos/bringing-duckdb-to-the-cloud-dual-execution-explained.md
    quote: Learn from Streamlit Developer Advocate Chanin Natasenamat
    char_start: 0
    char_end: 58
- statement: The feature 'checkout' is used by 360 distinct users.
  type: definition
  entity: checkout
  keywords:
  - definition
  - feature
  - checkout
  - used
  - '360'
  - distinct
  - users
  source:
    doc: motherduck.com/learn-more/pandas-dataframes-guide.md
    quote: '360'
    char_start: 0
    char_end: 3
- statement: PySheets enables intuitive, offline data manipulation without reliance
    on cloud services.
  type: definition
  entity: Chris Laffra
  keywords:
  - definition
  - pysheets
  - enables
  - intuitive
  - offline
  - data
  - manipulation
  - without
  - reliance
  - cloud
  - services
  source:
    doc: motherduck.com/blog/introducing-fixit-ai-sql-error-fixer.md
    quote: PySheets enables intuitive, offline data manipulation without reliance
      on cloud services.
    char_start: 0
    char_end: 89
- statement: Christophe Blefari has been thriving in the field of data engineering
    for the past 8 years.
  type: definition
  entity: Christophe Blefari
  keywords:
  - definition
  - christophe
  - blefari
  - thriving
  - field
  - data
  - engineering
  - past
  - years
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md
    quote: Meet Christophe, a dedicated individual who has been thriving in the field
      of data engineering for the past 8 years.
    char_start: 0
    char_end: 116
- statement: Christophe Blefari quacks and codes WASM with Mehdi Ouazza.
  type: definition
  entity: Christophe Blefari
  keywords:
  - definition
  - christophe
  - blefari
  - quacks
  - codes
  - wasm
  - mehdi
  - ouazza
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2024.md
    quote: Christophe Blefari quacks and codes WASM with MotherDuck’s Mehdi Ouazza
      in this episode.
    char_start: 0
    char_end: 88
- statement: Christophe Oudar is a Staff Software Engineer who works on cross-team
    initiatives scaling data systems.
  type: definition
  entity: Christophe Oudar
  keywords:
  - definition
  - christophe
  - oudar
  - staff
  - software
  - engineer
  - who
  - works
  - cross
  - team
  - initiatives
  - scaling
  - data
  - systems
  source:
    doc: motherduck.com/blog/building-motherduck-partner-ecosystem.md
    quote: Christophe Oudar, based in France, is a Staff Software Engineer who works
      on cross-team initiatives scaling data systems.
    char_start: 0
    char_end: 121
- statement: Churn Rate calculates the percentage of customers that stop using a product.
  type: definition
  entity: Churn Rate
  keywords:
  - definition
  - churn
  - rate
  - calculates
  - percentage
  - customers
  - stop
  - using
  - product
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: Churn Rate (User Churn, MRR Churn)
    char_start: 0
    char_end: 34
- statement: Churn rate measures the percentage of users lost over a period.
  type: definition
  entity: Churn Rate
  keywords:
  - definition
  - churn
  - rate
  - measures
  - percentage
  - users
  - lost
  - over
  - period
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-use-cases.md
    quote: The opposite of retention, measuring the percentage of users lost over
      a period.
    char_start: 0
    char_end: 80
- statement: CI/CD pipelines handle automated testing, deployment, and version control.
  type: definition
  entity: CI/CD
  keywords:
  - definition
  - ci
  - cd
  - pipelines
  - handle
  - automated
  - testing
  - deployment
  - version
  - control
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: Most of the time, it includes setting up an automated CI/CD pipeline that
      handles automated testing, deployment, version control.
    char_start: 0
    char_end: 129
- statement: The CIDR conference attracts a distinguished audience of researchers
    and practitioners working in data systems.
  type: definition
  entity: CIDR conference
  keywords:
  - definition
  - cidr
  - conference
  - attracts
  - distinguished
  - audience
  - researchers
  - practitioners
  - working
  - data
  - systems
  source:
    doc: motherduck.com/blog/announcing-motherduck-general-availability-data-warehousing-with-duckdb.md
    quote: Although CIDR is a relatively small conference, it attracts a distinguished
      audience of researchers and practitioners working in data systems attending
      it.
    char_start: 0
    char_end: 155
- statement: CircleCI is a cloud-native CI/CD platform known for fast build times
    and Docker-first approach to testing data engineering workflows.
  type: definition
  entity: CircleCI
  keywords:
  - definition
  - circleci
  - cloud
  - native
  - ci
  - cd
  - platform
  - known
  - fast
  - build
  - times
  - docker
  - first
  - approach
  - testing
  - data
  - engineering
  - workflows
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: Cloud-native CI/CD platform known for fast build times and Docker-first
      approach to testing data engineering workflows
    char_start: 0
    char_end: 118
- statement: AI coding assistants like Claude Artifacts can build web applications
    using only natural language instructions.
  type: definition
  entity: Claude Artifacts
  keywords:
  - definition
  - ai
  - coding
  - assistants
  - like
  - claude
  - artifacts
  - build
  - web
  - applications
  - using
  - natural
  - language
  - instructions
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: AI coding assistants like Claude Artifacts, LlamaCoder, GPT Engineer, and
      v0.dev can build web applications using only natural language instructions.
    char_start: 0
    char_end: 149
- statement: Claude Artifacts is an AI tool that can generate code for web applications.
  type: definition
  entity: Claude Artifacts
  keywords:
  - definition
  - claude
  - artifacts
  - ai
  - tool
  - generate
  - code
  - web
  - applications
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md
    quote: Claude Artifacts, an AI tool that can generate code and is specifically
      well suited for generating web applications.
    char_start: 0
    char_end: 116
- statement: Claude couldn't actually preview the app because it didn’t have the wasm-client
    dependency pre-installed.
  type: limitation
  entity: Claude Artifacts
  keywords:
  - limitation
  - claude
  - couldn
  - actually
  - preview
  - app
  - didn
  - wasm
  - client
  - dependency
  - pre
  - installed
  source:
    doc: motherduck.com/blog/data-app-generator.md
    quote: Claude couldn't actually preview the app, because it didn’t have the wasm-client
      dependency pre-installed.
    char_start: 0
    char_end: 106
- statement: Claude doesn't know about how to use the MotherDuck WASM SDK.
  type: limitation
  entity: Claude Artifacts
  keywords:
  - limitation
  - claude
  - doesn
  - know
  - about
  - use
  - motherduck
  - wasm
  - sdk
  source:
    doc: motherduck.com/blog/data-app-generator.md
    quote: We found out that Claude doesn't know about how to use the MotherDuck WASM
      SDK.
    char_start: 0
    char_end: 79
- statement: It would be difficult for Claude to generate correct SQL queries without
    context about the user’s database schemas.
  type: limitation
  entity: Claude Artifacts
  keywords:
  - limitation
  - difficult
  - claude
  - generate
  - correct
  - sql
  - queries
  - without
  - context
  - about
  - user
  - database
  - schemas
  source:
    doc: motherduck.com/blog/data-app-generator.md
    quote: We also realized that, even if this worked, it would be difficult for Claude
      to generate correct SQL queries because it wouldn’t have any context about the
      user’s database schemas.
    char_start: 0
    char_end: 180
- statement: Claude can run actual queries against databases to figure things out.
  type: definition
  entity: Claude Code
  keywords:
  - definition
  - claude
  - run
  - actual
  - queries
  - against
  - databases
  - figure
  - things
  - out
  source:
    doc: motherduck.com/blog/how-to-extract-analytics-from-bluesky.md
    quote: Claude can then run actual queries against my databases to figure things
      out.
    char_start: 0
    char_end: 77
- statement: Claude Code helps you code faster through natural language commands.
  type: definition
  entity: Claude Code
  keywords:
  - definition
  - claude
  - code
  - helps
  - faster
  - natural
  - language
  - commands
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: helps you code faster through natural language commands.
    char_start: 0
    char_end: 56
- statement: Claude handled complex analytical requirements through automatically
    generated SQL.
  type: definition
  entity: Claude Code
  keywords:
  - definition
  - claude
  - handled
  - complex
  - analytical
  - requirements
  - automatically
  - generated
  - sql
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: Claude handled complex analytical requirements, such as musical evolution
      trends and album release patterns, through automatically generated SQL.
    char_start: 0
    char_end: 145
- statement: The CLI is an essential tool for efficient data manipulation, analysis,
    and system management.
  type: definition
  entity: CLI
  keywords:
  - definition
  - cli
  - essential
  - tool
  - efficient
  - data
  - manipulation
  - analysis
  - system
  - management
  source:
    doc: motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md
    quote: The CLI, or Command-Line Interface, is a text-based interface used to interact
      with computer programs and operating systems through typed commands.
    char_start: 0
    char_end: 147
- statement: The CLI supports multiple output formats through the .mode command.
  type: definition
  entity: CLI
  keywords:
  - definition
  - cli
  - supports
  - multiple
  - output
  - formats
  - mode
  - command
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: The CLI supports multiple output formats through the .mode command.
    char_start: 0
    char_end: 67
- statement: ClickHouse provides superior price-performance for real-time observability.
  type: definition
  entity: ClickHouse
  keywords:
  - definition
  - clickhouse
  - provides
  - superior
  - price
  - performance
  - real
  - time
  - observability
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: specialized engines like ClickHouse often provide superior price-performance.
    char_start: 0
    char_end: 77
- statement: Clickhouse was faster than a couple dozen databases they tested against.
  type: definition
  entity: ClickHouse
  keywords:
  - definition
  - clickhouse
  - faster
  - couple
  - dozen
  - databases
  - tested
  - against
  source:
    doc: motherduck.com/blog/duckdb-enterprise-5-key-categories.md
    quote: A couple of years ago, Clickhouse released Clickbench, a benchmark that
      showed that Clickhouse was faster than a couple dozen databases they tested
      against.
    char_start: 0
    char_end: 156
- statement: Performance differences between databases tend to converge over time.
  type: definition
  entity: ClickHouse
  keywords:
  - definition
  - performance
  - differences
  - databases
  - tend
  - converge
  - over
  - time
  source:
    doc: motherduck.com/blog/separating-storage-compute-duckdb.md
    quote: If you take a bunch of databases, all actively maintained, and iterate
      them out a few years, performance is going to converge.
    char_start: 0
    char_end: 126
- statement: Cloud architectures enable separation of storage and compute.
  type: definition
  entity: cloud computing
  keywords:
  - definition
  - cloud
  - architectures
  - enable
  - separation
  - storage
  - compute
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: Cloud architectures also enable separation of storage and compute.
    char_start: 0
    char_end: 66
- statement: In the cloud, you don’t need to pay extra for a 'big iron' machine because
    you’re already running on one.
  type: definition
  entity: cloud computing
  keywords:
  - definition
  - cloud
  - don
  - need
  - pay
  - extra
  - big
  - iron
  - machine
  - re
  - already
  - running
  - one
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: In the cloud, you don’t need to pay extra for a 'big iron' machine because
      you’re already running on one.
    char_start: 0
    char_end: 105
- statement: Every optimization that reduces unnecessary data scanning or transfer
    directly cuts cloud costs.
  type: definition
  entity: cloud costs
  keywords:
  - definition
  - every
  - optimization
  - reduces
  - unnecessary
  - data
  - scanning
  - transfer
  - directly
  - cuts
  - cloud
  - costs
  source:
    doc: motherduck.com/videos.md
    quote: Every optimization that reduces unnecessary data scanning or transfer directly
      cuts cloud costs.
    char_start: 0
    char_end: 96
- statement: Cloud data warehouses can only handle a few concurrent queries at once.
  type: definition
  entity: cloud data warehouse
  keywords:
  - definition
  - cloud
  - data
  - warehouses
  - handle
  - concurrent
  - queries
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: even a well provisioned cloud data warehouse can only handle a few of these
      queries at once.
    char_start: 0
    char_end: 92
- statement: Legacy cloud warehouses come with significant administrative requirements.
  type: definition
  entity: cloud data warehouse
  keywords:
  - definition
  - legacy
  - cloud
  - warehouses
  - come
  - significant
  - administrative
  - requirements
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: Legacy cloud warehouses, designed for large enterprises, come with significant
      administrative requirements.
    char_start: 0
    char_end: 107
- statement: You can navigate and use a cloud-based data warehouse.
  type: definition
  entity: cloud data warehouse
  keywords:
  - definition
  - navigate
  - use
  - cloud
  - based
  - data
  - warehouse
  source:
    doc: motherduck.com/blog/summer-data-engineering-roadmap.md
    quote: You can navigate and use a cloud-based data warehouse.
    char_start: 0
    char_end: 54
- statement: Common misconfigurations are a primary cause of data breaches.
  type: definition
  entity: Cloud Security Alliance
  keywords:
  - definition
  - common
  - misconfigurations
  - primary
  - cause
  - data
  - breaches
  source:
    doc: motherduck.com/videos/understanding-ducklake-a-table-format-with-a-modern-architecture.md
    quote: According to the Cloud Security Alliance (CSA), common misconfigurations
      like improper secrets management, disabled logging, and overly permissive access
      are a primary cause of data breaches.
    char_start: 0
    char_end: 191
- statement: The separation of compute and storage leads to improved efficiency and
    cost management.
  type: definition
  entity: cloud-native architecture
  keywords:
  - definition
  - separation
  - compute
  - storage
  - leads
  - improved
  - efficiency
  - cost
  - management
  source:
    doc: motherduck.com/videos/using-sql-in-your-data-lake-with-duckdb-iceberg-dbt-and-motherduck.md
    quote: This model enabled businesses to scale their storage and computational
      needs independently, leading to improved efficiency and cost management.
    char_start: 0
    char_end: 143
- statement: Cloud-Native Design leverages cloud services for scalability and reduced
    operational overhead.
  type: definition
  entity: Cloud-Native Design
  keywords:
  - definition
  - cloud
  - native
  - design
  - leverages
  - services
  - scalability
  - reduced
  - operational
  - overhead
  source:
    doc: motherduck.com/learn-more/data-application-architecture.md
    quote: Embrace Cloud-Native Design Leverage cloud services for scalability, managed
      solutions, and reduced operational overhead.
    char_start: 0
    char_end: 121
- statement: It's super fast to upload because, again, it's just metadata.
  type: definition
  entity: cloud_ducky_catalog
  keywords:
  - definition
  - super
  - fast
  - upload
  - metadata
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-seven.md
    quote: It's super fast to upload because, again, it's just metadata.
    char_start: 0
    char_end: 61
- statement: Cloudflare R2 does not charge for egress.
  type: definition
  entity: Cloudflare R2
  keywords:
  - definition
  - cloudflare
  - r2
  - charge
  - egress
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: Cloudflare R2 buckets as they don’t charge for egress...
    char_start: 0
    char_end: 56
- statement: CloudQuery and DuckDB are very easy to run locally.
  type: definition
  entity: CloudQuery
  keywords:
  - definition
  - cloudquery
  - duckdb
  - easy
  - run
  - locally
  source:
    doc: motherduck.com/learn-more/fix-slow-bi-dashboards.md
    quote: One cool thing about CloudQuery and DuckDB is that both of them are very
      easy to run locally.
    char_start: 0
    char_end: 93
- statement: CloudQuery is an open-source data integration platform that enables the
    transformation of cloud assets into SQL-accessible databases.
  type: definition
  entity: CloudQuery
  keywords:
  - definition
  - cloudquery
  - open
  - source
  - data
  - integration
  - platform
  - enables
  - transformation
  - cloud
  - assets
  - sql
  - accessible
  - databases
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: CloudQuery is an open-source data integration platform that enables the
      transformation of cloud assets into SQL-accessible databases.
    char_start: 0
    char_end: 133
- statement: Running ELT pipelines locally can save time on feedback loops and surging
    cloud costs.
  type: definition
  entity: CloudQuery
  keywords:
  - definition
  - running
  - elt
  - pipelines
  - locally
  - save
  - time
  - feedback
  - loops
  - surging
  - cloud
  - costs
  source:
    doc: motherduck.com/learn-more/fix-slow-bi-dashboards.md
    quote: which can save time on feedback loops and surging cloud costs of compute,
      data, and egress - especially for development purposes.
    char_start: 0
    char_end: 129
- statement: Coalesce by dbt labs is happening in multiple locations.
  type: definition
  entity: Coalesce by dbt labs
  keywords:
  - definition
  - coalesce
  - dbt
  - labs
  - happening
  - multiple
  - locations
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-1.md
    quote: Coalesce by dbt labs is happening in multiple locations.
    char_start: 0
    char_end: 56
- statement: Cocoon is a semantic data profiling tool built by Zezhou Huang on DuckDB.
  type: definition
  entity: Cocoon
  keywords:
  - definition
  - cocoon
  - semantic
  - data
  - profiling
  - tool
  - built
  - zezhou
  - huang
  - duckdb
  source:
    doc: motherduck.com/blog/making-pyspark-code-faster-with-duckdb.md
    quote: Cocoon, a semantic data profiling tool built by Zezhou Huang on DuckDB,
      fits in here very well!
    char_start: 0
    char_end: 95
- statement: The CodeS model achieved a new top score on the Spider benchmark.
  type: definition
  entity: CodeS model
  keywords:
  - definition
  - codes
  - model
  - achieved
  - new
  - top
  - score
  - spider
  - benchmark
  source:
    doc: motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md
    quote: Notably, Renmin University of China presented the CodeS model, which achieved
      a new top score on the Spider benchmark.
    char_start: 0
    char_end: 118
- statement: CodeSandbox allows developers to create web applications.
  type: definition
  entity: CodeSandbox
  keywords:
  - definition
  - codesandbox
  - allows
  - developers
  - create
  - web
  - applications
  source:
    doc: motherduck.com/blog/analyze-x-data-nodejs-duckdb.md
    quote: An online code editor and prototyping tool that allows developers to create
      web applications.
    char_start: 0
    char_end: 93
- statement: Coginiti uses DuckDB for handling large result sets.
  type: definition
  entity: Coginiti
  keywords:
  - definition
  - coginiti
  - uses
  - duckdb
  - handling
  - large
  - result
  - sets
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: DuckDB is used for handling large result sets at Coginiti.
    char_start: 0
    char_end: 58
- statement: cognee combines three complementary storage systems.
  type: definition
  entity: Cognee
  keywords:
  - definition
  - cognee
  - combines
  - three
  - complementary
  - storage
  - systems
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: cognee combines three complementary storage systems.
    char_start: 0
    char_end: 52
- statement: cognee connects those embeddings to the knowledge graph.
  type: definition
  entity: Cognee
  keywords:
  - definition
  - cognee
  - connects
  - embeddings
  - knowledge
  - graph
  source:
    doc: motherduck.com/blog/announcing-duckdb-snippet-sets-with-motherduck-sharing-databases.md
    quote: cognee connects those embeddings to the knowledge graph.
    char_start: 0
    char_end: 56
- statement: Cognee enables the processing of large language models.
  type: definition
  entity: Cognee
  keywords:
  - definition
  - cognee
  - enables
  - processing
  - large
  - language
  - models
  source:
    doc: motherduck.com/case-studies/trunkrs-same-day-delivery-motherduck-from-redshift.md
    quote: Cognee enables the processing of LLMs by creating enriched datasets.
    char_start: 0
    char_end: 68
- statement: Cognee integrates SQL queries with knowledge graph memory.
  type: definition
  entity: Cognee
  keywords:
  - definition
  - cognee
  - integrates
  - sql
  - queries
  - knowledge
  - graph
  - memory
  source:
    doc: motherduck.com/blog/building-motherduck-partner-ecosystem.md
    quote: Cognee integrates SQL queries with knowledge graph memory.
    char_start: 0
    char_end: 58
- statement: Cognee is an open-source framework for knowledge and memory management
    for LLMs.
  type: definition
  entity: Cognee
  keywords:
  - definition
  - cognee
  - open
  - source
  - framework
  - knowledge
  - memory
  - management
  - llms
  source:
    doc: motherduck.com/blog/unstructured-analysis-tensorlake-motherduck.md
    quote: Cognee is an open-source framework for knowledge and memory management
      for LLMs.
    char_start: 0
    char_end: 80
- statement: cognee is built around a modular Extract, Cognify, Load (ECL) pipeline.
  type: definition
  entity: Cognee
  keywords:
  - definition
  - cognee
  - built
  - around
  - modular
  - extract
  - cognify
  - load
  - ecl
  - pipeline
  source:
    doc: motherduck.com/blog/announcing-duckdb-snippet-sets-with-motherduck-sharing-databases.md
    quote: cognee is built around a modular Extract, Cognify, Load (ECL) pipeline.
    char_start: 0
    char_end: 71
- statement: Cognee serves as a plugin for any langchain or llama index pipeline.
  type: definition
  entity: Cognee
  keywords:
  - definition
  - cognee
  - serves
  - plugin
  - any
  - langchain
  - llama
  - index
  - pipeline
  source:
    doc: motherduck.com/case-studies/trunkrs-same-day-delivery-motherduck-from-redshift.md
    quote: Cognee serves as a plugin for any langchain or llama index pipeline.
    char_start: 0
    char_end: 68
- statement: Cohort analysis is a method used to analyze user behavior over time.
  type: definition
  entity: Cohort Analysis
  keywords:
  - definition
  - cohort
  - analysis
  - method
  - used
  - analyze
  - user
  - behavior
  - over
  - time
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-use-cases.md
    quote: A method used to analyze user behavior over time by grouping users into
      cohorts.
    char_start: 0
    char_end: 80
- statement: Coiled Functions is a framework for scaling Python workloads with ease.
  type: definition
  entity: Coiled Functions
  keywords:
  - definition
  - coiled
  - functions
  - framework
  - scaling
  - python
  - workloads
  - ease
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: Coiled Functions is a framework for scaling Python workloads with ease.
    char_start: 0
    char_end: 71
- statement: Collaborative Data Environments foster collaboration between data scientists,
    analysts, and business users.
  type: definition
  entity: Collaborative Data Environments
  keywords:
  - definition
  - collaborative
  - data
  - environments
  - foster
  - collaboration
  - scientists
  - analysts
  - business
  - users
  source:
    doc: motherduck.com/learn-more/data-application.md
    quote: Fostering collaboration between data scientists, analysts, and business
      users through integrated platforms and version control for data and models.
    char_start: 0
    char_end: 147
- statement: Colton Padden transitioned from Airflow to Dagster.
  type: definition
  entity: Colton Padden
  keywords:
  - definition
  - colton
  - padden
  - transitioned
  - airflow
  - dagster
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Witness firsthand the journey of Colton Padden, who made a pivotal shift
      from Airflow to Dagster.
    char_start: 0
    char_end: 97
- statement: Column Explorer provides quick visual summaries of data.
  type: definition
  entity: Column Explorer
  keywords:
  - definition
  - column
  - explorer
  - provides
  - quick
  - visual
  - summaries
  - data
  source:
    doc: motherduck.com/learn-more/self-service-analytics-startups.md
    quote: Features like the Column Explorer provide quick visual summaries of data.
    char_start: 0
    char_end: 73
- statement: The Column Explorer provides a bird's-eye view of your data, allowing
    for fewer queries and more insights.
  type: definition
  entity: Column Explorer
  keywords:
  - definition
  - column
  - explorer
  - provides
  - bird
  - eye
  - view
  - data
  - allowing
  - fewer
  - queries
  - insights
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-seven.md
    quote: 'Column explorer : fewer queries, more insights'
    char_start: 0
    char_end: 46
- statement: The Table Explorer shows the table's structure and content overview.
  type: definition
  entity: Column Explorer
  keywords:
  - definition
  - table
  - explorer
  - shows
  - structure
  - content
  - overview
  source:
    doc: motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md
    quote: 'The Table Explorer (Bottom Left Panel): This activates when you click
      on a table in the Catalog Explorer.'
    char_start: 0
    char_end: 105
- statement: Columnar databases offer significant advantages for analytical workloads.
  type: definition
  entity: Columnar Database
  keywords:
  - definition
  - columnar
  - databases
  - offer
  - significant
  - advantages
  - analytical
  - workloads
  source:
    doc: motherduck.com/hack-night.md
    quote: While columnar databases offer significant advantages for analytical workloads,
      they're specialized tools.
    char_start: 0
    char_end: 106
- statement: Columnar databases store data in columns rather than rows.
  type: definition
  entity: Columnar Database
  keywords:
  - definition
  - columnar
  - databases
  - store
  - data
  - columns
  - rather
  - rows
  source:
    doc: motherduck.com/case-studies/reflex-careers-gig-economy-retail.md
    quote: The fundamental difference between these two storage models comes down
      to data layout on disk. A row-oriented database stores all ...
    char_start: 0
    char_end: 133
- statement: Columnar storage has become a critical foundational technology for modern
    data analytics.
  type: definition
  entity: Columnar Database
  keywords:
  - definition
  - columnar
  - storage
  - become
  - critical
  - foundational
  - technology
  - modern
  - data
  - analytics
  source:
    doc: motherduck.com/hack-night.md
    quote: Columnar storage has become a critical foundational technology for modern
      data analytics.
    char_start: 0
    char_end: 89
- statement: Columnar storage really shines at scale.
  type: definition
  entity: Columnar Database
  keywords:
  - definition
  - columnar
  - storage
  - really
  - shines
  - scale
  source:
    doc: motherduck.com/hack-night.md
    quote: Columnar storage really shines at scale.
    char_start: 0
    char_end: 40
- statement: Columnar systems can read just the necessary columns for a query, improving
    performance.
  type: definition
  entity: Columnar Database
  keywords:
  - definition
  - columnar
  - systems
  - read
  - necessary
  - columns
  - query
  - improving
  - performance
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: A columnar system can read just those two columns, while a row-based system
      must read every single column for each row in the query range.
    char_start: 0
    char_end: 138
- statement: Columnar storage groups data by column rather than by row, allowing for
    faster data retrieval and compression.
  type: definition
  entity: columnar storage
  keywords:
  - definition
  - columnar
  - storage
  - groups
  - data
  - column
  - rather
  - row
  - allowing
  - faster
  - retrieval
  - compression
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: Unlike traditional row-based storage systems, columnar storage groups data
      by column rather than by row, allowing for faster data retrieval and compression.
    char_start: 0
    char_end: 156
- statement: The COMMIT TRANSACTION command ensures that changes are durable.
  type: definition
  entity: COMMIT TRANSACTION
  keywords:
  - definition
  - commit
  - transaction
  - command
  - ensures
  - changes
  - durable
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: Once COMMIT succeeds, the changes are durable.
    char_start: 0
    char_end: 46
- statement: Common Table Expressions (CTEs) allow for more organized SQL queries.
  type: definition
  entity: Common Table Expression (CTE)
  keywords:
  - definition
  - common
  - table
  - expressions
  - ctes
  - allow
  - organized
  - sql
  - queries
  source:
    doc: motherduck.com/blog/scaling-duckdb-with-ducklings.md
    quote: During development, you might not want to run the whole thing, but just
      check the output of one piece.
    char_start: 0
    char_end: 102
- statement: CTEs allow seamless toggling between nodes in SQL queries.
  type: definition
  entity: Common Table Expressions
  keywords:
  - definition
  - ctes
  - allow
  - seamless
  - toggling
  - nodes
  - sql
  - queries
  source:
    doc: motherduck.com/blog/scaling-duckdb-with-ducklings.md
    quote: Going back to the CTE from previous step - you can seamless toggle between
      the CTE node and the final select node.
    char_start: 0
    char_end: 114
- statement: CTEs are easy to write, but difficult to debug.
  type: definition
  entity: Common Table Expressions
  keywords:
  - definition
  - ctes
  - easy
  - write
  - difficult
  - debug
  source:
    doc: motherduck.com/blog/effortless-etl-unstructured-data-unstructuredio-motherduck.md
    quote: CTEs are easy to write, but difficult to debug.
    char_start: 0
    char_end: 47
- statement: CTEs are used to compute size per database.
  type: definition
  entity: Common Table Expressions
  keywords:
  - definition
  - ctes
  - used
  - compute
  - size
  - per
  - database
  source:
    doc: motherduck.com/blog/simplifying-iot-analytics-motherduck.md
    quote: We first compute size per database in a common table expression (CTE).
    char_start: 0
    char_end: 70
- statement: Users can install community extensions easily by specifying the extension
    name.
  type: definition
  entity: community extension
  keywords:
  - definition
  - users
  - install
  - community
  - extensions
  - easily
  - specifying
  - extension
  - name
  source:
    doc: motherduck.com/learn-more/partitioned-writes-parquet-ducklake.md
    quote: 'To install a community extension, users simply specify: INSTALL extension_name
      FROM community;'
    char_start: 0
    char_end: 94
- statement: Community extensions are developed by users.
  type: definition
  entity: Community Extensions
  keywords:
  - definition
  - community
  - extensions
  - developed
  - users
  source:
    doc: motherduck.com/videos.md
    quote: Community extensions developed by users.
    char_start: 0
    char_end: 40
- statement: The computer vision system can now detect issues with plants and automatically
    notify users.
  type: definition
  entity: computer vision
  keywords:
  - definition
  - computer
  - vision
  - system
  - now
  - detect
  - issues
  - plants
  - automatically
  - notify
  - users
  source:
    doc: motherduck.com/videos/using-sql-in-your-data-lake-with-duckdb-iceberg-dbt-and-motherduck.md
    quote: The computer vision system can now detect issues with plants and automatically
      notify users.
    char_start: 0
    char_end: 92
- statement: ConnectorX is the fastest library to load data from the database to DataFrames.
  type: definition
  entity: ConnectorX
  keywords:
  - definition
  - connectorx
  - fastest
  - library
  - load
  - data
  - database
  - dataframes
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: The fastest library to load data from the database to DataFrames.
    char_start: 0
    char_end: 65
- statement: Consistency ensures that a transaction brings the database from one valid
    state to another.
  type: definition
  entity: Consistency
  keywords:
  - definition
  - consistency
  - ensures
  - transaction
  - brings
  - database
  - one
  - valid
  - state
  - another
  source:
    doc: motherduck.com/glossary/storage.md
    quote: Consistency ensures that a transaction brings the database from one valid
      state to another.
    char_start: 0
    char_end: 91
- statement: Containerization uses technologies like Docker for consistency across
    environments.
  type: definition
  entity: Containerization
  keywords:
  - definition
  - containerization
  - uses
  - technologies
  - like
  - docker
  - consistency
  - across
  - environments
  source:
    doc: motherduck.com/learn-more/data-application-architecture.md
    quote: Utilize Containerization Use technologies like Docker to ensure consistency
      across development, testing, and production environments.
    char_start: 0
    char_end: 133
- statement: Contextily adds basemaps from web tile services to matplotlib or GeoPandas
    plots.
  type: definition
  entity: Contextily
  keywords:
  - definition
  - contextily
  - adds
  - basemaps
  - web
  - tile
  - services
  - matplotlib
  - geopandas
  - plots
  source:
    doc: motherduck.com/blog/motherduck-duckdb-dbt.md
    quote: 'Contextily: Adds basemaps from web tile services to matplotlib or GeoPandas
      plots.'
    char_start: 0
    char_end: 82
- statement: Conversion Rate measures the percentage of users who take a desired action.
  type: definition
  entity: Conversion Rate
  keywords:
  - definition
  - conversion
  - rate
  - measures
  - percentage
  - users
  - who
  - take
  - desired
  - action
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: Conversion Rate
    char_start: 0
    char_end: 15
- statement: Convex Combination reportedly performs better than RRF when calibrated.
  type: definition
  entity: Convex Combination
  keywords:
  - definition
  - convex
  - combination
  - reportedly
  - performs
  - better
  - rrf
  - calibrated
  source:
    doc: motherduck.com/blog/search-using-duckdb-part-3.md
    quote: This method reportedly performs better than RRF when calibrated.
    char_start: 0
    char_end: 64
- statement: We collect personal information using cookies, pixel tags, or similar
    technologies.
  type: definition
  entity: Cookies
  keywords:
  - definition
  - collect
  - personal
  - information
  - using
  - cookies
  - pixel
  - tags
  - similar
  - technologies
  source:
    doc: motherduck.com/videos/duckdb-run-dbt-build-with-sub-second-execution-times.md
    quote: We and our third-party partners collect personal information using cookies,
      pixel tags, or similar technologies.
    char_start: 0
    char_end: 112
- statement: Access to Data Lakes is not just read-only in pg_duckdb, you can also
    write back by using the COPY command.
  type: definition
  entity: COPY command
  keywords:
  - definition
  - access
  - data
  - lakes
  - read
  - pg
  - duckdb
  - also
  - write
  - back
  - using
  - copy
  - command
  source:
    doc: motherduck.com/blog/preswald-health-data-analysis.md
    quote: Access to Data Lakes is not just read-only in pg_duckdb, you can also write
      back by using the COPY command.
    char_start: 0
    char_end: 107
- statement: The COPY command allows for filtering and selecting specific columns.
  type: definition
  entity: COPY command
  keywords:
  - definition
  - copy
  - command
  - allows
  - filtering
  - selecting
  - specific
  - columns
  source:
    doc: motherduck.com/videos/simple-way-to-convert-csv-and-parquet-files.md
    quote: The SELECT statement is your playground. You can perform filtering, transformations,
      and even simple aggregations as part of your conversion pipeline.
    char_start: 0
    char_end: 150
- statement: CorrDyn is a data-driven technology consultancy that enables scalable
    and affordable growth.
  type: definition
  entity: CorrDyn
  keywords:
  - definition
  - corrdyn
  - data
  - driven
  - technology
  - consultancy
  - enables
  - scalable
  - affordable
  - growth
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: CorrDyn is a data-driven technology consultancy that enables scalable and
      affordable growth.
    char_start: 0
    char_end: 92
- statement: Cosine similarity is a metric used to measure how similar two vectors
    are.
  type: definition
  entity: cosine similarity
  keywords:
  - definition
  - cosine
  - similarity
  - metric
  - used
  - measure
  - similar
  - two
  - vectors
  source:
    doc: motherduck.com/blog/sql-keyboard-shortcuts-for-joyful-querying.md
    quote: Cosine similarity is a metric used to measure how similar two vectors are.
    char_start: 0
    char_end: 74
- statement: Cosine similarity is utilized by DuckDB for comparing vector embeddings.
  type: definition
  entity: cosine similarity
  keywords:
  - definition
  - cosine
  - similarity
  - utilized
  - duckdb
  - comparing
  - vector
  - embeddings
  source:
    doc: motherduck.com/blog/streamlining-ai-agents-duckdb-rag-solutions.md
    quote: DuckDB utilizes cosine similarity for comparing vector embeddings.
    char_start: 0
    char_end: 66
- statement: Cost-Effectiveness balances performance needs with resource utilization.
  type: definition
  entity: Cost-Effectiveness
  keywords:
  - definition
  - cost
  - effectiveness
  - balances
  - performance
  - needs
  - resource
  - utilization
  source:
    doc: motherduck.com/case-studies/atm-com-analytics-costs-sql-expressibility.md
    quote: Cost-Effectiveness Balance performance needs with resource utilization
      to create economically viable solutions.
    char_start: 0
    char_end: 111
- statement: Count is an exotic notebook with a Canva style.
  type: definition
  entity: Count
  keywords:
  - definition
  - count
  - exotic
  - notebook
  - canva
  - style
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: 'Count: Exotic notebook with a Canva style.'
    char_start: 0
    char_end: 42
- statement: The create_fts_index command is used to create a full text search index.
  type: definition
  entity: create_fts_index
  keywords:
  - definition
  - create
  - fts
  - index
  - command
  - used
  - full
  - text
  - search
  source:
    doc: motherduck.com/blog/search-using-duckdb-part-3.md
    quote: 'We can now create the index using: pragma create_fts_index.'
    char_start: 0
    char_end: 59
- statement: Crescent empowers your journey with data by assessing where you are,
    defining a strategy of where to go, and developing using expert knowledge.
  type: definition
  entity: Crescent
  keywords:
  - definition
  - crescent
  - empowers
  - journey
  - data
  - assessing
  - defining
  - strategy
  - go
  - developing
  - using
  - expert
  - knowledge
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: We empower your journey with data by assessing where you are, defining
      a strategy of where to go, and developing using expert knowledge.
    char_start: 0
    char_end: 136
- statement: Cron jobs are used for automating data engineering tasks.
  type: definition
  entity: Cron jobs
  keywords:
  - definition
  - cron
  - jobs
  - used
  - automating
  - data
  - engineering
  - tasks
  source:
    doc: motherduck.com/learn-more/bigquery-alternative-motherduck.md
    quote: Basic automation scripts without the need for a heavy tool.
    char_start: 0
    char_end: 59
- statement: Crontabs are another way to schedule commands daily.
  type: definition
  entity: Crontabs
  keywords:
  - definition
  - crontabs
  - another
  - way
  - schedule
  - commands
  - daily
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-essential-tools.md
    quote: Crontabs are another way to schedule them daily, for example.
    char_start: 0
    char_end: 61
- statement: Crunchy Bridge adds Iceberg to Postgres.
  type: definition
  entity: Crunchy Bridge
  keywords:
  - definition
  - crunchy
  - bridge
  - adds
  - iceberg
  - postgres
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-five.md
    quote: Crunchy Bridge Adds Iceberg to Postgres & Powerful Analytics Features
    char_start: 0
    char_end: 69
- statement: Crunchy Data is extending Postgres features with DuckDB functionality.
  type: definition
  entity: Crunchy Data
  keywords:
  - definition
  - crunchy
  - data
  - extending
  - postgres
  - features
  - duckdb
  - functionality
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: Crunchy Data (one Postgres for Cloud) is extending Postgres features with
      DuckDB functionality.
    char_start: 0
    char_end: 95
- statement: Astrodata provides expert data engineering, analytics, software engineering
    and AI services.
  type: definition
  entity: CSV
  keywords:
  - definition
  - astrodata
  - provides
  - expert
  - data
  - engineering
  - analytics
  - software
  - ai
  - services
  source:
    doc: motherduck.com/glossary/Apache Arrow.md
    quote: Astrodata provides expert data engineering, analytics, software engineering
      and AI services.
    char_start: 0
    char_end: 92
- statement: BigQuery is designed for high concurrency on massive datasets.
  type: definition
  entity: CSV
  keywords:
  - definition
  - bigquery
  - designed
  - high
  - concurrency
  - massive
  - datasets
  source:
    doc: motherduck.com/ecosystem/hevo.md
    quote: BigQuery is designed for high concurrency on massive datasets.
    char_start: 0
    char_end: 62
- statement: Common alternatives to Parquet include row-based formats like CSV and
    Avro, and other columnar formats like Apache ORC.
  type: definition
  entity: CSV
  keywords:
  - definition
  - common
  - alternatives
  - parquet
  - include
  - row
  - based
  - formats
  - like
  - csv
  - avro
  - columnar
  - apache
  - orc
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Common alternatives to Parquet include row-based formats like CSV and Avro,
      and other columnar formats like Apache ORC.
    char_start: 0
    char_end: 119
- statement: 'CSV Error on Line: 35365 indicates a conversion issue.'
  type: definition
  entity: CSV
  keywords:
  - definition
  - csv
  - error
  - line
  - '35365'
  - indicates
  - conversion
  - issue
  source:
    doc: motherduck.com/blog/csv-files-persist-duckdb-solution.md
    quote: 'Conversion Error: CSV Error on Line: 35365'
    char_start: 0
    char_end: 42
- statement: CSV files are a straightforward, text-based format that organizes data
    in a tabular form.
  type: definition
  entity: CSV
  keywords:
  - definition
  - csv
  - files
  - straightforward
  - text
  - based
  - format
  - organizes
  - data
  - tabular
  - form
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: CSV files are a straightforward, text-based format that organizes data
      in a tabular form.
    char_start: 0
    char_end: 89
- statement: CSV files are still relevant in data management.
  type: definition
  entity: CSV
  keywords:
  - definition
  - csv
  - files
  - still
  - relevant
  - data
  - management
  source:
    doc: motherduck.com/blog/csv-files-persist-duckdb-solution.md
    quote: The biggest challenges when reading CSVs
    char_start: 0
    char_end: 40
- statement: CSV files persist for many reasons despite the existence of more efficient
    formats.
  type: definition
  entity: CSV
  keywords:
  - definition
  - csv
  - files
  - persist
  - many
  - reasons
  - despite
  - existence
  - efficient
  - formats
  source:
    doc: motherduck.com/blog/csv-files-persist-duckdb-solution.md
    quote: Yes, there are far more efficient formats, such as Parquet, which avoid
      schema nightmares thanks to their typing, but CSV files persist for many reasons.
    char_start: 0
    char_end: 153
- statement: CSV is a file format used for data storage.
  type: definition
  entity: CSV
  keywords:
  - definition
  - csv
  - file
  - format
  - used
  - data
  - storage
  source:
    doc: motherduck.com/videos/simple-way-to-convert-csv-and-parquet-files.md
    quote: CSV
    char_start: 0
    char_end: 3
- statement: CSV parsing is a challenging problem for database vendors.
  type: definition
  entity: CSV
  keywords:
  - definition
  - csv
  - parsing
  - challenging
  - problem
  - database
  - vendors
  source:
    doc: motherduck.com/blog/making-pyspark-code-faster-with-duckdb.md
    quote: It turns out the CSV parsing is actually hard.
    char_start: 0
    char_end: 46
- statement: dlt is an open-source data loading tool that simplifies the process of
    moving data from various sources into data warehouses or lakes.
  type: definition
  entity: CSV
  keywords:
  - definition
  - dlt
  - open
  - source
  - data
  - loading
  - tool
  - simplifies
  - process
  - moving
  - various
  - sources
  - warehouses
  - lakes
  source:
    doc: motherduck.com/ecosystem/sqlmesh.md
    quote: dlt is an open-source data loading tool that simplifies the process of
      moving data from various sources into data warehouses or lakes.
    char_start: 0
    char_end: 134
- statement: Manual cleaning is often more efficient than automation for data preparation.
  type: definition
  entity: CSV
  keywords:
  - definition
  - manual
  - cleaning
  - often
  - efficient
  - automation
  - data
  - preparation
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md
    quote: Sometimes, quick manual cleanup is the most efficient approach.
    char_start: 0
    char_end: 63
- statement: MotherDuck is the GOAT.
  type: definition
  entity: CSV
  keywords:
  - definition
  - motherduck
  - goat
  source:
    doc: motherduck.com/duckdb-book-summary-chapter4.md
    quote: 'As Hamm succinctly puts it: ''MotherDuck is the GOAT.'''
    char_start: 0
    char_end: 53
- statement: Neon is a cloud-native PostgreSQL database service.
  type: definition
  entity: CSV
  keywords:
  - definition
  - neon
  - cloud
  - native
  - postgresql
  - database
  - service
  source:
    doc: motherduck.com/ecosystem/polytomic.md
    quote: To quickly get started with a cloud PostgreSQL database, we'll use Neon.
    char_start: 0
    char_end: 72
- statement: Rill allows you to create dashboards using only SQL and YAML files.
  type: definition
  entity: CSV
  keywords:
  - definition
  - rill
  - allows
  - create
  - dashboards
  - using
  - sql
  - yaml
  - files
  source:
    doc: motherduck.com/ecosystem/rill-data.md
    quote: Rill, by Rilldata, allows you to create dashboards using only SQL and YAML
      files.
    char_start: 0
    char_end: 81
- statement: The dataset is available in CSV format.
  type: definition
  entity: CSV
  keywords:
  - definition
  - dataset
  - available
  - csv
  - format
  source:
    doc: motherduck.com/blog/csv-files-persist-duckdb-solution.md
    quote: 'These files are available on their website: https://survey.stackoverflow.co/'
    char_start: 0
    char_end: 76
- statement: The script ingests monthly orders with one CSV file per month.
  type: definition
  entity: CSV
  keywords:
  - definition
  - script
  - ingests
  - monthly
  - orders
  - one
  - csv
  - file
  - per
  - month
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-three.md
    quote: This script ingests monthly orders with one CSV file per month.
    char_start: 0
    char_end: 63
- statement: Vector databases store embeddings for AI workloads.
  type: definition
  entity: CSV
  keywords:
  - definition
  - vector
  - databases
  - store
  - embeddings
  - ai
  - workloads
  source:
    doc: motherduck.com/glossary/S3 bucket.md
    quote: However, there are also AI vector databases that store embeddings for AI
      workloads.
    char_start: 0
    char_end: 83
- statement: dbt can output data in CSV format.
  type: definition
  entity: CSV file
  keywords:
  - definition
  - dbt
  - output
  - data
  - csv
  - format
  source:
    doc: motherduck.com/learn-more/secure-startup-data-warehouse.md
    quote: dbt can output data in CSV format.
    char_start: 0
    char_end: 34
- statement: Once your data is loaded into your database, check that it’s there.
  type: definition
  entity: CSV file
  keywords:
  - definition
  - data
  - loaded
  - database
  - check
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-four.md
    quote: Once your data is loaded into your database, check that it’s there.
    char_start: 0
    char_end: 67
- statement: DuckDB can handle inconsistent schemas across files.
  type: definition
  entity: CSV sniffer
  keywords:
  - definition
  - duckdb
  - handle
  - inconsistent
  - schemas
  - across
  - files
  source:
    doc: motherduck.com/learn-more/data-warehouse-tco.md
    quote: Strategies for dealing with inconsistent schemas across files...
    char_start: 0
    char_end: 64
- statement: DuckDB will halt the import on the first error.
  type: definition
  entity: CSV sniffer
  keywords:
  - definition
  - duckdb
  - halt
  - import
  - first
  - error
  source:
    doc: motherduck.com/learn-more/data-warehouse-tco.md
    quote: By default, DuckDB will halt the import on the first error.
    char_start: 0
    char_end: 59
- statement: ignore_errors = true tells the reader to drop rows with errors.
  type: definition
  entity: CSV sniffer
  keywords:
  - definition
  - ignore
  - errors
  - 'true'
  - tells
  - reader
  - drop
  - rows
  source:
    doc: motherduck.com/learn-more/data-warehouse-tco.md
    quote: 'ignore_errors = true tells the reader: if you hit a row where ''Age''
      can''t become an INTEGER, just drop that row and keep going.'
    char_start: 0
    char_end: 127
- statement: The sniffer tests 24 different combinations of dialect configurations.
  type: definition
  entity: CSV sniffer
  keywords:
  - definition
  - sniffer
  - tests
  - '24'
  - different
  - combinations
  - dialect
  - configurations
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: the sniffer tests 24 different combinations of dialect configurations (delimiters,
      quotes, escapes, newlines)
    char_start: 0
    char_end: 109
- statement: Cube and MotherDuck talk about the MDCuRe stack for building data apps.
  type: definition
  entity: Cube
  keywords:
  - definition
  - cube
  - motherduck
  - talk
  - about
  - mdcure
  - stack
  - building
  - data
  - apps
  source:
    doc: motherduck.com/videos.md
    quote: 'Cube and MotherDuck talk about the MDCuRe stack for building data apps:
      MotherDuck, Cube, React.'
    char_start: 0
    char_end: 96
- statement: Cube collaborates with MotherDuck on data app monetization.
  type: definition
  entity: Cube
  keywords:
  - definition
  - cube
  - collaborates
  - motherduck
  - data
  - app
  - monetization
  source:
    doc: motherduck.com/videos.md
    quote: Cube collaborates with MotherDuck on data app monetization.
    char_start: 0
    char_end: 59
- statement: Cube is an API-first analytics platform that enables data engineers and
    developers to build data applications.
  type: definition
  entity: Cube
  keywords:
  - definition
  - cube
  - api
  - first
  - analytics
  - platform
  - enables
  - data
  - engineers
  - developers
  - build
  - applications
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: Cube is an API-first analytics platform that enables data engineers and
      developers to build data applications.
    char_start: 0
    char_end: 110
- statement: curl is a command-line tool for transferring data with URLs.
  type: definition
  entity: curl
  keywords:
  - definition
  - curl
  - command
  - line
  - tool
  - transferring
  - data
  - urls
  source:
    doc: motherduck.com/blog/perf-is-not-enough.md
    quote: curl is a command-line tool for transferring data with URLs.
    char_start: 0
    char_end: 60
- statement: curl is used to check if an API is available.
  type: definition
  entity: curl
  keywords:
  - definition
  - curl
  - used
  - check
  - api
  - available
  source:
    doc: motherduck.com/blog/data-warehouse-feature-roundup-oct-2024.md
    quote: 'curl: Quickly check an API is available through the cmd line.'
    char_start: 0
    char_end: 61
- statement: current_date is a SQL function that returns the current date.
  type: definition
  entity: current_date
  keywords:
  - definition
  - current
  - date
  - sql
  - function
  - returns
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-essential-tools.md
    quote: current_date is a SQL function that returns the current date.
    char_start: 0
    char_end: 61
- statement: The result returned should be the date from seven days ago.
  type: definition
  entity: current_date
  keywords:
  - definition
  - result
  - returned
  - date
  - seven
  - days
  - ago
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: The result returned should be the date from seven days ago.
    char_start: 0
    char_end: 59
- statement: Cursor + MotherDuck setup makes AI write working SQL on the first try.
  type: definition
  entity: Cursor
  keywords:
  - definition
  - cursor
  - motherduck
  - setup
  - makes
  - ai
  - write
  - working
  - sql
  - first
  - try
  source:
    doc: motherduck.com/blog/announcing-duckdb-13-on-motherduck-cdw.md
    quote: Learn the exact Cursor + MotherDuck setup that makes AI write working SQL
      on the first try.
    char_start: 0
    char_end: 91
- statement: Cursor allows adding documentation sources, including official DuckDB
    and MotherDuck documentation.
  type: definition
  entity: Cursor
  keywords:
  - definition
  - cursor
  - allows
  - adding
  - documentation
  - sources
  - including
  - official
  - duckdb
  - motherduck
  source:
    doc: motherduck.com/videos/faster-data-pipelines-development-with-mcp-and-duckdb.md
    quote: Cursor allows adding documentation sources, including official DuckDB and
      MotherDuck documentation.
    char_start: 0
    char_end: 99
- statement: Cursor allows users to add documentation sources to be used as context
    in prompts.
  type: definition
  entity: Cursor
  keywords:
  - definition
  - cursor
  - allows
  - users
  - add
  - documentation
  - sources
  - used
  - context
  - prompts
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md
    quote: In Cursor, under `Settings > Cursor Settings > Features > Docs`, you can
      add documentation sources to be used as context in your prompts.
    char_start: 0
    char_end: 137
- statement: Cursor dramatically accelerates the development of data applications.
  type: definition
  entity: Cursor
  keywords:
  - definition
  - cursor
  - dramatically
  - accelerates
  - development
  - data
  - applications
  source:
    doc: motherduck.com/learn-more/duckdb-vs-sqlite-databases.md
    quote: Cursor, an AI-powered IDE built on VS Code, dramatically accelerates the
      development of data applications.
    char_start: 0
    char_end: 106
- statement: Cursor functions as a development environment for AI.
  type: definition
  entity: Cursor
  keywords:
  - definition
  - cursor
  - functions
  - development
  - environment
  - ai
  source:
    doc: motherduck.com/blog/vibe-coding-sql-cursor.md
    quote: The AI-first editor that functions as our development environment.
    char_start: 0
    char_end: 66
- statement: Cursor is an AI-powered IDE that accelerates the development of data
    applications.
  type: definition
  entity: Cursor
  keywords:
  - definition
  - cursor
  - ai
  - powered
  - ide
  - accelerates
  - development
  - data
  - applications
  source:
    doc: motherduck.com/videos.md
    quote: Archie from Evidence demonstrated how Cursor, an AI-powered IDE built on
      VS Code, dramatically accelerates the development of data applications.
    char_start: 0
    char_end: 144
- statement: Cursor supports adding documentation sources.
  type: definition
  entity: Cursor
  keywords:
  - definition
  - cursor
  - supports
  - adding
  - documentation
  - sources
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: Cursor, for instance, supports adding documentation sources.
    char_start: 0
    char_end: 60
- statement: Users can reference documentation in their prompts using an alias.
  type: definition
  entity: Cursor
  keywords:
  - definition
  - users
  - reference
  - documentation
  - prompts
  - using
  - alias
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md
    quote: Once these are added, you can reference them in your prompt using `@docs
      <my alias name>`.
    char_start: 0
    char_end: 90
- statement: The customer table in SQLite is replaced by customerf in DuckDB.
  type: definition
  entity: customer
  keywords:
  - definition
  - customer
  - table
  - sqlite
  - replaced
  - customerf
  - duckdb
  source:
    doc: motherduck.com/blog/data-engineer-highlights-PyConDE-2023.md
    quote: The customer table in SQLite is replaced by customerf in DuckDB.
    char_start: 0
    char_end: 64
- statement: Customer Acquisition Cost (CAC) is the cost of acquiring a new customer.
  type: definition
  entity: Customer Acquisition Cost
  keywords:
  - definition
  - customer
  - acquisition
  - cost
  - cac
  - acquiring
  - new
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: Customer Acquisition Cost (CAC)
    char_start: 0
    char_end: 31
- statement: The average CAC is calculated by summing the costs and dividing by the
    number of distinct users.
  type: definition
  entity: Customer Acquisition Cost
  keywords:
  - definition
  - average
  - cac
  - calculated
  - summing
  - costs
  - dividing
  - number
  - distinct
  - users
  source:
    doc: motherduck.com/videos/faster-data-pipelines-development-with-mcp-and-duckdb.md
    quote: This query calculates the average CAC by summing the costs in the acquisition_costs
      table and dividing by the number of distinct users acquired.
    char_start: 0
    char_end: 144
- statement: Customer Lifetime Value estimates the total revenue a customer will generate.
  type: definition
  entity: Customer Lifetime Value
  keywords:
  - definition
  - customer
  - lifetime
  - value
  - estimates
  - total
  - revenue
  - generate
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-use-cases.md
    quote: Estimates the total revenue a customer will generate.
    char_start: 0
    char_end: 53
- statement: Customer Lifetime Value (CLTV or LTV) predicts the net profit from a
    customer relationship.
  type: definition
  entity: Customer Lifetime Value (CLTV or LTV)
  keywords:
  - definition
  - customer
  - lifetime
  - value
  - cltv
  - ltv
  - predicts
  - net
  - profit
  - relationship
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: Customer Lifetime Value (CLTV or LTV)
    char_start: 0
    char_end: 37
- statement: Queries must return in under a second to provide an interactive user
    experience.
  type: definition
  entity: customer-facing analytics dashboards
  keywords:
  - definition
  - queries
  - return
  - second
  - provide
  - interactive
  - user
  - experience
  source:
    doc: motherduck.com/videos/pg_duckdb-postgres-analytics-just-got-faster-with-duckdb.md
    quote: Queries must return in under a second to provide an interactive user experience.
    char_start: 0
    char_end: 80
- statement: The customer_segmentation_query_task segments customers based on recent
    e-commerce data.
  type: definition
  entity: customer_segmentation_query_task
  keywords:
  - definition
  - customer
  - segmentation
  - query
  - task
  - segments
  - customers
  - based
  - recent
  - commerce
  - data
  source:
    doc: motherduck.com/blog/estuary-streaming-cdc-replication.md
    quote: A task that segments customers based on recent e-commerce data.
    char_start: 0
    char_end: 63
- statement: Dagster enhances developer workflow and productivity.
  type: definition
  entity: Dagster
  keywords:
  - definition
  - dagster
  - enhances
  - developer
  - workflow
  - productivity
  source:
    doc: motherduck.com/videos/from-core-to-custom-unlocking-new-possibilities-with-duckdb-extensions.md
    quote: Dagster presents itself as a modern data orchestrator focused on enhancing
      developer workflow and productivity.
    char_start: 0
    char_end: 111
- statement: Dagster introduces a paradigm shift towards assets in data pipeline management.
  type: definition
  entity: Dagster
  keywords:
  - definition
  - dagster
  - introduces
  - paradigm
  - shift
  - towards
  - assets
  - data
  - pipeline
  - management
  source:
    doc: motherduck.com/videos/duckfooding-at-motherduck.md
    quote: Unlike traditional orchestrators that focus on tasks as discrete units
      of work, Dagster introduces a paradigm shift towards assets.
    char_start: 0
    char_end: 131
- statement: Dagster is a data orchestrator for machine learning, analytics, and ETL.
  type: definition
  entity: Dagster
  keywords:
  - definition
  - dagster
  - data
  - orchestrator
  - machine
  - learning
  - analytics
  - etl
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: A data orchestrator for machine learning, analytics, and ETL.
    char_start: 0
    char_end: 61
- statement: Dagster, MotherDuck, and Evidence present an unprecedented opportunity
    to reshape how data pipelines are developed.
  type: definition
  entity: Dagster
  keywords:
  - definition
  - dagster
  - motherduck
  - evidence
  - present
  - unprecedented
  - opportunity
  - reshape
  - data
  - pipelines
  - developed
  source:
    doc: motherduck.com/quacking-around-the-web.md
    quote: the integration of Dagster, MotherDuck, and Evidence presents an unprecedented
      opportunity to reshape how data pipelines are developed, managed, and scaled.
    char_start: 0
    char_end: 156
- statement: Develop locally and ship to production confidently with Dagster.
  type: definition
  entity: Dagster
  keywords:
  - definition
  - develop
  - locally
  - ship
  - production
  - confidently
  - dagster
  source:
    doc: motherduck.com/videos.md
    quote: Develop locally and ship to production confidently with Dagster.
    char_start: 0
    char_end: 64
- statement: Exploring these tools further is not just an option—it's a necessity
    for data professionals.
  type: definition
  entity: Dagster
  keywords:
  - definition
  - exploring
  - tools
  - option
  - necessity
  - data
  - professionals
  source:
    doc: motherduck.com/quacking-around-the-web.md
    quote: For data professionals seeking to tackle the challenges of data engineering,
      exploring these tools further is not just an option—it's a necessity.
    char_start: 0
    char_end: 146
- statement: The switch from Airflow to Dagster was driven by seamless dbt integration.
  type: definition
  entity: Dagster
  keywords:
  - definition
  - switch
  - airflow
  - dagster
  - driven
  - seamless
  - dbt
  - integration
  source:
    doc: motherduck.com/learn-more/fix-slow-bi-dashboards.md
    quote: The switch from Airflow to Dagster was driven by seamless dbt integration.
    char_start: 0
    char_end: 74
- statement: Daniel Beach is a senior Data engineer and an active writer in the data
    engineering community.
  type: definition
  entity: Daniel Beach
  keywords:
  - definition
  - daniel
  - beach
  - senior
  - data
  - engineer
  - active
  - writer
  - engineering
  - community
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2024.md
    quote: Daniel Beach is a senior Data engineer and a an active writer in the data
      engineering community through data engineering central and confession data guy.
    char_start: 0
    char_end: 153
- statement: The 2023 Darkbeam incident is a reminder of the risks of misconfiguration.
  type: definition
  entity: Darkbeam incident
  keywords:
  - definition
  - '2023'
  - darkbeam
  - incident
  - reminder
  - risks
  - misconfiguration
  source:
    doc: motherduck.com/videos/understanding-ducklake-a-table-format-with-a-modern-architecture.md
    quote: The 2023 Darkbeam incident, where an unauthenticated Elasticsearch and
      Kibana interface was publicly exposed due to human error, is a stark reminder
      of this reality.
    char_start: 0
    char_end: 165
- statement: Dashboards are user interfaces that display data visualizations and metrics.
  type: definition
  entity: dashboard
  keywords:
  - definition
  - dashboards
  - user
  - interfaces
  - display
  - data
  - visualizations
  - metrics
  source:
    doc: motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud.md
    quote: Building the dashboard.
    char_start: 0
    char_end: 23
- statement: Dask scales Python code from multi-core local machines to large distributed
    clusters in the cloud.
  type: definition
  entity: Dask
  keywords:
  - definition
  - dask
  - scales
  - python
  - code
  - multi
  - core
  - local
  - machines
  - large
  - distributed
  - clusters
  - cloud
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: Dask scales Python code from multi-core local machines to large distributed
      clusters in the cloud.
    char_start: 0
    char_end: 98
- statement: The DATA+AI Summit is organized by Databricks.
  type: definition
  entity: Data + AI Summit
  keywords:
  - definition
  - data
  - ai
  - summit
  - organized
  - databricks
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-use-cases.md
    quote: Adi Polak was interviewed after the DATA+AI summit.
    char_start: 0
    char_end: 51
- statement: The Data App Generator is a tool for generating data applications.
  type: definition
  entity: Data App Generator
  keywords:
  - definition
  - data
  - app
  - generator
  - tool
  - generating
  - applications
  source:
    doc: motherduck.com/blog/data-app-generator.md
    quote: What is a Data App?
    char_start: 0
    char_end: 19
- statement: Data application architecture encompasses the entire data lifecycle,
    from ingestion to visualization.
  type: definition
  entity: Data Application Architecture
  keywords:
  - definition
  - data
  - application
  - architecture
  - encompasses
  - entire
  - lifecycle
  - ingestion
  - visualization
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: It encompasses the entire data lifecycle, from ingestion to visualization.
    char_start: 0
    char_end: 74
- statement: Data application architecture is a critical framework for designing,
    implementing, and maintaining effective data solutions.
  type: definition
  entity: Data Application Architecture
  keywords:
  - definition
  - data
  - application
  - architecture
  - critical
  - framework
  - designing
  - implementing
  - maintaining
  - effective
  - solutions
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: Data application architecture stands as a critical framework for designing,
      implementing, and maintaining effective data solutions.
    char_start: 0
    char_end: 131
- statement: All applications are becoming data applications.
  type: definition
  entity: data applications
  keywords:
  - definition
  - applications
  - becoming
  - data
  source:
    doc: motherduck.com/blog/MotherDuck-Visualize-Embeddings-Marimo.md
    quote: All applications are becoming data applications.
    char_start: 0
    char_end: 48
- statement: Data applications can automate complex data processes.
  type: definition
  entity: data applications
  keywords:
  - definition
  - data
  - applications
  - automate
  - complex
  - processes
  source:
    doc: motherduck.com/learn-more/data-application.md
    quote: Data applications can automate complex data processes, freeing up resources
      and reducing the time required to generate insights.
    char_start: 0
    char_end: 128
- statement: Data Cataloging uses metadata management tools to maintain a clear inventory
    of data assets.
  type: definition
  entity: Data Catalogs
  keywords:
  - definition
  - data
  - cataloging
  - uses
  - metadata
  - management
  - tools
  - maintain
  - clear
  - inventory
  - assets
  source:
    doc: motherduck.com/learn-more/data-application-architecture.md
    quote: Implement Data Cataloging Use metadata management tools to maintain a clear
      inventory of data assets and their relationships.
    char_start: 0
    char_end: 125
- statement: Data Catalogs provide a lookup for datasets in data lakes.
  type: definition
  entity: Data Catalogs
  keywords:
  - definition
  - data
  - catalogs
  - provide
  - lookup
  - datasets
  - lakes
  source:
    doc: motherduck.com/blog/solving-advent-code-duckdb-dbt.md
    quote: You can view open data catalogs as a lookup service for the datasets in
      your data lake.
    char_start: 0
    char_end: 87
- statement: DataFrames are invaluable during data cleaning and feature engineering.
  type: definition
  entity: data cleaning
  keywords:
  - definition
  - dataframes
  - invaluable
  - data
  - cleaning
  - feature
  - engineering
  source:
    doc: motherduck.com/videos/pg_duckdb-postgres-analytics-just-got-faster-with-duckdb.md
    quote: This flexibility is invaluable during data cleaning and feature engineering.
    char_start: 0
    char_end: 76
- statement: Data contracts specify the schema, quality standards, and ownership of
    a dataset.
  type: definition
  entity: Data Contracts
  keywords:
  - definition
  - data
  - contracts
  - specify
  - schema
  - quality
  - standards
  - ownership
  - dataset
  source:
    doc: motherduck.com/learn-more/hybrid-analytics-guide.md
    quote: These contracts specify the schema, quality standards, and ownership of
      a dataset.
    char_start: 0
    char_end: 82
- statement: Data Council hosts events and conferences related to data science and
    analytics.
  type: definition
  entity: Data Council
  keywords:
  - definition
  - data
  - council
  - hosts
  - events
  - conferences
  - related
  - science
  - analytics
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md
    quote: An organization that hosts events and conferences related to data science
      and analytics.
    char_start: 0
    char_end: 88
- statement: Data egress charges apply when moving information between cloud systems.
  type: definition
  entity: Data Egress Charges
  keywords:
  - definition
  - data
  - egress
  - charges
  - apply
  - moving
  - information
  - cloud
  - systems
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: Data egress charges apply when moving information between cloud systems
      or exporting to other services.
    char_start: 0
    char_end: 103
- statement: The best data engineers step outside their technical comfort zone and
    engage with stakeholders.
  type: definition
  entity: data engineer
  keywords:
  - definition
  - best
  - data
  - engineers
  - step
  - outside
  - technical
  - comfort
  - zone
  - engage
  - stakeholders
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: The best data engineers step outside their technical comfort zone and engage
      with stakeholders.
    char_start: 0
    char_end: 95
- statement: Today's data engineers face challenges similar to those of data scientists,
    with added complexity of infrastructure setup.
  type: definition
  entity: data engineer
  keywords:
  - definition
  - today
  - data
  - engineers
  - face
  - challenges
  - similar
  - scientists
  - added
  - complexity
  - infrastructure
  - setup
  source:
    doc: motherduck.com/blog/announcing-duckdb-13-on-motherduck-cdw.md
    quote: I'd argue that today's data engineers face similar challenges, but with
      the added complexity of infrastructure setup.
    char_start: 0
    char_end: 117
- statement: By the end of this 3-week roadmap, you should have learned a lot, especially
    the key components of data engineering.
  type: definition
  entity: data engineering
  keywords:
  - definition
  - end
  - week
  - roadmap
  - learned
  - lot
  - especially
  - key
  - components
  - data
  - engineering
  source:
    doc: motherduck.com/blog/summer-data-engineering-roadmap.md
    quote: By the end of this 3-week roadmap, you should have learned a lot, especially
      the key components of data engineering.
    char_start: 0
    char_end: 116
- statement: Data engineering is the field focused on the design and management of
    data systems.
  type: definition
  entity: data engineering
  keywords:
  - definition
  - data
  - engineering
  - field
  - focused
  - design
  - management
  - systems
  source:
    doc: motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud.md
    quote: data engineering
    char_start: 0
    char_end: 16
- statement: Skilled log analysis is critical for the data engineer's success.
  type: definition
  entity: data engineering
  keywords:
  - definition
  - skilled
  - log
  - analysis
  - critical
  - data
  - engineer
  - success
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: skilled log analysis is critical for the data engineer's success.
    char_start: 0
    char_end: 65
- statement: Technical expertise alone isn't always enough; strong communication skills
    and business understanding transform data engineers into 10x contributors.
  type: definition
  entity: data engineering
  keywords:
  - definition
  - technical
  - expertise
  - alone
  - isn
  - always
  - enough
  - strong
  - communication
  - skills
  - business
  - understanding
  - transform
  - data
  - engineers
  - 10x
  - contributors
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: Technical expertise alone isn't always enough; strong communication skills
      and business understanding transform data engineers into 10x contributors.
    char_start: 0
    char_end: 149
- statement: The Data Engineer Toolkit covers advanced data engineering tools.
  type: definition
  entity: data engineering
  keywords:
  - definition
  - data
  - engineer
  - toolkit
  - covers
  - advanced
  - engineering
  - tools
  source:
    doc: motherduck.com/blog/announcing-duckdb-snippet-sets-with-motherduck-sharing-databases.md
    quote: A comprehensive guide to advanced data engineering tools covering everything
      from SQL engines and orchestration platforms to DevOps, data quality, AI workflows,
      and the soft skills needed to build pro
    char_start: 0
    char_end: 229
- statement: You have a rough idea of what real-time data workloads look like.
  type: definition
  entity: data engineering
  keywords:
  - definition
  - rough
  - idea
  - what
  - real
  - time
  - data
  - workloads
  - look
  - like
  source:
    doc: motherduck.com/blog/summer-data-engineering-roadmap.md
    quote: You have a rough idea of what real-time data workloads look like.
    char_start: 0
    char_end: 65
- statement: Data Fabric creates a unified data management layer that spans hybrid
    and multi-cloud environments.
  type: definition
  entity: Data Fabric
  keywords:
  - definition
  - data
  - fabric
  - creates
  - unified
  - management
  - layer
  - spans
  - hybrid
  - multi
  - cloud
  - environments
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: Data Fabric Creating a unified data management layer that spans hybrid
      and multi-cloud environments.
    char_start: 0
    char_end: 100
- statement: Data governance & lineage is essential for ensuring compliance, security,
    and trustworthiness.
  type: definition
  entity: data governance & lineage
  keywords:
  - definition
  - data
  - governance
  - lineage
  - essential
  - ensuring
  - compliance
  - security
  - trustworthiness
  source:
    doc: motherduck.com/blog/how-to-extract-analytics-from-bluesky.md
    quote: This is often overlooked in architectural diagrams but is essential for
      ensuring the compliance, security, and trustworthiness of the data architecture.
    char_start: 0
    char_end: 152
- statement: Data governance at scale is essential for systematic data management.
  type: definition
  entity: Data governance catalog
  keywords:
  - definition
  - data
  - governance
  - scale
  - essential
  - systematic
  - management
  source:
    doc: motherduck.com/learn-more/hybrid-analytics-guide.md
    quote: allowing you to systematically clean data or mask PII before exposing it
      to a wider audience.
    char_start: 0
    char_end: 93
- statement: Data governance catalogs help for centrally defined governance policies
    across different databases.
  type: definition
  entity: Data governance catalog
  keywords:
  - definition
  - data
  - governance
  - catalogs
  - help
  - centrally
  - defined
  - policies
  - across
  - different
  - databases
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-seven.md
    quote: helps for centrally defined governance policies across different databases
      and searchable metadata.
    char_start: 0
    char_end: 99
- statement: 'Effective governance relies on three pillars: Access Control, Metric
    Consistency, and Process.'
  type: definition
  entity: Data governance catalog
  keywords:
  - definition
  - effective
  - governance
  - relies
  - three
  - pillars
  - access
  - control
  - metric
  - consistency
  - process
  source:
    doc: motherduck.com/videos/simple-way-to-convert-csv-and-parquet-files.md
    quote: 'Effective governance relies on three pillars: 1) Access Control... 3)
      Process...'
    char_start: 0
    char_end: 80
- statement: Data applications start with robust data ingestion capabilities.
  type: definition
  entity: Data Ingestion
  keywords:
  - definition
  - data
  - applications
  - start
  - robust
  - ingestion
  - capabilities
  source:
    doc: motherduck.com/ecosystem.md
    quote: Data applications start with robust data ingestion capabilities.
    char_start: 0
    char_end: 64
- statement: Data integration systems excel in extracting data and effectively mapping
    data types.
  type: definition
  entity: data integration systems
  keywords:
  - definition
  - data
  - integration
  - systems
  - excel
  - extracting
  - effectively
  - mapping
  - types
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2024.md
    quote: These data integration systems excel in extracting data and effectively
      mapping data types to their respective destinations.
    char_start: 0
    char_end: 124
- statement: Data lakes can turn into 'data swamps' without strong governance.
  type: definition
  entity: Data Lake
  keywords:
  - definition
  - data
  - lakes
  - turn
  - swamps
  - without
  - strong
  - governance
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: However, without strong governance, data lakes can turn into 'data swamps'
      – disorganized, undocumented, and ultimately unusable repositories of data.
    char_start: 0
    char_end: 150
- statement: Data Load Tool simplifies the process of building data pipelines.
  type: definition
  entity: Data Load Tool
  keywords:
  - definition
  - data
  - load
  - tool
  - simplifies
  - process
  - building
  - pipelines
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: dlt is an open-source Python library designed to simplify the process of
      building data pipelines.
    char_start: 0
    char_end: 97
- statement: dlt supports extracting data from various sources.
  type: definition
  entity: Data Load Tool
  keywords:
  - definition
  - dlt
  - supports
  - extracting
  - data
  - various
  - sources
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: dlt supports extracting data from various sources, including APIs and databases.
    char_start: 0
    char_end: 80
- statement: Data Mesh is a decentralized approach that treats data as a product.
  type: definition
  entity: Data Mesh
  keywords:
  - definition
  - data
  - mesh
  - decentralized
  - approach
  - treats
  - product
  source:
    doc: motherduck.com/learn-more/data-application-architecture.md
    quote: Data Mesh A decentralized approach that treats data as a product.
    char_start: 0
    char_end: 65
- statement: Data Mesh Architecture empowers domain-specific teams to own and manage
    their data products.
  type: definition
  entity: Data Mesh Architecture
  keywords:
  - definition
  - data
  - mesh
  - architecture
  - empowers
  - domain
  - specific
  - teams
  - manage
  - products
  source:
    doc: motherduck.com/learn-more/data-application.md
    quote: A decentralized approach to data management, empowering domain-specific
      teams to own and manage their data products.
    char_start: 0
    char_end: 116
- statement: Data Minded specializes in data engineering and analytics.
  type: definition
  entity: Data Minded
  keywords:
  - definition
  - data
  - minded
  - specializes
  - engineering
  - analytics
  source:
    doc: motherduck.com/videos.md
    quote: Niels Claeys of Data Minded
    char_start: 0
    char_end: 27
- statement: Data modeling is critical to learn with the rise of AI and automation.
  type: definition
  entity: data modeling
  keywords:
  - definition
  - data
  - modeling
  - critical
  - learn
  - rise
  - ai
  - automation
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: However, with the rise of AI and automation, it hasn't been more critical
      to learn.
    char_start: 0
    char_end: 83
- statement: Data modeling, and listening or asking questions to the business users
    is crucial.
  type: definition
  entity: data modeling
  keywords:
  - definition
  - data
  - modeling
  - listening
  - asking
  - questions
  - business
  - users
  - crucial
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: Data modeling, and listening or asking questions to the business users.
    char_start: 0
    char_end: 71
- statement: Efficient data partitioning and query optimization can analyze large
    datasets effectively.
  type: definition
  entity: data partitioning
  keywords:
  - definition
  - efficient
  - data
  - partitioning
  - query
  - optimization
  - analyze
  - large
  - datasets
  - effectively
  source:
    doc: motherduck.com/videos/from-core-to-custom-unlocking-new-possibilities-with-duckdb-extensions.md
    quote: careful data partitioning and query optimization allow even billion-row
      datasets to be analyzed efficiently.
    char_start: 0
    char_end: 108
- statement: Data Pipeline Logs document each step of orchestration tools.
  type: definition
  entity: Data Pipeline Logs
  keywords:
  - definition
  - data
  - pipeline
  - logs
  - document
  - step
  - orchestration
  - tools
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: 'Data Pipeline Logs: Changes and logs of orchestration tools documenting
      each step.'
    char_start: 0
    char_end: 82
- statement: Data pipelines frequently involve multiple tools, complex transformations,
    and a heavy reliance on data storage.
  type: definition
  entity: Data Pipelines
  keywords:
  - definition
  - data
  - pipelines
  - frequently
  - involve
  - multiple
  - tools
  - complex
  - transformations
  - heavy
  - reliance
  - storage
  source:
    doc: motherduck.com/blog/simplifying-iot-analytics-motherduck.md
    quote: Data pipelines frequently involve multiple tools, complex transformations,
      and a heavy reliance on data storage.
    char_start: 0
    char_end: 112
- statement: Data locality has become crucial, with organizations recognizing the
    benefits of processing data where it lives whenever possible.
  type: definition
  entity: data processing
  keywords:
  - definition
  - data
  - locality
  - become
  - crucial
  - organizations
  - recognizing
  - benefits
  - processing
  - lives
  - whenever
  - possible
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: Data locality has become crucial, with organizations recognizing the benefits
      of processing data where it lives whenever possible.
    char_start: 0
    char_end: 130
- statement: Oversized solutions for modest data volumes lead to increased costs.
  type: definition
  entity: data processing
  keywords:
  - definition
  - oversized
  - solutions
  - modest
  - data
  - volumes
  - lead
  - increased
  - costs
  source:
    doc: motherduck.com/videos/from-core-to-custom-unlocking-new-possibilities-with-duckdb-extensions.md
    quote: A major cost driver is using oversized solutions for modest data volumes.
    char_start: 0
    char_end: 73
- statement: The industry is moving away from the 'bigger is better' mindset toward
    more efficient, practical solutions.
  type: definition
  entity: data processing
  keywords:
  - definition
  - industry
  - moving
  - away
  - bigger
  - better
  - mindset
  - toward
  - efficient
  - practical
  - solutions
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: The industry is moving away from the 'bigger is better' mindset toward
      more efficient, practical solutions.
    char_start: 0
    char_end: 107
- statement: Data often requires cleaning, normalization, and transformation.
  type: definition
  entity: Data Processing and Transformation
  keywords:
  - definition
  - data
  - often
  - requires
  - cleaning
  - normalization
  - transformation
  source:
    doc: motherduck.com/ecosystem.md
    quote: Once ingested, data often requires cleaning, normalization, and transformation.
    char_start: 0
    char_end: 79
- statement: Data Quality incorporates data validation, cleansing, and monitoring
    in data pipelines.
  type: definition
  entity: Data Quality
  keywords:
  - definition
  - data
  - quality
  - incorporates
  - validation
  - cleansing
  - monitoring
  - pipelines
  source:
    doc: motherduck.com/learn-more/data-application-architecture.md
    quote: Design for Data Quality Incorporate data validation, cleansing, and monitoring
      at multiple stages of the data pipeline.
    char_start: 0
    char_end: 119
- statement: Ensuring data accuracy and consistency across various sources remains
    a significant challenge in data application development.
  type: definition
  entity: Data Quality
  keywords:
  - definition
  - ensuring
  - data
  - accuracy
  - consistency
  - across
  - various
  - sources
  - remains
  - significant
  - challenge
  - application
  - development
  source:
    doc: motherduck.com/ecosystem.md
    quote: Data Quality and Consistency Ensuring data accuracy and consistency across
      various sources remains a significant challenge in data application development.
    char_start: 0
    char_end: 155
- statement: Data quality monitoring helps in detecting issues such as duplication
    and incorrect formatting.
  type: definition
  entity: Data Quality Monitoring
  keywords:
  - definition
  - data
  - quality
  - monitoring
  - helps
  - detecting
  - issues
  - duplication
  - incorrect
  - formatting
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: Set monitors and thresholds to automatically detect data quality issues
      such as duplication, incorrect formatting, and missing values.
    char_start: 0
    char_end: 134
- statement: Data Science Platforms provide end-to-end capabilities for data scientists.
  type: definition
  entity: Data Science Platforms
  keywords:
  - definition
  - data
  - science
  - platforms
  - provide
  - end
  - capabilities
  - scientists
  source:
    doc: motherduck.com/ecosystem.md
    quote: Data Science Platforms These comprehensive applications provide end-to-end
      capabilities for data scientists.
    char_start: 0
    char_end: 108
- statement: Data stacks and data platforms are essentially built around logs.
  type: definition
  entity: data stacks
  keywords:
  - definition
  - data
  - stacks
  - platforms
  - essentially
  - built
  - around
  - logs
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2024.md
    quote: Data stacks and data platforms are essentially built around logs.
    char_start: 0
    char_end: 65
- statement: Efficient data storage is crucial for data applications.
  type: definition
  entity: data storage
  keywords:
  - definition
  - efficient
  - data
  - storage
  - crucial
  - applications
  source:
    doc: motherduck.com/ecosystem.md
    quote: Efficient data storage is crucial for data applications.
    char_start: 0
    char_end: 56
- statement: The complexity of data systems can delay the moment when you can actually
    start querying your data.
  type: definition
  entity: data systems
  keywords:
  - definition
  - complexity
  - data
  - systems
  - delay
  - moment
  - actually
  - start
  - querying
  source:
    doc: motherduck.com/blog/python-faker-duckdb-exploration.md
    quote: the path to data analysis is often paved with complexity.
    char_start: 0
    char_end: 57
- statement: Self-service analytics enables business people to serve themselves.
  type: definition
  entity: Data Visualization
  keywords:
  - definition
  - self
  - service
  - analytics
  - enables
  - business
  - people
  - serve
  - themselves
  source:
    doc: motherduck.com/blog/streaming-oracle-to-motherduck.md
    quote: Self-service analytics enables business people to serve themselves.
    char_start: 0
    char_end: 67
- statement: A Data Lake is a centralized storage solution that holds raw data in
    its original format.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - data
  - lake
  - centralized
  - storage
  - solution
  - holds
  - raw
  - original
  - format
  source:
    doc: motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md
    quote: A Data Lake is a centralized storage solution that holds raw data in its
      original format.
    char_start: 0
    char_end: 89
- statement: A Data Lakehouse provides a scalable, affordable, and open foundation.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - data
  - lakehouse
  - provides
  - scalable
  - affordable
  - open
  - foundation
  source:
    doc: motherduck.com/blog/streamlining-ai-agents-duckdb-rag-solutions.md
    quote: This provides a scalable, affordable, and open foundation.
    char_start: 0
    char_end: 58
- statement: A data warehouse becomes the authoritative source for key business metrics.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - data
  - warehouse
  - becomes
  - authoritative
  - source
  - key
  - business
  - metrics
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: By integrating data from disparate systems and applying consistent definitions
      and business rules, the DWH becomes the authoritative source for key business
      metrics.
    char_start: 0
    char_end: 165
- statement: A Data Warehouse is a centralized repository that stores structured data
    from various sources.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - data
  - warehouse
  - centralized
  - repository
  - stores
  - structured
  - various
  - sources
  source:
    doc: motherduck.com/case-studies/layers-multi-tenant-data-warehouse.md
    quote: A Data Warehouse is a centralized repository that stores structured data
      from various sources in a highly organized format.
    char_start: 0
    char_end: 123
- statement: A Data Warehouse is a system used for reporting and data analysis.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - data
  - warehouse
  - system
  - used
  - reporting
  - analysis
  source:
    doc: motherduck.com/blog/streamkap-mysql-to-motherduck.md
    quote: What is a Data Warehouse?
    char_start: 0
    char_end: 25
- statement: A well-designed data warehouse allows business users to explore data
    independently.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - well
  - designed
  - data
  - warehouse
  - allows
  - business
  - users
  - explore
  - independently
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: A well-designed DWH, coupled with user-friendly BI tools, allows business
      users to explore data, create their reports, and answer their questions.
    char_start: 0
    char_end: 146
- statement: Cloud data warehouses can escalate costs if used for processing and storing
    raw data.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - cloud
  - data
  - warehouses
  - escalate
  - costs
  - used
  - processing
  - storing
  - raw
  source:
    doc: motherduck.com/blog/dosomething-motherduck-data-warehouse-ROI.md
    quote: Cloud data warehouses are powerful all-in-one tools, but costs can quickly
      escalate if used for processing and storing raw data.
    char_start: 0
    char_end: 128
- statement: Data can come from a multitude of places, including internal operational
    databases such as ERPs, CRMs, and billing systems.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - data
  - come
  - multitude
  - places
  - including
  - internal
  - operational
  - databases
  - erps
  - crms
  - billing
  - systems
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: Data can come from a multitude of places, including internal operational
      databases such as ERPs, CRMs, and billing systems.
    char_start: 0
    char_end: 123
- statement: Data catalogs are essential for future data platforms.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - data
  - catalogs
  - essential
  - future
  - platforms
  source:
    doc: motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md
    quote: Why are data catalogs essential for future data platforms?
    char_start: 0
    char_end: 58
- statement: Data Lake stores all data types in their raw format, ideal for Machine
    Learning and data exploration.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - data
  - lake
  - stores
  - types
  - raw
  - format
  - ideal
  - machine
  - learning
  - exploration
  source:
    doc: motherduck.com/case-studies/reflex-careers-gig-economy-retail.md
    quote: A Data Lake stores all data types (structured, unstructured) in their raw
      format...
    char_start: 0
    char_end: 83
- statement: Data Lake uses a schema-on-read model.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - data
  - lake
  - uses
  - schema
  - read
  - model
  source:
    doc: motherduck.com/blog/streamkap-mysql-to-motherduck.md
    quote: A data lake uses a schema-on-read model.
    char_start: 0
    char_end: 40
- statement: Data lakes are the foundation for training machine learning models.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - data
  - lakes
  - foundation
  - training
  - machine
  - learning
  - models
  source:
    doc: motherduck.com/blog/streamkap-mysql-to-motherduck.md
    quote: Data lakes are the foundation for training machine learning models.
    char_start: 0
    char_end: 67
- statement: Data Lakes are used for Machine Learning and Exploration.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - data
  - lakes
  - used
  - machine
  - learning
  - exploration
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: 'Core Use Case: Machine Learning & Exploration'
    char_start: 0
    char_end: 45
- statement: Data Warehouse stores structured data in a predefined schema optimized
    for Business Intelligence.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - data
  - warehouse
  - stores
  - structured
  - predefined
  - schema
  - optimized
  - business
  - intelligence
  source:
    doc: motherduck.com/case-studies/reflex-careers-gig-economy-retail.md
    quote: A Data Warehouse is a centralized repository that stores structured data
      from various sources in a high...
    char_start: 0
    char_end: 106
- statement: Data warehouses are a critical piece of the modern data stack.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - data
  - warehouses
  - critical
  - piece
  - modern
  - stack
  source:
    doc: motherduck.com/blog/why-web-developers-should-care-about-analytical-databases.md
    quote: Data warehouses are a critical piece of the modern data stack, where data
      is aggregated and organized for analytics and BI.
    char_start: 0
    char_end: 123
- statement: Data warehouses are designed for OLAP, which involves complex queries
    over large volumes of historical data.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - data
  - warehouses
  - designed
  - olap
  - which
  - involves
  - complex
  - queries
  - over
  - large
  - volumes
  - historical
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Data warehouses, on the other hand, are designed for OLAP (Online Analytical
      Processing), which involves complex queries over large volumes of historical
      data to support analysis and decision-making.
    char_start: 0
    char_end: 199
- statement: Data Warehouses are used for Business Intelligence and Reporting.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - data
  - warehouses
  - used
  - business
  - intelligence
  - reporting
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: 'Core Use Case: Business Intelligence & Reporting'
    char_start: 0
    char_end: 48
- statement: Data warehouses enhance performance for analytical queries.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - data
  - warehouses
  - enhance
  - performance
  - analytical
  - queries
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: Because data warehouses are specifically designed and optimized for complex
      analytical queries, they can return results much faster.
    char_start: 0
    char_end: 132
- statement: Data warehouses improve decision-making by providing access to reliable
    data.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - data
  - warehouses
  - improve
  - decision
  - making
  - providing
  - access
  - reliable
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: With access to consolidated, reliable, and historical data, business leaders
      and analysts can make decisions based on facts.
    char_start: 0
    char_end: 124
- statement: Data Warehouses operate on a schema-on-write model.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - data
  - warehouses
  - operate
  - schema
  - write
  - model
  source:
    doc: motherduck.com/case-studies/layers-multi-tenant-data-warehouse.md
    quote: A data warehouse operates on a schema-on-write model, where a strict structure
      is defined before any data is loaded.
    char_start: 0
    char_end: 116
- statement: It allows organizations to run analytics directly on data stored in open
    file formats like Apache Parquet in object storage such as Amazon S3.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - allows
  - organizations
  - run
  - analytics
  - directly
  - data
  - stored
  - open
  - file
  - formats
  - like
  - apache
  - parquet
  - object
  - storage
  - amazon
  - s3
  source:
    doc: motherduck.com/blog/streaming-oracle-to-motherduck.md
    quote: It allows organizations to run analytics directly on data stored in open
      file formats like Apache Parquet in object storage such as Amazon S3.
    char_start: 0
    char_end: 142
- statement: Startups can manage costs by choosing a data warehouse whose economic
    model fits their interactive and often unpredictable workloads.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - startups
  - manage
  - costs
  - choosing
  - data
  - warehouse
  - whose
  - economic
  - model
  - fits
  - interactive
  - often
  - unpredictable
  - workloads
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part1.md
    quote: Startups can manage costs by choosing a data warehouse whose economic model
      fits their interactive and often unpredictable workloads.
    char_start: 0
    char_end: 133
- statement: The architecture provides a single source of truth for both BI and AI
    workloads.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - architecture
  - provides
  - single
  - source
  - truth
  - both
  - bi
  - ai
  - workloads
  source:
    doc: motherduck.com/learn-more/big-data.md
    quote: It supports both BI and AI workloads on the same copy of the data, eliminating
      silos and duplication.
    char_start: 0
    char_end: 101
- statement: 'The benefits are immediate: a vastly simplified architecture, guaranteed
    access to the freshest data, zero data duplication, and a much faster time-to-market
    for building the tools that help the business run.'
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - benefits
  - immediate
  - vastly
  - simplified
  - architecture
  - guaranteed
  - access
  - freshest
  - data
  - zero
  - duplication
  - much
  - faster
  - time
  - market
  - building
  - tools
  - help
  - business
  - run
  source:
    doc: motherduck.com/learn-more/web-assembly.md
    quote: 'The benefits are immediate: a vastly simplified architecture, guaranteed
      access to the freshest data, zero data duplication, and a much faster time-to-market
      for building the tools that help the busin'
    char_start: 0
    char_end: 208
- statement: The best architecture is the one that helps your team deliver value faster
    and more reliably.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - best
  - architecture
  - one
  - helps
  - team
  - deliver
  - value
  - faster
  - reliably
  source:
    doc: motherduck.com/blog/dosomething-motherduck-data-warehouse-ROI.md
    quote: In the end, the best architecture isn't the newest one; it's the one that
      helps your team deliver value faster and more reliably.
    char_start: 0
    char_end: 129
- statement: The Data Lakehouse architecture brings ACID transactions to data files
    in object storage.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - data
  - lakehouse
  - architecture
  - brings
  - acid
  - transactions
  - files
  - object
  - storage
  source:
    doc: motherduck.com/learn-more/big-data.md
    quote: It brings the atomicity, consistency, isolation, and durability guarantees
      of a database to data files in object storage.
    char_start: 0
    char_end: 121
- statement: The document discusses the differences between data lakes and data warehouses.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - document
  - discusses
  - differences
  - data
  - lakes
  - warehouses
  source:
    doc: motherduck.com/learn-more/bigquery-alternative-motherduck.md
    quote: The document discusses the differences between data lakes and data warehouses.
    char_start: 0
    char_end: 78
- statement: The key innovation of the lakehouse is a transactional metadata layer
    built on top of data stored in open file formats.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - key
  - innovation
  - lakehouse
  - transactional
  - metadata
  - layer
  - built
  - top
  - data
  - stored
  - open
  - file
  - formats
  source:
    doc: motherduck.com/learn-more/big-data.md
    quote: The key innovation of the lakehouse is a transactional metadata layer built
      on top of data stored in open file formats.
    char_start: 0
    char_end: 119
- statement: The lakehouse avoids vendor lock-in by relying on open file and table
    formats.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - lakehouse
  - avoids
  - vendor
  - lock
  - relying
  - open
  - file
  - table
  - formats
  source:
    doc: motherduck.com/learn-more/big-data.md
    quote: By relying on open file and table formats, the lakehouse avoids vendor
      lock-in.
    char_start: 0
    char_end: 79
- statement: The loading phase physically moves the transformed data into the data
    warehouse.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - loading
  - phase
  - physically
  - moves
  - transformed
  - data
  - warehouse
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: The loading phase physically moves the transformed data into the data warehouse.
    char_start: 0
    char_end: 80
- statement: They had an on-premise data warehouse that was around 100 TB of data.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - premise
  - data
  - warehouse
  - around
  - '100'
  - tb
  source:
    doc: motherduck.com/blog.md
    quote: They had an on-premise data warehouse that was around 100 TB of data.
    char_start: 0
    char_end: 69
- statement: When they moved to the cloud, they ended up with 30 PB of data, a 300x
    increase.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - moved
  - cloud
  - ended
  - up
  - '30'
  - pb
  - data
  - 300x
  - increase
  source:
    doc: motherduck.com/blog.md
    quote: When they moved to the cloud, they ended up with 30 PB of data, a 300x
      increase.
    char_start: 0
    char_end: 80
- statement: Without understanding this hierarchy, developers waste time optimizing
    the wrong things.
  type: definition
  entity: Data Warehouse
  keywords:
  - definition
  - without
  - understanding
  - hierarchy
  - developers
  - waste
  - time
  - optimizing
  - wrong
  - things
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: Without understanding this hierarchy, developers waste time optimizing
      the wrong things.
    char_start: 0
    char_end: 88
- statement: Data Warehousing is the process of collecting and managing data from
    various sources to provide meaningful business insights.
  type: definition
  entity: Data Warehousing
  keywords:
  - definition
  - data
  - warehousing
  - process
  - collecting
  - managing
  - various
  - sources
  - provide
  - meaningful
  - business
  - insights
  source:
    doc: motherduck.com/learn-more/star-schema-data-warehouse-guide.md
    quote: In the world of data warehousing, complexity often creeps in where simplicity
      should reign.
    char_start: 0
    char_end: 91
- statement: Data warehousing organizes data optimized for consumption.
  type: definition
  entity: Data Warehousing
  keywords:
  - definition
  - data
  - warehousing
  - organizes
  - optimized
  - consumption
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: The sole purpose of these is to organize data optimized for consumption.
    char_start: 0
    char_end: 72
- statement: Building data applications is still an arduous effort for engineering
    teams.
  type: definition
  entity: data-driven components
  keywords:
  - definition
  - building
  - data
  - applications
  - still
  - arduous
  - effort
  - engineering
  - teams
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: building data applications today is still an arduous effort for engineering
      teams.
    char_start: 0
    char_end: 82
- statement: Data-driven learning learns data distributions over complex relational
    schemas without executing large workloads.
  type: definition
  entity: data-driven learning
  keywords:
  - definition
  - data
  - driven
  - learning
  - learns
  - distributions
  - over
  - complex
  - relational
  - schemas
  - without
  - executing
  - large
  - workloads
  source:
    doc: motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw.md
    quote: Data-driven learning caught my attention as it learns data distributions
      over complex relational schemas without having to execute large workloads.
    char_start: 0
    char_end: 147
- statement: The query computes database sizes and divides them into order-of-magnitude
    size buckets.
  type: definition
  entity: database
  keywords:
  - definition
  - query
  - computes
  - database
  - sizes
  - divides
  - them
  - order
  - magnitude
  - size
  - buckets
  source:
    doc: motherduck.com/blog/simplifying-iot-analytics-motherduck.md
    quote: This query computes database sizes and divides them into order-of-magnitude
      size buckets.
    char_start: 0
    char_end: 89
- statement: Database object catalogs are used directly by data platforms and query
    engines.
  type: definition
  entity: Database object catalog
  keywords:
  - definition
  - database
  - object
  - catalogs
  - used
  - directly
  - data
  - platforms
  - query
  - engines
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-seven.md
    quote: used directly by data platforms and query engines to read and write data.
    char_start: 0
    char_end: 73
- statement: Most database systems can do partition pruning, column projection, filter
    pushdown, segment selection, or other optimizations.
  type: definition
  entity: database systems
  keywords:
  - definition
  - database
  - systems
  - partition
  - pruning
  - column
  - projection
  - filter
  - pushdown
  - segment
  - selection
  - optimizations
  source:
    doc: motherduck.com/blog/python-faker-duckdb-exploration.md
    quote: Most database systems can do partition pruning, column projection, filter
      pushdown, segment selection, or other optimizations to be able to read a lot
      less than the full table size.
    char_start: 0
    char_end: 181
- statement: Databricks has offered a single node option since late 2020.
  type: definition
  entity: Databricks
  keywords:
  - definition
  - databricks
  - offered
  - single
  - node
  - option
  - since
  - late
  - '2020'
  source:
    doc: motherduck.com/blog/local-duckdb-ui-visual-data-analysis.md
    quote: Databricks has offered a single node option since late 2020.
    char_start: 0
    char_end: 60
- statement: Databricks is a cloud platform for big data analytics and machine learning.
  type: definition
  entity: Databricks
  keywords:
  - definition
  - databricks
  - cloud
  - platform
  - big
  - data
  - analytics
  - machine
  - learning
  source:
    doc: motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md
    quote: A cloud platform for big data analytics and machine learning.
    char_start: 0
    char_end: 61
- statement: Databricks is built on Delta Lake.
  type: definition
  entity: Databricks
  keywords:
  - definition
  - databricks
  - built
  - delta
  - lake
  source:
    doc: motherduck.com/blog/streaming-oracle-to-motherduck.md
    quote: Databricks (built on Delta Lake)
    char_start: 0
    char_end: 32
- statement: For complex ML and AI workloads where control over open formats is essential,
    a Data Lakehouse such as Databricks provides maximum flexibility.
  type: definition
  entity: Databricks
  keywords:
  - definition
  - complex
  - ml
  - ai
  - workloads
  - control
  - over
  - open
  - formats
  - essential
  - data
  - lakehouse
  - databricks
  - provides
  - maximum
  - flexibility
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: For complex ML and AI workloads where control over open formats is essential,
      a Data Lakehouse such as Databricks provides maximum flexibility.
    char_start: 0
    char_end: 143
- statement: Transitioning notebooks to production remains challenging even on platforms
    like Databricks.
  type: definition
  entity: Databricks Notebook
  keywords:
  - definition
  - transitioning
  - notebooks
  - production
  - remains
  - challenging
  - even
  - platforms
  - like
  - databricks
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-essential-tools.md
    quote: However, transitioning notebooks to production remains challenging even
      on platforms like Databricks.
    char_start: 0
    char_end: 101
- statement: DataDog and New Relic are monitoring and analytics platforms.
  type: definition
  entity: DataDog
  keywords:
  - definition
  - datadog
  - new
  - relic
  - monitoring
  - analytics
  - platforms
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: DataDog and New Relic are monitoring and analytics platforms.
    char_start: 0
    char_end: 61
- statement: We often load logs into tools like DataDog, Datafold, ELK Stack, or InfluxDB
    for monitoring.
  type: definition
  entity: DataDog
  keywords:
  - definition
  - often
  - load
  - logs
  - tools
  - like
  - datadog
  - datafold
  - elk
  - stack
  - influxdb
  - monitoring
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2024.md
    quote: For monitoring, we often load logs into tools like DataDog, Datafold, ELK
      Stack, or InfluxDB.
    char_start: 0
    char_end: 93
- statement: DataEngBytes is a unique annual conference happening across four cities
    in Australia.
  type: definition
  entity: DataEngBytes
  keywords:
  - definition
  - dataengbytes
  - unique
  - annual
  - conference
  - happening
  - across
  - four
  - cities
  - australia
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eight.md
    quote: DataEngBytes is a unique annual conference happening across four cities
      in Australia.
    char_start: 0
    char_end: 85
- statement: A DataFrame is a two-dimensional, size-mutable, potentially heterogeneous
    tabular data structure with labeled axes.
  type: definition
  entity: DataFrame
  keywords:
  - definition
  - dataframe
  - two
  - dimensional
  - size
  - mutable
  - potentially
  - heterogeneous
  - tabular
  - data
  - structure
  - labeled
  - axes
  source:
    doc: motherduck.com/videos/pg_duckdb-postgres-analytics-just-got-faster-with-duckdb.md
    quote: At its core, a DataFrame is a two-dimensional, size-mutable, potentially
      heterogeneous tabular data structure with labeled axes (rows and columns).
    char_start: 0
    char_end: 147
- statement: DataFrames are possibly the most useful abstraction for working with
    structured data in the last decade.
  type: definition
  entity: DataFrame
  keywords:
  - definition
  - dataframes
  - possibly
  - useful
  - abstraction
  - working
  - structured
  - data
  - last
  - decade
  source:
    doc: motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse.md
    quote: DataFrames come in, possibly the most useful abstraction for working with
      structured data in the last decade.
    char_start: 0
    char_end: 109
- statement: DataFrames can cut development time in half and execution time by 90%.
  type: definition
  entity: DataFrame
  keywords:
  - definition
  - dataframes
  - cut
  - development
  - time
  - half
  - execution
  - '90'
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: the switch to DataFrames can cut development time in half and execution
      time by 90%.
    char_start: 0
    char_end: 84
- statement: DataFrames provide a structured way to represent and work with virtually
    any tabular dataset.
  type: definition
  entity: DataFrame
  keywords:
  - definition
  - dataframes
  - provide
  - structured
  - way
  - represent
  - work
  - virtually
  - any
  - tabular
  - dataset
  source:
    doc: motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse.md
    quote: DataFrames are the whole bakery. They provide a structured way to represent
      and work with virtually any tabular dataset you'll encounter in the wild.
    char_start: 0
    char_end: 149
- statement: DataFrames were built for quick experimentation and in-memory computation.
  type: definition
  entity: DataFrame
  keywords:
  - definition
  - dataframes
  - built
  - quick
  - experimentation
  - memory
  - computation
  source:
    doc: motherduck.com/blog/llm-data-pipelines-prompt-motherduck-dbt.md
    quote: 'They were built for: Quick experimentation, In-memory computation, One-off
      analysis.'
    char_start: 0
    char_end: 84
- statement: The pie chart will dynamically adjust as you change the filters.
  type: definition
  entity: dataframe2
  keywords:
  - definition
  - pie
  - chart
  - dynamically
  - adjust
  - change
  - filters
  source:
    doc: motherduck.com/blog/making-pyspark-code-faster-with-duckdb.md
    quote: Your pie chart will dynamically adjust as you change the filters above.
    char_start: 0
    char_end: 71
- statement: Understanding DataFrames is essential for data professionals.
  type: definition
  entity: DataFrames
  keywords:
  - definition
  - understanding
  - dataframes
  - essential
  - data
  - professionals
  source:
    doc: motherduck.com/learn-more/pandas-dataframes-guide.md
    quote: For data professionals, understanding DataFrames isn't just helpful, it's
      essential.
    char_start: 0
    char_end: 84
- statement: DataFusion can write 1 billion rows in under 3 seconds.
  type: performance
  entity: DataFusion
  keywords:
  - performance
  - datafusion
  - write
  - billion
  - rows
  - seconds
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: noting it could write 1 billion rows in under 3 seconds.
    char_start: 0
    char_end: 56
- statement: DataGrip is a powerful database management tool developed by JetBrains,
    designed for SQL developers.
  type: definition
  entity: DataGrip
  keywords:
  - definition
  - datagrip
  - powerful
  - database
  - management
  - tool
  - developed
  - jetbrains
  - designed
  - sql
  - developers
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: DataGrip is a powerful database management tool developed by JetBrains,
      designed for SQL developers.
    char_start: 0
    char_end: 100
- statement: DataLab is a collaborative data science platform designed for data analysts
    and scientists to explore, analyze, and visualize data.
  type: definition
  entity: DataLab
  keywords:
  - definition
  - datalab
  - collaborative
  - data
  - science
  - platform
  - designed
  - analysts
  - scientists
  - explore
  - analyze
  - visualize
  source:
    doc: motherduck.com/ecosystem.md
    quote: DataLab is a collaborative data science platform designed for data analysts
      and scientists to explore, analyze, and visualize data in a unified workspace.
    char_start: 0
    char_end: 154
- statement: DataPoint objects are used as standardized input/output schemas in cognee.
  type: definition
  entity: DataPoint
  keywords:
  - definition
  - datapoint
  - objects
  - used
  - standardized
  - input
  - output
  - schemas
  - cognee
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: the data is then loaded from cognee’s DataPoint objects.
    char_start: 0
    char_end: 56
- statement: The Datasets Explorer Chrome Extension allows querying datasets using
    SQL.
  type: definition
  entity: Datasets Explorer Chrome Extension
  keywords:
  - definition
  - datasets
  - explorer
  - chrome
  - extension
  - allows
  - querying
  - using
  - sql
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md
    quote: Querying Datasets with the Datasets Explorer Chrome Extension
    char_start: 0
    char_end: 61
- statement: Datashader renders even the largest datasets accurately as images.
  type: definition
  entity: Datashader
  keywords:
  - definition
  - datashader
  - renders
  - even
  - largest
  - datasets
  - accurately
  - images
  source:
    doc: motherduck.com/blog/motherduck-duckdb-dbt.md
    quote: 'Datashader: Renders even the largest datasets accurately as images'
    char_start: 0
    char_end: 66
- statement: Datastream offers data replication onto platforms such as BigQuery.
  type: definition
  entity: Datastream
  keywords:
  - definition
  - datastream
  - offers
  - data
  - replication
  - onto
  - platforms
  - bigquery
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2024.md
    quote: managed solutions like Datastream exist, offering data replication onto
      platforms such as BigQuery.
    char_start: 0
    char_end: 99
- statement: 'David Neal will speak about ''Hybrid Queries: the Future of Data Analytics''.'
  type: definition
  entity: DataTune conference
  keywords:
  - definition
  - david
  - neal
  - speak
  - about
  - hybrid
  - queries
  - future
  - data
  - analytics
  source:
    doc: motherduck.com/blog/just-enough-sql-for-ai.md
    quote: 'David Neal will speak about “Hybrid Queries: the Future of Data Analytics”'
    char_start: 0
    char_end: 74
- statement: Datawisp is a no code analytics platform that lets anyone analyze data
    and discover insights regardless of their technical knowledge.
  type: definition
  entity: Datawisp
  keywords:
  - definition
  - datawisp
  - code
  - analytics
  - platform
  - lets
  - anyone
  - analyze
  - data
  - discover
  - insights
  - regardless
  - technical
  - knowledge
  source:
    doc: motherduck.com/ecosystem.md
    quote: Datawisp is a no code analytics platform that lets anyone analyze data
      and discover insights regardless of their technical knowledge.
    char_start: 0
    char_end: 133
- statement: David Gasquez created a GitHub project to curate DuckDB resources.
  type: definition
  entity: David Gasquez
  keywords:
  - definition
  - david
  - gasquez
  - created
  - github
  - project
  - curate
  - duckdb
  - resources
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: David Gasquez has done an awesome service to the DuckDB community by creating
      a GitHub project to curate all the awesome DuckDB libraries, tools and resources.
    char_start: 0
    char_end: 159
- statement: David Gasquez is a data engineer at Protocol Labs.
  type: definition
  entity: David Gasquez
  keywords:
  - definition
  - david
  - gasquez
  - data
  - engineer
  - protocol
  - labs
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: David Gasquez is a data engineer at Protocol Labs.
    char_start: 0
    char_end: 50
- statement: David is building on atproto-data-tools.
  type: definition
  entity: David Gasquez
  keywords:
  - definition
  - david
  - building
  - atproto
  - data
  - tools
  source:
    doc: motherduck.com/blog/duckdb-wasm-in-browser.md
    quote: 'David is building on [atproto-data-tools](https://github.com/davidgasquez/atproto-data-tools):
      🦋 Small scripts and tools to do data stuff with the AT Protocol.'
    char_start: 0
    char_end: 159
- statement: A modern dev-to-prod workflow combines this with tools like dbt.
  type: definition
  entity: dbt
  keywords:
  - definition
  - modern
  - dev
  - prod
  - workflow
  - combines
  - tools
  - like
  - dbt
  source:
    doc: motherduck.com/learn-more/no-etl-query-raw-files.md
    quote: A modern dev-to-prod workflow combines this with tools like dbt (data build
      tool).
    char_start: 0
    char_end: 82
- statement: dbt can read data from S3.
  type: definition
  entity: dbt
  keywords:
  - definition
  - dbt
  - read
  - data
  - s3
  source:
    doc: motherduck.com/blog/introducing-motherduck-for-business-analytics.md
    quote: dbt can read data from S3.
    char_start: 0
    char_end: 26
- statement: dbt can work with Iceberg for data modeling.
  type: definition
  entity: dbt
  keywords:
  - definition
  - dbt
  - work
  - iceberg
  - data
  - modeling
  source:
    doc: motherduck.com/videos.md
    quote: dbt can work with Iceberg for data modeling.
    char_start: 0
    char_end: 44
- statement: dbt doesn't support incremental loading when writing to an external source
    like AWS S3.
  type: definition
  entity: dbt
  keywords:
  - definition
  - dbt
  - doesn
  - support
  - incremental
  - loading
  - writing
  - external
  - source
  - like
  - aws
  - s3
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: dbt doesn't support incremental loading when writing to an external source
      like AWS S3.
    char_start: 0
    char_end: 87
- statement: dbt enables data analysts and engineers to transform data in their warehouse
    more effectively.
  type: definition
  entity: dbt
  keywords:
  - definition
  - dbt
  - enables
  - data
  - analysts
  - engineers
  - transform
  - warehouse
  - effectively
  source:
    doc: motherduck.com/blog/data-app-generator.md
    quote: A command line tool that enables data analysts and engineers to transform
      data in their warehouse more effectively.
    char_start: 0
    char_end: 115
- statement: dbt is a great and straightforward tool for building production-ready
    data pipelines with SQL.
  type: definition
  entity: dbt
  keywords:
  - definition
  - dbt
  - great
  - straightforward
  - tool
  - building
  - production
  - ready
  - data
  - pipelines
  - sql
  source:
    doc: motherduck.com/blog/duckdb-dbt-e2e-data-engineering-project-part-2.md
    quote: dbt is a great and straightforward tool for building production-ready data
      pipelines with SQL.
    char_start: 0
    char_end: 94
- statement: dbt is improving unit tests in its April 1.8 release.
  type: definition
  entity: dbt
  keywords:
  - definition
  - dbt
  - improving
  - unit
  - tests
  - april
  - '1.8'
  - release
  source:
    doc: motherduck.com/blog/dual-execution-dbt.md
    quote: dbt is improving unit tests in its April 1.8 release.
    char_start: 0
    char_end: 53
- statement: dbt is particularly useful for implementing the ELT (Extract, Load, Transform)
    paradigm.
  type: definition
  entity: dbt
  keywords:
  - definition
  - dbt
  - particularly
  - useful
  - implementing
  - elt
  - extract
  - load
  - transform
  - paradigm
  source:
    doc: motherduck.com/blog/summer-data-engineering-roadmap.md
    quote: This tool is particularly useful for implementing the ELT (Extract, Load,
      Transform) paradigm.
    char_start: 0
    char_end: 94
- statement: dbt is used for transforming data in DuckDB.
  type: definition
  entity: dbt
  keywords:
  - definition
  - dbt
  - used
  - transforming
  - data
  - duckdb
  source:
    doc: motherduck.com/blog/csv-files-persist-duckdb-solution.md
    quote: A command line tool that enables data analysts and engineers to transform
      data in their warehouse more effectively.
    char_start: 0
    char_end: 115
- statement: dbt is used for transforming data in the cloud.
  type: definition
  entity: dbt
  keywords:
  - definition
  - dbt
  - used
  - transforming
  - data
  - cloud
  source:
    doc: motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud.md
    quote: dual execution in data build tools (dbt)
    char_start: 0
    char_end: 40
- statement: dbt profiles can specify duckdb as a database type.
  type: definition
  entity: dbt
  keywords:
  - definition
  - dbt
  - profiles
  - specify
  - duckdb
  - database
  - type
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: In the example dbt profile below, `prod` runs entirely in the cloud, while
      `local` runs mostly on local but is also linked to MotherDuck for reading data
      into your local database.
    char_start: 0
    char_end: 179
- statement: dbt runs dropped from 8 hours to 2 minutes.
  type: definition
  entity: dbt
  keywords:
  - definition
  - dbt
  - runs
  - dropped
  - hours
  - minutes
  source:
    doc: motherduck.com/learn-more/star-schema-data-warehouse-guide.md
    quote: With dbt runs dropping from 8 hours to 2 minutes and queries returning
      in seconds.
    char_start: 0
    char_end: 82
- statement: dbt runs full refreshes by default, which recreates the table each time
    the model is executed.
  type: definition
  entity: dbt
  keywords:
  - definition
  - dbt
  - runs
  - full
  - refreshes
  - default
  - which
  - recreates
  - table
  - time
  - model
  - executed
  source:
    doc: motherduck.com/blog/faster-ducks.md
    quote: By default, dbt runs full refreshes, which recreates the table each time
      the model is executed.
    char_start: 0
    char_end: 95
- statement: dbt supports a wide range of data platforms, including Snowflake, BigQuery,
    and Redshift.
  type: definition
  entity: dbt
  keywords:
  - definition
  - dbt
  - supports
  - wide
  - range
  - data
  - platforms
  - including
  - snowflake
  - bigquery
  - redshift
  source:
    doc: motherduck.com/blog/summer-data-engineering-roadmap.md
    quote: It supports a wide range of data platforms, including Snowflake, BigQuery,
      and Redshift.
    char_start: 0
    char_end: 88
- statement: Eliminating SQL translation between dev and prod environments is possible
    with dbt and DuckDB.
  type: definition
  entity: dbt
  keywords:
  - definition
  - eliminating
  - sql
  - translation
  - dev
  - prod
  - environments
  - possible
  - dbt
  - duckdb
  source:
    doc: motherduck.com/learn-more/self-service-analytics-startups.md
    quote: while eliminating sql translation between your dev and prod environments.
    char_start: 0
    char_end: 73
- statement: I use dbt daily during my job as an analytics engineer.
  type: definition
  entity: dbt
  keywords:
  - definition
  - use
  - dbt
  - daily
  - my
  - job
  - analytics
  - engineer
  source:
    doc: motherduck.com/blog/semantic-layer-duckdb-tutorial.md
    quote: I use dbt daily during my job as an analytics engineer...
    char_start: 0
    char_end: 57
- statement: I was able to build a dbt project based on the TPC-DS dataset in MotherDuck
    in about 12-15 minutes.
  type: definition
  entity: dbt
  keywords:
  - definition
  - able
  - build
  - dbt
  - project
  - based
  - tpc
  - ds
  - dataset
  - motherduck
  - about
  - '12'
  - '15'
  - minutes
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: I was able to build a dbt project based on the TPC-DS dataset (about 40GB
      in Iceberg) in MotherDuck in about 12-15 minutes, which was a pleasant surprise.
    char_start: 0
    char_end: 154
- statement: Nightly dbt Cloud jobs that took 8 hours were replaced with a dbt Core
    project running via GitHub Actions.
  type: definition
  entity: dbt
  keywords:
  - definition
  - nightly
  - dbt
  - cloud
  - jobs
  - took
  - hours
  - replaced
  - core
  - project
  - running
  - via
  - github
  - actions
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: Nightly dbt Cloud jobs that took 8 hours were replaced with a dbt Core
      project running via GitHub Actions.
    char_start: 0
    char_end: 106
- statement: Switching execution engines is becoming a reality for SQL users.
  type: definition
  entity: dbt
  keywords:
  - definition
  - switching
  - execution
  - engines
  - becoming
  - reality
  - sql
  - users
  source:
    doc: motherduck.com/blog/galileo-world-geospatial.md
    quote: switching to different compute engine (assuming the SQL dialect is compatible)
      starts to be a reality through the usage of dbt.
    char_start: 0
    char_end: 127
- statement: The next blog will dive into the transformation layer using dbt duckdb.
  type: definition
  entity: dbt
  keywords:
  - definition
  - next
  - blog
  - dive
  - transformation
  - layer
  - using
  - dbt
  - duckdb
  source:
    doc: motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md
    quote: The next blog will dive into the transformation layer using dbt duckdb.
    char_start: 0
    char_end: 71
- statement: Using dbt and DuckDB can drop your warehouse development costs to zero.
  type: definition
  entity: dbt
  keywords:
  - definition
  - using
  - dbt
  - duckdb
  - drop
  - warehouse
  - development
  - costs
  - zero
  source:
    doc: motherduck.com/learn-more/self-service-analytics-startups.md
    quote: This discussion between the co-founders of Paradime and MotherDuck talks
      about using dbt and DuckDB to drop your warehouse development costs to zero.
    char_start: 0
    char_end: 149
- statement: You could use dbt to manage dependencies.
  type: definition
  entity: dbt
  keywords:
  - definition
  - use
  - dbt
  - manage
  - dependencies
  source:
    doc: motherduck.com/blog/semantic-layer-duckdb-tutorial.md
    quote: Obviously, you could use dbt to manage dependencies.
    char_start: 0
    char_end: 52
- statement: Debezium allows for real-time data replication from PostgreSQL to DuckDB.
  type: definition
  entity: Debezium
  keywords:
  - definition
  - debezium
  - allows
  - real
  - time
  - data
  - replication
  - postgresql
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: This article explores setting up a real-time Change Data Capture (CDC)
      pipeline using Debezium and Python, loading data into DuckDB via dlt.
    char_start: 0
    char_end: 140
- statement: Debezium enables streaming data from databases to systems like Kafka.
  type: definition
  entity: Debezium
  keywords:
  - definition
  - debezium
  - enables
  - streaming
  - data
  - databases
  - systems
  - like
  - kafka
  source:
    doc: motherduck.com/blog/duckdb-wasm-in-browser.md
    quote: change data capture platforms like Debezium. These platforms enable streaming
      data from databases to systems like Kafka.
    char_start: 0
    char_end: 120
- statement: Debezium is a mature, open-source platform supporting many databases.
  type: definition
  entity: Debezium
  keywords:
  - definition
  - debezium
  - mature
  - open
  - source
  - platform
  - supporting
  - many
  - databases
  source:
    doc: motherduck.com/blog/motherduck-union-orchestration.md
    quote: 'Debezium: Mature, open-source platform supporting many databases.'
    char_start: 0
    char_end: 65
- statement: The integration of Debezium with Python simplifies the CDC process.
  type: definition
  entity: Debezium
  keywords:
  - definition
  - integration
  - debezium
  - python
  - simplifies
  - cdc
  - process
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: The pipeline leverages Debezium to monitor PostgreSQL transaction logs,
      producing change event streams.
    char_start: 0
    char_end: 103
- statement: Deck.gl is a GPU-powered framework for visual exploratory data analysis
    of large datasets.
  type: definition
  entity: deck.gl
  keywords:
  - definition
  - deck
  - gl
  - gpu
  - powered
  - framework
  - visual
  - exploratory
  - data
  - analysis
  - large
  - datasets
  source:
    doc: motherduck.com/blog/motherduck-duckdb-dbt.md
    quote: 'Deck.gl: GPU-powered framework for visual exploratory data analysis of
      large datasets'
    char_start: 0
    char_end: 85
- statement: Deepnote is a closed-source notebook for data analysis.
  type: definition
  entity: Deepnote
  keywords:
  - definition
  - deepnote
  - closed
  - source
  - notebook
  - data
  - analysis
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: 'Deepnote: Closed-source notebook for data analysis.'
    char_start: 0
    char_end: 51
- statement: DeepSeek's smallpond has impressive 110TB benchmarks.
  type: definition
  entity: DeepSeek
  keywords:
  - definition
  - deepseek
  - smallpond
  - impressive
  - 110tb
  - benchmarks
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: DeepSeek's smallpond has taken the data world by storm with its distributed
      DuckDB capabilities and impressive 110TB benchmarks.
    char_start: 0
    char_end: 128
- statement: Definite reported over 70% cost reduction compared to a provisioned warehouse.
  type: definition
  entity: Definite
  keywords:
  - definition
  - definite
  - reported
  - over
  - '70'
  - cost
  - reduction
  - compared
  - provisioned
  - warehouse
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: while the data platform Definite reported over 70% cost reduction compared
      to a provisioned warehouse.
    char_start: 0
    char_end: 102
- statement: Delta Lake and Apache Iceberg build on the strengths of Parquet, introducing
    advanced table management features.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - delta
  - lake
  - apache
  - iceberg
  - build
  - strengths
  - parquet
  - introducing
  - advanced
  - table
  - management
  - features
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Delta Lake and Apache Iceberg build on the strengths of Parquet, introducing
      advanced table management features.
    char_start: 0
    char_end: 112
- statement: Delta Lake and Apache Iceberg support operations like UPDATE and DELETE.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - delta
  - lake
  - apache
  - iceberg
  - support
  - operations
  - like
  - update
  - delete
  source:
    doc: motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md
    quote: Table formats like Delta Lake and Apache Iceberg, unlike vanilla Parquet
      files, support operations like UPDATE and DELETE.
    char_start: 0
    char_end: 122
- statement: Delta Lake offers capabilities like ACID transactions and data versioning.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - delta
  - lake
  - offers
  - capabilities
  - like
  - acid
  - transactions
  - data
  - versioning
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Delta Lake, with its seamless Spark integration, offers capabilities like
      ACID transactions and data versioning.
    char_start: 0
    char_end: 112
- statement: Delta Lake provides a better format than Parquet.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - delta
  - lake
  - provides
  - better
  - format
  - parquet
  source:
    doc: motherduck.com/videos.md
    quote: Delta Lake provides a better format than Parquet.
    char_start: 0
    char_end: 49
- statement: DuckLake 0.3 introduces native support for geometry data types.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - ducklake
  - '0.3'
  - introduces
  - native
  - support
  - geometry
  - data
  - types
  source:
    doc: motherduck.com/blog/announcing-duckdb-141-motherduck.md
    quote: DuckLake 0.3 introduces native support for geometry data types, allowing
      users to take advantage of the DuckDB spatial extension’s functionality in DuckLake.
    char_start: 0
    char_end: 157
- statement: DuckLake 0.3 introduces the DuckLake CHECKPOINT function that makes table
    maintenance automatic.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - ducklake
  - '0.3'
  - introduces
  - checkpoint
  - function
  - makes
  - table
  - maintenance
  - automatic
  source:
    doc: motherduck.com/blog/announcing-series-seed-and-a.md
    quote: DuckLake 0.3 introduces the DuckLake CHECKPOINT function that makes table
      maintenance automatic.
    char_start: 0
    char_end: 96
- statement: DuckLake 0.3 now fully supports the MERGE INTO statement.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - ducklake
  - '0.3'
  - now
  - fully
  - supports
  - merge
  - statement
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: DuckLake 0.3 now fully supports the `MERGE INTO` statement.
    char_start: 0
    char_end: 59
- statement: DuckLake 0.3 speeds up write performance by allowing each thread to write
    separate files.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - ducklake
  - '0.3'
  - speeds
  - up
  - write
  - performance
  - allowing
  - thread
  - separate
  - files
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: DuckLake 0.3 speeds up write performance by allowing each thread to write
      separate files.
    char_start: 0
    char_end: 89
- statement: DuckLake allows fast writes and parquet imports.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - ducklake
  - allows
  - fast
  - writes
  - parquet
  - imports
  source:
    doc: motherduck.com/blog/announcing-ducklake-support-motherduck-preview.md
    quote: DuckLake provides fast writes using simple transactions, without having
      to update multiple layers of metadata.
    char_start: 0
    char_end: 110
- statement: DuckLake offers the same massive data capabilities as Apache Iceberg
    and Delta Lake, but with radically faster performance.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - ducklake
  - offers
  - massive
  - data
  - capabilities
  - apache
  - iceberg
  - delta
  - lake
  - radically
  - faster
  - performance
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: Get the same scale as Iceberg/Delta Lake, but with the snappy performance
      of a modern data warehouse.
    char_start: 0
    char_end: 101
- statement: DuckLake provides 10-100x faster metadata lookups compared to Iceberg
    and Delta Lake.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - ducklake
  - provides
  - '10'
  - 100x
  - faster
  - metadata
  - lookups
  - compared
  - iceberg
  - delta
  - lake
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: 10-100x faster metadata lookups - Database indexes beat file scanning every
      time
    char_start: 0
    char_end: 80
- statement: DuckLake provides a current_snapshot() function for easier snapshot management.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - ducklake
  - provides
  - current
  - snapshot
  - function
  - easier
  - management
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eight.md
    quote: New current_snapshot() function for easier snapshot management
    char_start: 0
    char_end: 62
- statement: DuckLake provides warehouse speed at lake scale.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - ducklake
  - provides
  - warehouse
  - speed
  - lake
  - scale
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: DuckLake provides warehouse speed at lake scale.
    char_start: 0
    char_end: 48
- statement: DuckLake supports adding/renaming columns and promoting types without
    re-writing any data files.
  type: feature
  entity: Delta Lake
  keywords:
  - feature
  - ducklake
  - supports
  - adding
  - renaming
  - columns
  - promoting
  - types
  - without
  - re
  - writing
  - any
  - data
  - files
  source:
    doc: motherduck.com/blog/bigquery-to-duckdb-motherduck.md
    quote: DuckLake supports this DuckLake feature to add/rename columns and promote
      types without re-writing any data files.
    char_start: 0
    char_end: 114
- statement: DuckLake supports time travel.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - ducklake
  - supports
  - time
  - travel
  source:
    doc: motherduck.com/blog/announcing-ducklake-support-motherduck-preview.md
    quote: Time travel enables querying the state of the database as of any recorded
      snapshot.
    char_start: 0
    char_end: 83
- statement: DuckLake takes consistent snapshots of your data and enables you to query
    the state of the data as of any snapshot.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - ducklake
  - takes
  - consistent
  - snapshots
  - data
  - enables
  - query
  - state
  - any
  - snapshot
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: DuckLake takes consistent snapshots of your data and enables you to query
      the state of the data as of any snapshot.
    char_start: 0
    char_end: 115
- statement: Support for using your own compute with a fully-managed DuckLake will
    be available soon.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - support
  - using
  - compute
  - fully
  - managed
  - ducklake
  - available
  - soon
  source:
    doc: motherduck.com/blog/announcing-ducklake-support-motherduck-preview.md
    quote: Support for using your own compute with a fully-managed DuckLake will be
      available soon.
    char_start: 0
    char_end: 88
- statement: The DuckLake approach fits seamlessly into a modern analytics platform.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - ducklake
  - approach
  - fits
  - seamlessly
  - modern
  - analytics
  - platform
  source:
    doc: motherduck.com/blog/streamlining-ai-agents-duckdb-rag-solutions.md
    quote: The DuckLake approach fits seamlessly into this model.
    char_start: 0
    char_end: 54
- statement: The DuckLake approach focuses on simplicity, speed, and cost-efficiency.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - ducklake
  - approach
  - focuses
  - simplicity
  - speed
  - cost
  - efficiency
  source:
    doc: motherduck.com/ecosystem.md
    quote: The primary benefits are simplicity, speed, and cost-efficiency.
    char_start: 0
    char_end: 64
- statement: The DuckLake approach offers a practical path forward for enterprises
    seeking to maintain control over their data assets while leveraging DuckDB's performance.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - ducklake
  - approach
  - offers
  - practical
  - path
  - forward
  - enterprises
  - seeking
  - maintain
  - control
  - over
  - data
  - assets
  - leveraging
  - duckdb
  - performance
  source:
    doc: motherduck.com/blog/bigquery-to-duckdb-motherduck.md
    quote: The DuckLake approach offers a practical path forward for enterprises seeking
      to maintain control over their data assets while leveraging DuckDB's performance.
    char_start: 0
    char_end: 159
- statement: The ducklake_delete_orphaned_files() function removes files no longer
    tracked by DuckLake.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - ducklake
  - delete
  - orphaned
  - files
  - function
  - removes
  - longer
  - tracked
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eight.md
    quote: The ducklake_delete_orphaned_files() function removes files no longer tracked
      by DuckLake.
    char_start: 0
    char_end: 90
- statement: The new CHECKPOINT statement combines all the maintenance operations
    you need into a single command.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - new
  - checkpoint
  - statement
  - combines
  - maintenance
  - operations
  - need
  - single
  - command
  source:
    doc: motherduck.com/blog/announcing-duckdb-141-motherduck.md
    quote: The new CHECKPOINT statement combines all the maintenance operations you
      need into a single, simple command.
    char_start: 0
    char_end: 108
- statement: Unified SQL interface whether querying megabytes or petabytes.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - unified
  - sql
  - interface
  - whether
  - querying
  - megabytes
  - petabytes
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: Unified SQL interface whether querying megabytes or petabytes.
    char_start: 0
    char_end: 62
- statement: You can bring your own compute to your DuckLake.
  type: definition
  entity: Delta Lake
  keywords:
  - definition
  - bring
  - compute
  - ducklake
  source:
    doc: motherduck.com/blog/announcing-ducklake-support-motherduck-preview.md
    quote: If you supply your own cloud storage bucket, you can bring your own compute
      (BYOC) to your DuckLake.
    char_start: 0
    char_end: 100
- statement: Delta-RS allows reading and writing Delta tables without Spark.
  type: definition
  entity: Delta-RS
  keywords:
  - definition
  - delta
  - rs
  - allows
  - reading
  - writing
  - tables
  - without
  - spark
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-six.md
    quote: Delta-RS allows reading and writing Delta tables without Spark.
    char_start: 0
    char_end: 63
- statement: Delta-rs is a Rust implementation of Delta Lake.
  type: definition
  entity: Delta-RS
  keywords:
  - definition
  - delta
  - rs
  - rust
  - implementation
  - lake
  source:
    doc: motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw.md
    quote: Delta-rs (Delta lake Rust implementation)
    char_start: 0
    char_end: 41
- statement: DevContainer is a pre-configured development environment that works seamlessly
    with Visual Studio Code.
  type: definition
  entity: DevContainer
  keywords:
  - definition
  - devcontainer
  - pre
  - configured
  - development
  - environment
  - works
  - seamlessly
  - visual
  - studio
  - code
  source:
    doc: motherduck.com/blog/spark-ducklake-getting-started.md
    quote: A pre-configured development environment that works seamlessly with Visual
      Studio Code.
    char_start: 0
    char_end: 87
- statement: The demo runs in a DevContainer environment.
  type: definition
  entity: DevContainer
  keywords:
  - definition
  - demo
  - runs
  - devcontainer
  - environment
  source:
    doc: motherduck.com/blog/spark-ducklake-getting-started.md
    quote: I've designed this demo to run in a DevContainer—think of it as a pre-configured
      development environment.
    char_start: 0
    char_end: 105
- statement: We receive information about the device and software you use to access
    our Website.
  type: definition
  entity: Device Information
  keywords:
  - definition
  - receive
  - information
  - about
  - device
  - software
  - use
  - access
  - website
  source:
    doc: motherduck.com/videos/duckdb-run-dbt-build-with-sub-second-execution-times.md
    quote: We receive information about the device and software you use to access
      our Website, including IP address, web browser type, and operating system version.
    char_start: 0
    char_end: 153
- statement: Devpod can be used in the cloud.
  type: definition
  entity: Devpod
  keywords:
  - definition
  - devpod
  - used
  - cloud
  source:
    doc: motherduck.com/blog/analyze-x-data-nodejs-duckdb.md
    quote: A development environment that can be used in the cloud.
    char_start: 0
    char_end: 56
- statement: Dexibit can handle a load spike or a huge amount of queries by spinning
    up more ducklings on demand.
  type: definition
  entity: Dexibit
  keywords:
  - definition
  - dexibit
  - handle
  - load
  - spike
  - huge
  - amount
  - queries
  - spinning
  - up
  - ducklings
  - demand
  source:
    doc: motherduck.com/blog/sql-keyboard-shortcuts-for-joyful-querying.md
    quote: If we need to handle a load spike or a huge amount of queries, we can spin
      up more ducklings on demand.
    char_start: 0
    char_end: 103
- statement: Dexibit used this approach to reduce query times from minutes to seconds.
  type: definition
  entity: Dexibit
  keywords:
  - definition
  - dexibit
  - used
  - approach
  - reduce
  - query
  - times
  - minutes
  - seconds
  source:
    doc: motherduck.com/videos/whats-new-in-data-small-data-big-impact.md
    quote: the museum analytics company Dexibit, for example, used this approach to
      reduce query times from minutes to seconds.
    char_start: 0
    char_end: 116
- statement: Ravi Chandra stated that MotherDuck has changed their behaviors due to
    cost efficiency.
  type: definition
  entity: Dexibit
  keywords:
  - definition
  - ravi
  - chandra
  - stated
  - motherduck
  - changed
  - behaviors
  - due
  - cost
  - efficiency
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: With MotherDuck working to solve amazing problems through data, our behaviors
      have changed because we know we don't have to pay enormous costs every time
      we run a query.
    char_start: 0
    char_end: 169
- statement: Differential Storage allows for efficient management of database snapshots.
  type: definition
  entity: Differential Storage
  keywords:
  - definition
  - differential
  - storage
  - allows
  - efficient
  - management
  - database
  - snapshots
  source:
    doc: motherduck.com/blog/announcing-motherduck-general-availability-data-warehousing-with-duckdb.md
    quote: Because all the previous snapshot layers are stored, it is an inexpensive
      metadata-only operation to materialize previous snapshots.
    char_start: 0
    char_end: 132
- statement: Differential Storage allows us to store many point-in-time versions of
    a database without needing to duplicate the data.
  type: definition
  entity: Differential Storage
  keywords:
  - definition
  - differential
  - storage
  - allows
  - us
  - store
  - many
  - point
  - time
  - versions
  - database
  - without
  - needing
  - duplicate
  - data
  source:
    doc: motherduck.com/blog/announcing-duckdb-13-on-motherduck-cdw.md
    quote: Differential Storage allows us to store many point-in-time versions of
      a database, without needing to duplicate the data that those versions have in
      common.
    char_start: 0
    char_end: 156
- statement: Differential Storage appends the data to the end of the active snapshot
    layer file.
  type: definition
  entity: Differential Storage
  keywords:
  - definition
  - differential
  - storage
  - appends
  - data
  - end
  - active
  - snapshot
  - layer
  - file
  source:
    doc: motherduck.com/blog/duckdb-110-hidden-gems.md
    quote: Differential Storage appends the data to the end of the active snapshot
      layer file.
    char_start: 0
    char_end: 83
- statement: Differential Storage enables features like efficient data sharing and
    zero-copy clone.
  type: definition
  entity: Differential Storage
  keywords:
  - definition
  - differential
  - storage
  - enables
  - features
  - like
  - efficient
  - data
  - sharing
  - zero
  - copy
  - clone
  source:
    doc: motherduck.com/blog/duckdb-110-hidden-gems.md
    quote: Thanks to Differential Storage, features like efficient data sharing and
      zero-copy clone are now available in MotherDuck.
    char_start: 0
    char_end: 121
- statement: Differential Storage has to upgrade the current active snapshot layer
    to become the newest snapshot layer.
  type: definition
  entity: Differential Storage
  keywords:
  - definition
  - differential
  - storage
  - upgrade
  - current
  - active
  - snapshot
  - layer
  - become
  - newest
  source:
    doc: motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw.md
    quote: Differential Storage has to upgrade the current active snapshot layer to
      become the newest snapshot layer.
    char_start: 0
    char_end: 106
- statement: Differential Storage is a key building block for a DuckDB-based data
    warehouse.
  type: definition
  entity: Differential Storage
  keywords:
  - definition
  - differential
  - storage
  - key
  - building
  - block
  - duckdb
  - based
  - data
  - warehouse
  source:
    doc: motherduck.com/blog/duckdb-dashboard-e2e-data-engineering-project-part-3.md
    quote: 'Differential Storage: A Key Building Block For A DuckDB-Based Data Warehouse'
    char_start: 0
    char_end: 76
- statement: Differential Storage is a key infrastructure-level enabler of new capabilities
    for MotherDuck users.
  type: definition
  entity: Differential Storage
  keywords:
  - definition
  - differential
  - storage
  - key
  - infrastructure
  - level
  - enabler
  - new
  - capabilities
  - motherduck
  - users
  source:
    doc: motherduck.com/blog/duckdb-110-hidden-gems.md
    quote: Today we’d like to talk about Differential Storage, a key infrastructure-level
      enabler of new capabilities and stronger semantics for MotherDuck users.
    char_start: 0
    char_end: 151
- statement: Differential storage operates as a FUSE-based system that represents
    database states through sequences of immutable layers.
  type: definition
  entity: Differential Storage
  keywords:
  - definition
  - differential
  - storage
  - operates
  - fuse
  - based
  - system
  - represents
  - database
  - states
  - sequences
  - immutable
  - layers
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: At its core, the differential storage operates as a FUSE-based system that
      represents database states through sequences of immutable 'layers'.
    char_start: 0
    char_end: 142
- statement: Differential Storage solves challenges around concurrency, performance,
    scalability, and unlocking new user capabilities.
  type: definition
  entity: Differential Storage
  keywords:
  - definition
  - differential
  - storage
  - solves
  - challenges
  - around
  - concurrency
  - performance
  - scalability
  - unlocking
  - new
  - user
  - capabilities
  source:
    doc: motherduck.com/blog/announcing-duckdb-13-on-motherduck-cdw.md
    quote: Differential Storage, that solves a number of challenges of running DuckDB
      as a central collaborative data warehouse...
    char_start: 0
    char_end: 119
- statement: DimDate slices sales by time periods.
  type: definition
  entity: DimDate
  keywords:
  - definition
  - dimdate
  - slices
  - sales
  - time
  - periods
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: 'Purpose: Slice sales by time periods'
    char_start: 0
    char_end: 36
- statement: Dimensional Modeling is a design technique used for data warehouses that
    structures data into fact and dimension tables.
  type: definition
  entity: Dimensional Modeling
  keywords:
  - definition
  - dimensional
  - modeling
  - design
  - technique
  - used
  - data
  - warehouses
  - structures
  - fact
  - dimension
  - tables
  source:
    doc: motherduck.com/learn-more/star-schema-data-warehouse-guide.md
    quote: This proven technique has become the backbone of successful data warehouses.
    char_start: 0
    char_end: 76
- statement: Direct Query on Object Storage minimizes data movement and complexity.
  type: definition
  entity: Direct Query on Object Storage
  keywords:
  - definition
  - direct
  - query
  - object
  - storage
  - minimizes
  - data
  - movement
  - complexity
  source:
    doc: motherduck.com/learn-more/what-is-duckdb.md
    quote: This approach, often used in lakehouse architectures, minimizes data movement
      and complexity.
    char_start: 0
    char_end: 93
- statement: DLT is an open-source library that can be integrated into Python scripts,
    enabling the loading of data from diverse and frequently disorganized sources
    into neatly organized, real-time datasets.
  type: definition
  entity: dlt
  keywords:
  - definition
  - dlt
  - open
  - source
  - library
  - integrated
  - python
  - scripts
  - enabling
  - loading
  - data
  - diverse
  - frequently
  - disorganized
  - sources
  - neatly
  - organized
  - real
  - time
  - datasets
  source:
    doc: motherduck.com/blog/unstructured-analysis-tensorlake-motherduck.md
    quote: DLT is an open-source library that can be integrated into Python scripts,
      enabling the loading of data from diverse and frequently disorganized sources
      into neatly organized, real-time datasets.
    char_start: 0
    char_end: 194
- statement: dlt is used to move data to destinations like DuckDB.
  type: definition
  entity: dlt
  keywords:
  - definition
  - dlt
  - used
  - move
  - data
  - destinations
  - like
  - duckdb
  source:
    doc: motherduck.com/case-studies/trunkrs-same-day-delivery-motherduck-from-redshift.md
    quote: We need to move it to destinations like DuckDB, which we can do by using
      dlt.
    char_start: 0
    char_end: 77
- statement: Using a tool made for ELT, something like dlt, is better.
  type: definition
  entity: dlt
  keywords:
  - definition
  - using
  - tool
  - made
  - elt
  - something
  - like
  - dlt
  - better
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eleven.md
    quote: Therefore, using a tool made for ELT, something like dlt, is better.
    char_start: 0
    char_end: 68
- statement: We ended up using dlt in production when I was at Bedag.
  type: definition
  entity: dlt
  keywords:
  - definition
  - ended
  - up
  - using
  - dlt
  - production
  - bedag
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eleven.md
    quote: We ended up using dlt in production when I was at Bedag.
    char_start: 0
    char_end: 56
- statement: dltHub's Python-based ETL capabilities empower users to build fast, scalable
    analytics pipelines.
  type: definition
  entity: dltHub
  keywords:
  - definition
  - dlthub
  - python
  - based
  - etl
  - capabilities
  - empower
  - users
  - build
  - fast
  - scalable
  - analytics
  - pipelines
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: Explore how dltHub's Python-based ETL capabilities, paired with MotherDuck,
      empower you to effortlessly build fast, scalable analytics pipelines from local
      development to cloud-native production.
    char_start: 0
    char_end: 195
- statement: Docker allows you to create a container image and build it for Linux
    on a Windows machine.
  type: definition
  entity: Docker
  keywords:
  - definition
  - docker
  - allows
  - create
  - container
  - image
  - build
  - linux
  - windows
  - machine
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: Docker is the engine that runs your Dockerfile on all platforms and architectures,
      letting you create a container image and build it for Linux on a Windows machine.
    char_start: 0
    char_end: 164
- statement: Docker containerization is a good start for learning about Infrastructure
    as Code.
  type: definition
  entity: Docker
  keywords:
  - definition
  - docker
  - containerization
  - good
  - start
  - learning
  - about
  - infrastructure
  - code
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: Docker containerization is a good start; here's a beginner's guide.
    char_start: 0
    char_end: 67
- statement: Docker supports different instructions that you can use in a Dockerfile.
  type: definition
  entity: Docker
  keywords:
  - definition
  - docker
  - supports
  - different
  - instructions
  - use
  - dockerfile
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: Docker also supports different instructions that you can use in a Dockerfile.
    char_start: 0
    char_end: 77
- statement: Lazydocker is a terminal UI for Docker that simplifies command usage
    and navigation.
  type: definition
  entity: Docker
  keywords:
  - definition
  - lazydocker
  - terminal
  - ui
  - docker
  - simplifies
  - command
  - usage
  - navigation
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: A terminal UI for Docker that simplifies command usage and navigation
    char_start: 0
    char_end: 69
- statement: Docker Compose is a tool for defining and running multi-container Docker
    applications.
  type: definition
  entity: Docker Compose
  keywords:
  - definition
  - docker
  - compose
  - tool
  - defining
  - running
  - multi
  - container
  - applications
  source:
    doc: motherduck.com/blog/motherduck-kestra-etl-pipelines.md
    quote: Docker Compose file
    char_start: 0
    char_end: 19
- statement: The DocumentAI API can extract AI risk data from filings.
  type: definition
  entity: DocumentAI
  keywords:
  - definition
  - documentai
  - api
  - extract
  - ai
  - risk
  - data
  - filings
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part2.md
    quote: result = doc_ai.parse_and_wait(...)
    char_start: 0
    char_end: 35
- statement: DOLocationID represents taxi zones.
  type: definition
  entity: DOLocationID
  keywords:
  - definition
  - dolocationid
  - represents
  - taxi
  - zones
  source:
    doc: motherduck.com/blog/pushing-geo-boundaries-with-motherduck-geobase.md
    quote: Drop-off Location ID representing taxi zones.
    char_start: 0
    char_end: 45
- statement: Dolt is a version-controlled database that allows for Git-like operations
    on data.
  type: definition
  entity: Dolt
  keywords:
  - definition
  - dolt
  - version
  - controlled
  - database
  - allows
  - git
  - like
  - operations
  - data
  source:
    doc: motherduck.com/blog/motherduck-union-orchestration.md
    quote: This is what I found during research about Dolt.
    char_start: 0
    char_end: 48
- statement: Applications incorporate domain expertise into their data models and
    analytical processes.
  type: definition
  entity: Domain-Specific Analytics Applications
  keywords:
  - definition
  - applications
  - incorporate
  - domain
  - expertise
  - data
  - models
  - analytical
  - processes
  source:
    doc: motherduck.com/ecosystem.md
    quote: Domain-Specific Analytics Applications Tailored for specific industries
      or use cases, these applications incorporate domain expertise into their data
      models and analytical processes.
    char_start: 0
    char_end: 182
- statement: Domain-Specific Analytics Applications incorporate domain expertise into
    their data models.
  type: definition
  entity: Domain-Specific Analytics Applications
  keywords:
  - definition
  - domain
  - specific
  - analytics
  - applications
  - incorporate
  - expertise
  - data
  - models
  source:
    doc: motherduck.com/ecosystem.md
    quote: Domain-Specific Analytics Applications Tailored for specific industries
      or use cases, these applications incorporate domain expertise into their data
      models and analytical processes.
    char_start: 0
    char_end: 182
- statement: DOOM has been ported to WebAssembly, showcasing the technology's ability
    to run complex legacy applications in the browser.
  type: definition
  entity: DOOM
  keywords:
  - definition
  - doom
  - ported
  - webassembly
  - showcasing
  - technology
  - ability
  - run
  - complex
  - legacy
  - applications
  - browser
  source:
    doc: motherduck.com/learn-more/pandas-dataframes-guide.md
    quote: The classic game DOOM has been ported to Wasm, showcasing the technology's
      ability to run complex legacy applications in the browser.
    char_start: 0
    char_end: 133
- statement: DoSomething achieved a 20X cost reduction using MotherDuck.
  type: definition
  entity: DoSomething
  keywords:
  - definition
  - dosomething
  - achieved
  - 20x
  - cost
  - reduction
  - using
  - motherduck
  source:
    doc: motherduck.com/learn-more/partitioned-writes-parquet-ducklake.md
    quote: achieving 20X cost reduction
    char_start: 0
    char_end: 28
- statement: DoSomething aims to fuel young people to change the world.
  type: definition
  entity: DoSomething
  keywords:
  - definition
  - dosomething
  - aims
  - fuel
  - young
  - people
  - change
  - world
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: 'We are proud to continue charting a path as early adopters in this digital
      age in service of our mission: Fueling young people to change the world.'
    char_start: 0
    char_end: 147
- statement: DoSomething focuses on being good stewards of data.
  type: definition
  entity: DoSomething
  keywords:
  - definition
  - dosomething
  - focuses
  - good
  - stewards
  - data
  source:
    doc: motherduck.com/blog/data-engineers-answer-10-top-reddit-questions.md
    quote: it’s important for us to focus on being good stewards of data.
    char_start: 0
    char_end: 62
- statement: DoSomething has adopted MotherDuck as their analytics data warehouse.
  type: definition
  entity: DoSomething
  keywords:
  - definition
  - dosomething
  - adopted
  - motherduck
  - analytics
  - data
  - warehouse
  source:
    doc: motherduck.com/blog/data-engineers-answer-10-top-reddit-questions.md
    quote: This blog highlights our journey and decision to adopt MotherDuck as our
      analytics data warehouse.
    char_start: 0
    char_end: 98
- statement: DoSomething is energized by the promise of Small Data to democratize
    data.
  type: definition
  entity: DoSomething
  keywords:
  - definition
  - dosomething
  - energized
  - promise
  - small
  - data
  - democratize
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: DoSomething is energized by the promise of Small Data to democratize data
      and empower users to move quickly from question to insight.
    char_start: 0
    char_end: 133
- statement: DoSomething is the leading platform for youth-centered impact and service.
  type: definition
  entity: DoSomething
  keywords:
  - definition
  - dosomething
  - leading
  - platform
  - youth
  - centered
  - impact
  - service
  source:
    doc: motherduck.com/blog/data-engineers-answer-10-top-reddit-questions.md
    quote: DoSomething is the leading platform for youth-centered impact and service.
    char_start: 0
    char_end: 74
- statement: DoSomething's previous data stack had become a significant burden.
  type: definition
  entity: DoSomething
  keywords:
  - definition
  - dosomething
  - previous
  - data
  - stack
  - become
  - significant
  - burden
  source:
    doc: motherduck.com/learn-more/secure-startup-data-warehouse.md
    quote: DoSomething has a long history of leveraging technology for good, but their
      previous data stack... had become a significant burden.
    char_start: 0
    char_end: 131
- statement: DoSomething's story is a powerful testament to the impact of data democratization.
  type: definition
  entity: DoSomething
  keywords:
  - definition
  - dosomething
  - story
  - powerful
  - testament
  - impact
  - data
  - democratization
  source:
    doc: motherduck.com/videos/whats-new-in-data-small-data-big-impact.md
    quote: DoSomething's story is a powerful testament to th...
    char_start: 0
    char_end: 52
- statement: DoSomething.org achieved a 20x cost reduction by building a new modern
    data stack.
  type: definition
  entity: DoSomething
  keywords:
  - definition
  - dosomething
  - org
  - achieved
  - 20x
  - cost
  - reduction
  - building
  - new
  - modern
  - data
  - stack
  source:
    doc: motherduck.com/videos/from-curiosity-to-impact-how-dosomething-democratized-data.md
    quote: By building a new modern data stack with MotherDuck, they achieved a 20x
      cost reduction.
    char_start: 0
    char_end: 88
- statement: DoSomething.org transformed their data culture and empowered their entire
    team.
  type: definition
  entity: DoSomething
  keywords:
  - definition
  - dosomething
  - org
  - transformed
  - data
  - culture
  - empowered
  - entire
  - team
  source:
    doc: motherduck.com/videos/from-curiosity-to-impact-how-dosomething-democratized-data.md
    quote: transformed their data culture, and empowered their entire team with self-serve
      analytics.
    char_start: 0
    char_end: 90
- statement: DoSomething.org used a SQL-first stack to enable non-technical users
    to explore data independently.
  type: definition
  entity: DoSomething
  keywords:
  - definition
  - dosomething
  - org
  - used
  - sql
  - first
  - stack
  - enable
  - non
  - technical
  - users
  - explore
  - data
  - independently
  source:
    doc: motherduck.com/videos/whats-new-in-data-small-data-big-impact.md
    quote: DoSomething.org used this approach to enable non-technical users to explore
      data independently, fostering a more data-driven culture.
    char_start: 0
    char_end: 133
- statement: Dot is an intelligent virtual data assistant that answers business data
    questions.
  type: definition
  entity: Dot
  keywords:
  - definition
  - dot
  - intelligent
  - virtual
  - data
  - assistant
  - answers
  - business
  - questions
  source:
    doc: motherduck.com/ecosystem.md
    quote: Dot, the data bot is an intelligent virtual data assistance that answers
      business data questions.
    char_start: 0
    char_end: 97
- statement: The dataset DQS_Cholesterol_in_adults_age_20 relates to cholesterol levels
    in adults aged 20.
  type: definition
  entity: DQS_Cholesterol_in_adults_age_20
  keywords:
  - definition
  - dataset
  - dqs
  - cholesterol
  - adults
  - age
  - '20'
  - relates
  - levels
  - aged
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md
    quote: A dataset related to cholesterol levels in adults aged 20.
    char_start: 0
    char_end: 58
- statement: Dremel can scan and aggregate over 85B records in about 20 seconds.
  type: performance
  entity: Dremel
  keywords:
  - performance
  - dremel
  - scan
  - aggregate
  - over
  - 85b
  - records
  - about
  - '20'
  - seconds
  source:
    doc: motherduck.com/ecosystem.md
    quote: In the Dremel paper, the main performance result showed being able to do
      a scan and aggregation query over 85B records in about 20 seconds.
    char_start: 0
    char_end: 139
- statement: Modern single-node machines can achieve performance levels previously
    thought only possible with large clusters.
  type: definition
  entity: Dremel
  keywords:
  - definition
  - modern
  - single
  - node
  - machines
  - achieve
  - performance
  - levels
  - previously
  - thought
  - possible
  - large
  - clusters
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: Today you can get equivalent performance on a single machine.
    char_start: 0
    char_end: 61
- statement: Optimizations reduce the round trips needed for many Dual Execution queries
    from two to one.
  type: definition
  entity: Dual Execution
  keywords:
  - definition
  - optimizations
  - reduce
  - round
  - trips
  - needed
  - many
  - dual
  - execution
  - queries
  - two
  - one
  source:
    doc: motherduck.com/blog/announcing-ducklake-support-motherduck-preview.md
    quote: We’ve made optimizations to reduce the round trips needed for many Dual
      Execution queries from two to one.
    char_start: 0
    char_end: 106
- statement: The dual execution planner reduces network traffic by orders of magnitude
    compared to traditional methods.
  type: definition
  entity: Dual Execution
  keywords:
  - definition
  - dual
  - execution
  - planner
  - reduces
  - network
  - traffic
  - orders
  - magnitude
  - compared
  - traditional
  - methods
  source:
    doc: motherduck.com/learn-more/ducklake-guide.md
    quote: This process can reduce network traffic by orders of magnitude compared
      to traditional methods.
    char_start: 0
    char_end: 95
- statement: The dual execution model minimizes data movement and improves query performance.
  type: definition
  entity: Dual Execution model
  keywords:
  - definition
  - dual
  - execution
  - model
  - minimizes
  - data
  - movement
  - improves
  - query
  - performance
  source:
    doc: motherduck.com/videos/taming-file-zoos-data-science-with-duckdb-database-files.md
    quote: The primary goal is to minimize data movement and leverage compute where
      it makes the most sense.
    char_start: 0
    char_end: 97
- statement: DuckCon is a conference organized by the DuckDB team.
  type: definition
  entity: DuckCon
  keywords:
  - definition
  - duckcon
  - conference
  - organized
  - duckdb
  - team
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: A conference organized by the DuckDB team.
    char_start: 0
    char_end: 42
- statement: DuckCon will be held for the first time outside of Europe in San Francisco.
  type: definition
  entity: DuckCon
  keywords:
  - definition
  - duckcon
  - held
  - first
  - time
  - outside
  - europe
  - san
  - francisco
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-six.md
    quote: DuckCon will be held for the first time outside of Europe in San Francisco.
    char_start: 0
    char_end: 75
- statement: DuckCon 2023 SF was an incredible event for the DuckDB ecosystem.
  type: definition
  entity: DuckCon 2023 SF
  keywords:
  - definition
  - duckcon
  - '2023'
  - sf
  - incredible
  - event
  - duckdb
  - ecosystem
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eight.md
    quote: Another month, another incredible time for the DuckDB ecosystem, especially
      after an incredible DuckCon 2023 SF.
    char_start: 0
    char_end: 112
- statement: A DISTINCT r, g, b query finishes in about 2 minutes.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - distinct
  - query
  - finishes
  - about
  - minutes
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: a DISTINCT r, g, b query, benefiting from DuckDB's larger-than-memory aggregate
      hash table, finishes in about 2 minutes.
    char_start: 0
    char_end: 120
- statement: A DuckDB checkpoint will trigger Differential Storage to perform a snapshot.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - checkpoint
  - trigger
  - differential
  - storage
  - perform
  - snapshot
  source:
    doc: motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw.md
    quote: A DuckDB checkpoint will trigger Differential Storage to perform a snapshot.
    char_start: 0
    char_end: 76
- statement: A key technical challenge was ensuring compatibility between MySQL and
    DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - key
  - technical
  - challenge
  - ensuring
  - compatibility
  - mysql
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: A key technical challenge was ensuring compatibility between MySQL and
      DuckDB.
    char_start: 0
    char_end: 78
- statement: A lean, low-latency warehouse is an ideal engine for operational dashboards.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - lean
  - low
  - latency
  - warehouse
  - ideal
  - engine
  - operational
  - dashboards
  source:
    doc: motherduck.com/videos/duckdb-tutorial-for-beginners.md
    quote: A lean, low-latency warehouse is an ideal engine for these operational
      dashboards.
    char_start: 0
    char_end: 82
- statement: A modern data warehouse changes the workflow by making the data scientist's
    notebook a powerful, direct client to terabytes of data.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - modern
  - data
  - warehouse
  - changes
  - workflow
  - making
  - scientist
  - notebook
  - powerful
  - direct
  - client
  - terabytes
  source:
    doc: motherduck.com/learn-more/hybrid-analytics-guide.md
    quote: A modern data warehouse changes this workflow by making the data scientist's
      notebook a powerful, direct client to terabytes of data.
    char_start: 0
    char_end: 133
- statement: A query on a local file runs entirely on your machine's resources.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - query
  - local
  - file
  - runs
  - entirely
  - machine
  - resources
  source:
    doc: motherduck.com/learn-more/pandas-dataframes-guide.md
    quote: A query on a local file runs entirely on your machine's resources.
    char_start: 0
    char_end: 66
- statement: A query scanning a 5 GB Apache Iceberg table took 5.093 seconds to run.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - query
  - scanning
  - gb
  - apache
  - iceberg
  - table
  - took
  - '5.093'
  - seconds
  - run
  source:
    doc: motherduck.com/videos/duckfooding-at-motherduck.md
    quote: a query scanning a 5 GB Apache Iceberg table with thousands of small files
      took **5.093 seconds** to run.
    char_start: 0
    char_end: 105
- statement: A semantic layer provides a unified view of metrics across different
    BI tools.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - semantic
  - layer
  - provides
  - unified
  - view
  - metrics
  - across
  - different
  - bi
  - tools
  source:
    doc: motherduck.com/blog/pushing-geo-boundaries-with-motherduck-geobase.md
    quote: Managing 100+ metrics across multiple tools without a single unified view
      becomes a governance nightmare.
    char_start: 0
    char_end: 105
- statement: A STRUCT in DuckDB is a way to group multiple related pieces of data
    into a single column.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - struct
  - duckdb
  - way
  - group
  - multiple
  - related
  - pieces
  - data
  - single
  - column
  source:
    doc: motherduck.com/videos/using-sql-in-your-data-lake-with-duckdb-iceberg-dbt-and-motherduck.md
    quote: At its core, a STRUCT in DuckDB is a way to group multiple related pieces
      of data, potentially of different data types, into a single column.
    char_start: 0
    char_end: 141
- statement: Adopting a local-first development workflow can help in cost management.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - adopting
  - local
  - first
  - development
  - workflow
  - help
  - cost
  - management
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: adopt a local-first development workflow by building and testing data models
      on a local machine...
    char_start: 0
    char_end: 98
- statement: Against PostgreSQL with all indexes, speed-ups are nice but not astounding–up
    to ~4x faster.
  type: performance
  entity: DuckDB
  keywords:
  - performance
  - against
  - postgresql
  - indexes
  - speed
  - ups
  - nice
  - astounding
  - up
  - 4x
  - faster
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: Against PostgreSQL with all indexes, speed-ups are nice but not astounding–up
      to ~4x faster.
    char_start: 0
    char_end: 92
- statement: AI assistants can work effectively with DuckDB by ensuring access to
    current documentation standards.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - ai
  - assistants
  - work
  - effectively
  - duckdb
  - ensuring
  - access
  - current
  - documentation
  - standards
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md
    quote: 'Two complementary approaches enable AI assistants to work effectively
      with DuckDB: ensuring access to current documentation standards, and creating
      self-correcting SQL workflows that let AI autonomous'
    char_start: 0
    char_end: 217
- statement: Airbyte is an open-source data integration platform that enables the
    seamless transfer of data from various sources to data warehouses.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - airbyte
  - open
  - source
  - data
  - integration
  - platform
  - enables
  - seamless
  - transfer
  - various
  - sources
  - warehouses
  source:
    doc: motherduck.com/glossary/CSV.md
    quote: Airbyte is an open-source data integration platform that enables the seamless
      transfer of data from various sources to data warehouses.
    char_start: 0
    char_end: 135
- statement: 'Alex Monahan of DuckDB Labs and MotherDuck will present a talk on ''Python
    and SQL: Better Together, Powered by @DuckDB.'''
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - alex
  - monahan
  - duckdb
  - labs
  - motherduck
  - present
  - talk
  - python
  - sql
  - better
  - together
  - powered
  source:
    doc: motherduck.com/blog/building-motherduck-partner-ecosystem.md
    quote: 'Alex Monahan of DuckDB Labs and MotherDuck will present a talk on ''Python
      and SQL: Better Together, Powered by @DuckDB.'''
    char_start: 0
    char_end: 120
- statement: Alibaba Cloud RDS has integrated DuckDB as a new storage engine to enhance
    analytical query performance within MySQL.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - alibaba
  - cloud
  - rds
  - integrated
  - duckdb
  - new
  - storage
  - engine
  - enhance
  - analytical
  - query
  - performance
  - within
  - mysql
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: Alibaba Cloud RDS has integrated DuckDB as a new storage engine to enhance
      analytical query performance within MySQL.
    char_start: 0
    char_end: 117
- statement: An interactive dashboard typically requires data and a query engine.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - interactive
  - dashboard
  - typically
  - requires
  - data
  - query
  - engine
  source:
    doc: motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud.md
    quote: 'When building an analytical dashboard, you typically need to have two
      things: The data and A query engine, typically an OLAP database.'
    char_start: 0
    char_end: 134
- statement: Analyzing a 20 GB file becomes straightforward with DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - analyzing
  - '20'
  - gb
  - file
  - becomes
  - straightforward
  - duckdb
  source:
    doc: motherduck.com/learn-more/product-analytics-motherduck-duckdb.md
    quote: This capability turns your laptop into a surprisingly powerful analytics
      workstation.
    char_start: 0
    char_end: 85
- statement: Andreas explains how to set up DuckDB locally, demonstrating querying
    CSV/Parquet files.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - andreas
  - explains
  - set
  - up
  - duckdb
  - locally
  - demonstrating
  - querying
  - csv
  - parquet
  - files
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md
    quote: Andreas explains how to set up DuckDB locally, demonstrating querying CSV/Parquet
      files.
    char_start: 0
    char_end: 88
- statement: Any DuckDB instance in the world running in Python or CLI can connect
    to MotherDuck with a single line of code.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - any
  - duckdb
  - instance
  - world
  - running
  - python
  - cli
  - connect
  - motherduck
  - single
  - line
  - code
  source:
    doc: motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud.md
    quote: To that end, any DuckDB instance in the world running in Python or CLI
      can connect to MotherDuck with a single line of code.
    char_start: 0
    char_end: 124
- statement: Apache Arrow is a cross-language development platform for in-memory data.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - apache
  - arrow
  - cross
  - language
  - development
  - platform
  - memory
  - data
  source:
    doc: motherduck.com/blog.md
    quote: A cross-language development platform for in-memory data.
    char_start: 0
    char_end: 57
- statement: Archie at Evidence.dev has built a DuckDB community extension for Google
    Sheets.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - archie
  - evidence
  - dev
  - built
  - duckdb
  - community
  - extension
  - google
  - sheets
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: Archie at Evidence.dev has been up to stuff - specifically building a DuckDB
      community extension for Google Sheets.
    char_start: 0
    char_end: 115
- statement: Artefact is a leading global consulting company dedicated to accelerating
    the adoption of data and AI.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - artefact
  - leading
  - global
  - consulting
  - company
  - dedicated
  - accelerating
  - adoption
  - data
  - ai
  source:
    doc: motherduck.com/glossary/Apache Arrow.md
    quote: Artefact is a leading global consulting company dedicated to accelerating
      the adoption of data and AI.
    char_start: 0
    char_end: 102
- statement: As soon as the file is uploaded, the flow will check it for anomalies
    using a DuckDB query.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - soon
  - file
  - uploaded
  - flow
  - check
  - anomalies
  - using
  - duckdb
  - query
  source:
    doc: motherduck.com/blog/effortless-etl-unstructured-data-unstructuredio-motherduck.md
    quote: As soon as the file is uploaded, the flow will check it for anomalies using
      a DuckDB query.
    char_start: 0
    char_end: 91
- statement: Atlan is replacing Apache Spark with DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - atlan
  - replacing
  - apache
  - spark
  - duckdb
  source:
    doc: motherduck.com/blog/announcing-ducklake-support-motherduck-preview.md
    quote: 'Atlan: Replacing Apache Spark by DuckDB'
    char_start: 0
    char_end: 39
- statement: Average query time reduced from 3.7s (Snowflake) to 0.455s (DuckDB).
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - average
  - query
  - time
  - reduced
  - '3.7'
  - snowflake
  - '0.455'
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: an average query time reduction from 3.7s (Snowflake) to 0.455s (DuckDB).
    char_start: 0
    char_end: 73
- statement: Building a zero-cost data engineering stack with DuckDB and MotherDuck
    for efficient data storage and analytics.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - building
  - zero
  - cost
  - data
  - engineering
  - stack
  - duckdb
  - motherduck
  - efficient
  - storage
  - analytics
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: Building a zero-cost data engineering stack with DuckDB and MotherDuck
      for efficient data storage and analytics.
    char_start: 0
    char_end: 112
- statement: Building on MotherDuck means I don't have to manage the server myself.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - building
  - motherduck
  - means
  - don
  - manage
  - server
  - myself
  source:
    doc: motherduck.com/glossary/result.md
    quote: And best of all, building on MotherDuck means I don't have to manage the
      server myself.
    char_start: 0
    char_end: 87
- statement: BuzzFeed's data team has integrated large language models and generative
    AI capabilities into their products.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - buzzfeed
  - data
  - team
  - integrated
  - large
  - language
  - models
  - generative
  - ai
  - capabilities
  - products
  source:
    doc: motherduck.com/videos/querying-data-from-s3-with-3-lines-in-your-terminal.md
    quote: BuzzFeed's data team, led by Gilad, has integrated large language models
      and generative AI capabilities into their products and toolkits to enhance creative
      processes.
    char_start: 0
    char_end: 167
- statement: By operating on cache-sized chunks, DuckDB avoids the main memory bottleneck
    and achieves incredible processing speed.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - operating
  - cache
  - sized
  - chunks
  - duckdb
  - avoids
  - main
  - memory
  - bottleneck
  - achieves
  - incredible
  - processing
  - speed
  source:
    doc: motherduck.com/learn-more/star-schema-data-warehouse-guide.md
    quote: By operating on these cache-sized chunks, DuckDB avoids the main memory
      bottleneck and achieves incredible processing speed.
    char_start: 0
    char_end: 124
- statement: By statically compiling DuckDB, developers can include essential extensions
    directly into the DuckDB binary.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - statically
  - compiling
  - duckdb
  - developers
  - include
  - essential
  - extensions
  - directly
  - binary
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2024.md
    quote: By statically compiling DuckDB, as outlined by Colin, developers can include
      essential extensions, such as icu, parquet, and sqlite_scanner, directly into
      the DuckDB binary.
    char_start: 0
    char_end: 173
- statement: By understanding these slightly more advanced options, you can often
    avoid external preprocessing steps.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - understanding
  - slightly
  - advanced
  - options
  - often
  - avoid
  - external
  - preprocessing
  - steps
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: By understanding these slightly more advanced options, you can often avoid
      external preprocessing steps, keeping your data loading logic right within your
      SQL workflow.
    char_start: 0
    char_end: 168
- statement: Bypassing the JVM can make pipelines with small data faster and more
    cost-efficient.
  type: performance
  entity: DuckDB
  keywords:
  - performance
  - bypassing
  - jvm
  - make
  - pipelines
  - small
  - data
  - faster
  - cost
  - efficient
  source:
    doc: motherduck.com/blog/local-duckdb-ui-visual-data-analysis.md
    quote: We’ve seen how bypassing the JVM can make pipelines with small data faster
      and more cost-efficient, especially around development, CI, and execution.
    char_start: 0
    char_end: 149
- statement: Changing the export as parquet and import to Postgres with an in-memory
    DuckDB speeded up the process order of magnitude.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - changing
  - export
  - parquet
  - import
  - postgres
  - memory
  - duckdb
  - speeded
  - up
  - process
  - order
  - magnitude
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eleven.md
    quote: Changing the export as parquet and import to Postgres with an in-memory
      DuckDB speeded up the process order of magnitude.
    char_start: 0
    char_end: 121
- statement: Choosing a database should consider its future capabilities.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - choosing
  - database
  - consider
  - future
  - capabilities
  source:
    doc: motherduck.com/blog/secoda-motherduck-integration-modern-duck-stack.md
    quote: A very important variable, then, is not just what the database can do now,
      but what it will be able to do a year in the future.
    char_start: 0
    char_end: 127
- statement: ClickHouse and DuckDB can be friends.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - clickhouse
  - duckdb
  - friends
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eight.md
    quote: ClickHouse and DuckDB can be friends
    char_start: 0
    char_end: 36
- statement: Combining current documentation access with isolated execution environments
    eliminates traditional AI-SQL debugging cycles.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - combining
  - current
  - documentation
  - access
  - isolated
  - execution
  - environments
  - eliminates
  - traditional
  - ai
  - sql
  - debugging
  - cycles
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: LLM Takeaway Combining current documentation access with isolated execution
      environments eliminates traditional AI-SQL debugging cycles.
    char_start: 0
    char_end: 136
- statement: Companies are running DuckDB in production.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - companies
  - running
  - duckdb
  - production
  source:
    doc: motherduck.com/blog/from-data-lake-to-lakehouse-duckdb-portable-catalog.md
    quote: Discover how companies are running DuckDB in production
    char_start: 0
    char_end: 55
- statement: Create VSCode shortcuts for making it easy to send your SQL queries to
    DuckDB for execution.
  type: instruction
  entity: DuckDB
  keywords:
  - instruction
  - create
  - vscode
  - shortcuts
  - making
  - easy
  - send
  - sql
  - queries
  - duckdb
  - execution
  source:
    doc: motherduck.com/videos.md
    quote: Create VSCode shortcuts for making it easy to send your SQL queries to
      DuckDB for execution in the integrated terminal.
    char_start: 0
    char_end: 119
- statement: Creating a huge number of partitions can be counterproductive.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - creating
  - huge
  - number
  - partitions
  - counterproductive
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: Creating a huge number of partitions (e.g., partitioning by a high-cardinality
      ID field or by the second) can be counterproductive.
    char_start: 0
    char_end: 131
- statement: Creating lookup tables for repeated values can reduce query time from
    several minutes to just 0.166 seconds.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - creating
  - lookup
  - tables
  - repeated
  - values
  - reduce
  - query
  - time
  - several
  - minutes
  - '0.166'
  - seconds
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: he created tables that normalized nested JSON with unique values and IDs,
      reducing the original query from several minutes to just 0.166 seconds.
    char_start: 0
    char_end: 145
- statement: Cross-version compatibility allows extensions to work across DuckDB versions.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - cross
  - version
  - compatibility
  - allows
  - extensions
  - work
  - across
  - duckdb
  - versions
  source:
    doc: motherduck.com/videos/what-if-sql-queries-returned-results-instantly.md
    quote: Cross-version compatibility (extensions may work across DuckDB versions)
    char_start: 0
    char_end: 72
- statement: Cursor integrates with DuckDB for SQL debugging.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - cursor
  - integrates
  - duckdb
  - sql
  - debugging
  source:
    doc: motherduck.com/blog/duckdb-dashboard-e2e-data-engineering-project-part-3.md
    quote: A tool that integrates with DuckDB for SQL debugging.
    char_start: 0
    char_end: 53
- statement: Dashboards load within the 110 ms SLA target.
  type: performance
  entity: DuckDB
  keywords:
  - performance
  - dashboards
  - load
  - within
  - '110'
  - ms
  - sla
  - target
  source:
    doc: motherduck.com/learn-more/columnar-storage-guide.md
    quote: Dashboards load within the 110 ms SLA target because there is no extra
      network hop through an external query API.
    char_start: 0
    char_end: 113
- statement: Data applications have become indispensable tools for organizations seeking
    to harness the power of their data assets.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - data
  - applications
  - become
  - indispensable
  - tools
  - organizations
  - seeking
  - harness
  - power
  - assets
  source:
    doc: motherduck.com/ecosystem/paradime.md
    quote: Data applications have become indispensable tools for organizations seeking
      to harness the power of their data assets.
    char_start: 0
    char_end: 118
- statement: Data is loaded into DuckDB using Debezium.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - data
  - loaded
  - duckdb
  - using
  - debezium
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: These events are then consumed by a Python-based dlt pipeline that uses
      pydbzengine, simplifying configuring and running Debezium within Python.
    char_start: 0
    char_end: 144
- statement: Data scientists, application developers, data engineers, and analysts
    use DuckDB to process and analyze large datasets efficiently.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - data
  - scientists
  - application
  - developers
  - engineers
  - analysts
  - use
  - duckdb
  - process
  - analyze
  - large
  - datasets
  - efficiently
  source:
    doc: motherduck.com/videos/is-bi-too-big-for-small-data.md
    quote: Data scientists, application developers, data engineers, and analysts use
      DuckDB to process and analyze large datasets efficiently.
    char_start: 0
    char_end: 131
- statement: Data volume under 10 TB is 'likely unnecessary' and potentially 'slower
    than vanilla DuckDB'.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - data
  - volume
  - '10'
  - tb
  - likely
  - unnecessary
  - potentially
  - slower
  - vanilla
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: Data volume under 10 TB is 'likely unnecessary' and potentially 'slower
      than vanilla DuckDB'.
    char_start: 0
    char_end: 93
- statement: Database benchmarks are a poor way to choose a database.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - database
  - benchmarks
  - poor
  - way
  - choose
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-one.md
    quote: Are database benchmarks still relevant? Let's understand why it's a poor
      way to choose a database.
    char_start: 0
    char_end: 98
- statement: DataCamp's SQL notebooks are powered by DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - datacamp
  - sql
  - notebooks
  - powered
  - duckdb
  source:
    doc: motherduck.com/learn-more/self-service-analytics-startups.md
    quote: DataCamp’s SQL notebooks, powered by DuckDB.
    char_start: 0
    char_end: 44
- statement: DataKit integrates DuckDB with PostgreSQL, allowing users to perform
    OLAP queries on OLTP data through a browser-based UI without needing data replicas.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - datakit
  - integrates
  - duckdb
  - postgresql
  - allowing
  - users
  - perform
  - olap
  - queries
  - oltp
  - data
  - browser
  - based
  - ui
  - without
  - needing
  - replicas
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: DataKit integrates DuckDB with PostgreSQL, allowing users to perform OLAP
      queries on OLTP data through a browser-based UI without needing data replicas.
    char_start: 0
    char_end: 152
- statement: DB Quacks introduces an interactive, browser-based SQL learning platform
    powered by DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - db
  - quacks
  - introduces
  - interactive
  - browser
  - based
  - sql
  - learning
  - platform
  - powered
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: DB Quacks introduces an interactive, browser-based SQL learning platform
      powered by DuckDB.
    char_start: 0
    char_end: 91
- statement: dbt tests are crucial for ensuring data quality and consistency.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - dbt
  - tests
  - crucial
  - ensuring
  - data
  - quality
  - consistency
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Ensuring data quality and consistency of your data (and your SQL code)
      might be more critical than ever.
    char_start: 0
    char_end: 104
- statement: Dedicated vector databases like Pinecone, Weaviate, Qdrant, Zilliz, and
    Chroma are specialized solutions for AI workloads.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - dedicated
  - vector
  - databases
  - like
  - pinecone
  - weaviate
  - qdrant
  - zilliz
  - chroma
  - specialized
  - solutions
  - ai
  - workloads
  source:
    doc: motherduck.com/ecosystem/unstructured.md
    quote: Dedicated vector databases like Pinecone, Weaviate, Qdrant, Zilliz, and
      Chroma have positioned themselves as specialized solutions for AI workloads.
    char_start: 0
    char_end: 148
- statement: DeepSeek's smallpond extends DuckDB's capabilities to distributed computing.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - deepseek
  - smallpond
  - extends
  - duckdb
  - capabilities
  - distributed
  - computing
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: DeepSeek's smallpond extends DuckDB's capabilities to distributed computing.
    char_start: 0
    char_end: 76
- statement: Delta Lake support was announced for DuckDB during the DATA+AI Summit
    2024.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - delta
  - lake
  - support
  - announced
  - duckdb
  - data
  - ai
  - summit
  - '2024'
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: During the DATA+AI Summit 2024 by Databricks, a major announcement was
      the support of Delta Lake in DuckDB.
    char_start: 0
    char_end: 107
- statement: Developer productivity with DuckDB is just awesome.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - developer
  - productivity
  - duckdb
  - awesome
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md
    quote: 'the post is worth a read because it highlights a very important point
      on why people are selecting DuckDB for more and more projects: developer productivity
      with DuckDB is just awesome'
    char_start: 0
    char_end: 183
- statement: Developers can start with SQL-only extensions using macros.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - developers
  - start
  - sql
  - extensions
  - using
  - macros
  source:
    doc: motherduck.com/learn-more/partitioned-writes-parquet-ducklake.md
    quote: Start with SQL-only extensions using macros - the simplest entry point.
    char_start: 0
    char_end: 71
- statement: Distributed systems create significant latency due to overhead.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - distributed
  - systems
  - create
  - significant
  - latency
  - due
  - overhead
  source:
    doc: motherduck.com/videos/whats-new-in-data-small-data-big-impact.md
    quote: The answer lies in the overhead of distributed computing.
    char_start: 0
    char_end: 57
- statement: dlt integrates with MotherDuck by enabling users to load data directly
    into the MotherDuck cloud data warehouse.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - dlt
  - integrates
  - motherduck
  - enabling
  - users
  - load
  - data
  - directly
  - cloud
  - warehouse
  source:
    doc: motherduck.com/ecosystem/sqlmesh.md
    quote: dlt integrates with MotherDuck by enabling users to load data directly
      into the MotherDuck cloud data warehouse.
    char_start: 0
    char_end: 112
- statement: Dot notation is the most common method to access STRUCT data.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - dot
  - notation
  - common
  - method
  - access
  - struct
  - data
  source:
    doc: motherduck.com/videos/the-power-of-wasm-for-analytics-duckdb-in-the-browser.md
    quote: The most common method, and probably the easiest to read, is dot notation.
    char_start: 0
    char_end: 74
- statement: Dual execution is a feature of DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - dual
  - execution
  - feature
  - duckdb
  source:
    doc: motherduck.com/videos.md
    quote: Mehdi and Steph explain dual execution, showing how it works and use cases
      for the technology.
    char_start: 0
    char_end: 94
- statement: Dual Query Execution allows applications to leverage local compute and
    cloud resources.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - dual
  - query
  - execution
  - allows
  - applications
  - leverage
  - local
  - compute
  - cloud
  - resources
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: Through Dual Query Execution, applications can leverage local compute and
      cloud resources.
    char_start: 0
    char_end: 90
- statement: 'DuckCon #4 talk videos have been released.'
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckcon
  - talk
  - videos
  - released
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: The DuckDB team released videos from the talks.
    char_start: 0
    char_end: 47
- statement: 'DuckCon #4 will take place on 2 February 2024 in Amsterdam.'
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckcon
  - take
  - place
  - february
  - '2024'
  - amsterdam
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: The event will begin with a talk by DuckDB's creators, Hannes Mühleisen
      and Mark Raasveldt.
    char_start: 0
    char_end: 91
- statement: 'DuckCon #6 will take place in Amsterdam.'
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckcon
  - take
  - place
  - amsterdam
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: 'DuckCon #6, DuckDB''s next user group meeting in Amsterdam, the Netherlands.'
    char_start: 0
    char_end: 75
- statement: DuckCon this year had an exciting mix of talks from the core DuckDB team
    and the community.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckcon
  - year
  - exciting
  - mix
  - talks
  - core
  - duckdb
  - team
  - community
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2024.md
    quote: DuckCon this year had an exciting mix of talks from the core DuckDB team
      and the community.
    char_start: 0
    char_end: 91
- statement: DuckDB 0.7.0 introduces JSON ingestion through read_json, partitioned
    Parquet and CSV export, and more.
  type: feature
  entity: DuckDB
  keywords:
  - feature
  - duckdb
  - 0.7.0
  - introduces
  - json
  - ingestion
  - read
  - partitioned
  - parquet
  - csv
  - export
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: This new release introduces JSON ingestion through read_json, partitioned
      Parquet and CSV export, attaching multiple DuckDB databases in the same instance,
      SQLite storage backend, UPSERTs, LATERAL and
    char_start: 0
    char_end: 269
- statement: DuckDB 1.3.0 introduces a file cache for remote data.
  type: feature
  entity: DuckDB
  keywords:
  - feature
  - duckdb
  - 1.3.0
  - introduces
  - file
  - cache
  - remote
  - data
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: DuckDB 1.3.0 'Ossivalis' introduces a file cache for remote data.
    char_start: 0
    char_end: 65
- statement: DuckDB 1.4.0 introduces database encryption using AES-256-GCM.
  type: feature
  entity: DuckDB
  keywords:
  - feature
  - duckdb
  - 1.4.0
  - introduces
  - database
  - encryption
  - using
  - aes
  - '256'
  - gcm
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: DuckDB 1.4.0 introduces several improvements, such as database encryption
      using industry-standard AES with 256-bit keys and GCM mode.
    char_start: 0
    char_end: 133
- statement: DuckDB 1.4.0 LTS includes database encryption and MERGE statements.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - 1.4.0
  - lts
  - includes
  - database
  - encryption
  - merge
  - statements
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: DuckDB 1.4.0 LTS with database encryption and MERGE statements
    char_start: 0
    char_end: 62
- statement: DuckDB 58× faster spatial joins.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - '58'
  - faster
  - spatial
  - joins
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: DuckDB 58× faster spatial joins
    char_start: 0
    char_end: 31
- statement: DuckDB achieves 99% SQL compatibility based on a test suite of 170,000
    SQL tests.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - achieves
  - '99'
  - sql
  - compatibility
  - based
  - test
  - suite
  - '170'
  - '000'
  - tests
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: was ensuring compatibility between MySQL and DuckDB, which involved extending
      DuckDB's parser and rewriting many functions to achieve 99% SQL compatibility
      based on a test suite of 170,000 SQL tests.
    char_start: 0
    char_end: 199
- statement: DuckDB aligns perfectly with data preparation in Machine Learning pipelines.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - aligns
  - perfectly
  - data
  - preparation
  - machine
  - learning
  - pipelines
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eleven.md
    quote: One of the most time-consuming steps in a Machine Learning pipeline is
      data preparation. DuckDB aligns perfectly with this use case as it integrates
      seamlessly with Pandas-like data workflows.
    char_start: 0
    char_end: 192
- statement: DuckDB allows comparison of STRUCTs using standard comparison operators.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - allows
  - comparison
  - structs
  - using
  - standard
  - operators
  source:
    doc: motherduck.com/videos/using-sql-in-your-data-lake-with-duckdb-iceberg-dbt-and-motherduck.md
    quote: While not as common as accessing or flattening, you can also compare STRUCTs
      in DuckDB using standard comparison operators.
    char_start: 0
    char_end: 123
- statement: DuckDB allows customization of output display.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - allows
  - customization
  - output
  - display
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: If you’re not 100% satisfied with DuckDB’s output to the console, there
      are lots of choices to customize the output.
    char_start: 0
    char_end: 116
- statement: DuckDB allows dynamic column selection using regular expressions.
  type: feature
  entity: DuckDB
  keywords:
  - feature
  - duckdb
  - allows
  - dynamic
  - column
  - selection
  - using
  - regular
  - expressions
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Mark uses a wide dataset from Kaggle's FIFA 2022 in this article and applies
      the new features.
    char_start: 0
    char_end: 94
- statement: DuckDB allows executing SQL queries using the fetchall() method.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - allows
  - executing
  - sql
  - queries
  - using
  - fetchall
  - method
  source:
    doc: motherduck.com/blog/streaming-oracle-to-motherduck.md
    quote: The other primary way to execute SQL is using the execute() method...
    char_start: 0
    char_end: 69
- statement: DuckDB allows for caching samples of certain table references.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - allows
  - caching
  - samples
  - certain
  - table
  - references
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-three.md
    quote: We need a way to locally cache samples of certain table references.
    char_start: 0
    char_end: 67
- statement: DuckDB allows for transaction management.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - allows
  - transaction
  - management
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part1.md
    quote: The first UPDATE statement debits money from Account A. The second UPDATE
      statement credits money to Account B.
    char_start: 0
    char_end: 111
- statement: DuckDB allows joining local and remote data.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - allows
  - joining
  - local
  - remote
  - data
  source:
    doc: motherduck.com/blog/vibe-coding-sql-cursor.md
    quote: You can join a local CSV file with a multi-gigabyte table stored in MotherDuck.
    char_start: 0
    char_end: 79
- statement: DuckDB allows loading everything as VARCHAR.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - allows
  - loading
  - everything
  - varchar
  source:
    doc: motherduck.com/glossary/SQL analytics.md
    quote: If you want to load everything as VARCHAR and deal with types later.
    char_start: 0
    char_end: 68
- statement: DuckDB allows querying of TV show data.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - allows
  - querying
  - tv
  - show
  - data
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: D SELECT show.name, show.type, show.summary FROM read_json('https://api.tvmaze.com/search/shows?q=duck',
      auto_detect=true);
    char_start: 0
    char_end: 123
- statement: DuckDB allows renaming fields in a SELECT * query across multiple tables.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - allows
  - renaming
  - fields
  - select
  - query
  - across
  - multiple
  - tables
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: Robin addresses the challenge of distinguishing fields from different tables
      after a JOIN operation...
    char_start: 0
    char_end: 102
- statement: DuckDB allows resampling time series data by implementing date truncation.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - allows
  - resampling
  - time
  - series
  - data
  - implementing
  - date
  - truncation
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eleven.md
    quote: resampling time series data by implementing date truncation and interval
      arithmetic.
    char_start: 0
    char_end: 84
- statement: DuckDB allows running pipeline transformations without needing a Spark
    cluster.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - allows
  - running
  - pipeline
  - transformations
  - without
  - needing
  - spark
  - cluster
  source:
    doc: motherduck.com/blog/pg-duckdb-release.md
    quote: This allows us to run any pipeline transformation with the Pyspark DataFrame
      API without needing a Spark cluster or dependencies.
    char_start: 0
    char_end: 129
- statement: DuckDB allows running workflows directly on your computer.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - allows
  - running
  - workflows
  - directly
  - computer
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2024.md
    quote: Turning documents into a knowledge base for AI with DuckDB is incredibly
      exciting because you can run this workflow directly on your computer.
    char_start: 0
    char_end: 142
- statement: DuckDB allows some processing to occur at the point of log creation.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - allows
  - processing
  - occur
  - point
  - log
  - creation
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-four.md
    quote: Thanks to its portability, DuckDB allows some of this processing to occur
      at the point of log creation.
    char_start: 0
    char_end: 103
- statement: DuckDB allows the use of custom HTTP headers for API calls.
  type: feature
  entity: DuckDB
  keywords:
  - feature
  - duckdb
  - allows
  - use
  - custom
  - http
  - headers
  - api
  - calls
  source:
    doc: motherduck.com/blog/data-engineer-highlights-PyConDE-2023.md
    quote: This is where the new HTTP headers come into play.
    char_start: 0
    char_end: 50
- statement: DuckDB allows users to bundle multiple code snippets together.
  type: feature
  entity: DuckDB
  keywords:
  - feature
  - duckdb
  - allows
  - users
  - bundle
  - multiple
  - code
  - snippets
  - together
  source:
    doc: motherduck.com/blog/duckdb-cognee-sql-analytics-graph-rag.md
    quote: the snippet I shared above bundled multiple code snippets together into
      a single set.
    char_start: 0
    char_end: 85
- statement: DuckDB allows users to connect to BI tools like Tableau, Looker, and
    Superset.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - allows
  - users
  - connect
  - bi
  - tools
  - like
  - tableau
  - looker
  - superset
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-1.md
    quote: DuckDB enables users to connect to powerful BI tools like Tableau, Looker,
      or Superset with standard ODBC or JDBC drivers.
    char_start: 0
    char_end: 122
- statement: DuckDB allows you to define Python functions and call them directly from
    your SQL queries.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - allows
  - define
  - python
  - functions
  - call
  - them
  - directly
  - sql
  - queries
  source:
    doc: motherduck.com/case-studies/atm-com-analytics-costs-sql-expressibility.md
    quote: DuckDB lets you define Python functions and call them directly from your
      SQL queries.
    char_start: 0
    char_end: 85
- statement: DuckDB allows you to encapsulate actual data source accesses.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - allows
  - encapsulate
  - actual
  - data
  - source
  - accesses
  source:
    doc: motherduck.com/blog/duckdb-wasm-in-browser.md
    quote: Views allow you to encapsulate actual data source accesses, leveraging
      the robust SQL features of DuckDB.
    char_start: 0
    char_end: 105
- statement: DuckDB and Mosaic provide interactive insights on large datasets.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - mosaic
  - provide
  - interactive
  - insights
  - large
  - datasets
  source:
    doc: motherduck.com/videos.md
    quote: 'DuckDB & Mosaic : Interactive Insights on Large datasets.'
    char_start: 0
    char_end: 57
- statement: DuckDB and MotherDuck are democratizing access to geospatial work.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - motherduck
  - democratizing
  - access
  - geospatial
  - work
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md
    quote: DuckDB and MotherDuck are democratizing access to geospatial work by supporting
      many needed features with a lightweight setup.
    char_start: 0
    char_end: 126
- statement: DuckDB and MotherDuck can help you take flight with your analytical needs.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - motherduck
  - help
  - take
  - flight
  - analytical
  - needs
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: This is where DuckDB and MotherDuck can help you take flight with your
      analytical needs.
    char_start: 0
    char_end: 88
- statement: DuckDB and Polars are better for interactive queries and embedded database
    operations.
  type: performance
  entity: DuckDB
  keywords:
  - performance
  - duckdb
  - polars
  - better
  - interactive
  - queries
  - embedded
  - database
  - operations
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: The takeaway seems not to abandon Spark completely but to strategically
      integrate these engines based on specific use cases. Polars and DuckDB for interactive
      queries, embedded database operation, and
    char_start: 0
    char_end: 232
- statement: DuckDB and Unity Catalog are fully integrated.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - unity
  - catalog
  - fully
  - integrated
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: The integration provides real-time updates in the Unity Catalog UI, confirming
      that DuckDB and Unity Catalog are fully integrated.
    char_start: 0
    char_end: 130
- statement: DuckDB attempts to read some range of bytes from the logical database
    file using Differential Storage.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - attempts
  - read
  - range
  - bytes
  - logical
  - database
  - file
  - using
  - differential
  - storage
  source:
    doc: motherduck.com/blog/data-warehouse-feature-roundup-dec-2024.md
    quote: When DuckDB attempts to read some range of bytes from the logical database
      file, Differential Storage will split up the total read range into subranges
      and loop through them.
    char_start: 0
    char_end: 174
- statement: DuckDB automatically detects when an extension is needed and loads it
    transparently.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - automatically
  - detects
  - extension
  - needed
  - loads
  - transparently
  source:
    doc: motherduck.com/learn-more/partitioned-writes-parquet-ducklake.md
    quote: DuckDB now automatically detects when an extension is needed and loads
      it transparently.
    char_start: 0
    char_end: 88
- statement: DuckDB automatically recognizes the DataFrame variable df in your Python
    environment.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - automatically
  - recognizes
  - dataframe
  - variable
  - df
  - python
  - environment
  source:
    doc: motherduck.com/case-studies/atm-com-analytics-costs-sql-expressibility.md
    quote: DuckDB automatically recognizes the DataFrame variable df in your Python
      environment.
    char_start: 0
    char_end: 85
- statement: DuckDB can analyze data stored in Azure blob storage.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - analyze
  - data
  - stored
  - azure
  - blob
  - storage
  source:
    doc: motherduck.com/blog/separating-storage-compute-duckdb.md
    quote: Analyze data stored in Azure blob storage using DuckDB or MotherDuck
    char_start: 0
    char_end: 68
- statement: DuckDB can analyze logs directly sitting on S3 without normalization.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - analyze
  - logs
  - directly
  - sitting
  - s3
  - without
  - normalization
  source:
    doc: motherduck.com/blog/flight-sql-vs-rest-vs-jdbc.md
    quote: As DuckDB is an analytics tool, besides just parsing logs, we can also
      create analytics dashboards.
    char_start: 0
    char_end: 99
- statement: DuckDB can be accessed remotely using Apache Arrow and Flight RPC.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - accessed
  - remotely
  - using
  - apache
  - arrow
  - flight
  - rpc
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-five.md
    quote: Mike demonstrates remote access to DuckDB using Apache Arrow and Flight
      RPC.
    char_start: 0
    char_end: 76
- statement: DuckDB can be installed on Linux operating systems.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - installed
  - linux
  - operating
  - systems
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: Download the appropriate archive for your OS and processor.
    char_start: 0
    char_end: 59
- statement: DuckDB can be installed using Homebrew on macOS.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - installed
  - using
  - homebrew
  - macos
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: Follow the Homebrew (`brew`) install instructions.
    char_start: 0
    char_end: 50
- statement: DuckDB can be installed using winget on Windows.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - installed
  - using
  - winget
  - windows
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: Follow the `winget` install instructions.
    char_start: 0
    char_end: 41
- statement: DuckDB can be integrated into data architecture using Estuary.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - integrated
  - data
  - architecture
  - using
  - estuary
  source:
    doc: motherduck.com/blog/git-for-data-part-1.md
    quote: integrating DuckDB into your data architecture can be a simple process
      when using Estuary.
    char_start: 0
    char_end: 90
- statement: DuckDB can be integrated with Amazon SageMaker Lakehouse using AWS Glue
    Iceberg REST endpoints.
  type: integration
  entity: DuckDB
  keywords:
  - integration
  - duckdb
  - integrated
  - amazon
  - sagemaker
  - lakehouse
  - using
  - aws
  - glue
  - iceberg
  - rest
  - endpoints
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Tobias demonstrates how to integrate Amazon SageMaker Lakehouse with DuckDB
      using AWS Glue Iceberg REST endpoints to query S3 Tables.
    char_start: 0
    char_end: 133
- statement: DuckDB can be integrated with the GPT4o model for data analysis.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - integrated
  - gpt4o
  - model
  - data
  - analysis
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: integrated with the GPT4o model.
    char_start: 0
    char_end: 32
- statement: DuckDB can be leveraged as an entry point to push to different destinations.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - leveraged
  - entry
  - point
  - push
  - different
  - destinations
  source:
    doc: motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md
    quote: In this blog, we saw how we can easily leverage DuckDB as an entry point
      to push to different destinations.
    char_start: 0
    char_end: 107
- statement: DuckDB can be scaled using AWS Lambda for querying operations.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - scaled
  - using
  - aws
  - lambda
  - querying
  - operations
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: how to use the power of AWS Lambda as a distributed system in order to
      scale DuckDB querying operations.
    char_start: 0
    char_end: 104
- statement: DuckDB can be scaled with various strategies.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - scaled
  - various
  - strategies
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: But what are your real options for scaling DuckDB today?
    char_start: 0
    char_end: 56
- statement: DuckDB can be up to 1000x more efficient than BigQuery.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - up
  - 1000x
  - efficient
  - bigquery
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-three.md
    quote: How DuckDB can be up to 1000x more efficient than BigQuery?
    char_start: 0
    char_end: 59
- statement: DuckDB can be used in conjunction with Kestra for ETL processes.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - used
  - conjunction
  - kestra
  - etl
  - processes
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-four.md
    quote: Scheduled and event-driven data workflows with S3, MotherDuck,...
    char_start: 0
    char_end: 65
- statement: DuckDB can be used to build a semantic layer.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - used
  - build
  - semantic
  - layer
  source:
    doc: motherduck.com/blog.md
    quote: how to build a simple one with DuckDB...
    char_start: 0
    char_end: 40
- statement: DuckDB can be used to create a system that serves consistent metrics.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - used
  - create
  - system
  - serves
  - consistent
  - metrics
  source:
    doc: motherduck.com/blog/pushing-geo-boundaries-with-motherduck-geobase.md
    quote: With just a YAML file and a few lines of Python, we've created a system
      that can serve consistent metrics across any tool in your data stack.
    char_start: 0
    char_end: 141
- statement: DuckDB can be used to query data from disparate sources, such as PostgreSQL
    and blockchain databases.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - used
  - query
  - data
  - disparate
  - sources
  - postgresql
  - blockchain
  - databases
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eight.md
    quote: This article illustrates how DuckDB can be used to query data from disparate
      sources, such as PostgreSQL and blockchain databases.
    char_start: 0
    char_end: 130
- statement: DuckDB can be used with Airflow.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - used
  - airflow
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-four.md
    quote: how to use MotherDuck and DuckDB with Airflow.
    char_start: 0
    char_end: 46
- statement: DuckDB can be used with Datasette for exploring data.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - used
  - datasette
  - exploring
  - data
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: DuckDB can be used with Datasette for exploring data.
    char_start: 0
    char_end: 53
- statement: DuckDB can be used with LlamaIndex for building applications.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - used
  - llamaindex
  - building
  - applications
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: DuckDB can be used with LlamaIndex.
    char_start: 0
    char_end: 35
- statement: DuckDB can be used with Polars for data analysis.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - used
  - polars
  - data
  - analysis
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-two.md
    quote: Another short but outstanding video tutorial from the one and only Mark
      Needham where he talked about how to combine the power of Parquet files with
      Pandas, Polars and DuckDB.
    char_start: 0
    char_end: 175
- statement: DuckDB can be used with SAP data.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - used
  - sap
  - data
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: DuckDB has definitely reached the enterprise! Simon Müller has released
      a DuckDB extension for using SAP Data in your workloads.
    char_start: 0
    char_end: 128
- statement: DuckDB can be used with Spark through the DuckDB Spark API.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - used
  - spark
  - api
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: This allows us to run any pipeline transformation with the Pyspark DataFrame
      API without needing a Spark cluster or dependencies.
    char_start: 0
    char_end: 129
- statement: DuckDB can be used with sqlite-utils for database management.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - used
  - sqlite
  - utils
  - database
  - management
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: DuckDB can be used with sqlite-utils for database management.
    char_start: 0
    char_end: 61
- statement: DuckDB can be very advantageous for government-focused initiatives.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - advantageous
  - government
  - focused
  - initiatives
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md
    quote: DuckDB can be very advantages for governemtn focused innitiaves.
    char_start: 0
    char_end: 64
- statement: DuckDB can connect to PostgreSQL databases in Supabase.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - connect
  - postgresql
  - databases
  - supabase
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-nine.md
    quote: you'll learn how to connect DuckDB to your PostgreSQL database in Supabase.
    char_start: 0
    char_end: 75
- statement: DuckDB can deal with multiple entries for the same event.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - deal
  - multiple
  - entries
  - event
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: He built a so-called operational data store (ODS) that can deal with multiple
      entries for the same event.
    char_start: 0
    char_end: 105
- statement: DuckDB can easily handle a volume of 100 MB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - easily
  - handle
  - volume
  - '100'
  - mb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md
    quote: a volume that a single DuckDB instance can easily handle
    char_start: 0
    char_end: 56
- statement: DuckDB can efficiently handle and analyze GTFS schedule data.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - efficiently
  - handle
  - analyze
  - gtfs
  - schedule
  - data
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: This article demonstrates how to use DuckDB to efficiently handle and analyze
      GTFS schedule data.
    char_start: 0
    char_end: 97
- statement: DuckDB can execute queries beyond memory.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - execute
  - queries
  - beyond
  - memory
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md
    quote: Beyond Memory Execution
    char_start: 0
    char_end: 23
- statement: DuckDB can handle different log formats without requiring data to be
    pre-loaded into a database.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - handle
  - different
  - log
  - formats
  - without
  - requiring
  - data
  - pre
  - loaded
  - database
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: The power of DuckDB as a log parser lies in its flexibility and performance.
    char_start: 0
    char_end: 76
- statement: DuckDB can handle error scenarios in CSV files.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - handle
  - error
  - scenarios
  - csv
  - files
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: He highlights DuckDB's ability to handle error scenarios in CSV files.
    char_start: 0
    char_end: 70
- statement: DuckDB can load AWS credentials based on a profile name.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - load
  - aws
  - credentials
  - based
  - profile
  - name
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-seven.md
    quote: This function will load AWS credentials based on a profile name.
    char_start: 0
    char_end: 64
- statement: DuckDB can load large CSVs at nearly 2 GB/s and execute TPC-H at multi-TB
    scale with acceptable runtimes.
  type: performance
  entity: DuckDB
  keywords:
  - performance
  - duckdb
  - load
  - large
  - csvs
  - nearly
  - gb
  - execute
  - tpc
  - multi
  - tb
  - scale
  - acceptable
  - runtimes
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: A 12‑core Framework Laptop 13 (AMD Ryzen AI 9 HX 370, 128 GB RAM, 8 TB
      NVMe) running DuckDB can load large CSVs at nearly 2 GB/s...
    char_start: 0
    char_end: 131
- statement: DuckDB can make HTTP requests to OpenStreetMap for geocoding.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - make
  - http
  - requests
  - openstreetmap
  - geocoding
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: DuckDB can GET-request OpenStreetMap with the address with a SQL query.
    char_start: 0
    char_end: 71
- statement: DuckDB can now push down more types of filter expressions directly into
    scans.
  type: feature
  entity: DuckDB
  keywords:
  - feature
  - duckdb
  - now
  - push
  - down
  - types
  - filter
  - expressions
  - directly
  - scans
  source:
    doc: motherduck.com/blog/announcing-motherduck-general-availability-data-warehousing-with-duckdb.md
    quote: DuckDB can now push down more types of filter expressions directly into
      scans.
    char_start: 0
    char_end: 78
- statement: DuckDB can outperform a distributed cluster for certain workloads.
  type: performance
  entity: DuckDB
  keywords:
  - performance
  - duckdb
  - outperform
  - distributed
  - cluster
  - certain
  - workloads
  source:
    doc: motherduck.com/learn-more/what-is-a-data-warehouse.md
    quote: How can a library running on a laptop outperform a distributed cluster
      for certain workloads?
    char_start: 0
    char_end: 93
- statement: DuckDB can parse JSON files effectively.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - parse
  - json
  - files
  - effectively
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: He showcases how effectively DuckDB can parse JSON files.
    char_start: 0
    char_end: 57
- statement: DuckDB can perform window functions for tasks like centering data.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - perform
  - window
  - functions
  - tasks
  - like
  - centering
  - data
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eleven.md
    quote: Marco showcases translating pandas/Polars operations to DuckDB SQL, focusing
      on window functions for tasks like centering data.
    char_start: 0
    char_end: 127
- statement: DuckDB can process 1.1 billion rows of PyPI package data in about 38
    seconds.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - process
  - '1.1'
  - billion
  - rows
  - pypi
  - package
  - data
  - about
  - '38'
  - seconds
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: He mentions how processing 1.1 billion rows of PyPI package data using
      DuckDB through Ibis in about 38 seconds on a laptop.
    char_start: 0
    char_end: 123
- statement: DuckDB can process files larger than memory.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - process
  - files
  - larger
  - memory
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md
    quote: If you are curious about how DuckDB can process files larger than memory...
    char_start: 0
    char_end: 75
- statement: DuckDB can quack after all.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - quack
  source:
    doc: motherduck.com/blog/local-duckdb-ui-visual-data-analysis.md
    quote: Finally, it looks like Spark can quack after all. 🦆
    char_start: 0
    char_end: 51
- statement: DuckDB can query and output data from and to other Python libraries without
    copying it.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - query
  - output
  - data
  - python
  - libraries
  - without
  - copying
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: This integration allows DuckDB to query and output data from and to other
      Python libraries without copying it.
    char_start: 0
    char_end: 110
- statement: DuckDB can query Parquet files directly from S3.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - query
  - parquet
  - files
  - directly
  - s3
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: DuckDB to query Parquet files directly from S3.
    char_start: 0
    char_end: 47
- statement: DuckDB can read about 90.75% of the data correctly in auto-detect mode.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - read
  - about
  - '90.75'
  - data
  - correctly
  - auto
  - detect
  - mode
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: Even in auto-detect mode with minimal configuration, DuckDB still managed
      to read about 90.75% of the data correctly.
    char_start: 0
    char_end: 117
- statement: DuckDB can read and write to Google Sheets.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - read
  - write
  - google
  - sheets
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: Archie took it further with duckdb-gsheets, reading, and writing to Google
      Sheets.
    char_start: 0
    char_end: 82
- statement: DuckDB can read CSV files directly from compressed gzipped files.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - read
  - csv
  - files
  - directly
  - compressed
  - gzipped
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: With the read_csv function, we can read the CSV files directly from the
      compressed gzipped files.
    char_start: 0
    char_end: 97
- statement: DuckDB can read ESRI Shapefile format.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - read
  - esri
  - shapefile
  - format
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2023.md
    quote: DuckDB can read ESRI Shapefile format.
    char_start: 0
    char_end: 38
- statement: DuckDB can read Excel files using the read_xlsx function.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - read
  - excel
  - files
  - using
  - xlsx
  - function
  source:
    doc: motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md
    quote: FROM read_xlsx('my_excel_file.xlsx', all_varchar = true, sheet = 'sheet2');
    char_start: 0
    char_end: 75
- statement: DuckDB can read from Iceberg tables.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - read
  - iceberg
  - tables
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: as well as Duckberg reading from Iceberg tables.
    char_start: 0
    char_end: 48
- statement: DuckDB can read MapInfo File format.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - read
  - mapinfo
  - file
  - format
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2023.md
    quote: DuckDB can read MapInfo File format.
    char_start: 0
    char_end: 36
- statement: DuckDB can read posts from the Bluesky API.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - read
  - posts
  - bluesky
  - api
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: To illustrate, you can simply read the post with DuckDB - e.g. reading
      my last 5 posts
    char_start: 0
    char_end: 86
- statement: DuckDB can run with zero-copy.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - run
  - zero
  - copy
  source:
    doc: motherduck.com/blog/search-using-duckdb-part-2.md
    quote: DuckDB can run with zero-copy.
    char_start: 0
    char_end: 30
- statement: DuckDB can save enterprises time and cloud costs by running tests on
    a cheap machine.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - save
  - enterprises
  - time
  - cloud
  - costs
  - running
  - tests
  - cheap
  - machine
  source:
    doc: motherduck.com/blog/separating-storage-compute-duckdb.md
    quote: A single-node or Single-Compute Lakehouse like DuckDB can save us a lot
      of time and cloud costs.
    char_start: 0
    char_end: 96
- statement: DuckDB can securely manage secrets based on your SSO setup.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - securely
  - manage
  - secrets
  - based
  - sso
  - setup
  source:
    doc: motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md
    quote: you can securely manage secrets based on your SSO setup.
    char_start: 0
    char_end: 56
- statement: DuckDB can serve as a catalog for Data Lake and Lakehouse patterns.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - serve
  - catalog
  - data
  - lake
  - lakehouse
  - patterns
  source:
    doc: motherduck.com/learn-more/fix-slow-bi-dashboards.md
    quote: Mehdi explores DuckDB as a catalog for Data Lake and Lakehouse pattern.
    char_start: 0
    char_end: 71
- statement: DuckDB can serve as a lightweight federated query engine to validate
    ELT pipelines.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - serve
  - lightweight
  - federated
  - query
  - engine
  - validate
  - elt
  - pipelines
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: DuckDB can serve as a lightweight federated query engine to validate ELT
      pipelines and detect deduplication issues between SQL Server and Snowflake.
    char_start: 0
    char_end: 148
- statement: DuckDB can skip reading data blocks that cannot possibly contain matching
    data.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - skip
  - reading
  - data
  - blocks
  - cannot
  - possibly
  - contain
  - matching
  source:
    doc: motherduck.com/videos/duckdb-run-dbt-build-with-sub-second-execution-times.md
    quote: DuckDB first checks these zone maps. It can instantly determine which data
      blocks _cannot possibly_ contain matching data and skips reading them entirely.
    char_start: 0
    char_end: 154
- statement: DuckDB can skip rows with errors and log details about rejected rows.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - skip
  - rows
  - errors
  - log
  - details
  - about
  - rejected
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: Ignoring errors is okay, but generally, you need to know _what_ went wrong
      and _which_ rows were rejected.
    char_start: 0
    char_end: 106
- statement: DuckDB can store and process video data by representing frames as relational
    tables.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - store
  - process
  - video
  - data
  - representing
  - frames
  - relational
  - tables
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: DuckDB can store and process video data by representing frames as relational
      tables.
    char_start: 0
    char_end: 84
- statement: DuckDB CLI allows you to run a SQL statement and exit using the -c option
    parameter.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - cli
  - allows
  - run
  - sql
  - statement
  - exit
  - using
  - option
  - parameter
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: DuckDB CLI allows you to run a SQL statement and exit using the `-c` option
      parameter.
    char_start: 0
    char_end: 86
- statement: DuckDB co-creator Hannes will be giving a keynote.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - co
  - creator
  - hannes
  - giving
  - keynote
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: DuckDB co-creator Hannes will be giving a keynote.
    char_start: 0
    char_end: 50
- statement: DuckDB combines OLTP with OLAP with no need for ETL.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - combines
  - oltp
  - olap
  - need
  - etl
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: DuckDB combines OLTP with OLAP with no need for ETL.
    char_start: 0
    char_end: 52
- statement: DuckDB consistently outperformed Spark by orders of magnitude on local
    Parquet scans up to ~23 GB.
  type: performance
  entity: DuckDB
  keywords:
  - performance
  - duckdb
  - consistently
  - outperformed
  - spark
  - orders
  - magnitude
  - local
  - parquet
  - scans
  - up
  - '23'
  - gb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: DuckDB consistently outperformed Spark by orders of magnitude on local
      Parquet scans up to ~23 GB.
    char_start: 0
    char_end: 98
- statement: DuckDB could be perfect for fixing iMessages on iOS.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - perfect
  - fixing
  - imessages
  - ios
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: DuckDB could be perfect for this use case here. Fixing iMessages on iOS
      is one of the most requested features out there.
    char_start: 0
    char_end: 120
- statement: DuckDB could be the perfect tool to work with the Beneficial Ownership
    Data Standard.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - perfect
  - tool
  - work
  - beneficial
  - ownership
  - data
  - standard
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-three.md
    quote: DuckDB could be the perfect tool to work with the Beneficial Ownership
      Data Standard.
    char_start: 0
    char_end: 85
- statement: DuckDB could fundamentally simplify how edge systems interact with cloud
    analytics.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - fundamentally
  - simplify
  - edge
  - systems
  - interact
  - cloud
  - analytics
  source:
    doc: motherduck.com/blog/simplifying-iot-analytics-motherduck.md
    quote: The dual execution capability could fundamentally simplify how edge systems
      interact with cloud analytics.
    char_start: 0
    char_end: 106
- statement: DuckDB creates a dev.duckdb file during a run.
  type: feature
  entity: DuckDB
  keywords:
  - feature
  - duckdb
  - creates
  - dev
  - file
  - run
  source:
    doc: motherduck.com/learn-more/what-is-OLAP.md
    quote: dbt-duckdb creates a dev.duckdb file in your project directory during a
      run.
    char_start: 0
    char_end: 76
- statement: DuckDB documentation is open-source.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - documentation
  - open
  - source
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: the DuckDB Documentation is open-source.
    char_start: 0
    char_end: 40
- statement: DuckDB doesn't require provisioning long-running instances.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - doesn
  - require
  - provisioning
  - long
  - running
  - instances
  source:
    doc: motherduck.com/videos/duckdb-motherduck-for-beginners-your-ultimate-guide.md
    quote: Unlike server-based databases, DuckDB doesn't require provisioning long-running
      instances.
    char_start: 0
    char_end: 90
- statement: DuckDB earned a 100-second legendary video by Fireship.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - earned
  - '100'
  - second
  - legendary
  - video
  - fireship
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-three.md
    quote: DuckDB earned a 100-second legendary video by Fireship.
    char_start: 0
    char_end: 55
- statement: DuckDB enabled the shipping of the extension in 60 days.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - enabled
  - shipping
  - extension
  - '60'
  - days
  source:
    doc: motherduck.com/blog/python-duckdb-vs-dataframe-libraries.md
    quote: How DuckDB enabled us to ship the extension in 60 days.
    char_start: 0
    char_end: 55
- statement: DuckDB enables data analysts and engineers to work entirely locally during
    development phases.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - enables
  - data
  - analysts
  - engineers
  - work
  - entirely
  - locally
  - development
  - phases
  source:
    doc: motherduck.com/videos/duckdb-motherduck-for-beginners-your-ultimate-guide.md
    quote: DuckDB enables data analysts and engineers to work entirely locally during
      development phases.
    char_start: 0
    char_end: 94
- statement: DuckDB enables detailed product-level analysis.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - enables
  - detailed
  - product
  - level
  - analysis
  source:
    doc: motherduck.com/blog/introducing-instant-sql.md
    quote: This enables more detailed product-level analysis.
    char_start: 0
    char_end: 50
- statement: DuckDB enables querying YAML files with YamlQL.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - enables
  - querying
  - yaml
  - files
  - yamlql
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eleven.md
    quote: enables querying your YAML files with SQL
    char_start: 0
    char_end: 41
- statement: DuckDB enables the creation of HTAP databases.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - enables
  - creation
  - htap
  - databases
  source:
    doc: motherduck.com/blog/data-engineers-answer-10-top-reddit-questions.md
    quote: DuckDB enables the creation of HTAP databases.
    char_start: 0
    char_end: 46
- statement: DuckDB enables you to easily build your own PyPI stats dashboard for
    your Python project.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - enables
  - easily
  - build
  - pypi
  - stats
  - dashboard
  - python
  - project
  source:
    doc: motherduck.com/blog/streamkap-mysql-to-motherduck.md
    quote: DuckDB enables you to easily build your own PyPI stats dashboard for your
      Python project!
    char_start: 0
    char_end: 89
- statement: DuckDB enables you to run directly in a browser using Wasm.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - enables
  - run
  - directly
  - browser
  - using
  - wasm
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md
    quote: DuckDB Wasm is great because it enables you to run DuckDB directly in a
      browser!
    char_start: 0
    char_end: 80
- statement: DuckDB establishes its first Long Term Support (LTS) model with one year
    of community support.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - establishes
  - first
  - long
  - term
  - support
  - lts
  - model
  - one
  - year
  - community
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: the release establishes DuckDB's first Long Term Support (LTS) model with
      one year of community support.
    char_start: 0
    char_end: 104
- statement: DuckDB executes complex queries in milliseconds on a standard laptop.
  type: performance
  entity: DuckDB
  keywords:
  - performance
  - duckdb
  - executes
  - complex
  - queries
  - milliseconds
  - standard
  - laptop
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: execute complex queries in milliseconds on a standard laptop.
    char_start: 0
    char_end: 61
- statement: DuckDB exports data from the orders table to a directory named output_orders_parquet.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - exports
  - data
  - orders
  - table
  - directory
  - named
  - output
  - parquet
  source:
    doc: motherduck.com/videos.md
    quote: COPY orders TO 'output_orders_parquet' (FORMAT PARQUET, PARTITION_BY (year,
      month));
    char_start: 0
    char_end: 84
- statement: DuckDB FastAPI enables bidirectional integration between REST APIs and
    DuckDB queries.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - fastapi
  - enables
  - bidirectional
  - integration
  - rest
  - apis
  - queries
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: DuckDB FastAPI enables bidirectional integration between REST APIs and
      DuckDB queries.
    char_start: 0
    char_end: 86
- statement: DuckDB features streaming execution, intermediate spilling, and a buffer
    manager.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - features
  - streaming
  - execution
  - intermediate
  - spilling
  - buffer
  - manager
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md
    quote: 'three main behind-the-scenes features that make DuckDB great: streaming
      execution, intermediate spilling, and the buffer manager.'
    char_start: 0
    char_end: 129
- statement: DuckDB felt like an obvious choice.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - felt
  - like
  - obvious
  - choice
  source:
    doc: motherduck.com/blog/semantic-layer-duckdb-tutorial.md
    quote: I decided to pair it with DuckDB...
    char_start: 0
    char_end: 35
- statement: DuckDB Foundation supports the development of DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - foundation
  - supports
  - development
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: DuckDB Foundation supports the development of DuckDB.
    char_start: 0
    char_end: 53
- statement: DuckDB function chaining can make SQL scripts more readable.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - function
  - chaining
  - make
  - sql
  - scripts
  - readable
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: It's again something I haven't seen many people using but really useful
      to make your code cleaner!
    char_start: 0
    char_end: 98
- statement: DuckDB has 6 million downloads per month.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - million
  - downloads
  - per
  - month
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Just the Python client has 6 million downloads per month.
    char_start: 0
    char_end: 57
- statement: DuckDB has a native Swift API.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - native
  - swift
  - api
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: Native Swift API.
    char_start: 0
    char_end: 17
- statement: DuckDB has a richer SQL feature set compared to DataFusion.
  type: comparison
  entity: DuckDB
  keywords:
  - comparison
  - duckdb
  - richer
  - sql
  - feature
  - set
  - compared
  - datafusion
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: Matt concludes that DuckDB has a richer SQL feature set.
    char_start: 0
    char_end: 56
- statement: DuckDB has a slow leak of connections when using SELECT FROM s3:// commands.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - slow
  - leak
  - connections
  - using
  - select
  - s3
  - commands
  source:
    doc: motherduck.com/learn-more/star-schema-data-warehouse-guide.md
    quote: We discovered a slow leak of connections when using SELECT FROM s3:// commands...
    char_start: 0
    char_end: 81
- statement: DuckDB has a thriving open source community.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - thriving
  - open
  - source
  - community
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: A thriving open source community
    char_start: 0
    char_end: 32
- statement: DuckDB has been able to strip all that away by being an in-process database.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - able
  - strip
  - away
  - process
  - database
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2024.md
    quote: DuckDB has been able to kind of strip all that away by being an in-process
      database.
    char_start: 0
    char_end: 84
- statement: DuckDB has enhanced ACID compliance.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - enhanced
  - acid
  - compliance
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: enhanced ACID compliance
    char_start: 0
    char_end: 24
- statement: DuckDB has implemented improvements in detecting and managing formatting
    errors in datasets.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - implemented
  - improvements
  - detecting
  - managing
  - formatting
  - errors
  - datasets
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2024.md
    quote: A series of improvements have been implemented on how DuckDB detects and
      manages formatting errors in our datasets.
    char_start: 0
    char_end: 115
- statement: DuckDB has multi-database support.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - multi
  - database
  - support
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: Want to join DuckDB tables with tables in Postgres, SQLite, and MySQL?
      You can!
    char_start: 0
    char_end: 79
- statement: DuckDB has no licensing costs, allowing immediate development on existing
    laptops.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - licensing
  - costs
  - allowing
  - immediate
  - development
  - existing
  - laptops
  source:
    doc: motherduck.com/videos/from-core-to-custom-unlocking-new-possibilities-with-duckdb-extensions.md
    quote: Since DuckDB has no licensing costs, development can start immediately
      on existing laptops without budget approval processes.
    char_start: 0
    char_end: 125
- statement: DuckDB has passed the specific ACID Transaction tests from the TPC-H
    Benchmark tests.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - passed
  - specific
  - acid
  - transaction
  - tests
  - tpc
  - benchmark
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: DuckDB has passed the specific ACID Transaction tests from the TPC-H Benchmark
      tests.
    char_start: 0
    char_end: 85
- statement: DuckDB has seamless integration with Kafka.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - seamless
  - integration
  - kafka
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eleven.md
    quote: the seamless Kafka integration with Tributary and YamlQL
    char_start: 0
    char_end: 56
- statement: DuckDB has seamless integration with popular data tools like Python,
    R, and Pandas.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - seamless
  - integration
  - popular
  - data
  - tools
  - like
  - python
  - pandas
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: DuckDB's seamless integration with popular data tools like Python, R, and
      Pandas.
    char_start: 0
    char_end: 81
- statement: DuckDB has shown explosive 50.7% year-over-year growth.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - shown
  - explosive
  - '50.7'
  - year
  - over
  - growth
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: DuckDB's explosive 50.7% year-over-year growth.
    char_start: 0
    char_end: 47
- statement: DuckDB has updates including block-based caching for remote files.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - updates
  - including
  - block
  - based
  - caching
  - remote
  - files
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-three.md
    quote: This month, we've got updates including block-based caching for remote
      files.
    char_start: 0
    char_end: 77
- statement: DuckDB implements a Medallion architecture.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - implements
  - medallion
  - architecture
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: implementing a Medallion architecture (Bronze → Silver → Gold)
    char_start: 0
    char_end: 62
- statement: DuckDB includes capabilities to interact with Object Stores.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - includes
  - capabilities
  - interact
  - object
  - stores
  source:
    doc: motherduck.com/blog/motherduck-kestra-etl-pipelines.md
    quote: DuckDB also includes capabilities to interact with Object Stores.
    char_start: 0
    char_end: 65
- statement: DuckDB integrates with Dagster's Software-Defined Assets.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - integrates
  - dagster
  - software
  - defined
  - assets
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-seven.md
    quote: The Dagster team just released a tutorial to show how to combine DuckDB
      I/O Manager and Dagster’s Software-Defined Assets.
    char_start: 0
    char_end: 122
- statement: DuckDB integrates with drugDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - integrates
  - drugdb
  source:
    doc: motherduck.com/blog/bigquery-to-duckdb-motherduck.md
    quote: 'DuckDB Monthly: Unity catalog, drugDB and more!'
    char_start: 0
    char_end: 47
- statement: DuckDB integrates with DuckDB-WASM for browser analytics.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - integrates
  - wasm
  - browser
  - analytics
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: DuckDB integrates with DuckDB-WASM for browser analytics.
    char_start: 0
    char_end: 57
- statement: DuckDB introduces VARINT to optimize memory usage.
  type: feature
  entity: DuckDB
  keywords:
  - feature
  - duckdb
  - introduces
  - varint
  - optimize
  - memory
  - usage
  source:
    doc: motherduck.com/blog/data-warehouse-feature-roundup-nov-2024.md
    quote: 'More data types to optimize memory: VARINT'
    char_start: 0
    char_end: 42
- statement: DuckDB is a database management system used with the Data App Generator.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - database
  - management
  - system
  - used
  - data
  - app
  - generator
  source:
    doc: motherduck.com/blog/data-app-generator.md
    quote: Learn how to use DuckDB's read_csv functionality.
    char_start: 0
    char_end: 49
- statement: DuckDB is a great developer tool for analyzing music data.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - great
  - developer
  - tool
  - analyzing
  - music
  - data
  source:
    doc: motherduck.com/blog/from-data-lake-to-lakehouse-duckdb-portable-catalog.md
    quote: This month keeps showing the rising popularity of DuckDB as a great developer
      tool.
    char_start: 0
    char_end: 83
- statement: DuckDB is a lightweight app you install on your computer and execute
    queries by typing in commands at your terminal.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - lightweight
  - app
  - install
  - computer
  - execute
  - queries
  - typing
  - commands
  - terminal
  source:
    doc: motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md
    quote: DuckDB is a lightweight app you install on your computer and execute queries
      by typing in commands at your terminal.
    char_start: 0
    char_end: 116
- statement: DuckDB is adopted by companies like Meta, Google, and Airbnb.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - adopted
  - companies
  - like
  - meta
  - google
  - airbnb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: He notes real-world adoption (e.g., Meta, Google, Airbnb).
    char_start: 0
    char_end: 58
- statement: DuckDB is an in-memory process and won't persist any data by default.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - memory
  - process
  - won
  - persist
  - any
  - data
  - default
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-two.md
    quote: By default, DuckDB is an in-memory process and won't persist any data.
    char_start: 0
    char_end: 70
- statement: DuckDB is an in-process database that you can literally pip install and
    start using immediately.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - process
  - database
  - literally
  - pip
  - install
  - start
  - using
  - immediately
  source:
    doc: motherduck.com/blog/llm-data-pipelines-prompt-motherduck-dbt.md
    quote: It's an in-process database that you can literally pip install duckdb and
      start using immediately.
    char_start: 0
    char_end: 98
- statement: DuckDB is being selected for more projects due to its developer productivity.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - selected
  - projects
  - due
  - developer
  - productivity
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: developer productivity with DuckDB is just awesome
    char_start: 0
    char_end: 50
- statement: DuckDB is better at handling geographical data.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - better
  - handling
  - geographical
  - data
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: The database is also better at handling geographical data.
    char_start: 0
    char_end: 58
- statement: DuckDB is compared to Snowflake as a data warehousing solution.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - compared
  - snowflake
  - data
  - warehousing
  - solution
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: DuckDB is compared to Snowflake as a data warehousing solution.
    char_start: 0
    char_end: 63
- statement: DuckDB is currently top of ClickBench in a handful of machine sizes.
  type: performance
  entity: DuckDB
  keywords:
  - performance
  - duckdb
  - currently
  - top
  - clickbench
  - handful
  - machine
  - sizes
  source:
    doc: motherduck.com/blog/making-pyspark-code-faster-with-duckdb.md
    quote: DuckDB is currently top of ClickBench in a handful of machine sizes.
    char_start: 0
    char_end: 68
- statement: DuckDB is designed for single users and assumes sole ownership of its
    database file.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - designed
  - single
  - users
  - assumes
  - sole
  - ownership
  - database
  - file
  source:
    doc: motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md
    quote: DuckDB, as it is designed for single users, assumes sole ownership of its
      database file.
    char_start: 0
    char_end: 88
- statement: DuckDB is efficient for rapid prototyping.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - efficient
  - rapid
  - prototyping
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: showcasing the power of DuckDB for rapid prototyping
    char_start: 0
    char_end: 52
- statement: DuckDB is embedded inside the lakeFS UI.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - embedded
  - inside
  - lakefs
  - ui
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-two.md
    quote: Oz Katz (co-founder and CTO at Treeverse) shared some insights about how
      they embedded DuckDB inside the lakeFS UI.
    char_start: 0
    char_end: 115
- statement: DuckDB is extended with differential storage capabilities.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - extended
  - differential
  - storage
  - capabilities
  source:
    doc: motherduck.com/blog/data-warehouse-feature-roundup-nov-2024.md
    quote: The Need To Extend DuckDB
    char_start: 0
    char_end: 25
- statement: DuckDB is featured in an interactive SQL tutorial.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - featured
  - interactive
  - sql
  - tutorial
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: DB Quacks introduces an interactive, browser-based SQL learning platform
      powered by DuckDB.
    char_start: 0
    char_end: 91
- statement: DuckDB is limited by its inability to support concurrent writers and
    simultaneous reads during writes.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - limited
  - inability
  - support
  - concurrent
  - writers
  - simultaneous
  - reads
  - writes
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md
    quote: DuckDB is limited by its inability to support concurrent writers and simultaneous
      reads during writes.
    char_start: 0
    char_end: 102
- statement: DuckDB is more efficient than traditional methods for selecting metadata.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - efficient
  - traditional
  - methods
  - selecting
  - metadata
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: This is interesting and a more efficient way than the traditional select
      * from information_schema.tables.
    char_start: 0
    char_end: 106
- statement: DuckDB is often used on a laptop, but servers were also popular.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - often
  - used
  - laptop
  - servers
  - also
  - popular
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: It's no surprise that DuckDB is often used on a laptop, but servers were
      also popular.
    char_start: 0
    char_end: 86
- statement: DuckDB is powerful enough to analyze a rich dataset like StackOverflow
    data.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - powerful
  - enough
  - analyze
  - rich
  - dataset
  - like
  - stackoverflow
  - data
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eight.md
    quote: Michael Hunger proved in this post that DuckDB is powerful enough to analyze
      a rich dataset like StackOverflow data.
    char_start: 0
    char_end: 116
- statement: DuckDB is revolutionizing data processing.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - revolutionizing
  - data
  - processing
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Discover how DuckDB is revolutionizing data processing...
    char_start: 0
    char_end: 57
- statement: DuckDB is suitable for enterprises.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - suitable
  - enterprises
  source:
    doc: motherduck.com/blog/duckdb-enterprise-5-key-categories.md
    quote: but is it also suitable for enterprises?
    char_start: 0
    char_end: 40
- statement: DuckDB is the default execution engine for our columnstore tables.
  type: feature
  entity: DuckDB
  keywords:
  - feature
  - duckdb
  - default
  - execution
  - engine
  - columnstore
  - tables
  source:
    doc: motherduck.com/blog/pg-mooncake-columnstore.md
    quote: DuckDB is the default execution engine for our columnstore tables.
    char_start: 0
    char_end: 66
- statement: DuckDB is the secret to unlocking your GIS potential.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - secret
  - unlocking
  - gis
  - potential
  source:
    doc: motherduck.com/videos/simple-way-to-convert-csv-and-parquet-files.md
    quote: Is DuckDB the Secret to Unlocking Your GIS Potential?
    char_start: 0
    char_end: 53
- statement: DuckDB is the vector store adapter used in cognee.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - vector
  - store
  - adapter
  - used
  - cognee
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: The DuckDB adapter is the vector store adapter.
    char_start: 0
    char_end: 47
- statement: DuckDB is used as a vector database for building RAG applications.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - used
  - vector
  - database
  - building
  - rag
  - applications
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: DuckDB as a vector database.
    char_start: 0
    char_end: 28
- statement: DuckDB is used as an in-memory data engine by Mode.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - used
  - memory
  - data
  - engine
  - mode
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-five.md
    quote: 'This very interesting post from the Mode team explains why they selected
      DuckDB as its in-memory data engine for one of its core features: speed.'
    char_start: 0
    char_end: 145
- statement: DuckDB is used as both the client and server in the project.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - used
  - both
  - client
  - server
  - project
  source:
    doc: motherduck.com/blog/python-faker-duckdb-exploration.md
    quote: I was using DuckDB as both the client AND server (the exact same compute
      engine!)
    char_start: 0
    char_end: 81
- statement: DuckDB is used for analyzing your own Fitbit data.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - used
  - analyzing
  - fitbit
  - data
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: from using it for creating dummy data to analyzing your own Fitbit data
      with it.
    char_start: 0
    char_end: 80
- statement: DuckDB is used for Monte Carlo simulations.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - used
  - monte
  - carlo
  - simulations
  source:
    doc: motherduck.com/learn-more/self-service-analytics-startups.md
    quote: James McNeill talks about Monte Carlo simulations at th...
    char_start: 0
    char_end: 58
- statement: DuckDB is used for public transportation data.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - used
  - public
  - transportation
  - data
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-six.md
    quote: using DuckDB for public transportation data
    char_start: 0
    char_end: 43
- statement: DuckDB is used for real-time analytics and embedded data processing.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - used
  - real
  - time
  - analytics
  - embedded
  - data
  - processing
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: illustrating how DuckDB has been successfully implemented in various industries
      for tasks such as real-time analytics and embedded data processing.
    char_start: 0
    char_end: 147
- statement: DuckDB is used to automate the categorization of company names into predefined
    industry sectors.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - used
  - automate
  - categorization
  - company
  - names
  - predefined
  - industry
  - sectors
  source:
    doc: motherduck.com/blog/building-data-applications-with-motherduck.md
    quote: Nate addresses common challenges in maintaining accurate industry classifications
      and leverages LLMs, specifically within Snowflake's database environment, to
      automate the categorization of company na
    char_start: 0
    char_end: 237
- statement: DuckDB is used to explore the Open Food Database.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - used
  - explore
  - open
  - food
  - database
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: Explore the Largest Open Food Database using DuckDB.
    char_start: 0
    char_end: 52
- statement: DuckDB is used to ingest data from the OpenChargeMap API.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - used
  - ingest
  - data
  - openchargemap
  - api
  source:
    doc: motherduck.com/blog/faster-data-pipelines-with-mcp-duckdb-ai.md
    quote: con.sql(f"CREATE TABLE IF NOT EXISTS geo_playground.poi_france AS SELECT
      * FROM read_json_auto('{poi_url}')")
    char_start: 0
    char_end: 109
- statement: DuckDB isn't locked into Python.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - isn
  - locked
  - python
  source:
    doc: motherduck.com/blog/spark-ducklake-getting-started.md
    quote: Here's something important for Python users - DuckDB isn't locked into
      Python.
    char_start: 0
    char_end: 78
- statement: DuckDB Labs released their usual blog.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - labs
  - released
  - usual
  - blog
  source:
    doc: motherduck.com/blog/analyze-data-in-azure-with-duckdb.md
    quote: DuckDB Labs released their usual blog.
    char_start: 0
    char_end: 38
- statement: DuckDB Labs surveyed 500+ DuckDB users.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - labs
  - surveyed
  - '500'
  - users
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: DuckDB Labs surveyed 500+ DuckDB users and shared their findings.
    char_start: 0
    char_end: 65
- statement: DuckDB makes writing data in Hive-partitioned format straightforward
    using the PARTITION_BY clause.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - makes
  - writing
  - data
  - hive
  - partitioned
  - format
  - straightforward
  - using
  - partition
  - clause
  source:
    doc: motherduck.com/videos.md
    quote: DuckDB makes writing data in Hive-partitioned format straightforward using
      the PARTITION_BY clause.
    char_start: 0
    char_end: 99
- statement: DuckDB may lack some specialized features available in mature cloud warehouses.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - lack
  - specialized
  - features
  - available
  - mature
  - cloud
  - warehouses
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: As a relatively young project, DuckDB may lack some specialized features
      available in mature cloud warehouses.
    char_start: 0
    char_end: 110
- statement: DuckDB meetup by DuckDB Dublin community is scheduled for 23 January
    2024.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - meetup
  - dublin
  - community
  - scheduled
  - '23'
  - january
  - '2024'
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: Join us for an exciting in-person DuckDB meetup at TechMeetup.space in
      Dublin City Centre from 6:30 PM to 9:00 PM!
    char_start: 0
    char_end: 114
- statement: DuckDB might become your new best friend or pet.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - become
  - new
  - best
  - friend
  - pet
  source:
    doc: motherduck.com/blog/llm-data-pipelines-prompt-motherduck-dbt.md
    quote: DuckDB might become your new best friend or pet.
    char_start: 0
    char_end: 48
- statement: 'DuckDB Monthly #25 discusses updates on PyIceberg and local development
    workflows with dbt.'
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - monthly
  - '25'
  - discusses
  - updates
  - pyiceberg
  - local
  - development
  - workflows
  - dbt
  source:
    doc: motherduck.com/blog/csv-files-persist-duckdb-solution.md
    quote: 'DuckDB Monthly #25: PyIceberg, 0$ data distribution and more!'
    char_start: 0
    char_end: 61
- statement: DuckDB Newsletter readers get $100 off tickets with code ‘DuckDB100’.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - newsletter
  - readers
  - get
  - '100'
  - 'off'
  - tickets
  - code
  - duckdb100
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md
    quote: DuckDB Newsletter readers get $100 off tickets with code ‘DuckDB100’.
    char_start: 0
    char_end: 69
- statement: DuckDB now has native support for Delta Lake.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - now
  - native
  - support
  - delta
  - lake
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: DuckDB now has native support for Delta Lake.
    char_start: 0
    char_end: 45
- statement: DuckDB now processes multiple lists at once and eliminates unnecessary
    copying.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - now
  - processes
  - multiple
  - lists
  - eliminates
  - unnecessary
  - copying
  source:
    doc: motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw.md
    quote: DuckDB now processes multiple lists at once and eliminates unnecessary
      copying to deliver better performance for common patterns like unpivoting a
      few columns.
    char_start: 0
    char_end: 159
- statement: DuckDB now supports adding a shared database attached to your DuckDB
    snippet(s).
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - now
  - supports
  - adding
  - shared
  - database
  - attached
  - snippet
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: DuckDBsnippets.com now supports adding a shared database attached to your
      DuckDB snippet(s), making sharing your queries even easier.
    char_start: 0
    char_end: 133
- statement: DuckDB now supports Apache Iceberg REST Catalogs, enabling seamless connections
    to Amazon S3 Tables and SageMaker Lakehouse.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - now
  - supports
  - apache
  - iceberg
  - rest
  - catalogs
  - enabling
  - seamless
  - connections
  - amazon
  - s3
  - tables
  - sagemaker
  - lakehouse
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: DuckDB now supports Apache Iceberg REST Catalogs, enabling seamless connections
      to Amazon S3 Tables and SageMaker Lakehouse.
    char_start: 0
    char_end: 124
- statement: DuckDB now supports ON CONFLICT clause on upserts.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - now
  - supports
  - conflict
  - clause
  - upserts
  source:
    doc: motherduck.com/blog/spark-ducklake-getting-started.md
    quote: Now available in the latest 0.7.0 release.
    char_start: 0
    char_end: 42
- statement: DuckDB now supports Pyodide, which means you can install the duckdb package
    directly there.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - now
  - supports
  - pyodide
  - which
  - means
  - install
  - package
  - directly
  source:
    doc: motherduck.com/blog/data-warehouse-feature-roundup-nov-2024.md
    quote: DuckDB now supports Pyodide, which means you can install the duckdb package
      directly there.
    char_start: 0
    char_end: 91
- statement: DuckDB now supports vectorized Scalar Python UDFs.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - now
  - supports
  - vectorized
  - scalar
  - python
  - udfs
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-four.md
    quote: DuckDB now supports vectorized Scalar Python UDFs.
    char_start: 0
    char_end: 50
- statement: DuckDB offers a promising solution for data sharing by encapsulating
    large datasets into a single compressed database file.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - offers
  - promising
  - solution
  - data
  - sharing
  - encapsulating
  - large
  - datasets
  - single
  - compressed
  - database
  - file
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: DuckDB offers a promising solution for data sharing by encapsulating large
      datasets into a single compressed database file, simplifying data transfer processes.
    char_start: 0
    char_end: 160
- statement: DuckDB offers capabilities to build recommendation engines and optimize
    data modeling for machine learning.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - offers
  - capabilities
  - build
  - recommendation
  - engines
  - optimize
  - data
  - modeling
  - machine
  - learning
  source:
    doc: motherduck.com/videos.md
    quote: He shows what DuckDB offers you to move quickly when building recommendation
      engines and optimizing data modeling for machine learning.
    char_start: 0
    char_end: 135
- statement: DuckDB offers data compression features.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - offers
  - data
  - compression
  - features
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md
    quote: and Data Compression
    char_start: 0
    char_end: 20
- statement: DuckDB offers search functionality with embeddings.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - offers
  - search
  - functionality
  - embeddings
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-five.md
    quote: DuckDB doesn't have to shy away from them, as several features enable it
      to offer search functionality with embeddings.
    char_start: 0
    char_end: 119
- statement: DuckDB offers streamlined syntax, such as FROM-first syntax when you’re
    selecting all columns.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - offers
  - streamlined
  - syntax
  - first
  - re
  - selecting
  - columns
  source:
    doc: motherduck.com/blog/git-for-data-part-1.md
    quote: DuckDB offers streamlined syntax, such as FROM-first syntax when you’re
      selecting all columns.
    char_start: 0
    char_end: 94
- statement: DuckDB offers unmatched simplicity and flexibility for visualizing large
    datasets using JupySQL.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - offers
  - unmatched
  - simplicity
  - flexibility
  - visualizing
  - large
  - datasets
  - using
  - jupysql
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: DuckDB offers unmatched simplicity and flexibility!
    char_start: 0
    char_end: 51
- statement: DuckDB operates as a single-node database, excelling until individual
    machine resources become insufficient for workloads.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - operates
  - single
  - node
  - database
  - excelling
  - individual
  - machine
  - resources
  - become
  - insufficient
  - workloads
  source:
    doc: motherduck.com/learn-more/secure-startup-data-warehouse.md
    quote: DuckDB operates as a single-node database, excelling until individual machine
      resources become insufficient for workloads.
    char_start: 0
    char_end: 122
- statement: DuckDB operates in-process, allowing us to iterate quickly on our model
    since computation occurs locally within the same dbt process.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - operates
  - process
  - allowing
  - us
  - iterate
  - quickly
  - model
  - since
  - computation
  - occurs
  - locally
  - within
  - dbt
  source:
    doc: motherduck.com/blog/dual-execution-dbt.md
    quote: DuckDB operates in-process, allowing us to iterate quickly on our model
      since computation occurs locally within the same dbt process.
    char_start: 0
    char_end: 133
- statement: DuckDB performed the normalization in-memory and immediately attached
    it to Postgres.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - performed
  - normalization
  - memory
  - immediately
  - attached
  - postgres
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: Using the exported parquet files, DuckDB performed the normalization in-memory
      and immediately attached it to Postgres.
    char_start: 0
    char_end: 119
- statement: DuckDB pg_scanner allows access to data in Postgres.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - pg
  - scanner
  - allows
  - access
  - data
  - postgres
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-nine.md
    quote: we can use the DuckDB pg_scanner to easily get at data in Postgres.
    char_start: 0
    char_end: 67
- statement: DuckDB pipelines built with ArgoCD replaced Spark with a ~2.3x performance
    improvement.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - pipelines
  - built
  - argocd
  - replaced
  - spark
  - '2.3'
  - performance
  - improvement
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: Junaid at Atlan built DuckDB pipelines with ArgoCD and replaced Spark with
      a ~2.3x performance improvement.
    char_start: 0
    char_end: 107
- statement: DuckDB plays two critical and distinct roles within the Evidence ecosystem.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - plays
  - two
  - critical
  - distinct
  - roles
  - within
  - evidence
  - ecosystem
  source:
    doc: motherduck.com/videos/simple-way-to-convert-csv-and-parquet-files.md
    quote: DuckDB plays two critical and distinct roles within the Evidence ecosystem,
      enabling both high-performance data processing and rich client-side interactivity.
    char_start: 0
    char_end: 158
- statement: DuckDB powers everything from Metabase to Doom.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - powers
  - everything
  - metabase
  - doom
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: DuckDB powers everything.
    char_start: 0
    char_end: 25
- statement: DuckDB powers Instant SQL's local execution capabilities.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - powers
  - instant
  - sql
  - local
  - execution
  - capabilities
  source:
    doc: motherduck.com/quacking-around-the-web.md
    quote: Powered by DuckDB's local execution capabilities
    char_start: 0
    char_end: 48
- statement: DuckDB processed 108 million lines in 2.2 seconds compared to the single-threaded
    wc at 3.2 seconds.
  type: performance
  entity: DuckDB
  keywords:
  - performance
  - duckdb
  - processed
  - '108'
  - million
  - lines
  - '2.2'
  - seconds
  - compared
  - single
  - threaded
  - wc
  - '3.2'
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: DuckDB processed 108 million lines in 2.2 seconds compared to the single-threaded
      wc at 3.2 seconds.
    char_start: 0
    char_end: 100
- statement: DuckDB provides a convenient fixed array size and list data type to store
    vector embeddings.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - provides
  - convenient
  - fixed
  - array
  - size
  - list
  - data
  - type
  - store
  - vector
  - embeddings
  source:
    doc: motherduck.com/blog/flight-sql-vs-rest-vs-jdbc.md
    quote: DuckDB provides a convenient fixed array size and list (variable size)
      data type to store vector embeddings.
    char_start: 0
    char_end: 108
- statement: DuckDB provides a unique workflow where developers can easily transition
    between DataFrames and SQL.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - provides
  - unique
  - workflow
  - developers
  - easily
  - transition
  - dataframes
  - sql
  source:
    doc: motherduck.com/blog/search-using-duckdb-part-3.md
    quote: DuckDB provides a unique workflow where developers can easily transition
      between DataFrames and SQL within a single tool.
    char_start: 0
    char_end: 121
- statement: DuckDB provides hash() and md5() utility functions that can hash sensitive
    columns between the extract and load steps in a pipeline.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - provides
  - hash
  - md5
  - utility
  - functions
  - sensitive
  - columns
  - extract
  - load
  - steps
  - pipeline
  source:
    doc: motherduck.com/blog/faster-ducks.md
    quote: DuckDB provides hash() and md5() utility functions that can hash sensitive
      columns between the extract and load steps in a pipeline.
    char_start: 0
    char_end: 132
- statement: DuckDB provides the struct_insert function for adding fields to STRUCTs.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - provides
  - struct
  - insert
  - function
  - adding
  - fields
  - structs
  source:
    doc: motherduck.com/videos/duckfooding-at-motherduck.md
    quote: DuckDB provides the struct_insert function for adding fields.
    char_start: 0
    char_end: 61
- statement: DuckDB reduces data size from 1.4GB to 118MB when exporting to Parquet
    format.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - reduces
  - data
  - size
  - '1.4'
  - gb
  - 118mb
  - exporting
  - parquet
  - format
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: He also demonstrates exporting the data to Parquet format using the `EXPORT
      DATABASE` command, reducing the data size from 1.4GB (unzipped CSV) to 118MB
      (compressed Parquet).
    char_start: 0
    char_end: 174
- statement: DuckDB replaces Spark for 10GB-1TB tasks on laptops with fast, seamless
    Python integration.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - replaces
  - spark
  - 10gb
  - 1tb
  - tasks
  - laptops
  - fast
  - seamless
  - python
  - integration
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: DuckDB replaces Spark for 10GB-1TB tasks on laptops with fast, seamless
      Python integration.
    char_start: 0
    char_end: 91
- statement: DuckDB requires an Azure connection string to authenticate.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - requires
  - azure
  - connection
  - string
  - authenticate
  source:
    doc: motherduck.com/blog/duckdb-110-hidden-gems.md
    quote: DuckDB requires an Azure connection string to authenticate.
    char_start: 0
    char_end: 59
- statement: DuckDB requires minimal setup with no additional infrastructure.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - requires
  - minimal
  - setup
  - additional
  - infrastructure
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: This approach required minimal setup with no additional infrastructure,
      making it an ideal validation layer.
    char_start: 0
    char_end: 108
- statement: DuckDB requires strict data types and will throw an error if types do
    not match.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - requires
  - strict
  - data
  - types
  - throw
  - error
  - match
  source:
    doc: motherduck.com/blog/duckdb-cognee-sql-analytics-graph-rag.md
    quote: if we pop over into the strongly-typed DuckDB and try to query this table,
      we'll get an error.
    char_start: 0
    char_end: 94
- statement: DuckDB returns a 'relation' object rather than immediately materializing
    the total result.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - returns
  - relation
  - object
  - rather
  - immediately
  - materializing
  - total
  - result
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: When writing queries in Python, DuckDB returns a 'relation' object (an
      abstract representation of the query)...
    char_start: 0
    char_end: 111
- statement: DuckDB should use all available compute all the time.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - use
  - available
  - compute
  - time
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-nine.md
    quote: it should use all available compute all the time!
    char_start: 0
    char_end: 49
- statement: DuckDB Snippets site has been a source of inspiration for powerful analytic
    capabilities.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - snippets
  - site
  - source
  - inspiration
  - powerful
  - analytic
  - capabilities
  source:
    doc: motherduck.com/blog/building-motherduck-partner-ecosystem.md
    quote: The DuckDB Snippets site has been a source of inspiration for me as I’ve
      explored all the powerful analytic capabilities and SQL simplification in DuckDB.
    char_start: 0
    char_end: 154
- statement: DuckDB SQL offers a toolkit that can be shared across roles.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - sql
  - offers
  - toolkit
  - shared
  - across
  - roles
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2024.md
    quote: DuckDB SQL offers a toolkit that can be shared across these roles.
    char_start: 0
    char_end: 66
- statement: DuckDB struggled with memory usage when processing deeply nested JSON.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - struggled
  - memory
  - usage
  - processing
  - deeply
  - nested
  - json
  source:
    doc: motherduck.com/learn-more/star-schema-data-warehouse-guide.md
    quote: DuckDB wasn't prepared for this and used about 500 times the memory of
      the string just to parse it.
    char_start: 0
    char_end: 99
- statement: DuckDB supports accessing private S3 buckets by using CREATE SECRET to
    specify and store your credentials.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - supports
  - accessing
  - private
  - s3
  - buckets
  - using
  - create
  - secret
  - specify
  - store
  - credentials
  source:
    doc: motherduck.com/blog/duckdb-tutorial-for-beginners.md
    quote: DuckDB and MotherDuck also support accessing private S3 buckets by using
      [`CREATE SECRET`](https://motherduck.com/docs/integrations/cloud-storage/amazon-s3/)
      to specify and store your credentials.
    char_start: 0
    char_end: 196
- statement: DuckDB supports end-to-end query optimization.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - supports
  - end
  - query
  - optimization
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md
    quote: End-to-end Query Optimization
    char_start: 0
    char_end: 29
- statement: DuckDB supports Excel-style pivoting.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - supports
  - excel
  - style
  - pivoting
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: 'This year, in the year of the return of Pivot Tables... DuckDB supports
      these now, too, with: INSTALL pivot_table FROM community; LOAD pivot_table;'
    char_start: 0
    char_end: 147
- statement: DuckDB supports glob patterns for loading multiple files.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - supports
  - glob
  - patterns
  - loading
  - multiple
  - files
  source:
    doc: motherduck.com/blog/csv-files-persist-duckdb-solution.md
    quote: DuckDB supports glob patterns for loading multiple files.
    char_start: 0
    char_end: 57
- statement: DuckDB supports JavaScript, Java, and Rust, enabling consistent access
    across diverse environments.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - supports
  - javascript
  - java
  - rust
  - enabling
  - consistent
  - access
  - across
  - diverse
  - environments
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: And perhaps the biggest advantage, DuckDB's language agnosticism, which
      supports JavaScript (WebAssembly), Java, and Rust, enables consistent access
      across diverse environments.
    char_start: 0
    char_end: 177
- statement: DuckDB supports Pyodide for browser usage.
  type: feature
  entity: DuckDB
  keywords:
  - feature
  - duckdb
  - supports
  - pyodide
  - browser
  - usage
  source:
    doc: motherduck.com/blog/data-warehouse-feature-roundup-nov-2024.md
    quote: 'More DuckDB in the browser: Pyodide support'
    char_start: 0
    char_end: 43
- statement: DuckDB supports Raspberry Pi.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - supports
  - raspberry
  - pi
  source:
    doc: motherduck.com/blog/bigquery-to-duckdb-motherduck.md
    quote: Using MotherDuck’s Dual Query execution on a Raspberry Pi...
    char_start: 0
    char_end: 60
- statement: DuckDB supports rolling window aggregations, which can reduce thousands
    of events into summarized time-based buckets.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - supports
  - rolling
  - window
  - aggregations
  - which
  - reduce
  - thousands
  - events
  - summarized
  - time
  - based
  - buckets
  source:
    doc: motherduck.com/blog/sql-keyboard-shortcuts-for-joyful-querying.md
    quote: DuckDB supports rolling window aggregations, which can reduce thousands
      of events into summarized time-based buckets.
    char_start: 0
    char_end: 117
- statement: DuckDB supports vector similarity search for finding similar items.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - supports
  - vector
  - similarity
  - search
  - finding
  - similar
  - items
  source:
    doc: motherduck.com/blog/search-using-duckdb-part-2.md
    quote: A technique used in databases to find similar items based on vector representations.
    char_start: 0
    char_end: 84
- statement: DuckDB supports window functions and regular expressions for log parsing.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - supports
  - window
  - functions
  - regular
  - expressions
  - log
  - parsing
  source:
    doc: motherduck.com/blog/preswald-health-data-analysis.md
    quote: This advanced log parsing query is easy to express thanks to DuckDB's full-featured
      SQL dialect.
    char_start: 0
    char_end: 96
- statement: 'DuckDB usage has grown from 0.6% to 1.4%, ranking it at #3 of the most
    desired databases to use.'
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - usage
  - grown
  - '0.6'
  - '1.4'
  - ranking
  - desired
  - databases
  - use
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md
    quote: 'DuckDB usage has grown from 0.6% to 1.4%, ranking it at #3 of the most
      desired databases to use.'
    char_start: 0
    char_end: 96
- statement: DuckDB uses a vectorized execution model, processing data in chunks of
    2048 values at a time.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - uses
  - vectorized
  - execution
  - model
  - processing
  - data
  - chunks
  - '2048'
  - values
  - time
  source:
    doc: motherduck.com/learn-more/star-schema-data-warehouse-guide.md
    quote: DuckDB uses a vectorized execution model, which is a powerful middle ground.
      We process data in 'vectors'—chunks of 2048 values at a time.
    char_start: 0
    char_end: 138
- statement: DuckDB uses Plotly for visualizations.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - uses
  - plotly
  - visualizations
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: She uses the choropleth map functionality to avoid having to acquire a
      Mapbox API key, which is also supported by Plotly.
    char_start: 0
    char_end: 121
- statement: DuckDB uses PostgreSQL's efficient binary transfer protocol to read data
    with minimal overhead.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - uses
  - postgresql
  - efficient
  - binary
  - transfer
  - protocol
  - read
  - data
  - minimal
  - overhead
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md
    quote: Behind the scenes, DuckDB uses PostgreSQL's efficient binary transfer protocol
      to read data with minimal overhead.
    char_start: 0
    char_end: 114
- statement: DuckDB uses snapshot isolation by default, which is equivalent to SERIALIZABLE.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - uses
  - snapshot
  - isolation
  - default
  - which
  - equivalent
  - serializable
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: DuckDB uses snapshot isolation by default, which is equivalent to SERIALIZABLE.
    char_start: 0
    char_end: 79
- statement: DuckDB uses snapshot isolation to ensure consistency during transactions.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - uses
  - snapshot
  - isolation
  - ensure
  - consistency
  - transactions
  source:
    doc: motherduck.com/learn-more/data-warehouse-tco.md
    quote: In DuckDB, transaction isolation is handled automatically with snapshot
      isolation...
    char_start: 0
    char_end: 84
- statement: DuckDB uses Soda for data quality monitoring.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - uses
  - soda
  - data
  - quality
  - monitoring
  source:
    doc: motherduck.com/blog/just-enough-sql-for-ai.md
    quote: DuckDB uses Soda for data quality monitoring.
    char_start: 0
    char_end: 45
- statement: DuckDB utilizes the text-embedding-3-small model for embedding tasks.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - utilizes
  - text
  - embedding
  - small
  - model
  - tasks
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: DuckDB utilizes the text-embedding-3-small model.
    char_start: 0
    char_end: 49
- statement: DuckDB v1.2 'Harlequin' release will feature improved CSV reader performance.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - v1.2
  - harlequin
  - release
  - feature
  - improved
  - csv
  - reader
  - performance
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: The upcoming DuckDB v1.2 'Harlequin' release will feature improved CSV
      reader performance.
    char_start: 0
    char_end: 90
- statement: DuckDB version 0.10.0 introduces backwards compatibility in the DuckDB
    storage format.
  type: feature
  entity: DuckDB
  keywords:
  - feature
  - duckdb
  - version
  - 0.10.0
  - introduces
  - backwards
  - compatibility
  - storage
  - format
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: the DuckDB team just released 0.10.0, which introduces backwards compatibility
      in the DuckDB storage format
    char_start: 0
    char_end: 107
- statement: DuckDB version 1.1 added a feature to export EXPLAIN as HTML.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - version
  - '1.1'
  - added
  - feature
  - export
  - explain
  - html
  source:
    doc: motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md
    quote: The DuckDB team added a neat feature to export your EXPLAIN as HTML.
    char_start: 0
    char_end: 68
- statement: DuckDB version 1.1.0 brings many new features and improvements.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - version
  - 1.1.0
  - brings
  - many
  - new
  - features
  - improvements
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: With its latest release, DuckDB version 1.1.0, "Eatoni", brings many new
      features and improvements.
    char_start: 0
    char_end: 99
- statement: DuckDB was between 4X and 200X faster than Postgres for this use case.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - 4x
  - 200x
  - faster
  - postgres
  - use
  - case
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: they found that DuckDB was between 4X and 200X faster than Postgres for
      this use case.
    char_start: 0
    char_end: 86
- statement: DuckDB was discovered during a complete platform rebuild in 2024.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - discovered
  - complete
  - platform
  - rebuild
  - '2024'
  source:
    doc: motherduck.com/learn-more/secure-startup-data-warehouse.md
    quote: During a complete platform rebuild in 2024, Sahil discovered DuckDB and
      the 'small data movement.'
    char_start: 0
    char_end: 98
- statement: 'DuckDB was indeed faster, putting Polars in #2 and Pandas wasn’t able
    to get it through.'
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - indeed
  - faster
  - putting
  - polars
  - pandas
  - wasn
  - able
  - get
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: 'DuckDB was indeed faster, putting Polars in #2 and Pandas wasn’t able
      to get it through.'
    char_start: 0
    char_end: 88
- statement: DuckDB WASM is currently one of the fastest engines for querying fully
    in-browser.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - wasm
  - currently
  - one
  - fastest
  - engines
  - querying
  - fully
  - browser
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-seven.md
    quote: Despite all of this, DuckDB WASM is currently one of the fastest (if not
      the fastest) engines for querying fully in-browser.
    char_start: 0
    char_end: 124
- statement: DuckDB website hits 600k unique visitors per month.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - website
  - hits
  - 600k
  - unique
  - visitors
  - per
  - month
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: The website hits 600k unique web visitors per month.
    char_start: 0
    char_end: 52
- statement: DuckDB will automatically infer the schema from the Parquet files.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - automatically
  - infer
  - schema
  - parquet
  - files
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: DuckDB will automatically infer the schema from the Parquet files.
    char_start: 0
    char_end: 66
- statement: DuckDB will be featured at PyCon US 2024.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - featured
  - pycon
  - us
  - '2024'
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2023.md
    quote: 'Alex Monahan of DuckDB Labs and MotherDuck will present a talk on ''Python
      and SQL: Better Together, Powered by @DuckDB.'''
    char_start: 0
    char_end: 120
- statement: DuckDB will be featured in the keynote session at the Data & AI Summit.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - featured
  - keynote
  - session
  - data
  - ai
  - summit
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2023.md
    quote: Hannes will be featured in the keynote session on Thursday.
    char_start: 0
    char_end: 59
- statement: DuckDB will perform better if run locally on your machine.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - perform
  - better
  - run
  - locally
  - machine
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: Speedwise will probably be much better if you run it locally on your machine.
    char_start: 0
    char_end: 77
- statement: DuckDB writes data to a random offset in the database file.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - writes
  - data
  - random
  - offset
  - database
  - file
  source:
    doc: motherduck.com/blog/duckdb-110-hidden-gems.md
    quote: When DucKDB writes data to a random offset in the database file...
    char_start: 0
    char_end: 66
- statement: DuckDB's ability to create pre-aggregated tables or materialized views
    helps minimize cloud usage during development.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - ability
  - create
  - pre
  - aggregated
  - tables
  - materialized
  - views
  - helps
  - minimize
  - cloud
  - usage
  - development
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: Prevent surprise bills by leveraging DuckDB's ability to create pre-aggregated
      tables or materialized views.
    char_start: 0
    char_end: 108
- statement: DuckDB's approach to these formats showcases its flexibility and adaptability.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - approach
  - formats
  - showcases
  - flexibility
  - adaptability
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: DuckDB’s approach to these formats showcases its flexibility and adaptability.
    char_start: 0
    char_end: 78
- statement: DuckDB's columnar storage and SQL/GQL compatibility make it an attractive
    alternative to traditional databases.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - columnar
  - storage
  - sql
  - gql
  - compatibility
  - make
  - attractive
  - alternative
  - traditional
  - databases
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: DuckDB's columnar storage and SQL/GQL compatibility make it an attractive
      alternative to traditional databases.
    char_start: 0
    char_end: 111
- statement: DuckDB's COPY TO ... PARTITION_BY can help you export data into a structured,
    Hive-partitioned layout.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - copy
  - partition
  - help
  - export
  - data
  - structured
  - hive
  - partitioned
  - layout
  source:
    doc: motherduck.com/videos.md
    quote: DuckDB's `COPY TO ... PARTITION_BY` can help you export data into a structured,
      Hive-partitioned layout.
    char_start: 0
    char_end: 104
- statement: DuckDB's creators Hannes Mühleisen and Mark Raasveldt will speak at DuckCon.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - creators
  - hannes
  - hleisen
  - mark
  - raasveldt
  - speak
  - duckcon
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: it will start with a talk from DuckDB’s creators Hannes Mühleisen and Mark
      Raasveldt about the state of DuckDB.
    char_start: 0
    char_end: 111
- statement: DuckDB's creators will discuss DuckDB's current state and the upcoming
    release of version 1.0.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - creators
  - discuss
  - current
  - state
  - upcoming
  - release
  - version
  - '1.0'
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: The event will begin with a talk by DuckDB's creators, Hannes Mühleisen
      and Mark Raasveldt, discussing DuckDB's current state and the upcoming release
      of version 1.0.
    char_start: 0
    char_end: 166
- statement: DuckDB's CSV reader achieves top ranking in the Pollock Benchmark due
    to its robustness in handling non-standard CSV files.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - csv
  - reader
  - achieves
  - top
  - ranking
  - pollock
  - benchmark
  - due
  - robustness
  - handling
  - non
  - standard
  - files
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: DuckDB's CSV reader achieves top ranking in the Pollock Benchmark due to
      its robustness in handling non-standard CSV files.
    char_start: 0
    char_end: 123
- statement: DuckDB's CSV sniffer operates through multiple phases to determine the
    best way to read your file.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - csv
  - sniffer
  - operates
  - multiple
  - phases
  - determine
  - best
  - way
  - read
  - file
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: DuckDB's CSV sniffer actually operates through multiple phases to determine
      the best way to read your file.
    char_start: 0
    char_end: 107
- statement: DuckDB's database internals allow toolmakers to build parser-powered
    features.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - database
  - internals
  - allow
  - toolmakers
  - build
  - parser
  - powered
  - features
  source:
    doc: motherduck.com/blog/llm-data-pipelines-prompt-motherduck-dbt.md
    quote: This means any toolmaker can build parser-powered features using this important
      part of DuckDB's database internals.
    char_start: 0
    char_end: 116
- statement: DuckDB's Excel support was initially developed as part of the spatial
    extension.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - excel
  - support
  - initially
  - developed
  - part
  - spatial
  - extension
  source:
    doc: motherduck.com/blog/pg_duckdb-postgresql-extension-for-duckdb-motherduck.md
    quote: DuckDB's Excel support was initially developed as part of the spatial extension...
    char_start: 0
    char_end: 82
- statement: DuckDB's extension ecosystem is rapidly expanding, with 127 extensions
    providing diverse functionalities.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - extension
  - ecosystem
  - rapidly
  - expanding
  - '127'
  - extensions
  - providing
  - diverse
  - functionalities
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: DuckDB's extension ecosystem is rapidly expanding, with 127 extensions
      providing diverse functionalities from core data format support to advanced
      community-driven integrations.
    char_start: 0
    char_end: 177
- statement: DuckDB's extension system successfully handles SQL, graph queries, vector
    searches, and full-text searches.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - extension
  - system
  - successfully
  - handles
  - sql
  - graph
  - queries
  - vector
  - searches
  - full
  - text
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: Sixing concluded that DuckDB's extension system successfully handles SQL,
      graph queries, vector searches, and full-text searches.
    char_start: 0
    char_end: 129
- statement: DuckDB's FTS extension creates an inverted index for efficient searching.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - fts
  - extension
  - creates
  - inverted
  - index
  - efficient
  - searching
  source:
    doc: motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md
    quote: In DuckDB, the FTS extension provides the means to search through strings,
      and this is done so by creating an Inverted Index.
    char_start: 0
    char_end: 125
- statement: DuckDB's initial UI design for SQL error messages was not practical for
    complex queries.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - initial
  - ui
  - design
  - sql
  - error
  - messages
  - practical
  - complex
  - queries
  source:
    doc: motherduck.com/learn-more/star-schema-data-warehouse-guide.md
    quote: Our initial UI design placed SQL error messages below the query...
    char_start: 0
    char_end: 66
- statement: DuckDB's internal format supports efficient INSERT, UPDATE, DELETE operations.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - internal
  - format
  - supports
  - efficient
  - insert
  - update
  - delete
  - operations
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: Mutable; supports efficient INSERT, UPDATE, DELETE operations.
    char_start: 0
    char_end: 62
- statement: DuckDB's local-first design allows for low-latency data querying.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - local
  - first
  - design
  - allows
  - low
  - latency
  - data
  - querying
  source:
    doc: motherduck.com/blog/motherduck-kestra-etl-pipelines.md
    quote: DuckDB’s local-first design, along with principled performance optimizations
      and friendly SQL, made it possible to use _your computer_ to parse queries,
      cache dependencies, and rewrite & run them.
    char_start: 0
    char_end: 196
- statement: DuckDB's multi-threaded query execution allows it to utilize multiple
    CPU cores for parallel processing.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - multi
  - threaded
  - query
  - execution
  - allows
  - utilize
  - multiple
  - cpu
  - cores
  - parallel
  - processing
  source:
    doc: motherduck.com/videos/understanding-ducklake-a-table-format-with-a-modern-architecture.md
    quote: DuckDB's multi-threaded query execution allows it to utilize multiple CPU
      cores for parallel processing.
    char_start: 0
    char_end: 104
- statement: DuckDB's partitioned write capability is essential for efficient data
    exports.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - partitioned
  - write
  - capability
  - essential
  - efficient
  - data
  - exports
  source:
    doc: motherduck.com/videos.md
    quote: 'Today, I want to share a technique that''s become an essential part of
      my toolkit: DuckDB''s partitioned write capability.'
    char_start: 0
    char_end: 120
- statement: DuckDB's performance and MotherDuck's serverless scale transform the
    pipeline into an 8-minute workflow.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - performance
  - motherduck
  - serverless
  - scale
  - transform
  - pipeline
  - minute
  - workflow
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: able to use DuckDB's performance and MotherDuck's serverless scale to transform
      that pipeline into an 8-minute workflow.
    char_start: 0
    char_end: 120
- statement: DuckDB's performance is benchmarked with the NYC Taxi Dataset.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - performance
  - benchmarked
  - nyc
  - taxi
  - dataset
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md
    quote: 'Driving CSV Performance: Benchmarking DuckDB with the NYC Taxi Dataset.'
    char_start: 0
    char_end: 71
- statement: DuckDB's portability is achieved through its C++11 codebase and minimal
    external dependencies.
  type: feature
  entity: DuckDB
  keywords:
  - feature
  - duckdb
  - portability
  - achieved
  - '11'
  - codebase
  - minimal
  - external
  - dependencies
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: He explains column-oriented storage, vectorized execution, and using zone
      maps for indexing.
    char_start: 0
    char_end: 92
- statement: DuckDB's query plans are displayed as a tree structure.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - query
  - plans
  - displayed
  - tree
  - structure
  source:
    doc: motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md
    quote: DuckDB's query plans are displayed as a tree structure, with each operation
      indented to show its relationship to other operations.
    char_start: 0
    char_end: 130
- statement: DuckDB's READ_JSON() function simplifies complex data processing tasks.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - read
  - json
  - function
  - simplifies
  - complex
  - data
  - processing
  - tasks
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md
    quote: DuckDB's READ_JSON() function is pivotal, allowing automatic configuration
      flag inference from JSON files.
    char_start: 0
    char_end: 106
- statement: DuckDB's resource handling capabilities were improved based on insights
    gained from internal use.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - resource
  - handling
  - capabilities
  - improved
  - based
  - insights
  - gained
  - internal
  - use
  source:
    doc: motherduck.com/learn-more/fix-slow-bi-dashboards.md
    quote: These learnings informed improvements to DuckDB's resource handling capabilities.
    char_start: 0
    char_end: 81
- statement: DuckDB's sniff_csv function analyzes a sample of the file and reports
    back the detected dialect, types, header presence, and more.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - sniff
  - csv
  - function
  - analyzes
  - sample
  - file
  - reports
  - back
  - detected
  - dialect
  - types
  - header
  - presence
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: Before attempting to load the data using DuckDB’s auto-detection capabilities,
      it's incredibly useful to understand what DuckDB thinks it's dealing with.
    char_start: 0
    char_end: 153
- statement: DuckDB's SQL features can be leveraged by the generator.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - sql
  - features
  - leveraged
  - generator
  source:
    doc: motherduck.com/blog/data-app-generator.md
    quote: how to leverage DuckDB's and MotherDuck's extensive SQL features
    char_start: 0
    char_end: 64
- statement: DuckDB's storage engine supports both in-memory and persistent disk-based
    storage.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - storage
  - engine
  - supports
  - both
  - memory
  - persistent
  - disk
  - based
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: DuckDB's storage engine supports both in-memory and persistent disk-based
      storage.
    char_start: 0
    char_end: 82
- statement: DuckDB's success is all about simplicity, and we are bringing it directly
    to PostgreSQL users.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - success
  - about
  - simplicity
  - bringing
  - directly
  - postgresql
  - users
  source:
    doc: motherduck.com/blog/motherduck-duckdb-dbt.md
    quote: DuckDB's success is all about simplicity, and we are bringing it directly
      to PostgreSQL users in their existing database.
    char_start: 0
    char_end: 121
- statement: DuckDB's time_bucket() function is used to truncate timestamps and align
    them into buckets.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - time
  - bucket
  - function
  - used
  - truncate
  - timestamps
  - align
  - them
  - buckets
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: DuckDB's time_bucket() function is used to truncate timestamps and align
      them into buckets, facilitating the aggregation of sensor readings.
    char_start: 0
    char_end: 140
- statement: DuckDB's timeout settings need to account for query selectivity.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - timeout
  - settings
  - need
  - account
  - query
  - selectivity
  source:
    doc: motherduck.com/learn-more/star-schema-data-warehouse-guide.md
    quote: These timed out unnecessarily, teaching us that timeouts need to account
      for query selectivity...
    char_start: 0
    char_end: 97
- statement: DuckDB's tolerance for trailing commas makes it especially great for
    SQL queries.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - tolerance
  - trailing
  - commas
  - makes
  - especially
  - great
  - sql
  - queries
  source:
    doc: motherduck.com/blog/duckdb-excel-extension.md
    quote: DuckDB's tolerance for trailing commas makes this especially great feeling.
    char_start: 0
    char_end: 75
- statement: DuckDB, dbt, and Great Expectations can be combined to build incredibly
    simple and reliable data pipelines.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - dbt
  - great
  - expectations
  - combined
  - build
  - incredibly
  - simple
  - reliable
  - data
  - pipelines
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: you could build incredibly simple and reliable data pipelines.
    char_start: 0
    char_end: 62
- statement: DuckDB-NSQL is a Text2SQL model for DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - nsql
  - text2sql
  - model
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-six.md
    quote: Introducing DuckDB-NSQL, a LLM for DuckDB SQL
    char_start: 0
    char_end: 45
- statement: DuckDB-WASM can manage game state, collision detection, and 3D rendering
    through SQL queries.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - wasm
  - manage
  - game
  - state
  - collision
  - detection
  - 3d
  - rendering
  - sql
  - queries
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-nine.md
    quote: Patrick's project uses DuckDB-WASM to manage game state, collision detection,
      and 3D rendering through SQL queries.
    char_start: 0
    char_end: 115
- statement: DuckDB’s SUMMARIZE command provides a quick overview of the dataset.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - summarize
  - command
  - provides
  - quick
  - overview
  - dataset
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: DuckDB’s SUMMARIZE command provides a quick overview of the dataset, including
      the number of values, distribution, and magnitude of numerical values without
      ingestion.
    char_start: 0
    char_end: 167
- statement: DuckLake v0.2 introduces credential management with secrets, enhanced
    Parquet file settings, and improved file organization capabilities.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - ducklake
  - v0.2
  - introduces
  - credential
  - management
  - secrets
  - enhanced
  - parquet
  - file
  - settings
  - improved
  - organization
  - capabilities
  source:
    doc: motherduck.com/blog/duckdb-dbt-e2e-data-engineering-project-part-2.md
    quote: DuckLake v0.2 introduces credential management with secrets, enhanced Parquet
      file settings, and improved file organization capabilities.
    char_start: 0
    char_end: 137
- statement: Each task is executed in its own DuckDB instance using Ray’s parallel
    execution capabilities.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - task
  - executed
  - duckdb
  - instance
  - using
  - ray
  - parallel
  - execution
  - capabilities
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: Each task is executed in its own DuckDB instance using Ray’s parallel execution
      capabilities.
    char_start: 0
    char_end: 93
- statement: Evidence built its query engine Universal SQL with DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - evidence
  - built
  - query
  - engine
  - universal
  - sql
  - duckdb
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: Evidence built its query engine [Universal SQL] with DuckDB’s WebAssembly.
    char_start: 0
    char_end: 74
- statement: Evidence dashboards powered by DuckDB and Markdown.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - evidence
  - dashboards
  - powered
  - duckdb
  - markdown
  source:
    doc: motherduck.com/videos.md
    quote: Evidence dashboards powered by DuckDB and Markdown.
    char_start: 0
    char_end: 51
- statement: Executing a full table scan query took only 6 seconds.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - executing
  - full
  - table
  - scan
  - query
  - took
  - seconds
  source:
    doc: motherduck.com/blog/redshift-files-hunt-for-big-data.md
    quote: After generation, executing a full table scan query (`SELECT  SUM(id) FROM
      '*.parquet' WHERE email LIKE '%gmail.com'`) took only 6 seconds.
    char_start: 0
    char_end: 139
- statement: Flight SQL makes dashboards 10x faster.
  type: performance
  entity: DuckDB
  keywords:
  - performance
  - flight
  - sql
  - makes
  - dashboards
  - 10x
  - faster
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: 10x faster dashboard refreshes → From coffee-break wait times to blink-and-you-miss-it
      speed
    char_start: 0
    char_end: 92
- statement: Full text search scans the entire text for specific word matches.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - full
  - text
  - search
  - scans
  - entire
  - specific
  - word
  - matches
  source:
    doc: motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md
    quote: Full text search, that scans the entire text for specific word matches,
      is particularly beneficial in scenarios where exact keyword matching is necessary.
    char_start: 0
    char_end: 154
- statement: Get up to speed quickly with DuckDB, including installation, VSCode workflow
    integration and your first SQL analytics project.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - get
  - up
  - speed
  - quickly
  - duckdb
  - including
  - installation
  - vscode
  - workflow
  - integration
  - first
  - sql
  - analytics
  - project
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md
    quote: Get up to speed quickly with DuckDB, including installation, VSCode workflow
      integration and your first SQL analytics project.
    char_start: 0
    char_end: 126
- statement: Google invented a new model for computation by applying functional programming
    and distributed systems algorithms.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - google
  - invented
  - new
  - model
  - computation
  - applying
  - functional
  - programming
  - distributed
  - systems
  - algorithms
  source:
    doc: motherduck.com/glossary/auto inference.md
    quote: In order to be able to index every website everywhere, Google invented
      a new model for computation; by applying functional programming and distributed
      systems algorithms...
    char_start: 0
    char_end: 172
- statement: Google pioneered several groundbreaking solutions for indexing the entire
    web.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - google
  - pioneered
  - several
  - groundbreaking
  - solutions
  - indexing
  - entire
  - web
  source:
    doc: motherduck.com/glossary/CLI.md
    quote: Google, facing the challenge of indexing the entire web, pioneered several
      groundbreaking solutions.
    char_start: 0
    char_end: 100
- statement: Graham Wetzler used DuckDB and Python to solve Advent of Code challenges.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - graham
  - wetzler
  - used
  - duckdb
  - python
  - solve
  - advent
  - code
  - challenges
  source:
    doc: motherduck.com/blog/spark-ducklake-getting-started.md
    quote: A very interesting article from Graham Wetzler about he used DuckDB and
      Python to solve some of the Advent of Code challenges.
    char_start: 0
    char_end: 126
- statement: Harlequin is an IDE for DuckDB in the console.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - harlequin
  - ide
  - duckdb
  - console
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: It’s a very cool project developed by Ted Conbeer. As its name indicates,
      is an IDE for DuckDB in the console.
    char_start: 0
    char_end: 110
- statement: Hex has improved its performance by migrating to a DuckDB-based architecture.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - hex
  - improved
  - performance
  - migrating
  - duckdb
  - based
  - architecture
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: Hex, a notebook-based solution, has improved its performance by migrating
      to a DuckDB-based architecture.
    char_start: 0
    char_end: 105
- statement: Iceberg writes are now supported through COPY FROM DATABASE.
  type: feature
  entity: DuckDB
  keywords:
  - feature
  - iceberg
  - writes
  - now
  - supported
  - copy
  - database
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: For the data lake ecosystem, Iceberg writes are now supported through COPY
      FROM DATABASE duckdb_db TO iceberg_datalake.
    char_start: 0
    char_end: 119
- statement: Implementing DuckDB transformed FinQore's data pipeline performance from
    eight hours to just eight minutes.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - implementing
  - duckdb
  - transformed
  - finqore
  - data
  - pipeline
  - performance
  - eight
  - hours
  - minutes
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: implementing DuckDB transformed their data pipeline performance from eight
      hours to just eight minutes
    char_start: 0
    char_end: 102
- statement: In just 60 days of hands-on keyboard, we were able to ship a clean and
    efficient system, thanks to the DuckDB execution engine.
  type: performance
  entity: DuckDB
  keywords:
  - performance
  - '60'
  - days
  - hands
  - keyboard
  - able
  - ship
  - clean
  - efficient
  - system
  - thanks
  - duckdb
  - execution
  - engine
  source:
    doc: motherduck.com/blog/pg-mooncake-columnstore.md
    quote: In just 60 days of hands-on keyboard, we were able to ship a clean and
      efficient system, thanks to the DuckDB execution engine.
    char_start: 0
    char_end: 127
- statement: In this second part, we'll transform this raw data using dbt and DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - second
  - part
  - ll
  - transform
  - raw
  - data
  - using
  - dbt
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: In this second part, we'll transform this raw data using dbt and DuckDB.
    char_start: 0
    char_end: 72
- statement: In-memory data offers speed and flexibility, making it ideal for processing
    real-time or recent data.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - memory
  - data
  - offers
  - speed
  - flexibility
  - making
  - ideal
  - processing
  - real
  - time
  - recent
  source:
    doc: motherduck.com/blog/solving-advent-code-duckdb-dbt.md
    quote: In-memory data offers speed and flexibility, making it ideal for processing
      real-time or recent data.
    char_start: 0
    char_end: 101
- statement: Infera is a new DuckDB extension that integrates machine learning.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - infera
  - new
  - duckdb
  - extension
  - integrates
  - machine
  - learning
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md
    quote: Infera is a new DuckDB extension, developed in Rust, that integrates machine
      learning.
    char_start: 0
    char_end: 86
- statement: Instant SQL works for more than just DuckDB tables; it works for massive
    tables in MotherDuck, parquet files in S3, Postgres tables, SQLite, MySQL, Iceberg,
    Delta.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - instant
  - sql
  - works
  - duckdb
  - tables
  - massive
  - motherduck
  - parquet
  - files
  - s3
  - postgres
  - sqlite
  - mysql
  - iceberg
  - delta
  source:
    doc: motherduck.com/blog/redshift-files-hunt-for-big-data.md
    quote: Instant SQL works for more than just DuckDB tables; it works for massive
      tables in MotherDuck, parquet files in S3, Postgres tables, SQLite, MySQL, Iceberg,
      Delta.
    char_start: 0
    char_end: 163
- statement: Integrating DuckDB and PuppyGraph enables the incorporation of graph
    querying into your existing data warehouse.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - integrating
  - duckdb
  - puppygraph
  - enables
  - incorporation
  - graph
  - querying
  - existing
  - data
  - warehouse
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Discover how integrating DuckDB and PuppyGraph enables the incorporation
      of graph querying into your existing data warehouse!
    char_start: 0
    char_end: 125
- statement: Integrating DuckDB into your data architecture can be a simple process.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - integrating
  - duckdb
  - data
  - architecture
  - simple
  - process
  source:
    doc: motherduck.com/blog/git-for-data-part-1.md
    quote: integrating DuckDB into your data architecture can be a simple process
      when using MotherDuck and Estuary.
    char_start: 0
    char_end: 105
- statement: Integrating the data governance unity catalog with DuckDB is a good practice
    for getting to an enterprise data platform.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - integrating
  - data
  - governance
  - unity
  - catalog
  - duckdb
  - good
  - practice
  - getting
  - enterprise
  - platform
  source:
    doc: motherduck.com/blog/bigquery-to-duckdb-motherduck.md
    quote: Integrating the data governance unity catalog with DuckDB is a good practice
      for getting to an enterprise data platform and handling data more securely.
    char_start: 0
    char_end: 152
- statement: It has never been easier to join in your data from spreadsheet sources
    using DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - never
  - easier
  - join
  - data
  - spreadsheet
  - sources
  - using
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-the-great-federator.md
    quote: Now in MotherDuck & DuckDB, its never been easier to join in your data
      from spreadsheet sources.
    char_start: 0
    char_end: 96
- statement: It makes exploratory analysis more intuitive while maintaining the performance
    you've come to expect from DuckDB.
  type: feature
  entity: DuckDB
  keywords:
  - feature
  - makes
  - exploratory
  - analysis
  - intuitive
  - maintaining
  - performance
  - ve
  - come
  - expect
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-enterprise-5-key-categories.md
    quote: It makes exploratory analysis more intuitive while maintaining the performance
      you've come to expect from DuckDB.
    char_start: 0
    char_end: 113
- statement: Jared built a complete Spotify analytics solution for Coldplay's music
    catalog in under 15 minutes using Claude Code, dlt, DuckDB, and Visivo.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - jared
  - built
  - complete
  - spotify
  - analytics
  - solution
  - coldplay
  - music
  - catalog
  - '15'
  - minutes
  - using
  - claude
  - code
  - dlt
  - duckdb
  - visivo
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: Jared built a complete Spotify analytics solution for Coldplay's music
      catalog in under 15 minutes using Claude Code, dlt, DuckDB, and Visivo.
    char_start: 0
    char_end: 142
- statement: Jordan leveraged DuckDB's ODBC extension to simultaneously query both
    source and target databases.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - jordan
  - leveraged
  - duckdb
  - odbc
  - extension
  - simultaneously
  - query
  - both
  - source
  - target
  - databases
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: Jordan leveraged DuckDB's ODBC extension to simultaneously query both source
      and target databases for comparison.
    char_start: 0
    char_end: 113
- statement: Jordan Tigani chose DuckDB as the foundation for MotherDuck.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - jordan
  - tigani
  - chose
  - duckdb
  - foundation
  - motherduck
  source:
    doc: motherduck.com/videos/duckdb-run-dbt-build-with-sub-second-execution-times.md
    quote: Jordan Tigani shares why he chose DuckDB as the foundation for MotherDuck.
    char_start: 0
    char_end: 74
- statement: Julien explores the '0$ Data Distribution' using Apache Iceberg and DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - julien
  - explores
  - data
  - distribution
  - using
  - apache
  - iceberg
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: In this article, Julien explores the '0$ Data Distribution' using Apache
      Iceberg and DuckDB...
    char_start: 0
    char_end: 94
- statement: Junaid replaced Spark with DuckDB, achieving a ~2.3x performance improvement.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - junaid
  - replaced
  - spark
  - duckdb
  - achieving
  - '2.3'
  - performance
  - improvement
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Junaid at Atlan built DuckDB pipelines with ArgoCD and replaced Spark with
      a ~2.3x performance improvement.
    char_start: 0
    char_end: 107
- statement: Knowing a few advanced techniques can save you from writing custom preprocessing
    scripts.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - knowing
  - advanced
  - techniques
  - save
  - writing
  - custom
  - preprocessing
  - scripts
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: knowing a few advanced techniques can save you from writing custom preprocessing
      scripts when things get messy.
    char_start: 0
    char_end: 111
- statement: knowledge graph embeddings are stored in DuckDB’s columnar format.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - knowledge
  - graph
  - embeddings
  - stored
  - duckdb
  - columnar
  - format
  source:
    doc: motherduck.com/blog/announcing-duckdb-snippet-sets-with-motherduck-sharing-databases.md
    quote: This integration means knowledge graph embeddings are stored in DuckDB’s
      columnar format.
    char_start: 0
    char_end: 89
- statement: Large language models are particularly well-suited for BI as code frameworks.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - large
  - language
  - models
  - particularly
  - well
  - suited
  - bi
  - code
  - frameworks
  source:
    doc: motherduck.com/videos/taming-file-zoos-data-science-with-duckdb-database-files.md
    quote: Large language models are particularly well-suited for BI as code frameworks.
    char_start: 0
    char_end: 77
- statement: Learn how to set up a Data Warehouse from scratch with DuckDB and other
    OSS tools.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - learn
  - set
  - up
  - data
  - warehouse
  - scratch
  - duckdb
  - oss
  - tools
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: Learn how to set up a Data Warehouse from scratch with DuckDB and other
      OSS tools.
    char_start: 0
    char_end: 82
- statement: Log-based CDC provides low overhead and high throughput, making it suitable
    for high-volume data environments.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - log
  - based
  - cdc
  - provides
  - low
  - overhead
  - high
  - throughput
  - making
  - suitable
  - volume
  - data
  - environments
  source:
    doc: motherduck.com/case-studies/gardyn.md
    quote: Log-based CDC provides low overhead and high throughput, making it suitable
      for high-volume data environments.
    char_start: 0
    char_end: 110
- statement: Mage integrates with MotherDuck by allowing users to create data pipelines
    that connect to MotherDuck's cloud data warehouse.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - mage
  - integrates
  - motherduck
  - allowing
  - users
  - create
  - data
  - pipelines
  - connect
  - cloud
  - warehouse
  source:
    doc: motherduck.com/ecosystem/llamaindex.md
    quote: Mage integrates with MotherDuck by allowing users to create data pipelines
      that connect to MotherDuck's cloud data warehouse.
    char_start: 0
    char_end: 125
- statement: Marcos is involved in the DuckDB community.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - marcos
  - involved
  - duckdb
  - community
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md
    quote: After getting involved in the DuckDB community.
    char_start: 0
    char_end: 47
- statement: Mark Needham has a video series explaining data engineering tasks with
    DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - mark
  - needham
  - video
  - series
  - explaining
  - data
  - engineering
  - tasks
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-two.md
    quote: Mark Needham does incredible work explaining in just 5 minutes how to do
      some common data engineering tasks with DuckDB.
    char_start: 0
    char_end: 120
- statement: Mark Needham, Michael Hunger, and Michael Simons contributed to the DuckDB
    in Action book.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - mark
  - needham
  - michael
  - hunger
  - simons
  - contributed
  - duckdb
  - action
  - book
  source:
    doc: motherduck.com/blog/duckdb-dbt-e2e-data-engineering-project-part-2.md
    quote: Well, I just spoiled the answer above—they all contributed to the DuckDB
      in Action book!
    char_start: 0
    char_end: 88
- statement: Materializing JSON data into a table speeds up analytics queries.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - materializing
  - json
  - data
  - table
  - speeds
  - up
  - analytics
  - queries
  source:
    doc: motherduck.com/blog/flight-sql-vs-rest-vs-jdbc.md
    quote: This works, but is still quite slow (`29.7s`) as we need to download the
      larger Bluesky data over the network.
    char_start: 0
    char_end: 110
- statement: Matt defaults to DuckDB for pipelines and only switches to Spark when
    datasets exceed ~20 GB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - matt
  - defaults
  - duckdb
  - pipelines
  - switches
  - spark
  - datasets
  - exceed
  - '20'
  - gb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: Matt says he defaults to DuckDB for pipelines and only switches to Spark
      when datasets exceed ~20 GB.
    char_start: 0
    char_end: 101
- statement: Matt shows how to generate test data of 12GB, written in about 12 seconds
    using DuckDB and SQL.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - matt
  - shows
  - generate
  - test
  - data
  - 12gb
  - written
  - about
  - '12'
  - seconds
  - using
  - duckdb
  - sql
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: Matt shows how to generate test data of 12GB, written in about 12 seconds
      using DuckDB and SQL.
    char_start: 0
    char_end: 95
- statement: Mehdi tackles an end-to-end data engineering project using DuckDB and
    Python.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - mehdi
  - tackles
  - end
  - data
  - engineering
  - project
  - using
  - duckdb
  - python
  source:
    doc: motherduck.com/learn-more/self-service-analytics-startups.md
    quote: 'Mehdi tackles an end-to-end data engineering project : getting usage insights
      from a python library using Python, SQL and DuckDB!'
    char_start: 0
    char_end: 129
- statement: Mehdi will discuss data visualization with DuckDB/MotherDuck.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - mehdi
  - discuss
  - data
  - visualization
  - duckdb
  - motherduck
  source:
    doc: motherduck.com/videos.md
    quote: Mehdi will discuss data visualization with DuckDB/MotherDuck.
    char_start: 0
    char_end: 61
- statement: Meltano is an open-source data integration platform designed for data
    teams to manage their ELT pipelines.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - meltano
  - open
  - source
  - data
  - integration
  - platform
  - designed
  - teams
  - manage
  - elt
  - pipelines
  source:
    doc: motherduck.com/ecosystem/streamkap.md
    quote: Meltano is an open-source data integration platform designed for data teams
      to manage their ELT pipelines with ease.
    char_start: 0
    char_end: 116
- statement: Memory management is critical for a high-performance analytics engine.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - memory
  - management
  - critical
  - high
  - performance
  - analytics
  - engine
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md
    quote: it is a critical component for a high-performance analytics engine.
    char_start: 0
    char_end: 67
- statement: Memory management is important for DuckDB's performance.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - memory
  - management
  - important
  - duckdb
  - performance
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: Memory management might seem boring in the sense that if it works, it 'just
      works.'
    char_start: 0
    char_end: 83
- statement: Migrating a Spark pipeline to dbt-duckdb can run in under a second.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - migrating
  - spark
  - pipeline
  - dbt
  - duckdb
  - run
  - second
  source:
    doc: motherduck.com/videos/duckdb-run-dbt-build-with-sub-second-execution-times.md
    quote: Here’s how we can replace it with a simple, elegant `dbt-duckdb` project
      that runs in under a second.
    char_start: 0
    char_end: 101
- statement: Mimoune built a Poor Man's Lakehouse in Azure using DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - mimoune
  - built
  - poor
  - man
  - lakehouse
  - azure
  - using
  - duckdb
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: Mimoune built one by implementing a Poor Man's Lakehouse in Azure using
      DuckDB as the preparation stage.
    char_start: 0
    char_end: 104
- statement: Minimal configuration enables robust reading of non-standard CSVs.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - minimal
  - configuration
  - enables
  - robust
  - reading
  - non
  - standard
  - csvs
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: The article notes that minimal configuration, such as read_csv('file_path',
      null_padding = true, strict_mode = false, ignore_errors = true), enables robust
      reading of non-standard CSVs.
    char_start: 0
    char_end: 185
- statement: Modal's serverless infrastructure can efficiently download 50K+ files
    of GitHub event data.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - modal
  - serverless
  - infrastructure
  - efficiently
  - download
  - 50k
  - files
  - github
  - event
  - data
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: Modal is a serverless cloud engine for Python that provides highly concurrent
      infrastructure to efficiently download 50K+ files of GitHub event data from
      GitHub Archive.
    char_start: 0
    char_end: 169
- statement: Mode switched its engine to DuckDB to boost visual data exploration speed.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - mode
  - switched
  - engine
  - duckdb
  - boost
  - visual
  - data
  - exploration
  - speed
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: Mode switched its engine to DuckDB to boost visual data exploration speed.
    char_start: 0
    char_end: 74
- statement: Modern SQL features supported by DuckDB provide powerful tools for data
    aggregation and analysis.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - modern
  - sql
  - features
  - supported
  - duckdb
  - provide
  - powerful
  - tools
  - data
  - aggregation
  - analysis
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: Modern SQL features supported by DuckDB, such as CTEs, window functions,
      and list aggregations, provide powerful tools for data aggregation and analysis.
    char_start: 0
    char_end: 153
- statement: More than 96% of queries were under 200 ms.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - '96'
  - queries
  - '200'
  - ms
  source:
    doc: motherduck.com/blog/introducing-instant-sql.md
    quote: With DuckDB 1.4, more than 96% of queries were under 200 ms.
    char_start: 0
    char_end: 60
- statement: Most users don't have giant data sets but appreciate the high performance.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - users
  - don
  - giant
  - data
  - sets
  - appreciate
  - high
  - performance
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Most users don't have giant data sets but appreciate the high performance.
    char_start: 0
    char_end: 74
- statement: MotherDuck and Estuary are hosting a live webinar on building a real-time
    Change Data Capture (CDC) pipeline.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - motherduck
  - estuary
  - hosting
  - live
  - webinar
  - building
  - real
  - time
  - change
  - data
  - capture
  - cdc
  - pipeline
  source:
    doc: motherduck.com/blog/small-data-sf-recap-2025.md
    quote: Join MotherDuck and Estuary for a live webinar where we’ll show you how
      to build a real-time Change Data Capture (CDC) pipeline.
    char_start: 0
    char_end: 128
- statement: MotherDuck is organizing a DuckDB user meetup in Berlin.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - motherduck
  - organizing
  - duckdb
  - user
  - meetup
  - berlin
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-six.md
    quote: MotherDuck is happy to announce the second MotherDuck/DuckDB meetup in
      Berlin!
    char_start: 0
    char_end: 78
- statement: MotherDuck is the organization behind the pg_duckdb extension.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - motherduck
  - organization
  - behind
  - pg
  - duckdb
  - extension
  source:
    doc: motherduck.com/blog/just-enough-sql-for-ai.md
    quote: MotherDuck is the organization behind the pg_duckdb extension.
    char_start: 0
    char_end: 62
- statement: MotherDuck supports workflows involving large language models.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - motherduck
  - supports
  - workflows
  - involving
  - large
  - language
  - models
  source:
    doc: motherduck.com/videos/cultivating-growth-how-gardyn-scaled-its-data-operations-with-motherduck.md
    quote: MotherDuck supports workflows involving large language models.
    char_start: 0
    char_end: 62
- statement: Moving data processing from Python to DuckDB and Arrow in their backend
    service enabled lazy loading and more efficient data handling.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - moving
  - data
  - processing
  - python
  - duckdb
  - arrow
  - backend
  - service
  - enabled
  - lazy
  - loading
  - efficient
  - handling
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: Moving data processing from Python to DuckDB and Arrow in their backend
      service enabled lazy loading and more efficient data handling.
    char_start: 0
    char_end: 134
- statement: New Newsletter 'Learning DuckDB by example' highlights recent developments
    and practical SQL tips.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - new
  - newsletter
  - learning
  - duckdb
  - example
  - highlights
  - recent
  - developments
  - practical
  - sql
  - tips
  source:
    doc: motherduck.com/blog/small-data-sf-recap-2025.md
    quote: New Newsletter 'Learning DuckDB by example' highlights recent developments
      and practical SQL tips.
    char_start: 0
    char_end: 98
- statement: New SQL syntax, faster sorting, Iceberg interoperability, and more.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - new
  - sql
  - syntax
  - faster
  - sorting
  - iceberg
  - interoperability
  source:
    doc: motherduck.com/blog/data-engineers-answer-10-top-reddit-questions.md
    quote: with new SQL syntax, faster sorting, Iceberg interoperability, and more.
    char_start: 0
    char_end: 72
- statement: Nico's Wizard extension for DuckDB enables natural language queries and
    direct JavaScript execution within SQL.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - nico
  - wizard
  - extension
  - duckdb
  - enables
  - natural
  - language
  - queries
  - direct
  - javascript
  - execution
  - within
  - sql
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Nico's Wizard extension for DuckDB enables natural language queries and
      direct JavaScript execution within SQL via an embedded V8 interpreter.
    char_start: 0
    char_end: 142
- statement: Normalizing high-cardinality JSON fields in DuckDB can substantially
    improve query performance.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - normalizing
  - high
  - cardinality
  - json
  - fields
  - duckdb
  - substantially
  - improve
  - query
  - performance
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: 'A practical takeaway: This is a good example of how normalizing high-cardinality
      JSON fields in DuckDB can substantially improve query performance.'
    char_start: 0
    char_end: 147
- statement: Not using the Result Cache leaves money on the table.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - using
  - result
  - cache
  - leaves
  - money
  - table
  source:
    doc: motherduck.com/videos/sql-ide-safari-harlequin-in-your-terminal.md
    quote: Not using it leaves money on the table.
    char_start: 0
    char_end: 39
- statement: Okta reduced data processing costs from approximately $2,000 per day
    on Snowflake to a much smaller amount using the DuckDB-based solution.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - okta
  - reduced
  - data
  - processing
  - costs
  - approximately
  - '000'
  - per
  - day
  - snowflake
  - much
  - smaller
  - amount
  - using
  - duckdb
  - based
  - solution
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: 'The financial impact was dramatic: they reduced data processing costs
      from approximately $2,000 per day on Snowflake to a much smaller amount using
      the DuckDB-based solution.'
    char_start: 0
    char_end: 174
- statement: On average, remote workers seem to be happier than in-person workers.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - average
  - remote
  - workers
  - seem
  - happier
  - person
  source:
    doc: motherduck.com/blog/csv-files-persist-duckdb-solution.md
    quote: on average, they seem to be happier too!
    char_start: 0
    char_end: 40
- statement: Once a checkpoint completes, DuckDB can load a database from just the
    current database file without having to access the WAL.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - checkpoint
  - completes
  - duckdb
  - load
  - database
  - current
  - file
  - without
  - having
  - access
  - wal
  source:
    doc: motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw.md
    quote: This means that once a checkpoint completes, DuckDB can load a database
      from just the current database file without having to access the WAL to perform
      WAL replay.
    char_start: 0
    char_end: 163
- statement: Organizations can save 95% on log processing costs by using Bacalhau
    and DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - organizations
  - save
  - '95'
  - log
  - processing
  - costs
  - using
  - bacalhau
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-four.md
    quote: Many organizations spend a ton of time and money centralizing data in a
      data warehouse, only to discard most of it via an ETL process.
    char_start: 0
    char_end: 134
- statement: Organizations of all sizes are interested in the 'Quack Stack'.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - organizations
  - sizes
  - interested
  - quack
  - stack
  source:
    doc: motherduck.com/blog/duckdb-tutorial-for-beginners.md
    quote: the 'Quack Stack' is thriving and organizations of all sizes are more and
      more interested in it.
    char_start: 0
    char_end: 96
- statement: Paradime integrates seamlessly with various data warehouses and tools.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - paradime
  - integrates
  - seamlessly
  - various
  - data
  - warehouses
  - tools
  source:
    doc: motherduck.com/glossary/dataset.md
    quote: Paradime integrates seamlessly with various data warehouses and tools.
    char_start: 0
    char_end: 70
- statement: Paradime offers a dbt development environment that pairs with DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - paradime
  - offers
  - dbt
  - development
  - environment
  - pairs
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eight.md
    quote: Paradime offers a dbt development environment, which pairs perfectly with
      DuckDB.
    char_start: 0
    char_end: 81
- statement: Pedro and Sam teased the audience about the power of DuckDB Extensions.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - pedro
  - sam
  - teased
  - audience
  - about
  - power
  - duckdb
  - extensions
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2024.md
    quote: In their talk, Pedro and Sam teased the audience about the power of DuckDB
      Extensions.
    char_start: 0
    char_end: 86
- statement: Performance improvements are variable based on project complexity, but
    we’ve seen 5-10x speedups in execution times for specific project types.
  type: performance
  entity: DuckDB
  keywords:
  - performance
  - improvements
  - variable
  - based
  - project
  - complexity
  - ve
  - seen
  - 10x
  - speedups
  - execution
  - times
  - specific
  - types
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: Performance improvements are variable based on project complexity, but
      we’ve seen 5-10x speedups in execution times for specific project types.
    char_start: 0
    char_end: 143
- statement: Performance improvements include complete rewrite of the sorting implementation
    using k-way merge sort.
  type: performance
  entity: DuckDB
  keywords:
  - performance
  - improvements
  - include
  - complete
  - rewrite
  - sorting
  - implementation
  - using
  - way
  - merge
  - sort
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: Performance improvements include complete rewrite of the sorting implementation
      using k-way merge sort with better thread scaling.
    char_start: 0
    char_end: 130
- statement: pg_duckdb 1.0 released.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - pg
  - duckdb
  - '1.0'
  - released
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: pg_duckdb 1.0
    char_start: 0
    char_end: 13
- statement: pg_duckdb allows you to push your analytical workload to the Cloud.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - pg
  - duckdb
  - allows
  - push
  - analytical
  - workload
  - cloud
  source:
    doc: motherduck.com/blog/pgduckdb-beta-release-duckdb-postgres.md
    quote: With pg_duckdb, you can leverage MotherDuck to push your analytical workload
      to the Cloud again without leaving PostgreSQL.
    char_start: 0
    char_end: 123
- statement: pg_duckdb embeds DuckDB directly inside Postgres.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - pg
  - duckdb
  - embeds
  - directly
  - inside
  - postgres
  source:
    doc: motherduck.com/blog/why-web-developers-should-care-about-analytical-databases.md
    quote: This is a new Postgres extension that embeds DuckDB directly inside Postgres.
    char_start: 0
    char_end: 77
- statement: pg_duckdb enables in-database ETL capabilities.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - pg
  - duckdb
  - enables
  - database
  - etl
  - capabilities
  source:
    doc: motherduck.com/blog/perf-is-not-enough.md
    quote: The result is 'in-database ETL'–you can now handle data transformations
      that traditionally required external tools directly within SQL queries.
    char_start: 0
    char_end: 143
- statement: pg_duckdb extension delivers impressive performance gains.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - pg
  - duckdb
  - extension
  - delivers
  - impressive
  - performance
  - gains
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: the pg_duckdb extension embeds DuckDB directly within PostgreSQL, delivering
      impressive performance gains...
    char_start: 0
    char_end: 108
- statement: Pg_duckdb integrates with cognee for SQL analytics.
  type: feature
  entity: DuckDB
  keywords:
  - feature
  - pg
  - duckdb
  - integrates
  - cognee
  - sql
  - analytics
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2024.md
    quote: SQL analytics and graph-native retrieval together.
    char_start: 0
    char_end: 50
- statement: pg_duckdb offers PostgreSQL users a path for speedy analytical queries.
  type: feature
  entity: DuckDB
  keywords:
  - feature
  - pg
  - duckdb
  - offers
  - postgresql
  - users
  - path
  - speedy
  - analytical
  - queries
  source:
    doc: motherduck.com/blog/read-scaling-preview.md
    quote: pg_duckdb offers PostgreSQL users a path for speedy analytical queries.
    char_start: 0
    char_end: 71
- statement: Ponder uses DuckDB as a backend for both pandas and Numpy operations.
  type: integration
  entity: DuckDB
  keywords:
  - integration
  - ponder
  - uses
  - duckdb
  - backend
  - both
  - pandas
  - numpy
  - operations
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: Ponder now transparently uses DuckDB as a backend for both pandas and Numpy
      operations, making them significantly faster.
    char_start: 0
    char_end: 121
- statement: Popular options for storage solutions include Amazon S3, Google Cloud
    Storage, and Azure Blob Storage.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - popular
  - options
  - storage
  - solutions
  - include
  - amazon
  - s3
  - google
  - cloud
  - azure
  - blob
  source:
    doc: motherduck.com/ecosystem/cloudquery.md
    quote: Popular options include Amazon S3, Google Cloud Storage, or Azure Blob
      Storage.
    char_start: 0
    char_end: 79
- statement: Processing data where it is created reduces the amount of data that needs
    to be transferred.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - processing
  - data
  - created
  - reduces
  - amount
  - needs
  - transferred
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-four.md
    quote: Wouldn't it be easier to process data where it was created?
    char_start: 0
    char_end: 59
- statement: Projects like DuckDB (and MotherDuck) move incredibly fast.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - projects
  - like
  - duckdb
  - motherduck
  - move
  - incredibly
  - fast
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-two.md
    quote: Projects like DuckDB (and MotherDuck) move incredibly fast.
    char_start: 0
    char_end: 59
- statement: PyIceberg could be the solution to integrate DuckDB with Snowflake.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - pyiceberg
  - solution
  - integrate
  - duckdb
  - snowflake
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2024.md
    quote: PyIceberg could be the solution you've been looking for to integrate DuckDB
      with Snowflake.
    char_start: 0
    char_end: 91
- statement: Python is used for generating fake data for DuckDB.
  type: integration
  entity: DuckDB
  keywords:
  - integration
  - python
  - used
  - generating
  - fake
  - data
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: Ryan develops a simple way how to generate fake data with Python and DuckDB.
    char_start: 0
    char_end: 76
- statement: Queries have taken less time to run.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - queries
  - taken
  - less
  - time
  - run
  source:
    doc: motherduck.com/blog/introducing-instant-sql.md
    quote: in the last few weeks, their queries have taken less time to run.
    char_start: 0
    char_end: 65
- statement: Queries that time out within the 10 minute window on PostgreSQL alone
    now complete in less than 10 seconds with pg_duckdb!
  type: performance
  entity: DuckDB
  keywords:
  - performance
  - queries
  - time
  - out
  - within
  - '10'
  - minute
  - window
  - postgresql
  - alone
  - now
  - complete
  - less
  - seconds
  - pg
  - duckdb
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: Queries that time out within the 10 minute window on PostgreSQL alone now
      complete in less than 10 seconds with pg_duckdb!
    char_start: 0
    char_end: 122
- statement: Reflex processes large volumes of transactions daily.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - reflex
  - processes
  - large
  - volumes
  - transactions
  - daily
  source:
    doc: motherduck.com/duckdb-book-summary-chapter4.md
    quote: Today, Reflex processes large volumes of transactions daily across their
      marketplace.
    char_start: 0
    char_end: 85
- statement: Remote and hybrid workers make up the majority of survey responses.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - remote
  - hybrid
  - workers
  - make
  - up
  - majority
  - survey
  - responses
  source:
    doc: motherduck.com/blog/csv-files-persist-duckdb-solution.md
    quote: 'Two interesting takeaways: remote and hybrid workers make up the majority
      of survey responses.'
    char_start: 0
    char_end: 94
- statement: Rill Data relies on DuckDB to build its product.
  type: integration
  entity: DuckDB
  keywords:
  - integration
  - rill
  - data
  - relies
  - duckdb
  - build
  - product
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: Michael Driscoll (CEO of Rill Data) explains why they rely on DuckDB to
      build Rill’s product in his own words.
    char_start: 0
    char_end: 110
- statement: Rill offers a cloud service for deployment.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - rill
  - offers
  - cloud
  - service
  - deployment
  source:
    doc: motherduck.com/ecosystem/bytewax.md
    quote: Deployment is done through Rill’s Cloud offering.
    char_start: 0
    char_end: 49
- statement: Rill provides a Command Line Interface (CLI) for installation.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - rill
  - provides
  - command
  - line
  - interface
  - cli
  - installation
  source:
    doc: motherduck.com/ecosystem/bytewax.md
    quote: Rill provides a Command Line Interface (CLI), essentially a binary (written
      in Golang) for installation.
    char_start: 0
    char_end: 104
- statement: Running DuckDB directly on your production PostgreSQL primary instance
    can affect performance.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - running
  - duckdb
  - directly
  - production
  - postgresql
  - primary
  - instance
  - affect
  - performance
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: Running this directly on your production PostgreSQL primary instance is
      like trying to fit a grand piano into a tiny studio apartment.
    char_start: 0
    char_end: 134
- statement: Running DuckDB in the browser reduces server-side cost.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - running
  - duckdb
  - browser
  - reduces
  - server
  - side
  - cost
  source:
    doc: motherduck.com/blog/data-warehouse-feature-roundup-nov-2024.md
    quote: It's a better experience for the user as things run on the client, and
      it reduces server-side cost 💸.
    char_start: 0
    char_end: 101
- statement: Running iterative SQL tests '100 times a day' locally saves substantial
    money compared to constantly spinning up cloud clusters for each iteration.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - running
  - iterative
  - sql
  - tests
  - '100'
  - times
  - day
  - locally
  - saves
  - substantial
  - money
  - compared
  - constantly
  - spinning
  - up
  - cloud
  - clusters
  - iteration
  source:
    doc: motherduck.com/videos/duckdb-motherduck-for-beginners-your-ultimate-guide.md
    quote: Running iterative SQL tests '100 times a day' locally saves substantial
      money compared to constantly spinning up cloud clusters for each iteration.
    char_start: 0
    char_end: 147
- statement: Running unverified, AI-generated code directly on your live database
    is risky.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - running
  - unverified
  - ai
  - generated
  - code
  - directly
  - live
  - database
  - risky
  source:
    doc: motherduck.com/blog/streaming-data-to-motherduck.md
    quote: In the worst-case scenario, you're running unverified, AI-generated code
      directly on your live database.
    char_start: 0
    char_end: 104
- statement: SaaSCo has a high-concurrency BI workload powered by 10 active users.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - saasco
  - high
  - concurrency
  - bi
  - workload
  - powered
  - '10'
  - active
  - users
  source:
    doc: motherduck.com/glossary/pipelines.md
    quote: Let's apply this to a hypothetical 'SaaSCo,' a 100-person company with
      a high-concurrency BI workload powered by 10 active users.
    char_start: 0
    char_end: 129
- statement: Schema changes can cause DuckDB to abort running queries due to out-of-sync
    local catalogs.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - schema
  - changes
  - cause
  - duckdb
  - abort
  - running
  - queries
  - due
  - out
  - sync
  - local
  - catalogs
  source:
    doc: motherduck.com/learn-more/star-schema-data-warehouse-guide.md
    quote: We found that when schema changes occurred, our system would pessimistically
      abort running queries...
    char_start: 0
    char_end: 101
- statement: Semantic layers generate queries on demand, reflecting the latest data.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - semantic
  - layers
  - generate
  - queries
  - demand
  - reflecting
  - latest
  - data
  source:
    doc: motherduck.com/blog/pushing-geo-boundaries-with-motherduck-geobase.md
    quote: Unlike pre-computed aggregation tables that need to be reprocessed when
      source data changes, semantic layers generate queries on demand.
    char_start: 0
    char_end: 136
- statement: Setting options like strict_mode = false allows parsing CSVs with unescaped
    quotes or inconsistent column counts.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - setting
  - options
  - like
  - strict
  - mode
  - 'false'
  - allows
  - parsing
  - csvs
  - unescaped
  - quotes
  - inconsistent
  - column
  - counts
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md
    quote: Setting these options will enable DuckDB to correctly read 99.61% of data
      from the Pollock Benchmark files.
    char_start: 0
    char_end: 107
- statement: Setting these options will enable DuckDB to correctly read 99.61% of
    data from the Pollock Benchmark files.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - setting
  - options
  - enable
  - duckdb
  - correctly
  - read
  - '99.61'
  - data
  - pollock
  - benchmark
  - files
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md
    quote: Setting these options will enable DuckDB to correctly read 99.61% of data
      from the Pollock Benchmark files.
    char_start: 0
    char_end: 107
- statement: Single-node engines like DuckDB can be constrained by the memory and
    I/O of a single machine.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - single
  - node
  - engines
  - like
  - duckdb
  - constrained
  - memory
  - machine
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: When scanning billions of rows, single-node engines like DuckDB can be
      constrained by the memory and I/O of a single machine.
    char_start: 0
    char_end: 125
- statement: Speedwise will probably be much better if you run it locally on your
    machine or on the server.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - speedwise
  - probably
  - much
  - better
  - run
  - locally
  - machine
  - server
  source:
    doc: motherduck.com/blog/getting-started-gis-duckdb.md
    quote: Speedwise will probably be much better if you run it locally on your machine
      or on the server.
    char_start: 0
    char_end: 94
- statement: SQL analytics and graph-native retrieval can be combined to eliminate
    the trade-off between fast analytics and one-off RAG retrievals.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - sql
  - analytics
  - graph
  - native
  - retrieval
  - combined
  - eliminate
  - trade
  - 'off'
  - fast
  - one
  - rag
  - retrievals
  source:
    doc: motherduck.com/blog/announcing-duckdb-141-motherduck.md
    quote: SQL analytics and graph-native retrieval together, eliminating the trade-off
      between fast analytics and one-off RAG retrievals.
    char_start: 0
    char_end: 127
- statement: SQLMesh integrates with MotherDuck by leveraging DuckDB's capabilities.
  type: integration
  entity: DuckDB
  keywords:
  - integration
  - sqlmesh
  - integrates
  - motherduck
  - leveraging
  - duckdb
  - capabilities
  source:
    doc: motherduck.com/ecosystem/dlt.md
    quote: SQLMesh integrates with MotherDuck by leveraging DuckDB's capabilities
      within the MotherDuck cloud data warehouse.
    char_start: 0
    char_end: 114
- statement: Staging small files to local SSD/NVMe before conversion can yield a 2–10×
    wall‑clock improvement versus direct S3 reads.
  type: performance
  entity: DuckDB
  keywords:
  - performance
  - staging
  - small
  - files
  - local
  - ssd
  - nvme
  - conversion
  - yield
  - '10'
  - wall
  - clock
  - improvement
  - versus
  - direct
  - s3
  - reads
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: staging small files to local SSD/NVMe before conversion can yield a 2–10×
      wall‑clock improvement versus direct S3 reads.
    char_start: 0
    char_end: 120
- statement: Statically compiling DuckDB enhances security, reduces startup time,
    and supports offline environments.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - statically
  - compiling
  - duckdb
  - enhances
  - security
  - reduces
  - startup
  - time
  - supports
  - offline
  - environments
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2024.md
    quote: Statically compiling DuckDB enhances security, reduces startup time, and
      supports offline environments by embedding necessary extensions directly into
      the binary.
    char_start: 0
    char_end: 162
- statement: Streamlit can be used to share DuckDB as a web app.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - streamlit
  - used
  - share
  - duckdb
  - web
  - app
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-five.md
    quote: Mike demonstrates remote access to DuckDB using Apache Arrow and Flight
      RPC and sharing it as a web app with Streamlit.
    char_start: 0
    char_end: 119
- statement: Striim helps set up a streaming data pipeline with DuckDB.
  type: integration
  entity: DuckDB
  keywords:
  - integration
  - striim
  - helps
  - set
  - up
  - streaming
  - data
  - pipeline
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: Pedram Navid explains how to set up a streaming Data pipeline with the
      help of Striim and DuckDB.
    char_start: 0
    char_end: 97
- statement: Subscribe to DuckDB Newsletter
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - subscribe
  - duckdb
  - newsletter
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: Subscribe to DuckDB Newsletter
    char_start: 0
    char_end: 30
- statement: Subsequent queries took only 1.03 seconds.
  type: performance
  entity: DuckDB
  keywords:
  - performance
  - subsequent
  - queries
  - took
  - '1.03'
  - seconds
  source:
    doc: motherduck.com/blog/python-faker-duckdb-exploration.md
    quote: subsequent queries (with different values, no caching) took only 1.03 seconds.
    char_start: 0
    char_end: 78
- statement: SUMMARIZE on this massive table completes in around 20 minutes on a MacBook.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - summarize
  - massive
  - table
  - completes
  - around
  - '20'
  - minutes
  - macbook
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: Hannes demonstrated that SUMMARIZE on this massive table completes in around
      20 minutes on a MacBook.
    char_start: 0
    char_end: 101
- statement: Supabase's ETL provides near real-time data synchronization through PostgreSQL's
    logical decoding capabilities.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - supabase
  - etl
  - provides
  - near
  - real
  - time
  - data
  - synchronization
  - postgresql
  - logical
  - decoding
  - capabilities
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: Supabase's ETL provides near real-time data synchronization through PostgreSQL's
      logical decoding capabilities.
    char_start: 0
    char_end: 111
- statement: Tensorlake cracks open the wide world of documents, turning verbose text
    into structured data with 91-98% accuracy.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - tensorlake
  - cracks
  - open
  - wide
  - world
  - documents
  - turning
  - verbose
  - text
  - structured
  - data
  - '91'
  - '98'
  - accuracy
  source:
    doc: motherduck.com/glossary/DuckDB.md
    quote: Tensorlake cracks open the wide world of documents, turning verbose text
      into structured data with 91-98% accuracy.
    char_start: 0
    char_end: 115
- statement: Tensorlake delivers best-in-class accuracy for document processing, achieving
    a 91.7% F1 score.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - tensorlake
  - delivers
  - best
  - class
  - accuracy
  - document
  - processing
  - achieving
  - '91.7'
  - f1
  - score
  source:
    doc: motherduck.com/glossary/DuckDB.md
    quote: Tensorlake delivers best-in-class accuracy for document processing, achieving
      a 91.7% F1 score.
    char_start: 0
    char_end: 95
- statement: The 'DuckDB in Action' book has added four new chapters.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - action
  - book
  - added
  - four
  - new
  - chapters
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md
    quote: The top-rated 'DuckDB in Action' book published by Manning has added four
      new chapters to the MEAP (early access) book.
    char_start: 0
    char_end: 119
- statement: The 1.0 release introduces enhanced MotherDuck integration.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - '1.0'
  - release
  - introduces
  - enhanced
  - motherduck
  - integration
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: The 1.0 release introduces enhanced MotherDuck integration, expanded support
      for various data types, improved stability, and enhanced performance.
    char_start: 0
    char_end: 146
- statement: The AI doesn't just write code; it executes, observes, debugs, and refines
    it.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - ai
  - doesn
  - write
  - code
  - executes
  - observes
  - debugs
  - refines
  source:
    doc: motherduck.com/case-studies/trunkrs-same-day-delivery-motherduck-from-redshift.md
    quote: The AI doesn't just write code; it executes, observes, debugs, and refines
      it.
    char_start: 0
    char_end: 78
- statement: The AI generates a correct query, saves it to a file, and immediately
    runs it using the DuckDB CLI.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - ai
  - generates
  - correct
  - query
  - saves
  - file
  - immediately
  - runs
  - using
  - duckdb
  - cli
  source:
    doc: motherduck.com/blog/vibe-coding-sql-cursor.md
    quote: the AI generates a correct query, saves it to a file, and immediately runs
      it using the DuckDB CLI.
    char_start: 0
    char_end: 99
- statement: The analysis of Netflix viewing trends during the COVID-19 lockdown showcases
    the database's technical prowess.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - analysis
  - netflix
  - viewing
  - trends
  - covid
  - '19'
  - lockdown
  - showcases
  - database
  - technical
  - prowess
  source:
    doc: motherduck.com/learn-more/web-assembly.md
    quote: The analysis of Netflix viewing trends during the COVID-19 lockdown showcases
      the database's technical prowess.
    char_start: 0
    char_end: 111
- statement: The API currently supports reading from csv, parquet, and json formats.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - api
  - currently
  - supports
  - reading
  - csv
  - parquet
  - json
  - formats
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-six.md
    quote: Currently, the API supports reading from **`csv`**, **`parquet`**, and
      **`json`** formats.
    char_start: 0
    char_end: 90
- statement: The architecture facilitates parallel data loading and querying without
    the traditional limitations of DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - architecture
  - facilitates
  - parallel
  - data
  - loading
  - querying
  - without
  - traditional
  - limitations
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md
    quote: Ritchie emphasizes that this architecture facilitates parallel data loading
      and querying without the traditional limitations of DuckDB.
    char_start: 0
    char_end: 135
- statement: The architecture implements an event-driven pipeline where AWS EventBridge
    triggers Lambda functions to fetch news data twice daily.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - architecture
  - implements
  - event
  - driven
  - pipeline
  - aws
  - eventbridge
  - triggers
  - lambda
  - functions
  - fetch
  - news
  - data
  - twice
  - daily
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: The architecture implements an event-driven pipeline where AWS EventBridge
      triggers Lambda functions to fetch news data twice daily.
    char_start: 0
    char_end: 132
- statement: The average query got 19% faster.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - average
  - query
  - got
  - '19'
  - faster
  source:
    doc: motherduck.com/blog/introducing-instant-sql.md
    quote: The average query got 19% faster.
    char_start: 0
    char_end: 33
- statement: The blog post covers the main features of Pandas, Polars, and DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - blog
  - post
  - covers
  - main
  - features
  - pandas
  - polars
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-the-great-federator.md
    quote: we will cover the main features of Pandas, Polars, and DuckDB.
    char_start: 0
    char_end: 62
- statement: The book 'Getting Started with DuckDB' is a practical guide for accelerating
    data workflows.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - book
  - getting
  - started
  - duckdb
  - practical
  - guide
  - accelerating
  - data
  - workflows
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eleven.md
    quote: This is a practical guide for accelerating your data science, data analytics,
      and data engineering workflows with DuckDB.
    char_start: 0
    char_end: 121
- statement: The book can be downloaded for free.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - book
  - downloaded
  - free
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: You can download the book for free, courtesy of MotherDuck.
    char_start: 0
    char_end: 59
- statement: The book DuckDB in Action is officially out.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - book
  - duckdb
  - action
  - officially
  - out
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md
    quote: Finally, the book DuckDB in Action is officially out 🎉.
    char_start: 0
    char_end: 55
- statement: The change to materialize CTEs is part of the performance improvements.
  type: performance
  entity: DuckDB
  keywords:
  - change
  - materialize
  - ctes
  - part
  - performance
  - improvements
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: and the change to materialize CTEs.
    char_start: 0
    char_end: 35
- statement: The CLI efficiently handles SQL statements, executing them upon encountering
    a semicolon and a newline.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - cli
  - efficiently
  - handles
  - sql
  - statements
  - executing
  - them
  - upon
  - encountering
  - semicolon
  - newline
  source:
    doc: motherduck.com/learn-more/data-warehouse-tco.md
    quote: The CLI efficiently handles SQL statements, executing them upon encountering
      a semicolon and a newline.
    char_start: 0
    char_end: 103
- statement: The data size is reduced from 1.4GB (unzipped CSV) to 118MB (compressed
    Parquet).
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - data
  - size
  - reduced
  - '1.4'
  - gb
  - unzipped
  - csv
  - 118mb
  - compressed
  - parquet
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: He also demonstrates exporting the data to Parquet format using the `EXPORT
      DATABASE` command, reducing the data size from 1.4GB (unzipped CSV) to 118MB
      (compressed Parquet).
    char_start: 0
    char_end: 174
- statement: The data types provided by DuckDB are very comprehensive.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - data
  - types
  - provided
  - duckdb
  - comprehensive
  source:
    doc: motherduck.com/blog/solving-advent-code-duckdb-dbt.md
    quote: The data types provided by DuckDB are very comprehensive.
    char_start: 0
    char_end: 57
- statement: The DNS extension integrates powerful DNS lookup and reverse DNS capabilities
    into DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - dns
  - extension
  - integrates
  - powerful
  - lookup
  - reverse
  - capabilities
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: The DNS extension, a pure Rust implementation, integrates powerful DNS
      lookup and reverse DNS capabilities into DuckDB.
    char_start: 0
    char_end: 119
- statement: The driver supports using DuckDB in-memory, which can help process data
    without persisting.
  type: feature
  entity: DuckDB
  keywords:
  - feature
  - driver
  - supports
  - using
  - duckdb
  - memory
  - which
  - help
  - process
  - data
  - without
  - persisting
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md
    quote: The driver also supports using DuckDB in-memory, which can help process
      data without persisting.
    char_start: 0
    char_end: 96
- statement: The Dual Execution query planner minimizes network latency and data transfer
    costs.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - dual
  - execution
  - query
  - planner
  - minimizes
  - network
  - latency
  - data
  - transfer
  - costs
  source:
    doc: motherduck.com/sql-duckdb-book-form.md
    quote: Instead of forcing you to move all your data to the cloud, it intelligently
      pushes the computation to where the data lives, minimizing network latency and
      data transfer costs.
    char_start: 0
    char_end: 175
- statement: The dual execution setup can lead to a 5X increase in dbt run speeds.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - dual
  - execution
  - setup
  - lead
  - 5x
  - increase
  - dbt
  - run
  - speeds
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: with an approximate 5X increase in dbt run speeds by minimizing local data
      size and optimizing compute resources.
    char_start: 0
    char_end: 113
- statement: The DuckDB CLI gets a fresh upgrade with syntax highlighting and thousands-separator
    support.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - cli
  - gets
  - fresh
  - upgrade
  - syntax
  - highlighting
  - thousands
  - separator
  - support
  source:
    doc: motherduck.com/blog/announcing-motherduck-general-availability-data-warehousing-with-duckdb.md
    quote: Plus, the DuckDB CLI gets a fresh upgrade with syntax highlighting and
      thousands-separator support for better readability.
    char_start: 0
    char_end: 122
- statement: The DuckDB Postgres Extension offers the most straightforward approach.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - postgres
  - extension
  - offers
  - straightforward
  - approach
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: The DuckDB Postgres Extension offers the most straightforward approach,
      requiring minimal setup...
    char_start: 0
    char_end: 98
- statement: The duckdb-docker repository provides a small Docker image that exposes
    the DuckDB CLI.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - duckdb
  - docker
  - repository
  - provides
  - small
  - image
  - exposes
  - cli
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: The duckdb-docker repository provides a small Docker image that exposes
      the DuckDB CLI for interactive and non‑interactive use.
    char_start: 0
    char_end: 127
- statement: The DuckLake approach, powered by MotherDuck, represents the next step
    in simplifying the query and compute layer.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - ducklake
  - approach
  - powered
  - motherduck
  - represents
  - next
  - step
  - simplifying
  - query
  - compute
  - layer
  source:
    doc: motherduck.com/glossary/DuckDB CLI.md
    quote: The DuckLake approach, powered by MotherDuck, represents this next step.
    char_start: 0
    char_end: 72
- statement: The easiest way to get started is to use the Docker image provided.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - easiest
  - way
  - get
  - started
  - use
  - docker
  - image
  - provided
  source:
    doc: motherduck.com/blog/just-enough-sql-for-ai.md
    quote: The easiest way to get started is to use the Docker image provided.
    char_start: 0
    char_end: 67
- statement: The entire pipeline now completes in less than half a second on my laptop.
  type: performance
  entity: DuckDB
  keywords:
  - performance
  - entire
  - pipeline
  - now
  - completes
  - less
  - half
  - second
  - my
  - laptop
  source:
    doc: motherduck.com/learn-more/what-is-OLAP.md
    quote: The entire pipeline, which used to take ages and cost a fortune on Spark,
      now completes in less than half a second on my laptop.
    char_start: 0
    char_end: 128
- statement: The estimated monthly bill for compute and storage for SaaSCo is $2,000.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - estimated
  - monthly
  - bill
  - compute
  - storage
  - saasco
  - '000'
  source:
    doc: motherduck.com/glossary/pipelines.md
    quote: Their estimated monthly bill for compute and storage is **$2,000**.
    char_start: 0
    char_end: 67
- statement: The execute() method returns a cursor-like object.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - execute
  - method
  - returns
  - cursor
  - like
  - object
  source:
    doc: motherduck.com/blog/streaming-oracle-to-motherduck.md
    quote: It immediately executes the query and returns a cursor-like object...
    char_start: 0
    char_end: 69
- statement: The EXPLAIN clause shows how DuckDB plans to execute your SQL query.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - explain
  - clause
  - shows
  - duckdb
  - plans
  - execute
  - sql
  - query
  source:
    doc: motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md
    quote: The `EXPLAIN` clause is a powerful diagnostic tool that shows how DuckDB
      plans to execute your SQL query.
    char_start: 0
    char_end: 105
- statement: The extension also supports Iceberg's schema evolution.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - extension
  - also
  - supports
  - iceberg
  - schema
  - evolution
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: The extension also supports Iceberg's schema evolution.
    char_start: 0
    char_end: 55
- statement: The extension equips DuckDB with a two-way radio, enabling event-driven
    workflows directly within SQL.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - extension
  - equips
  - duckdb
  - two
  - way
  - radio
  - enabling
  - event
  - driven
  - workflows
  - directly
  - within
  - sql
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: This extension equips DuckDB with a two-way radio, enabling event-driven
      workflows directly within SQL.
    char_start: 0
    char_end: 103
- statement: The extension supports Auth, Read, and Write to Google Sheets.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - extension
  - supports
  - auth
  - read
  - write
  - google
  - sheets
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: It supports Auth, Read, and Write to Google Sheets.
    char_start: 0
    char_end: 51
- statement: The extension system democratizes contribution to DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - extension
  - system
  - democratizes
  - contribution
  - duckdb
  source:
    doc: motherduck.com/learn-more/partitioned-writes-parquet-ducklake.md
    quote: The extension system democratizes contribution to DuckDB, allowing developers
      to add functionality without the overhead of core development requirements.
    char_start: 0
    char_end: 153
- statement: The extensions went from January this year with 2 million to 17 million
    per month.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - extensions
  - went
  - january
  - year
  - million
  - '17'
  - per
  - month
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: The extensions went from January this year with 2 million to 17 million
      per month.
    char_start: 0
    char_end: 82
- statement: The first full table scan query took 10.82 seconds.
  type: performance
  entity: DuckDB
  keywords:
  - performance
  - first
  - full
  - table
  - scan
  - query
  - took
  - '10.82'
  - seconds
  source:
    doc: motherduck.com/blog/python-faker-duckdb-exploration.md
    quote: My first full table scan query took 10.82 seconds.
    char_start: 0
    char_end: 50
- statement: The free course introduces data engineers and analysts to building versatile
    data workflows using DuckDB for local processing and MotherDuck for scalable cloud
    analytics.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - free
  - course
  - introduces
  - data
  - engineers
  - analysts
  - building
  - versatile
  - workflows
  - using
  - duckdb
  - local
  - processing
  - motherduck
  - scalable
  - cloud
  - analytics
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md
    quote: The free course introduces data engineers and analysts to building versatile
      data workflows using DuckDB for local processing and MotherDuck for scalable
      cloud analytics.
    char_start: 0
    char_end: 170
- statement: The full movie, at 720x392 resolution, resulted in a table of 47 billion
    rows, stored in approximately 200 GB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - full
  - movie
  - 720x392
  - resolution
  - resulted
  - table
  - '47'
  - billion
  - rows
  - stored
  - approximately
  - '200'
  - gb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md
    quote: The full movie, at 720x392 resolution, resulted in a table of 47 billion
      rows, stored in approximately 200 GB.
    char_start: 0
    char_end: 110
- statement: The gsheets extension makes exporting data to Google Sheets straightforward.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - gsheets
  - extension
  - makes
  - exporting
  - data
  - google
  - sheets
  - straightforward
  source:
    doc: motherduck.com/videos/using-sql-in-your-data-lake-with-duckdb-iceberg-dbt-and-motherduck.md
    quote: 'The gsheets extension makes this remarkably straightforward:'
    char_start: 0
    char_end: 60
- statement: The HTTP DuckDB Community Extension allows making HTTP requests directly
    from within DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - http
  - duckdb
  - community
  - extension
  - allows
  - making
  - requests
  - directly
  - within
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: With it, you can make HTTP requests directly from within DuckDB.
    char_start: 0
    char_end: 64
- statement: The HTTP Server Extension transforms DuckDB into an HTTP OLAP API server.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - http
  - server
  - extension
  - transforms
  - duckdb
  - olap
  - api
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: Quackscience also released another extension, the HTTP Server Extension,
      which transforms any DuckDB instance into an HTTP OLAP API server.
    char_start: 0
    char_end: 139
- statement: The integration creates a synergy of semantic knowledge analytics and
    cognee’s retrieval capabilities.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - integration
  - creates
  - synergy
  - semantic
  - knowledge
  - analytics
  - cognee
  - retrieval
  - capabilities
  source:
    doc: motherduck.com/blog/announcing-duckdb-snippet-sets-with-motherduck-sharing-databases.md
    quote: the DuckDB vector store integration creates a synergy of semantic knowledge
      analytics and cognee’s retrieval capabilities.
    char_start: 0
    char_end: 122
- statement: The integration facilitates efficient data transformations and analytics.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - integration
  - facilitates
  - efficient
  - data
  - transformations
  - analytics
  source:
    doc: motherduck.com/glossary/dataset.md
    quote: This integration facilitates efficient data transformations and analytics.
    char_start: 0
    char_end: 74
- statement: The integration leverages DuckDB's PostgreSQL extension to create virtual
    tables on top of PostgreSQL tables.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - integration
  - leverages
  - duckdb
  - postgresql
  - extension
  - create
  - virtual
  - tables
  - top
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: The integration leverages DuckDB's PostgreSQL extension to create virtual
      tables on top of PostgreSQL tables.
    char_start: 0
    char_end: 109
- statement: The integration of DuckDB WebAssembly propels Evidence into the forefront
    of responsive and interactive user experiences.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - integration
  - duckdb
  - webassembly
  - propels
  - evidence
  - forefront
  - responsive
  - interactive
  - user
  - experiences
  source:
    doc: motherduck.com/quacking-around-the-web.md
    quote: At the heart of its innovation is the integration of DuckDB WebAssembly,
      which propels Evidence into the forefront of responsive and interactive user
      experiences.
    char_start: 0
    char_end: 162
- statement: The integration works in both directions - creating APIs from DuckDB
    macros and accessing FastAPI endpoints as DuckDB tables.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - integration
  - works
  - both
  - directions
  - creating
  - apis
  - duckdb
  - macros
  - accessing
  - fastapi
  - endpoints
  - tables
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-seven.md
    quote: The integration works in both directions - creating APIs from DuckDB macros
      and accessing FastAPI endpoints as DuckDB tables.
    char_start: 0
    char_end: 125
- statement: The JavaScript executes in a sandboxed Deno environment.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - javascript
  - executes
  - sandboxed
  - deno
  - environment
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: The Wizard extension leverages LLMs (OpenAI/Anthropic) to translate natural
      language into JavaScript code that executes in a sandboxed Deno environment,
      returning results as DuckDB tables.
    char_start: 0
    char_end: 188
- statement: The median amount of data scanned by queries is only 100 MB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - median
  - amount
  - data
  - scanned
  - queries
  - '100'
  - mb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md
    quote: the median amount of data scanned by queries is only 100 MB
    char_start: 0
    char_end: 59
- statement: The MERGE INTO statement now supports complex upsert operations.
  type: feature
  entity: DuckDB
  keywords:
  - feature
  - merge
  - statement
  - now
  - supports
  - complex
  - upsert
  - operations
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: The MERGE INTO statement now supports complex upsert operations without
      requiring primary keys.
    char_start: 0
    char_end: 95
- statement: The metabase_duckdb_driver plugin enables Metabase to use DuckDB as a
    data source.
  type: feature
  entity: DuckDB
  keywords:
  - feature
  - metabase
  - duckdb
  - driver
  - plugin
  - enables
  - use
  - data
  - source
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md
    quote: The metabase_duckdb_driver plugin enables Metabase (BI tool) to use DuckDB
      as a data source, allowing direct SQL queries on Parquet files and in-memory
      databases.
    char_start: 0
    char_end: 162
- statement: The modern data warehouse is defined by simplicity, performance where
    you work, and predictable pricing.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - modern
  - data
  - warehouse
  - defined
  - simplicity
  - performance
  - work
  - predictable
  - pricing
  source:
    doc: motherduck.com/videos/unfinished-business-re-inventing-modern-data-tools.md
    quote: The modern data warehouse is defined by simplicity, performance where you
      work, and predictable pricing.
    char_start: 0
    char_end: 104
- statement: The new C API enables developers to create extensions in any language
    that supports FFI.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - new
  - api
  - enables
  - developers
  - create
  - extensions
  - any
  - language
  - supports
  - ffi
  source:
    doc: motherduck.com/learn-more/secure-startup-data-warehouse.md
    quote: The new C API represents a paradigm shift for extension development.
    char_start: 0
    char_end: 68
- statement: The new DuckDB Node client, Neo, provides a powerful and friendly way
    to use DuckDB in Node.js.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - new
  - duckdb
  - node
  - client
  - neo
  - provides
  - powerful
  - friendly
  - way
  - use
  - js
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md
    quote: The new DuckDB Node client, Neo, provides a powerful and friendly way to
      use your favorite database.
    char_start: 0
    char_end: 100
- statement: The new preview feature in the Iceberg extension allows attaching to
    Iceberg REST catalogs using the ATTACH command.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - new
  - preview
  - feature
  - iceberg
  - extension
  - allows
  - attaching
  - rest
  - catalogs
  - using
  - attach
  - command
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: The new preview feature in the Iceberg extension allows attaching to Iceberg
      REST catalogs using the ATTACH command.
    char_start: 0
    char_end: 116
- statement: The new spatial join operator is up to 100x faster than previous implementations.
  type: performance
  entity: DuckDB
  keywords:
  - performance
  - new
  - spatial
  - join
  - operator
  - up
  - 100x
  - faster
  - previous
  - implementations
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: a specialized spatial join operator that's up to 100x faster than previous
      implementations.
    char_start: 0
    char_end: 91
- statement: The new UI allows users to work with local data and data hosted in cloud
    object stores like S3.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - new
  - ui
  - allows
  - users
  - work
  - local
  - data
  - hosted
  - cloud
  - object
  - stores
  - like
  - s3
  source:
    doc: motherduck.com/blog/perf-is-not-enough.md
    quote: You can work with local data, data hosted in cloud object stores like S3.
    char_start: 0
    char_end: 73
- statement: The new UI provides a notebook interface tailored for SQL and DuckDB
    workflows.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - new
  - ui
  - provides
  - notebook
  - interface
  - tailored
  - sql
  - duckdb
  - workflows
  source:
    doc: motherduck.com/blog/making-pyspark-code-faster-with-duckdb.md
    quote: The new UI addresses this by providing a notebook interface that feels
      familiar if you've used Jupyter, but tailored specifically for SQL and DuckDB
      workflows.
    char_start: 0
    char_end: 159
- statement: The November 2023 newsletter features a tutorial for beginners.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - november
  - '2023'
  - newsletter
  - features
  - tutorial
  - beginners
  source:
    doc: motherduck.com/blog/analyze-sqlite-databases-duckdb.md
    quote: The monthly newsletter for DuckDB, featuring updates and events.
    char_start: 0
    char_end: 64
- statement: The official open source Postgres extension for DuckDB is in an experimental
    state.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - official
  - open
  - source
  - postgres
  - extension
  - duckdb
  - experimental
  - state
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md
    quote: the official open source Postgres extension for DuckDB where multiple companies
      will partner... while it's still in an experimental state.
    char_start: 0
    char_end: 138
- statement: The Open3FS community has developed a DuckDB-3FS plugin enabling DuckDB
    and Smallpond to access DeepSeek's 3FS storage.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - open3fs
  - community
  - developed
  - duckdb
  - 3fs
  - plugin
  - enabling
  - smallpond
  - access
  - deepseek
  - storage
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: The Open3FS community has developed a DuckDB-3FS plugin enabling DuckDB
      and Smallpond to access DeepSeek's 3FS storage using its high-performance user-space
      interface (hf3fs_usrbio).
    char_start: 0
    char_end: 182
- statement: The OSS project reached 10k stars on GitHub.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - oss
  - project
  - reached
  - 10k
  - stars
  - github
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: The OSS project reached 10k stars on GitHub.
    char_start: 0
    char_end: 44
- statement: The parser's flexibility is demonstrated through options like strict_mode
    = false.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - parser
  - flexibility
  - demonstrated
  - options
  - like
  - strict
  - mode
  - 'false'
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md
    quote: The parser's flexibility is demonstrated through options like strict_mode
      = false.
    char_start: 0
    char_end: 82
- statement: The performance gap for analytical queries widens as the complexity and
    scale of queries increase.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - performance
  - gap
  - analytical
  - queries
  - widens
  - complexity
  - scale
  - increase
  source:
    doc: motherduck.com/videos/understanding-ducklake-a-table-format-with-a-modern-architecture.md
    quote: The performance gap for analytical queries widens as the complexity and
      scale of queries increase.
    char_start: 0
    char_end: 98
- statement: The pg_duckdb extension will be fully capable of querying against data
    stored in the cloud.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - pg
  - duckdb
  - extension
  - fully
  - capable
  - querying
  - against
  - data
  - stored
  - cloud
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: The pg_duckdb extension will be fully capable of querying against data
      stored in the cloud in MotherDuck as if it were local.
    char_start: 0
    char_end: 125
- statement: The pipeline processes the data with VADER sentiment analysis, validates
    data quality using Pandas, and stores results as Parquet files in S3.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - pipeline
  - processes
  - data
  - vader
  - sentiment
  - analysis
  - validates
  - quality
  - using
  - pandas
  - stores
  - results
  - parquet
  - files
  - s3
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: The pipeline processes the data with VADER sentiment analysis, validates
      data quality using Pandas, and stores results as Parquet files in S3.
    char_start: 0
    char_end: 142
- statement: The platform includes a Notebook-like UI that provides an intuitive interface
    for browsing data catalogs.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - platform
  - includes
  - notebook
  - like
  - ui
  - provides
  - intuitive
  - interface
  - browsing
  - data
  - catalogs
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: The platform includes a Notebook-like UI that provides an intuitive interface
      for browsing data catalogs.
    char_start: 0
    char_end: 105
- statement: The Pollock Benchmark positions DuckDB at the top, achieving a weighted
    score of 9.599.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - pollock
  - benchmark
  - positions
  - duckdb
  - top
  - achieving
  - weighted
  - score
  - '9.599'
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: The Pollock Benchmark, which evaluates CSV readers against real-world CSV
      variations, positions DuckDB at the top, achieving a weighted score of 9.599.
    char_start: 0
    char_end: 151
- statement: The potential of DuckDB as a federated query layer is immense.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - potential
  - duckdb
  - federated
  - query
  - layer
  - immense
  source:
    doc: motherduck.com/blog/duckdb-wasm-in-browser.md
    quote: The potential of DuckDB as a federated query layer is immense.
    char_start: 0
    char_end: 62
- statement: The power of built-in extensions simplifies the code base.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - power
  - built
  - extensions
  - simplifies
  - code
  - base
  source:
    doc: motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md
    quote: The power of built-in extensions simplifies the code base as we don't rely
      on any extra Python packages.
    char_start: 0
    char_end: 104
- statement: The project extracts data from Warcraft Logs and loads it into DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - project
  - extracts
  - data
  - warcraft
  - logs
  - loads
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: The project extracts data from Warcraft Logs and loads it into DuckDB.
    char_start: 0
    char_end: 70
- statement: The project provides production-grade architecture for real-time financial
    news processing.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - project
  - provides
  - production
  - grade
  - architecture
  - real
  - time
  - financial
  - news
  - processing
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: This project claims to provide production-grade architecture for real-time
      financial news processing.
    char_start: 0
    char_end: 101
- statement: The Python client has 6 million downloads per month.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - python
  - client
  - million
  - downloads
  - per
  - month
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Just the Python client has 6 million downloads per month.
    char_start: 0
    char_end: 57
- statement: The Query.Farm Radio extension enables DuckDB to interact with real-time
    event systems.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - query
  - farm
  - radio
  - extension
  - enables
  - duckdb
  - interact
  - real
  - time
  - event
  - systems
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: The Query.Farm Radio extension enables DuckDB to interact with real-time
      event systems like WebSocket and Redis Pub/Sub.
    char_start: 0
    char_end: 120
- statement: The recently announced DuckDB UI offers a user-friendly interface for
    local DuckDB instances.
  type: feature
  entity: DuckDB
  keywords:
  - feature
  - recently
  - announced
  - duckdb
  - ui
  - offers
  - user
  - friendly
  - interface
  - local
  - instances
  source:
    doc: motherduck.com/blog/data-engineers-answer-10-top-reddit-questions.md
    quote: The recently announced DuckDB UI offers a user-friendly interface for local
      DuckDB instances, enhancing productivity with features like interactive notebooks
      and column exploration.
    char_start: 0
    char_end: 181
- statement: The release also addresses breaking changes, such as an updated random
    function and changes in map indexing behavior.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - release
  - also
  - addresses
  - breaking
  - changes
  - updated
  - random
  - function
  - map
  - indexing
  - behavior
  source:
    doc: motherduck.com/blog/small-data-sf-recap-2025.md
    quote: The release also addresses breaking changes, such as an updated random
      function and changes in map indexing behavior.
    char_start: 0
    char_end: 117
- statement: The script connects to a DuckDB database, extracts the schema information,
    and outputs it in a machine-readable XML format.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - script
  - connects
  - duckdb
  - database
  - extracts
  - schema
  - information
  - outputs
  - machine
  - readable
  - xml
  - format
  source:
    doc: motherduck.com/blog/streaming-data-to-motherduck.md
    quote: This script connects to a DuckDB database, extracts the schema information,
      and outputs it in a machine-readable XML format that can be used in Cursor.
    char_start: 0
    char_end: 151
- statement: The security checksumming process in DuckDB was taking over 7 seconds
    on each extension load.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - security
  - checksumming
  - process
  - duckdb
  - taking
  - over
  - seconds
  - extension
  - load
  source:
    doc: motherduck.com/learn-more/star-schema-data-warehouse-guide.md
    quote: The security checksumming process (which is crucial and can't be skipped)
      was taking 7+ seconds on each extension load.
    char_start: 0
    char_end: 119
- statement: The site allows bundling multiple themed snippets together.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - site
  - allows
  - bundling
  - multiple
  - themed
  - snippets
  - together
  source:
    doc: motherduck.com/blog/building-motherduck-partner-ecosystem.md
    quote: the ability to bundle multiple themed snippets together
    char_start: 0
    char_end: 55
- statement: The solution leverages DuckDB and Postgres for data synchronization.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - solution
  - leverages
  - duckdb
  - postgres
  - data
  - synchronization
  source:
    doc: motherduck.com/blog/small-data-sf-workshops-agenda.md
    quote: Our solution leverages three specific components in a straightforward architecture.
    char_start: 0
    char_end: 83
- statement: The SQL examples provided can be used to analyze duck actions.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - sql
  - examples
  - provided
  - used
  - analyze
  - duck
  - actions
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: With the duck_samples table populated, we can now use it to analyze the
      data in new ways.
    char_start: 0
    char_end: 89
- statement: The SQL query obfuscates customer names and emails.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - sql
  - query
  - obfuscates
  - customer
  - names
  - emails
  source:
    doc: motherduck.com/blog/faster-ducks.md
    quote: The SQL query below obfuscates customer names and emails.
    char_start: 0
    char_end: 57
- statement: The storage layer is responsible for persistently storing and managing
    data.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - storage
  - layer
  - responsible
  - persistently
  - storing
  - managing
  - data
  source:
    doc: motherduck.com/ecosystem/cloudquery.md
    quote: The storage layer refers to the component of a data system responsible
      for persistently storing and managing data.
    char_start: 0
    char_end: 114
- statement: The UI features come with syntax highlights for SQL scripting and autocomplete.
  type: feature
  entity: DuckDB
  keywords:
  - feature
  - ui
  - features
  - come
  - syntax
  - highlights
  - sql
  - scripting
  - autocomplete
  source:
    doc: motherduck.com/blog/data-engineers-answer-10-top-reddit-questions.md
    quote: The UI features come with syntax highlights for SQL scripting and autocomplete.
    char_start: 0
    char_end: 79
- statement: The website hits 600k unique web visitors per month.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - website
  - hits
  - 600k
  - unique
  - web
  - visitors
  - per
  - month
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: The website hits 600k unique web visitors per month.
    char_start: 0
    char_end: 52
- statement: The Wizard extension leverages LLMs (OpenAI/Anthropic) to translate natural
    language into JavaScript code.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - wizard
  - extension
  - leverages
  - llms
  - openai
  - anthropic
  - translate
  - natural
  - language
  - javascript
  - code
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: The Wizard extension leverages LLMs (OpenAI/Anthropic) to translate natural
      language into JavaScript code that executes in a sandboxed Deno environment.
    char_start: 0
    char_end: 152
- statement: The workflow will send an email alert if new files detected in S3 have
    some anomalies.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - workflow
  - send
  - email
  - alert
  - new
  - files
  - detected
  - s3
  - anomalies
  source:
    doc: motherduck.com/blog/effortless-etl-unstructured-data-unstructuredio-motherduck.md
    quote: The workflow below will send an email alert if new files detected in S3
      have some anomalies.
    char_start: 0
    char_end: 92
- statement: There are a number of DuckDB related happenings this week at Databricks’
    Data & AI Summit.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - number
  - duckdb
  - related
  - happenings
  - week
  - databricks
  - data
  - ai
  - summit
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-three.md
    quote: There are a number of DuckDB related happenings this week at Databricks’
      Data & AI Summit.
    char_start: 0
    char_end: 90
- statement: There is a comparison between DuckDB in Julia and native Julia DataFrames.jl.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - comparison
  - duckdb
  - julia
  - native
  - dataframes
  - jl
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: an interesting comparison between native Julia and DuckDB in Julia doing
      some common operations.
    char_start: 0
    char_end: 96
- statement: There is no read_excel() function in DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - read
  - excel
  - function
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: Surprisingly, there is no read_excel() function yet...
    char_start: 0
    char_end: 54
- statement: They are not designed to be the primary backend for an application that
    requires thousands of concurrent, low-latency writes and updates per second.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - designed
  - primary
  - backend
  - application
  - requires
  - thousands
  - concurrent
  - low
  - latency
  - writes
  - updates
  - per
  - second
  source:
    doc: motherduck.com/glossary/Amazon S3.md
    quote: They are not designed to be the primary backend for an application that
      requires thousands of concurrent, low-latency writes and updates per second.
    char_start: 0
    char_end: 148
- statement: This approach ensures that extensions are loaded instantly, bypassing
    the typical delays seen with dynamic loading.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - approach
  - ensures
  - extensions
  - loaded
  - instantly
  - bypassing
  - typical
  - delays
  - seen
  - dynamic
  - loading
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: This approach ensures that extensions are loaded instantly, bypassing the
      typical delays seen with dynamic loading.
    char_start: 0
    char_end: 115
- statement: This approach frees data scientists from infrastructure management and
    eliminates the need for costly, dedicated clusters for exploratory analysis.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - approach
  - frees
  - data
  - scientists
  - infrastructure
  - management
  - eliminates
  - need
  - costly
  - dedicated
  - clusters
  - exploratory
  - analysis
  source:
    doc: motherduck.com/learn-more/hybrid-analytics-guide.md
    quote: This approach frees data scientists from infrastructure management and
      eliminates the need for costly, dedicated clusters for exploratory analysis.
    char_start: 0
    char_end: 147
- statement: This approach required minimal setup with no additional infrastructure.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - approach
  - required
  - minimal
  - setup
  - additional
  - infrastructure
  source:
    doc: motherduck.com/blog/from-data-lake-to-lakehouse-duckdb-portable-catalog.md
    quote: This approach required minimal setup with no additional infrastructure.
    char_start: 0
    char_end: 71
- statement: This breakthrough eliminates the guesswork and frustration that has defined
    SQL development for the past 50 years.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - breakthrough
  - eliminates
  - guesswork
  - frustration
  - defined
  - sql
  - development
  - past
  - '50'
  - years
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: This breakthrough eliminates the guesswork and frustration that has defined
      SQL development for the past 50 years.
    char_start: 0
    char_end: 114
- statement: This demo only works with DuckDB version 0.8.1.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - demo
  - works
  - duckdb
  - version
  - 0.8.1
  source:
    doc: motherduck.com/blog/introducing-motherduck-for-business-analytics.md
    quote: This demo only works with DuckDB version 0.8.1.
    char_start: 0
    char_end: 47
- statement: This edition explores DuckDB’s latest features, including UNION ALL BY
    NAME and new community-driven extensions.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - edition
  - explores
  - duckdb
  - latest
  - features
  - including
  - union
  - name
  - new
  - community
  - driven
  - extensions
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: This edition explores DuckDB’s latest features, including UNION ALL BY
      NAME and new community-driven extensions.
    char_start: 0
    char_end: 112
- statement: This project demonstrates a cost-efficient, serverless data pipeline
    for real-time financial news sentiment analysis using AWS services and DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - project
  - demonstrates
  - cost
  - efficient
  - serverless
  - data
  - pipeline
  - real
  - time
  - financial
  - news
  - sentiment
  - analysis
  - using
  - aws
  - services
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: This project demonstrates a cost-efficient, serverless data pipeline for
      real-time financial news sentiment analysis using AWS services and DuckDB.
    char_start: 0
    char_end: 147
- statement: This simple, SQL-based approach avoids complex ingestion pipelines.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - simple
  - sql
  - based
  - approach
  - avoids
  - complex
  - ingestion
  - pipelines
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: This simple, SQL-based approach avoids complex ingestion pipelines.
    char_start: 0
    char_end: 67
- statement: To persist data in DuckDB, you can provide a path to a database file.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - persist
  - data
  - duckdb
  - provide
  - path
  - database
  - file
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-two.md
    quote: 'To persist data, you have two options: Provide a path to a database file
      when starting DuckDB.'
    char_start: 0
    char_end: 94
- statement: Tobias created three functions to determine if IPs from CIDRs are in
    a certain range.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - tobias
  - created
  - three
  - functions
  - determine
  - ips
  - cidrs
  - certain
  - range
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Tobias created three functions (called Macros in DuckDB) to determine if
      IPs from CIDRs are in a certain range.
    char_start: 0
    char_end: 111
- statement: Tools like Evidence, powered by DuckDB, are lowering the barrier to this
    new paradigm.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - tools
  - like
  - evidence
  - powered
  - duckdb
  - lowering
  - barrier
  - new
  - paradigm
  source:
    doc: motherduck.com/videos.md
    quote: Tools like Evidence, powered by the performance and flexibility of DuckDB,
      are lowering the barrier to this new paradigm.
    char_start: 0
    char_end: 121
- statement: Traditional cloud data warehouses like Snowflake and BigQuery remain
    the best choice for enterprise-scale analytics on massive, petabyte-scale datasets.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - traditional
  - cloud
  - data
  - warehouses
  - like
  - snowflake
  - bigquery
  - remain
  - best
  - choice
  - enterprise
  - scale
  - analytics
  - massive
  - petabyte
  - datasets
  source:
    doc: motherduck.com/ecosystem/estuary.md
    quote: Traditional cloud data warehouses like Snowflake and BigQuery remain the
      best choice for enterprise-scale analytics on massive, petabyte-scale datasets.
    char_start: 0
    char_end: 152
- statement: Trent Hauck demonstrated the DuckDB Document Loader.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - trent
  - hauck
  - demonstrated
  - duckdb
  - document
  - loader
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-two.md
    quote: the awesome work of Trent Hauck about how to use the DuckDB Document Loader.
    char_start: 0
    char_end: 76
- statement: uDisc cut query times from minutes to seconds.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - udisc
  - cut
  - query
  - times
  - minutes
  - seconds
  source:
    doc: motherduck.com/react-components-testing.md
    quote: uDisc cut query times from minutes to seconds.
    char_start: 0
    char_end: 46
- statement: Understanding the nuances of data applications is crucial for technical
    practitioners in data engineering, analytics, and application development.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - understanding
  - nuances
  - data
  - applications
  - crucial
  - technical
  - practitioners
  - engineering
  - analytics
  - application
  - development
  source:
    doc: motherduck.com/ecosystem/paradime.md
    quote: For technical practitioners in data engineering, analytics, and application
      development, understanding the nuances of data applications is crucial.
    char_start: 0
    char_end: 147
- statement: Understanding what content is truly about goes beyond simple named entity
    recognition.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - understanding
  - what
  - content
  - truly
  - about
  - goes
  - beyond
  - simple
  - named
  - entity
  - recognition
  source:
    doc: motherduck.com/videos/querying-data-from-s3-with-3-lines-in-your-terminal.md
    quote: Understanding what content is truly about goes beyond simple named entity
      recognition.
    char_start: 0
    char_end: 86
- statement: Users can configure authentication using DuckDB's Secrets Manager with
    their Hugging Face token for secured access to private datasets.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - users
  - configure
  - authentication
  - using
  - duckdb
  - secrets
  - manager
  - hugging
  - face
  - token
  - secured
  - access
  - private
  - datasets
  source:
    doc: motherduck.com/blog/data-engineers-answer-10-top-reddit-questions.md
    quote: Users can configure authentication using DuckDB's Secrets Manager with
      their Hugging Face token for secured access to private datasets.
    char_start: 0
    char_end: 135
- statement: Users can manually override column types in DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - users
  - manually
  - override
  - column
  - types
  - duckdb
  source:
    doc: motherduck.com/glossary/SQL analytics.md
    quote: Users can manually override specific column types if detection gets it
      wrong.
    char_start: 0
    char_end: 77
- statement: Users would like performance optimizations related to time series and
    partitioned data.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - users
  - like
  - performance
  - optimizations
  - related
  - time
  - series
  - partitioned
  - data
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Users would like performance optimizations related to time series and partitioned
      data.
    char_start: 0
    char_end: 87
- statement: Using 'store_rejects' in DuckDB allows for detailed reporting of rejected
    rows.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - using
  - store
  - rejects
  - duckdb
  - allows
  - detailed
  - reporting
  - rejected
  - rows
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: When you use `store_rejects`, DuckDB still skips the bad rows, but it also
      logs detailed information about each rejected row.
    char_start: 0
    char_end: 125
- statement: Using DuckDB as a caching layer reduced Snowflake BI spend by 79%.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - using
  - duckdb
  - caching
  - layer
  - reduced
  - snowflake
  - bi
  - spend
  - '79'
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: A smart caching layer using DuckDB significantly reduced Snowflake BI spend
      by 79% while improving query performance.
    char_start: 0
    char_end: 117
- statement: Using DuckDB locally and MotherDuck in the cloud can speed up dbt development.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - using
  - duckdb
  - locally
  - motherduck
  - cloud
  - speed
  - up
  - dbt
  - development
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Speed up dbt development using local dev and cloud prod setups with DuckDB
      and MotherDuck.
    char_start: 0
    char_end: 90
- statement: Using DuckDB significantly speeds up the pipeline compared to Pyspark.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - using
  - duckdb
  - significantly
  - speeds
  - up
  - pipeline
  - compared
  - pyspark
  source:
    doc: motherduck.com/blog/fabi-ai-llm-prompt-analysis.md
    quote: it's evident that using DuckDB significantly speeds up the pipeline.
    char_start: 0
    char_end: 68
- statement: Using DuckDB to consolidate thousands of small, drifting JSON files into
    one/few Parquet artifacts can reduce scans and stabilize schemas.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - using
  - duckdb
  - consolidate
  - thousands
  - small
  - drifting
  - json
  - files
  - one
  - parquet
  - artifacts
  - reduce
  - scans
  - stabilize
  - schemas
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: Using DuckDB to consolidate thousands of small, drifting JSON files into
      one/few Parquet artifacts with lineage, then load via connectors or query directly
      to reduce scans and stabilize schemas.
    char_start: 0
    char_end: 194
- statement: Using generated data allows analysts to focus on DuckDB's capabilities
    rather than data quality issues.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - using
  - generated
  - data
  - allows
  - analysts
  - focus
  - duckdb
  - capabilities
  - rather
  - quality
  - issues
  source:
    doc: motherduck.com/blog/getting-started-gis-duckdb.md
    quote: I’d rather use generated data where analysts can focus on how ducking awesome
      DuckDB is instead of how unclean the data is.
    char_start: 0
    char_end: 123
- statement: Using MotherDuck’s Dual Query execution on a Raspberry Pi to play a quack
    sound when users sign up for our service.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - using
  - motherduck
  - dual
  - query
  - execution
  - raspberry
  - pi
  - play
  - quack
  - sound
  - users
  - sign
  - up
  - service
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: Using MotherDuck’s Dual Query execution on a Raspberry Pi to play a quack
      sound when users sign up for our service.
    char_start: 0
    char_end: 115
- statement: Using STRUCTs improves schema readability and integrates well with DuckDB's
    performance-oriented architecture.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - using
  - structs
  - improves
  - schema
  - readability
  - integrates
  - well
  - duckdb
  - performance
  - oriented
  - architecture
  source:
    doc: motherduck.com/learn-more/what-is-a-data-warehouse.md
    quote: It provides a clean way to group related information, improves schema readability,
      and integrates well with DuckDB's performance-oriented architecture.
    char_start: 0
    char_end: 151
- statement: Vector engines leverage column-oriented architecture to perform analytical
    operations efficiently.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - vector
  - engines
  - leverage
  - column
  - oriented
  - architecture
  - perform
  - analytical
  - operations
  - efficiently
  source:
    doc: motherduck.com/glossary/S3 bucket.md
    quote: Generally, vector-based engines leverage column-oriented architecture to
      perform analytical operations efficiently across large datasets.
    char_start: 0
    char_end: 137
- statement: Vector engines process data in chunks or 'vectors' of values.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - vector
  - engines
  - process
  - data
  - chunks
  - vectors
  - values
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: These are general-purpose analytical engines that have vector processing
      capabilities built in.
    char_start: 0
    char_end: 95
- statement: Version 0.10 compared to 1.3.2 feels prehistoric.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - version
  - '0.10'
  - compared
  - 1.3.2
  - feels
  - prehistoric
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-two.md
    quote: Version `0.10` compared to `1.3.2` (current) feels prehistoric.
    char_start: 0
    char_end: 63
- statement: Version Independence allows users to benefit from updates without needing
    to upgrade their clients immediately.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - version
  - independence
  - allows
  - users
  - benefit
  - updates
  - without
  - needing
  - upgrade
  - clients
  - immediately
  source:
    doc: motherduck.com/blog/duckdb-the-great-federator.md
    quote: What makes this possible is Version Independence, a feature we quietly
      enabled a few weeks ago that decouples clients from the version of DuckDB that
      we run on our servers.
    char_start: 0
    char_end: 172
- statement: Watershed implemented DuckDB for carbon footprint analytics.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - watershed
  - implemented
  - duckdb
  - carbon
  - footprint
  - analytics
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: Watershed's implementation of leveraging DuckDB's lightweight yet powerful
      database for production workloads.
    char_start: 0
    char_end: 109
- statement: Watershed is migrating its enterprise data lake using DuckDB.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - watershed
  - migrating
  - enterprise
  - data
  - lake
  - using
  - duckdb
  source:
    doc: motherduck.com/blog/announcing-ducklake-support-motherduck-preview.md
    quote: 'Watershed: Enterprise Data Lake Migration'
    char_start: 0
    char_end: 41
- statement: We are a medium data organization.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - medium
  - data
  - organization
  source:
    doc: motherduck.com/glossary/time-series.md
    quote: We’re a “medium data” organization both in the scale of our data and the
      scale of our data engineering resources.
    char_start: 0
    char_end: 113
- statement: 'When it might not be the best choice: Handling joins with exceptionally
    large data volumes (e.g., > 1 TB of data).'
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - best
  - choice
  - handling
  - joins
  - exceptionally
  - large
  - data
  - volumes
  - tb
  source:
    doc: motherduck.com/blog/motherduck-data-warehouse.md
    quote: 'When it might not be the best choice: Handling joins with exceptionally
      large data volumes (e.g., > 1 TB of data).'
    char_start: 0
    char_end: 114
- statement: 'When to consider using DuckDB for data source federation: Building APIs
    that rely on multiple data sources while aiming for a responsive latency (< 1s).'
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - consider
  - using
  - duckdb
  - data
  - source
  - federation
  - building
  - apis
  - rely
  - multiple
  - sources
  - aiming
  - responsive
  - latency
  - 1s
  source:
    doc: motherduck.com/blog/motherduck-data-warehouse.md
    quote: 'When to consider using DuckDB for data source federation: Building APIs
      that rely on multiple data sources while aiming for a responsive latency (<
      1s).'
    char_start: 0
    char_end: 152
- statement: You can output the result to a Markdown file.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - output
  - result
  - markdown
  - file
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: Let’s say you would like to output the result to a Markdown file, you can
      set the display mode to Markdown with `.mode markdown`.
    char_start: 0
    char_end: 129
- statement: You can persist the data into a DuckDB table using the .to_table() method.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - persist
  - data
  - duckdb
  - table
  - using
  - method
  source:
    doc: motherduck.com/learn-more/data-warehouse-tco.md
    quote: If you find yourself querying the same file repeatedly or need better performance
      than reading the file anew each time, you can easily persist the data into a
      DuckDB table using the .to_table() method
    char_start: 0
    char_end: 218
- statement: You can query the CSV file directly using SQL syntax.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - query
  - csv
  - file
  - directly
  - using
  - sql
  - syntax
  source:
    doc: motherduck.com/learn-more/data-warehouse-tco.md
    quote: This is incredibly convenient! You're querying the CSV file directly using
      SQL syntax, without defining a schema or loading it fully into a table first.
    char_start: 0
    char_end: 152
- statement: You could complete a JSON parse and extract task on your laptop before
    a distributed compute cluster even finishes booting up.
  type: performance
  entity: DuckDB
  keywords:
  - performance
  - complete
  - json
  - parse
  - extract
  - task
  - laptop
  - distributed
  - compute
  - cluster
  - even
  - finishes
  - booting
  - up
  source:
    doc: motherduck.com/videos/4-lightning-talks-on-practical-ai-workflows-from-notion-1password-motherduck-evidence.md
    quote: What if I told you that you could complete a JSON parse and extract task
      on your laptop before a distributed compute cluster even finishes booting up?
    char_start: 0
    char_end: 150
- statement: You will create your own heatmap using DuckDB, Python, and MotherDuck.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - create
  - heatmap
  - using
  - duckdb
  - python
  - motherduck
  source:
    doc: motherduck.com/videos/simple-way-to-convert-csv-and-parquet-files.md
    quote: By the end, you will create your own heatmap using DuckDB, Python, and
      MotherDuck for sharing and scalability.
    char_start: 0
    char_end: 110
- statement: YouPlot is used to create data visualizations on the command line using
    DuckDB.
  type: integration
  entity: DuckDB
  keywords:
  - integration
  - youplot
  - used
  - create
  - data
  - visualizations
  - command
  - line
  - using
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: Mark Needham teaches us how to create data visualizations on the command
      line using YouPlot, DuckDB.
    char_start: 0
    char_end: 100
- statement: Zerodha's implementation of DuckDB has impacted their data processing
    capabilities.
  type: definition
  entity: DuckDB
  keywords:
  - definition
  - zerodha
  - implementation
  - duckdb
  - impacted
  - data
  - processing
  - capabilities
  source:
    doc: motherduck.com/learn-more/pandas-dataframes-guide.md
    quote: We will also walk through a case study of Zerodha’s implementation of DuckDB
      and its impact on their data processing capabilities.
    char_start: 0
    char_end: 130
- statement: The duckdb-async library allows asynchronous operations with DuckDB in
    Node.js.
  type: definition
  entity: duckdb-async
  keywords:
  - definition
  - duckdb
  - async
  - library
  - allows
  - asynchronous
  - operations
  - node
  - js
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: The first line imports the duckdb-async library.
    char_start: 0
    char_end: 48
- statement: DuckDB-NSQL can run locally with llama.cpp.
  type: definition
  entity: DuckDB-NSQL
  keywords:
  - definition
  - duckdb
  - nsql
  - run
  - locally
  - llama
  - cpp
  source:
    doc: motherduck.com/blog/search-using-duckdb-part-2.md
    quote: If you want to get the fully local experience with llama.cpp...
    char_start: 0
    char_end: 63
- statement: DuckDB-NSQL model weights are released on Hugging Face.
  type: definition
  entity: DuckDB-NSQL
  keywords:
  - definition
  - duckdb
  - nsql
  - model
  - weights
  - released
  - hugging
  - face
  source:
    doc: motherduck.com/blog/search-using-duckdb-part-2.md
    quote: We fully release the model weights on Hugging Face.
    char_start: 0
    char_end: 51
- statement: DuckDB-NSQL was trained and evaluated using datasets from Numbers Station.
  type: definition
  entity: DuckDB-NSQL
  keywords:
  - definition
  - duckdb
  - nsql
  - trained
  - evaluated
  - using
  - datasets
  - numbers
  - station
  source:
    doc: motherduck.com/blog/search-using-duckdb-part-2.md
    quote: trained on about 200k synthetically generated and validated DuckDB SQL
      queries, guided by the DuckDB documentation, and more than 250k general Text-2-SQL
      questions from Numbers Station.
    char_start: 0
    char_end: 185
- statement: OctoAI provides a fast and scalable demo endpoint for DuckDB-NSQL.
  type: definition
  entity: DuckDB-NSQL
  keywords:
  - definition
  - octoai
  - provides
  - fast
  - scalable
  - demo
  - endpoint
  - duckdb
  - nsql
  source:
    doc: motherduck.com/blog/search-using-duckdb-part-2.md
    quote: Thanks OctoAI for providing us with a fast and scalable demo endpoint.
    char_start: 0
    char_end: 70
- statement: The extensions, such as duckdb_mysql, need to enhance their support for
    advanced pushdowns.
  type: definition
  entity: duckdb_mysql
  keywords:
  - definition
  - extensions
  - duckdb
  - mysql
  - need
  - enhance
  - support
  - advanced
  - pushdowns
  source:
    doc: motherduck.com/blog/motherduck-data-warehouse.md
    quote: the extensions, such as duckdb_mysql, need to enhance their support for
      advanced pushdowns.
    char_start: 0
    char_end: 91
- statement: DuckDBPyRelation can be converted into an Apache Arrow Table.
  type: definition
  entity: DuckDBPyRelation
  keywords:
  - definition
  - duckdbpyrelation
  - converted
  - apache
  - arrow
  - table
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: '.arrow() or .fetcharrow(): Converts the result into an Apache Arrow Table.'
    char_start: 0
    char_end: 74
- statement: DuckDBPyRelation represents a query result or a data source.
  type: definition
  entity: DuckDBPyRelation
  keywords:
  - definition
  - duckdbpyrelation
  - represents
  - query
  - result
  - data
  - source
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: It represents a query result _or_ a data source (like a table or a file).
    char_start: 0
    char_end: 73
- statement: You can chain methods on a DuckDBPyRelation object.
  type: definition
  entity: DuckDBPyRelation
  keywords:
  - definition
  - chain
  - methods
  - duckdbpyrelation
  - object
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: Instead of writing a single SQL string, you can chain methods on a DuckDBPyRelation
      object.
    char_start: 0
    char_end: 91
- statement: A database file with the specified database name ‘knowledge_base’ will
    be created.
  type: definition
  entity: DuckDBVectorStore
  keywords:
  - definition
  - database
  - file
  - specified
  - name
  - knowledge
  - base
  - created
  source:
    doc: motherduck.com/blog/search-using-duckdb-part-2.md
    quote: This means that a database file with the specified database name ‘knowledge_base’
      will be created in the listed directory.
    char_start: 0
    char_end: 122
- statement: It is important to specify the dimensions of the vector embeddings used.
  type: definition
  entity: DuckDBVectorStore
  keywords:
  - definition
  - important
  - specify
  - dimensions
  - vector
  - embeddings
  - used
  source:
    doc: motherduck.com/blog/search-using-duckdb-part-2.md
    quote: It’s important to specify the dimensions of the vector embeddings used,
      as this information will be required for the embedding field data type when
      we create the table to store the embeddings.
    char_start: 0
    char_end: 192
- statement: Every successful Quack To SQL user will earn 10 Duckets.
  type: definition
  entity: Duckets
  keywords:
  - definition
  - every
  - successful
  - quack
  - sql
  - user
  - earn
  - '10'
  - duckets
  source:
    doc: motherduck.com/blog/small-data-sf-recap.md
    quote: Every successful Quack To SQL user will earn 10 Duckets.
    char_start: 0
    char_end: 56
- statement: A comprehensive disaster recovery strategy requires a customer-managed
    plan.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - comprehensive
  - disaster
  - recovery
  - strategy
  - requires
  - customer
  - managed
  - plan
  source:
    doc: motherduck.com/videos/understanding-ducklake-a-table-format-with-a-modern-architecture.md
    quote: A comprehensive disaster recovery strategy requires a customer-managed
      plan.
    char_start: 0
    char_end: 76
- statement: A modern hybrid platform with a dual-execution engine solves the challenge
    of data gravity by intelligently minimizing data transfer.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - modern
  - hybrid
  - platform
  - dual
  - execution
  - engine
  - solves
  - challenge
  - data
  - gravity
  - intelligently
  - minimizing
  - transfer
  source:
    doc: motherduck.com/videos/ducklake-big-data-small-coalesce-2025.md
    quote: A modern hybrid platform with a dual-execution engine solves this by intelligently
      minimizing data transfer.
    char_start: 0
    char_end: 108
- statement: A per-thread output write option reduced a 1B-row copy from ~4.5s to
    ~3.4s (~25% faster).
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - per
  - thread
  - output
  - write
  - option
  - reduced
  - 1b
  - row
  - copy
  - '4.5'
  - '3.4'
  - '25'
  - faster
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: a per-thread output write option that reduced a 1B-row copy from ~4.5s
      to ~3.4s (~25% faster)
    char_start: 0
    char_end: 93
- statement: A phased approach to migration de-risks the process and avoids a high-stakes
    'big bang' cutover.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - phased
  - approach
  - migration
  - de
  - risks
  - process
  - avoids
  - high
  - stakes
  - big
  - bang
  - cutover
  source:
    doc: motherduck.com/learn-more/secure-startup-data-warehouse.md
    quote: This phased approach de-risks the migration and avoids a high-stakes 'big
      bang' cutover.
    char_start: 0
    char_end: 88
- statement: A serverless, hybrid engine eliminates the need to manage clusters, provides
    a responsive development experience, and keeps costs low by only charging for
    compute that is actively used.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - serverless
  - hybrid
  - engine
  - eliminates
  - need
  - manage
  - clusters
  - provides
  - responsive
  - development
  - experience
  - keeps
  - costs
  - low
  - charging
  - compute
  - actively
  - used
  source:
    doc: motherduck.com/videos/cultivating-growth-how-gardyn-scaled-its-data-operations-with-motherduck.md
    quote: A serverless, hybrid engine eliminates the need to manage clusters, provides
      a responsive development experience, and keeps costs low by only charging for
      compute that is actively used.
    char_start: 0
    char_end: 185
- statement: A simple Streamlit application can be built to monitor user sign-ups
    with just a few lines of Python.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - simple
  - streamlit
  - application
  - built
  - monitor
  - user
  - sign
  - ups
  - lines
  - python
  source:
    doc: motherduck.com/webinar/scaling-duckdb-panel-ondemand.md
    quote: For example, a simple Streamlit application to monitor user sign-ups could
      be built with just a few lines of Python.
    char_start: 0
    char_end: 116
- statement: A slow analytics stack is a direct drag on speed to market, speed to
    insight, and speed of execution.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - slow
  - analytics
  - stack
  - direct
  - drag
  - speed
  - market
  - insight
  - execution
  source:
    doc: motherduck.com/videos/duckfooding-at-motherduck.md
    quote: A slow analytics stack is a direct drag on all three.
    char_start: 0
    char_end: 53
- statement: A small team can set up a secure, multi-user warehouse on MotherDuck
    in under two hours.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - small
  - team
  - set
  - up
  - secure
  - multi
  - user
  - warehouse
  - motherduck
  - two
  - hours
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: A small team can set up a secure, multi-user warehouse on MotherDuck in
      under two hours.
    char_start: 0
    char_end: 88
- statement: Adopt a serverless SQL analytics platform to eliminate the high cost
    and operational overhead of managing idle clusters.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - adopt
  - serverless
  - sql
  - analytics
  - platform
  - eliminate
  - high
  - cost
  - operational
  - overhead
  - managing
  - idle
  - clusters
  source:
    doc: motherduck.com/videos/ducklake-big-data-small-coalesce-2025.md
    quote: Adopt a serverless SQL analytics platform. These services handle all infrastructure
      provisioning, scaling, and maintenance for you.
    char_start: 0
    char_end: 131
- statement: Adopting a serverless, hybrid approach reduces cloud data warehouse costs.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - adopting
  - serverless
  - hybrid
  - approach
  - reduces
  - cloud
  - data
  - warehouse
  - costs
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: By adopting a serverless, hybrid approach, you can reduce your cloud data
      warehouse costs.
    char_start: 0
    char_end: 90
- statement: After 50 years since SQL's inception, this innovation from MotherDuck
    represents a fundamental shift in the SQL development experience.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - '50'
  - years
  - since
  - sql
  - inception
  - innovation
  - motherduck
  - represents
  - fundamental
  - shift
  - development
  - experience
  source:
    doc: motherduck.com/learn-more/duckdb-vs-sqlite-databases.md
    quote: After 50 years since SQL's inception, this innovation from MotherDuck represents
      a fundamental shift in the SQL development experience.
    char_start: 0
    char_end: 135
- statement: Artefact is evaluating the potential of MotherDuck.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - artefact
  - evaluating
  - potential
  - motherduck
  source:
    doc: motherduck.com/learn-more/star-schema-data-warehouse-guide.md
    quote: 'we knew what we had to do: put it to the test, evaluate its potential.'
    char_start: 0
    char_end: 70
- statement: BI as code follows the same principles that revolutionized infrastructure
    management with infrastructure as code.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - bi
  - code
  - follows
  - principles
  - revolutionized
  - infrastructure
  - management
  source:
    doc: motherduck.com/videos/taming-file-zoos-data-science-with-duckdb-database-files.md
    quote: BI as code follows the same principles that revolutionized infrastructure
      management with infrastructure as code.
    char_start: 0
    char_end: 113
- statement: Big Data is a topic of debate regarding its relevance.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - big
  - data
  - topic
  - debate
  - regarding
  - relevance
  source:
    doc: motherduck.com/videos/unleashing-the-power-of-duckdb-for-interactive-sql-notebooks.md
    quote: Jordan Tigani of MotherDuck and Aditya Parameswaran of Ponder debate whether
      Big Data is Dead or not.
    char_start: 0
    char_end: 101
- statement: BuzzFeed blends human creativity with cutting-edge technology.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - buzzfeed
  - blends
  - human
  - creativity
  - cutting
  - edge
  - technology
  source:
    doc: motherduck.com/videos/making-pyspark-code-faster-with-duckdb.md
    quote: blending human creativity with cutting-edge technology.
    char_start: 0
    char_end: 55
- statement: By developing locally and pushing to the Cloud, it's easy to develop,
    debug and iterate.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - developing
  - locally
  - pushing
  - cloud
  - easy
  - develop
  - debug
  - iterate
  source:
    doc: motherduck.com/videos/where-data-science-meets-shrek-how-buzzfeed-uses-ai.md
    quote: By developing locally and pushing to the Cloud it's not only easy to develop,
      debug and iterate.
    char_start: 0
    char_end: 96
- statement: Choosing a modern, lightweight BI tool that integrates well with your
    warehouse ensures that insights are accessible to everyone on the team, not just
    data specialists.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - choosing
  - modern
  - lightweight
  - bi
  - tool
  - integrates
  - well
  - warehouse
  - ensures
  - insights
  - accessible
  - everyone
  - team
  - data
  - specialists
  source:
    doc: motherduck.com/videos/cultivating-growth-how-gardyn-scaled-its-data-operations-with-motherduck.md
    quote: Choosing a modern, lightweight BI tool that integrates well with your warehouse
      ensures that insights are accessible to everyone on the team, not just data
      specialists.
    char_start: 0
    char_end: 168
- statement: CRN names MotherDuck as one of the coolest data analytics companies of
    2024.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - crn
  - names
  - motherduck
  - one
  - coolest
  - data
  - analytics
  - companies
  - '2024'
  source:
    doc: motherduck.com/privacy-policy.md
    quote: CRN, the Channel Company, names MotherDuck among the coolest data analytics
      companies of the 2024 Big Data 100.
    char_start: 0
    char_end: 111
- statement: Datacoves and MotherDuck make it possible to connect directly to S3,
    build dbt models in DuckLake, and visualize the results.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - datacoves
  - motherduck
  - make
  - possible
  - connect
  - directly
  - s3
  - build
  - dbt
  - models
  - ducklake
  - visualize
  - results
  source:
    doc: motherduck.com/videos/what-if-sql-queries-returned-results-instantly.md
    quote: In this webinar, we show how Datacoves and MotherDuck make it possible
      to connect directly to S3, build dbt models in DuckLake, and visualize the results
      without the heavy lift of traditional data sta
    char_start: 0
    char_end: 204
- statement: Datacoves and MotherDuck make it possible to connect.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - datacoves
  - motherduck
  - make
  - possible
  - connect
  source:
    doc: motherduck.com/learn-more/duckdb-vs-sqlite-databases.md
    quote: we show how Datacoves and MotherDuck make it possible to connect...
    char_start: 0
    char_end: 67
- statement: Definite achieved over 70% reduction in their data warehousing expenses.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - definite
  - achieved
  - over
  - '70'
  - reduction
  - data
  - warehousing
  - expenses
  source:
    doc: motherduck.com/videos/going-beyond-the-dataframe.md
    quote: Definite migrated its entire data warehouse from Snowflake to a DuckDB-based
      solution. The results were quick and significant, achieving an over 70% reduction
      in their data warehousing expenses.
    char_start: 0
    char_end: 194
- statement: Dogfooding has proved invaluable in uncovering real-world issues and
    accelerating product development.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - dogfooding
  - proved
  - invaluable
  - uncovering
  - real
  - world
  - issues
  - accelerating
  - product
  - development
  source:
    doc: motherduck.com/videos/using-sql-in-your-data-lake-with-duckdb-iceberg-dbt-and-motherduck.md
    quote: this approach has proved invaluable in uncovering real-world issues and
      accelerating product development.
    char_start: 0
    char_end: 105
- statement: DuckDB can be installed through various methods including direct binary
    download and package managers.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - duckdb
  - installed
  - various
  - methods
  - including
  - direct
  - binary
  - download
  - package
  - managers
  source:
    doc: motherduck.com/videos/unleashing-duckdb-dbt-for-local-analytics-triumphs.md
    quote: 'DuckDB can be installed through various methods: Direct binary download
      for CLI usage, Package managers (Homebrew for macOS), Language-specific packages
      (Python, R, Java, etc.).'
    char_start: 0
    char_end: 177
- statement: DuckDB eliminates data ingress and egress charges.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - duckdb
  - eliminates
  - data
  - ingress
  - egress
  - charges
  source:
    doc: motherduck.com/videos/pg_duckdb-ducking-awesome-analytics-in-postgres.md
    quote: DuckDB eliminates these fees by bringing processing directly to data locations.
    char_start: 0
    char_end: 79
- statement: DuckDB eliminates idle billing entirely.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - duckdb
  - eliminates
  - idle
  - billing
  - entirely
  source:
    doc: motherduck.com/videos/pg_duckdb-ducking-awesome-analytics-in-postgres.md
    quote: This embedded design eliminates idle billing entirely.
    char_start: 0
    char_end: 54
- statement: DuckDB introduces a new table format, DuckLake, which rethinks how we
    handle metadata and open table format.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - duckdb
  - introduces
  - new
  - table
  - format
  - ducklake
  - which
  - rethinks
  - handle
  - metadata
  - open
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: DuckDB introduces a new table format, what does it mean for the future
      of data lakes?
    char_start: 0
    char_end: 85
- statement: DuckLake allows for partition evolution where you can change the partitioning
    scheme over time.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - allows
  - partition
  - evolution
  - change
  - partitioning
  - scheme
  - over
  - time
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: partition evolution where you can change the partitioning scheme of a DuckLake
      table over time and this only affects new data written.
    char_start: 0
    char_end: 134
- statement: DuckLake automatically generates unique encryption keys for each file.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - automatically
  - generates
  - unique
  - encryption
  - keys
  - file
  source:
    doc: motherduck.com/learn-more/partitioned-writes-parquet-ducklake.md
    quote: DuckLake automatically generates unique encryption keys for each file when
      it's written.
    char_start: 0
    char_end: 88
- statement: DuckLake builds upon the concept of partitioning with advanced features
    like catalog-managed metadata and data encryption.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - builds
  - upon
  - concept
  - partitioning
  - advanced
  - features
  - like
  - catalog
  - managed
  - metadata
  - data
  - encryption
  source:
    doc: motherduck.com/videos.md
    quote: DuckLake builds upon the concept of partitioning with advanced features
      like catalog-managed metadata and data encryption.
    char_start: 0
    char_end: 122
- statement: DuckLake can dramatically reduce the number of small files written to
    storage.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - dramatically
  - reduce
  - number
  - small
  - files
  - written
  - storage
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: It can dramatically reduce the number of small files written to storage.
    char_start: 0
    char_end: 72
- statement: DuckLake can handle data partitioning automatically.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - handle
  - data
  - partitioning
  - automatically
  source:
    doc: motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse.md
    quote: DuckLake can handle data partitioning automatically, so users get the performance
      benefits without needing to specify partition columns in their queries.
    char_start: 0
    char_end: 153
- statement: DuckLake can store data in AWS S3, Google Cloud Storage, and Azure Blob
    Storage.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - store
  - data
  - aws
  - s3
  - google
  - cloud
  - storage
  - azure
  - blob
  source:
    doc: motherduck.com/videos/motherduck-ga-produck-tour.md
    quote: 'This is where your data lives: standard Parquet files stored in a blob
      store like AWS S3, Google Cloud Storage, or Azure Blob Storage.'
    char_start: 0
    char_end: 134
- statement: DuckLake combines a catalog and table format in one.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - combines
  - catalog
  - table
  - format
  - one
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: the highlight is the new DuckLake extension, which combines a catalog +
      table format in one.
    char_start: 0
    char_end: 92
- statement: DuckLake could become a compelling alternative to established formats
    like Iceberg and Delta Lake.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - become
  - compelling
  - alternative
  - established
  - formats
  - like
  - iceberg
  - delta
  - lake
  source:
    doc: motherduck.com/learn-more/partitioned-writes-parquet-ducklake.md
    quote: DuckLake could become a compelling alternative to established formats like
      Iceberg and Delta Lake.
    char_start: 0
    char_end: 98
- statement: DuckLake delivers enterprise grade features with startling simplicity.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - delivers
  - enterprise
  - grade
  - features
  - startling
  - simplicity
  source:
    doc: motherduck.com/learn-more/fix-slow-bi-dashboards.md
    quote: this sleek lakehouse solution delivers enterprise grade features with startling
      simplicity
    char_start: 0
    char_end: 90
- statement: DuckLake enables faster, scalable, and ACID-compliant analytics on object
    storage like S3.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - enables
  - faster
  - scalable
  - acid
  - compliant
  - analytics
  - object
  - storage
  - like
  - s3
  source:
    doc: motherduck.com/learn-more/duckdb-vs-sqlite-databases.md
    quote: enabling faster, scalable, and ACID-compliant analytics on object storage
      like S3.
    char_start: 0
    char_end: 82
- statement: DuckLake has plans to support Spark and Ray as compute engines.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - plans
  - support
  - spark
  - ray
  - compute
  - engines
  source:
    doc: motherduck.com/videos/motherduck-ga-produck-tour.md
    quote: A Spark connector is already in the works, and there are plans to support
      other engines like Ray in the future.
    char_start: 0
    char_end: 111
- statement: DuckLake is a fully open format, licensed under MIT.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - fully
  - open
  - format
  - licensed
  - mit
  source:
    doc: motherduck.com/learn-more/no-etl-query-raw-files.md
    quote: DuckLake is a fully open format, licensed under MIT.
    char_start: 0
    char_end: 52
- statement: DuckLake is a practical choice for analytical workloads, where high-throughput
    reads and batch writes are the norm.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - practical
  - choice
  - analytical
  - workloads
  - high
  - throughput
  - reads
  - batch
  - writes
  - norm
  source:
    doc: motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse.md
    quote: It works especially well for analytical workloads, where high-throughput
      reads and batch writes are the norm.
    char_start: 0
    char_end: 109
- statement: DuckLake is a technology related to data loading and management.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - technology
  - related
  - data
  - loading
  - management
  source:
    doc: motherduck.com/learn-more/fix-slow-bi-dashboards.md
    quote: A technology related to data loading and management.
    char_start: 0
    char_end: 52
- statement: DuckLake is built on an open foundation and is MIT licensed.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - built
  - open
  - foundation
  - mit
  - licensed
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: DuckLake is built on an open foundation. It’s MIT licensed, vendor-neutral,
      and intended to be a community-driven standard.
    char_start: 0
    char_end: 123
- statement: DuckLake is designed to be open and integrated with other engines and
    tools.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - designed
  - open
  - integrated
  - engines
  - tools
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: DuckLake is designed to be open and integrated with other engines and tools.
    char_start: 0
    char_end: 76
- statement: DuckLake is developed by Carnegie Mellon.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - developed
  - carnegie
  - mellon
  source:
    doc: motherduck.com/learn-more/fix-slow-bi-dashboards.md
    quote: learning from Cloud Data Warehouses to Build a Robust 'Lakehouse'
    char_start: 0
    char_end: 65
- statement: DuckLake is not intended for OLTP-style point updates.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - intended
  - oltp
  - style
  - point
  - updates
  source:
    doc: motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse.md
    quote: It is not intended for OLTP-style point updates.
    char_start: 0
    char_end: 48
- statement: DuckLake offers advanced data management features including partitioned
    writes.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - offers
  - advanced
  - data
  - management
  - features
  - including
  - partitioned
  - writes
  source:
    doc: motherduck.com/videos.md
    quote: it's also worth looking at DuckLake, an integrated data lake and catalog
      format built on DuckDB, which offers more advanced data management features
      including its own approach to partitioned writes.
    char_start: 0
    char_end: 198
- statement: DuckLake offers fully managed services for handling ACID transactions
    and schema management.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - offers
  - fully
  - managed
  - services
  - handling
  - acid
  - transactions
  - schema
  - management
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: If you need ACID transactions and schema management for your data lake,
      MotherDuck offers fully managed DuckLake with a single command.
    char_start: 0
    char_end: 135
- statement: DuckLake offers real advantages by simplifying the architecture while
    improving performance.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - offers
  - real
  - advantages
  - simplifying
  - architecture
  - improving
  - performance
  source:
    doc: motherduck.com/videos/why-dont-data-producers-pay-attention-to-how-their-data-is-used-downstream.md
    quote: DuckLake offers real advantages by simplifying the architecture while improving
      performance.
    char_start: 0
    char_end: 92
- statement: DuckLake optionally encrypts all data files written to the data store.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - optionally
  - encrypts
  - data
  - files
  - written
  - store
  source:
    doc: motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse.md
    quote: Optionally encrypt all data files written to the data store, making zero-trust
      data hosting possible.
    char_start: 0
    char_end: 101
- statement: DuckLake provides ACID guarantees for your data lake.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - provides
  - acid
  - guarantees
  - data
  - lake
  source:
    doc: motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse.md
    quote: With DuckLake, you get ACID guarantees for your data lake.
    char_start: 0
    char_end: 58
- statement: DuckLake requires a blob storage bucket for data storage.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - requires
  - blob
  - storage
  - bucket
  - data
  source:
    doc: motherduck.com/videos.md
    quote: 'Setting up DuckLake requires three components: 1. Data storage: A blob
      storage bucket (e.g., AWS S3) with read/write access'
    char_start: 0
    char_end: 123
- statement: DuckLake simplifies lakehouses by using a standard SQL database for all
    metadata.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - simplifies
  - lakehouses
  - using
  - standard
  - sql
  - database
  - metadata
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: DuckLake simplifies lakehouses by using a standard SQL database for all
      metadata, offering a more reliable, faster, and easier-to-manage solution than
      file-based systems.
    char_start: 0
    char_end: 170
- statement: DuckLake supports schema evolution.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - supports
  - schema
  - evolution
  source:
    doc: motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse.md
    quote: 'Schema Evolution: Safely add, rename, drop, or change column types without
      rewriting any data.'
    char_start: 0
    char_end: 94
- statement: DuckLake uses a dedicated metadata catalog to manage information about
    data files and their partitions.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - uses
  - dedicated
  - metadata
  - catalog
  - manage
  - information
  - about
  - data
  - files
  - partitions
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: Instead of relying solely on the physical Hive directory structure, DuckLake
      uses a dedicated metadata catalog (stored in a SQL database) to manage information
      about data files and their partitions.
    char_start: 0
    char_end: 198
- statement: DuckLake v0.3 adds Iceberg interoperability, geometry types, MERGE/CHECKPOINT
    support.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - v0.3
  - adds
  - iceberg
  - interoperability
  - geometry
  - types
  - merge
  - checkpoint
  - support
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: DuckLake v0.3 (ducklake DuckDB extension in DuckDB v1.4.0) adds Iceberg
      interoperability, geometry types, MERGE/CHECKPOINT support.
    char_start: 0
    char_end: 131
- statement: DuckLake will support Iceberg import/export for migration and interoperability.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - support
  - iceberg
  - import
  - export
  - migration
  - interoperability
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: it will support Iceberg import/export for migration and interoperability.
    char_start: 0
    char_end: 73
- statement: DuckLake's catalog contains the actual metadata itself.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - ducklake
  - catalog
  - contains
  - actual
  - metadata
  - itself
  source:
    doc: motherduck.com/learn-more/hybrid-analytics-guide.md
    quote: In the DuckLake approach, the catalog isn't just a pointer; it contains
      the actual metadata itself.
    char_start: 0
    char_end: 99
- statement: During idle periods, compute charges are zero.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - idle
  - periods
  - compute
  - charges
  - zero
  source:
    doc: motherduck.com/videos/from-core-to-custom-unlocking-new-possibilities-with-duckdb-extensions.md
    quote: During idle periods, compute charges are zero.
    char_start: 0
    char_end: 46
- statement: Each user or service account in MotherDuck runs on an isolated compute
    instance called a 'Duckling'.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - user
  - service
  - account
  - motherduck
  - runs
  - isolated
  - compute
  - instance
  - called
  - duckling
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: Each user or service account in MotherDuck runs on an isolated compute
      instance called a 'Duckling'.
    char_start: 0
    char_end: 100
- statement: Enterprises are jumping on the duck train due to its performance, cost-efficiency,
    and scalability.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - enterprises
  - jumping
  - duck
  - train
  - due
  - performance
  - cost
  - efficiency
  - scalability
  source:
    doc: motherduck.com/learn-more/pandas-dataframes-guide.md
    quote: Enterprises are jumping on the duck train due to its performance, cost-efficiency,
      and scalability.
    char_start: 0
    char_end: 99
- statement: For macOS users, the process is simplified through the use of Homebrew.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - macos
  - users
  - process
  - simplified
  - use
  - homebrew
  source:
    doc: motherduck.com/videos/bringing-duckdb-to-the-cloud-dual-execution-explained.md
    quote: For macOS users, the process is simplified through the use of Homebrew.
    char_start: 0
    char_end: 71
- statement: Gardyn found their MotherDuck-powered stack to be 10x more affordable
    than leading alternatives for their IoT analytics workload.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - gardyn
  - found
  - motherduck
  - powered
  - stack
  - 10x
  - affordable
  - leading
  - alternatives
  - iot
  - analytics
  - workload
  source:
    doc: motherduck.com/videos.md
    quote: Gardyn found their MotherDuck-powered stack to be [**10x more affordable**]
      than leading alternatives for their IoT analytics workload.
    char_start: 0
    char_end: 135
- statement: Gardyn scaled its data operations using MotherDuck's solutions.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - gardyn
  - scaled
  - data
  - operations
  - using
  - motherduck
  - solutions
  source:
    doc: motherduck.com/quacking-around-the-web.md
    quote: 'Cultivating Growth: How Gardyn Scaled its Data Operations'
    char_start: 0
    char_end: 57
- statement: Getting started with DuckLake is simple, even if you’re coming from an
    existing data lake setup.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - getting
  - started
  - ducklake
  - simple
  - even
  - re
  - coming
  - existing
  - data
  - lake
  - setup
  source:
    doc: motherduck.com/videos/why-dont-data-producers-pay-attention-to-how-their-data-is-used-downstream.md
    quote: Getting started with DuckLake is simple, even if you’re coming from an
      existing data lake setup.
    char_start: 0
    char_end: 96
- statement: Git-like operations for databases offer zero-copy cloning and branching.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - git
  - like
  - operations
  - databases
  - offer
  - zero
  - copy
  - cloning
  - branching
  source:
    doc: motherduck.com/quacking-around-the-web.md
    quote: Git-like operations for databases stand out as one of MotherDuck's most
      groundbreaking features.
    char_start: 0
    char_end: 96
- statement: GROUP BY aggregations in PostgreSQL can take 30+ seconds.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - group
  - aggregations
  - postgresql
  - take
  - '30'
  - seconds
  source:
    doc: motherduck.com/videos/the-surprising-birth-of-duckdb-ft-co-creator-hannes-muhleisen.md
    quote: Perfect for GROUP BY aggregations taking 30+ seconds.
    char_start: 0
    char_end: 53
- statement: Guen Prawiroatmodjo shares a talk at SciPy 2024 on how to bootstrap a
    data warehouse on your laptop using open source.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - guen
  - prawiroatmodjo
  - shares
  - talk
  - scipy
  - '2024'
  - bootstrap
  - data
  - warehouse
  - laptop
  - using
  - open
  - source
  source:
    doc: motherduck.com/videos/duckdb-dbt-accelerating-the-developer-experience-with-local-power.md
    quote: Guen Prawiroatmodjo, Software Engineer at MotherDuck, shares a talk at
      SciPy 2024 on how to bootstrap a data warehouse on your laptop using open source,
      including ETL, data pipelines, dashboard visual
    char_start: 0
    char_end: 235
- statement: Hoyt Emerson explores how DuckLake transforms data processing.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - hoyt
  - emerson
  - explores
  - ducklake
  - transforms
  - data
  - processing
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: Hoyt Emerson, The Full Data Stack, explores how this sleek lakehouse...
    char_start: 0
    char_end: 71
- statement: Jelte Fennema-Nio currently works at MotherDuck.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - jelte
  - fennema
  - nio
  - currently
  - works
  - motherduck
  source:
    doc: motherduck.com/videos.md
    quote: Jelte Fennema-Nio currently works at MotherDuck.
    char_start: 0
    char_end: 48
- statement: Managing the encryption keys within the trusted metadata catalog adds
    an extra layer of security.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - managing
  - encryption
  - keys
  - within
  - trusted
  - metadata
  - catalog
  - adds
  - extra
  - layer
  - security
  source:
    doc: motherduck.com/learn-more/partitioned-writes-parquet-ducklake.md
    quote: Managing the encryption keys within the trusted metadata catalog database
      adds an extra layer of security compared to storing keys alongside the data
      files.
    char_start: 0
    char_end: 156
- statement: Misconfiguration, not malware, is the biggest threat to your cloud data.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - misconfiguration
  - malware
  - biggest
  - threat
  - cloud
  - data
  source:
    doc: motherduck.com/privacy-policy.md
    quote: Discover why misconfiguration, not malware, is the biggest threat to your
      cloud data.
    char_start: 0
    char_end: 85
- statement: Modern data tools like dbt make managing the ETL process much more maintainable.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - modern
  - data
  - tools
  - like
  - dbt
  - make
  - managing
  - etl
  - process
  - much
  - maintainable
  source:
    doc: motherduck.com/videos/the-magic-of-duckdb-extensions-for-data-engineering-and-analytics.md
    quote: Modern data tools like dbt (data build tool) make managing this process
      much more maintainable.
    char_start: 0
    char_end: 95
- statement: Most analytical workloads can be handled efficiently on a single node
    with modern hardware.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - analytical
  - workloads
  - handled
  - efficiently
  - single
  - node
  - modern
  - hardware
  source:
    doc: motherduck.com/learn-more/fix-slow-bi-dashboards.md
    quote: It has also reinforced our core thesis that most analytical workloads can
      be handled efficiently on a single node with modern hardware.
    char_start: 0
    char_end: 135
- statement: MotherDuck and Artefact are hosting webinars on data analytics.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - artefact
  - hosting
  - webinars
  - data
  - analytics
  source:
    doc: motherduck.com/videos/what-if-sql-queries-returned-results-instantly.md
    quote: Watch this webinar with MotherDuck and Artefact for a discussion...
    char_start: 0
    char_end: 67
- statement: MotherDuck and DuckDB were built for the other 99% of us.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - duckdb
  - built
  - '99'
  - us
  source:
    doc: motherduck.com/videos/a-new-paradigm-for-data-visualization-with-just-sql-markdown.md
    quote: MotherDuck and DuckDB were built for the other 99% of us.
    char_start: 0
    char_end: 57
- statement: MotherDuck and Tasman Analytics discuss the temptation to over-engineer
    data stacks.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - tasman
  - analytics
  - discuss
  - temptation
  - over
  - engineer
  - data
  - stacks
  source:
    doc: motherduck.com/videos.md
    quote: 'Watch MotherDuck and Tasman Analytics for the antidote: a practical discussion
      of why companies try to overbuild and what they can do to resist the temptation.'
    char_start: 0
    char_end: 159
- statement: MotherDuck co-founder Ryan Boyd discusses DuckDB and AI agents/LLMs.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - co
  - founder
  - ryan
  - boyd
  - discusses
  - duckdb
  - ai
  - agents
  - llms
  source:
    doc: motherduck.com/videos.md
    quote: MotherDuck co-founder Ryan Boyd joins the Super Data Brothers show to talk
      about all things DuckDB, MotherDuck, AI agents/LLMs, hypertenancy and more.
    char_start: 0
    char_end: 150
- statement: MotherDuck continuously pushes the engine to its limits, uncovering opportunities
    for improvement.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - continuously
  - pushes
  - engine
  - limits
  - uncovering
  - opportunities
  - improvement
  source:
    doc: motherduck.com/videos/ai-powered-bi-can-llms-really-generate-your-dashboards-ft-michael-driscoll.md
    quote: As the largest production user of DuckDB, MotherDuck continuously pushes
      the engine to its limits, uncovering opportunities for improvement.
    char_start: 0
    char_end: 140
- statement: MotherDuck currently operates in the AWS us-east-1 and eu-central-1 regions.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - currently
  - operates
  - aws
  - us
  - east
  - eu
  - central
  - regions
  source:
    doc: motherduck.com/videos/duckfooding-at-motherduck.md
    quote: MotherDuck currently operates in the AWS us-east-1 and recently started
      in eu-central-1, hosted in Frankfurt.
    char_start: 0
    char_end: 109
- statement: MotherDuck directly solves the idle tax problem by replacing the provisioned
    warehouse model with per-query, usage-based compute.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - directly
  - solves
  - idle
  - tax
  - problem
  - replacing
  - provisioned
  - warehouse
  - model
  - per
  - query
  - usage
  - based
  - compute
  source:
    doc: motherduck.com/learn-more/what-is-duckdb.md
    quote: It directly solves the idle tax problem by replacing the provisioned warehouse
      model with per-query, usage-based compute.
    char_start: 0
    char_end: 121
- statement: MotherDuck eliminates infrastructure management tasks that otherwise
    require engineering time and associated salary costs.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - eliminates
  - infrastructure
  - management
  - tasks
  - otherwise
  - require
  - engineering
  - time
  - associated
  - salary
  - costs
  source:
    doc: motherduck.com/videos/why-should-you-care-about-duckdb-ft-mihai-bojin.md
    quote: MotherDuck eliminates infrastructure management tasks that otherwise require
      engineering time and associated salary costs.
    char_start: 0
    char_end: 122
- statement: MotherDuck eliminates the 'it worked on my machine' problem.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - eliminates
  - worked
  - my
  - machine
  - problem
  source:
    doc: motherduck.com/learn-more/product-analytics-motherduck-duckdb.md
    quote: MotherDuck eliminates this by using the exact same DuckDB engine both locally
      and in the cloud.
    char_start: 0
    char_end: 95
- statement: MotherDuck enables you to ship products faster, iterate more quickly,
    and compete effectively with larger, slower-moving competitors.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - enables
  - ship
  - products
  - faster
  - iterate
  - quickly
  - compete
  - effectively
  - larger
  - slower
  - moving
  - competitors
  source:
    doc: motherduck.com/videos/unfinished-business-re-inventing-modern-data-tools.md
    quote: It enables you to ship products faster, iterate more quickly, and compete
      effectively with larger, slower-moving competitors.
    char_start: 0
    char_end: 125
- statement: MotherDuck hosts educational videos on data engineering.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - hosts
  - educational
  - videos
  - data
  - engineering
  source:
    doc: motherduck.com/videos.md
    quote: MotherDuck provides video content on YouTube for educational purposes.
    char_start: 0
    char_end: 70
- statement: MotherDuck hosts webinars to educate users about DuckLake.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - hosts
  - webinars
  - educate
  - users
  - about
  - ducklake
  source:
    doc: motherduck.com/videos.md
    quote: Watch this special edition of our Getting Started with MotherDuck webinar
      where we'll cover how to use DuckLake with MotherDuck.
    char_start: 0
    char_end: 128
- statement: MotherDuck innovates in security model creation for cloud environments.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - innovates
  - security
  - model
  - creation
  - cloud
  - environments
  source:
    doc: motherduck.com/videos/duckfooding-at-motherduck.md
    quote: MotherDuck has had to innovate extensively, particularly in areas such
      as security model creation.
    char_start: 0
    char_end: 98
- statement: MotherDuck is chosen as a finalist in the GeekWire 'Next Tech Titan'
    awards.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - chosen
  - finalist
  - geekwire
  - next
  - tech
  - titan
  - awards
  source:
    doc: motherduck.com/videos/from-core-to-custom-unlocking-new-possibilities-with-duckdb-extensions.md
    quote: MotherDuck is chosen as a finalist in the GeekWire 'Next Tech Titan' awards.
    char_start: 0
    char_end: 76
- statement: MotherDuck is hosting a hands-on lab event focused on data engineering.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - hosting
  - hands
  - lab
  - event
  - focused
  - data
  - engineering
  source:
    doc: motherduck.com/learn-more/fix-slow-bi-dashboards.md
    quote: 'Hands-on Lab: Agentic Data Engineering with MotherDuck and Ascend'
    char_start: 0
    char_end: 65
- statement: MotherDuck is ideal for most startups.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - ideal
  - startups
  source:
    doc: motherduck.com/learn-more/secure-startup-data-warehouse.md
    quote: While MotherDuck is ideal for most startups...
    char_start: 0
    char_end: 46
- statement: MotherDuck offers a free tier with 10 GB storage and 10 CU hours/month.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - offers
  - free
  - tier
  - '10'
  - gb
  - storage
  - cu
  - hours
  - month
  source:
    doc: motherduck.com/learn-more/secure-startup-data-warehouse.md
    quote: Yes, 10 GB storage, 10 CU hours/month
    char_start: 0
    char_end: 37
- statement: MotherDuck offers a third way, purpose-built for the scale and agility
    of a modern startup.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - offers
  - third
  - way
  - purpose
  - built
  - scale
  - agility
  - modern
  - startup
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: MotherDuck offers a third way, purpose-built for the scale and agility
      of a modern startup.
    char_start: 0
    char_end: 91
- statement: MotherDuck opts for a simpler, more manageable security model.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - opts
  - simpler
  - manageable
  - security
  - model
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: MotherDuck deliberately opts for a simpler, more manageable security model.
    char_start: 0
    char_end: 75
- statement: MotherDuck provides a centralized Secret Manager for accessing external
    data sources.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - provides
  - centralized
  - secret
  - manager
  - accessing
  - external
  - data
  - sources
  source:
    doc: motherduck.com/videos/a-new-paradigm-for-data-visualization-with-just-sql-markdown.md
    quote: MotherDuck provides a centralized Secret Manager, co-designed with the
      DuckDB team.
    char_start: 0
    char_end: 83
- statement: MotherDuck provides a fast-paced tour of its product capabilities and
    features.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - provides
  - fast
  - paced
  - tour
  - product
  - capabilities
  - features
  source:
    doc: motherduck.com/videos.md
    quote: A duck gives you a fast-paced tour of MotherDuck product capabilities and
      features.
    char_start: 0
    char_end: 83
- statement: MotherDuck provides a highly secure environment.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - provides
  - highly
  - secure
  - environment
  source:
    doc: motherduck.com/videos/where-data-science-meets-shrek-how-buzzfeed-uses-ai.md
    quote: Yes, for most startups, MotherDuck provides a highly secure environment.
    char_start: 0
    char_end: 72
- statement: MotherDuck provides a multi-layered security model to minimize human
    error.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - provides
  - multi
  - layered
  - security
  - model
  - minimize
  - human
  - error
  source:
    doc: motherduck.com/videos/understanding-ducklake-a-table-format-with-a-modern-architecture.md
    quote: MotherDuck addresses these prevalent risks with a multi-layered security
      model designed to minimize the chance of human error.
    char_start: 0
    char_end: 126
- statement: MotherDuck provides data visualization tools including Hex and Preset.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - provides
  - data
  - visualization
  - tools
  - including
  - hex
  - preset
  source:
    doc: motherduck.com/videos.md
    quote: 'MotherDuck: @\_hex\_tech , @Preset-io & Superset.'
    char_start: 0
    char_end: 49
- statement: MotherDuck provides HIPAA Business Associate Agreements for healthcare
    customers.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - provides
  - hipaa
  - business
  - associate
  - agreements
  - healthcare
  - customers
  source:
    doc: motherduck.com/videos/4-lightning-talks-on-practical-ai-workflows-from-notion-1password-motherduck-evidence.md
    quote: It also offers HIPAA Business Associate Agreements (BAAs) for healthcare
      customers.
    char_start: 0
    char_end: 83
- statement: MotherDuck provides isolated engines per user and transactional storage
    that handles concurrent writes safely.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - provides
  - isolated
  - engines
  - per
  - user
  - transactional
  - storage
  - handles
  - concurrent
  - writes
  - safely
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: MotherDuck solves this by providing isolated engines per user and transactional
      storage that handles concurrent writes safely.
    char_start: 0
    char_end: 126
- statement: MotherDuck provides native durability with a 7-day 'Failsafe' retention
    period.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - provides
  - native
  - durability
  - day
  - failsafe
  - retention
  - period
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: MotherDuck provides native durability with a 7-day 'Failsafe' retention
      period for accidentally deleted data.
    char_start: 0
    char_end: 109
- statement: MotherDuck provides powerful functions to look inside the structure of
    your semi-structured and columnar files.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - provides
  - powerful
  - functions
  - look
  - inside
  - structure
  - semi
  - structured
  - columnar
  - files
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: MotherDuck provides powerful functions to look inside the structure of
      your semi-structured and columnar files without manually parsing them.
    char_start: 0
    char_end: 141
- statement: MotherDuck reduces the risk of misconfiguration.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - reduces
  - risk
  - misconfiguration
  source:
    doc: motherduck.com/videos/where-data-science-meets-shrek-how-buzzfeed-uses-ai.md
    quote: MotherDuck's simpler, secure-by-default model reduces the risk of misconfiguration.
    char_start: 0
    char_end: 83
- statement: MotherDuck revolutionizes the way you interact with your data, particularly
    when dealing with CSV files.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - revolutionizes
  - way
  - interact
  - data
  - particularly
  - dealing
  - csv
  - files
  source:
    doc: motherduck.com/videos/cultivating-growth-how-gardyn-scaled-its-data-operations-with-motherduck.md
    quote: In this post, we'll explore how MotherDuck, powered by DuckDB, revolutionizes
      the way you interact with your data, particularly when dealing with CSV files.
    char_start: 0
    char_end: 156
- statement: MotherDuck sidesteps complex ingestion jobs by treating an entire folder
    of files as a single, queryable database table.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - sidesteps
  - complex
  - ingestion
  - jobs
  - treating
  - entire
  - folder
  - files
  - single
  - queryable
  - database
  - table
  source:
    doc: motherduck.com/learn-more/pandas-dataframes-guide.md
    quote: MotherDuck sidesteps complex ingestion jobs by treating an entire folder
      of files as a single, queryable database table.
    char_start: 0
    char_end: 120
- statement: MotherDuck solves performance challenges with a flexible approach.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - solves
  - performance
  - challenges
  - flexible
  - approach
  source:
    doc: motherduck.com/learn-more/secure-startup-data-warehouse.md
    quote: A common challenge for startups is managing data warehouse performance
      and cost. MotherDuck solves this with a flexible approach.
    char_start: 0
    char_end: 129
- statement: MotherDuck solves this with a flexible approach that combines vertical
    instance sizing with horizontal read scaling.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - solves
  - flexible
  - approach
  - combines
  - vertical
  - instance
  - sizing
  - horizontal
  - read
  - scaling
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: MotherDuck solves this with a flexible approach that combines vertical
      instance sizing with horizontal read scaling.
    char_start: 0
    char_end: 116
- statement: MotherDuck supports standard JDBC/ODBC connections.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - supports
  - standard
  - jdbc
  - odbc
  - connections
  source:
    doc: motherduck.com/learn-more/secure-startup-data-warehouse.md
    quote: MotherDuck supports standard JDBC/ODBC connections.
    char_start: 0
    char_end: 51
- statement: MotherDuck's architecture enables server-side scanning for large datasets.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - architecture
  - enables
  - server
  - side
  - scanning
  - large
  - datasets
  source:
    doc: motherduck.com/quacking-around-the-web.md
    quote: 'MotherDuck''s architecture enables: Server-side scanning and filtering
      of massive tables'
    char_start: 0
    char_end: 87
- statement: MotherDuck's architecture inherently prevents many common causes of unexpected
    charges.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - architecture
  - inherently
  - prevents
  - many
  - common
  - causes
  - unexpected
  - charges
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: MotherDuck's architecture inherently prevents many common causes of unexpected
      charges.
    char_start: 0
    char_end: 87
- statement: MotherDuck's database-level security simplifies access control.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - database
  - level
  - security
  - simplifies
  - access
  - control
  source:
    doc: motherduck.com/learn-more/secure-startup-data-warehouse.md
    quote: MotherDuck deliberately opts for a simpler, more manageable security model.
      Access control is applied at the database level.
    char_start: 0
    char_end: 124
- statement: MotherDuck's dogfooding approach created a tight feedback loop between
    product development and real-world usage.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - dogfooding
  - approach
  - created
  - tight
  - feedback
  - loop
  - product
  - development
  - real
  - world
  - usage
  source:
    doc: motherduck.com/learn-more/fix-slow-bi-dashboards.md
    quote: For us at MotherDuck, dogfooding has proven essential in building a product
      that truly meets user needs.
    char_start: 0
    char_end: 104
- statement: MotherDuck's estimated monthly cost for the same workload is $5.87.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - estimated
  - monthly
  - cost
  - workload
  - '5.87'
  source:
    doc: motherduck.com/learn-more/hybrid-analytics-guide.md
    quote: 'Estimated Monthly Cost (@ $0.25/CU-hour, assuming 1 CU): 23.47 CU-hours
      * $0.25/CU-hour = $5.87.'
    char_start: 0
    char_end: 96
- statement: MotherDuck's free tier covers substantial usage, and costs scale gradually
    with actual growth.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - free
  - tier
  - covers
  - substantial
  - usage
  - costs
  - scale
  - gradually
  - actual
  - growth
  source:
    doc: motherduck.com/learn-more/secure-startup-data-warehouse.md
    quote: MotherDuck's free tier covers substantial usage, and costs scale gradually
      with actual growth rather than requiring large upfront commitments.
    char_start: 0
    char_end: 142
- statement: MotherDuck's Instant SQL Mode eliminates the traditional write-run-debug
    cycle.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - instant
  - sql
  - mode
  - eliminates
  - traditional
  - write
  - run
  - debug
  - cycle
  source:
    doc: motherduck.com/learn-more/star-schema-data-warehouse-guide.md
    quote: real-time query result previews eliminate the traditional write-run-debug
      cycle
    char_start: 0
    char_end: 79
- statement: MotherDuck's internal analytics stack handles about 6,000 queries daily
    across 40 scheduled jobs.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - internal
  - analytics
  - stack
  - handles
  - about
  - '000'
  - queries
  - daily
  - across
  - '40'
  - scheduled
  - jobs
  source:
    doc: motherduck.com/learn-more/fix-slow-bi-dashboards.md
    quote: The system now handles about 6,000 queries daily across 40 scheduled jobs.
    char_start: 0
    char_end: 74
- statement: MotherDuck's partnership with Hydra amplifies DuckDB's utility.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - partnership
  - hydra
  - amplifies
  - duckdb
  - utility
  source:
    doc: motherduck.com/videos/whats-new-in-data-small-data-big-impact.md
    quote: MotherDuck's partnership with other cutting-edge technologies like Hydra
      for Postgres integration further amplifies DuckDB's utility.
    char_start: 0
    char_end: 133
- statement: MotherDuck's query planner intelligently handles different scenarios.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - query
  - planner
  - intelligently
  - handles
  - different
  - scenarios
  source:
    doc: motherduck.com/learn-more/fix-slow-bi-dashboards.md
    quote: 'Here’s how MotherDuck''s query planner intelligently handles different
      scenarios:'
    char_start: 0
    char_end: 80
- statement: MotherDuck, Notion, 1Password, and Evidence use AI tools to automate
    workflows.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - notion
  - 1password
  - evidence
  - use
  - ai
  - tools
  - automate
  - workflows
  source:
    doc: motherduck.com/videos/4-lightning-talks-on-practical-ai-workflows-from-notion-1password-motherduck-evidence.md
    quote: Learn how data teams at MotherDuck, Notion, 1Password, and Evidence use
      AI tools to automate workflows.
    char_start: 0
    char_end: 103
- statement: MotherDuck’s architecture is fundamentally designed to mitigate the risk
    of vendor lock-in.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - architecture
  - fundamentally
  - designed
  - mitigate
  - risk
  - vendor
  - lock
  source:
    doc: motherduck.com/videos/where-data-science-meets-shrek-how-buzzfeed-uses-ai.md
    quote: MotherDuck’s architecture is fundamentally designed to mitigate this risk
      by using open standards and empowering local development.
    char_start: 0
    char_end: 131
- statement: MotherDuck’s query engine pushes down filters and projections to the
    file level, minimizing the amount of data read from cloud storage.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - motherduck
  - query
  - engine
  - pushes
  - down
  - filters
  - projections
  - file
  - level
  - minimizing
  - amount
  - data
  - read
  - cloud
  - storage
  source:
    doc: motherduck.com/learn-more/pandas-dataframes-guide.md
    quote: MotherDuck’s query engine pushes down filters and projections to the file
      level, minimizing the amount of data read from cloud storage.
    char_start: 0
    char_end: 135
- statement: Nathaniel Thompson gives an overview of the MotherDuck cloud data warehouse.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - nathaniel
  - thompson
  - gives
  - overview
  - motherduck
  - cloud
  - data
  - warehouse
  source:
    doc: motherduck.com/videos/simple-way-to-convert-csv-and-parquet-files.md
    quote: Produck expert Nathaniel Thompson gives an overview of the MotherDuck cloud
      data warehouse.
    char_start: 0
    char_end: 91
- statement: Pipeline runtime dropped from 24+ hours to just 10 minutes.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - pipeline
  - runtime
  - dropped
  - '24'
  - hours
  - '10'
  - minutes
  source:
    doc: motherduck.com/learn-more/fix-slow-bi-dashboards.md
    quote: Pipeline runtime dropped from 24+ hours to just 10 minutes.
    char_start: 0
    char_end: 59
- statement: Processing data locally eliminates cloud compute charges entirely during
    development and exploration phases.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - processing
  - data
  - locally
  - eliminates
  - cloud
  - compute
  - charges
  - entirely
  - development
  - exploration
  - phases
  source:
    doc: motherduck.com/videos/4-lightning-talks-on-practical-ai-workflows-from-notion-1password-motherduck-evidence.md
    quote: Processing data locally eliminates cloud compute charges entirely during
      development and exploration phases.
    char_start: 0
    char_end: 108
- statement: Serverless SQL analytics removes the burden of managing infrastructure.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - serverless
  - sql
  - analytics
  - removes
  - burden
  - managing
  - infrastructure
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: Serverless SQL analytics removes this burden entirely.
    char_start: 0
    char_end: 54
- statement: Snowflake's multi-layered cache is one of its most powerful cost-saving
    features.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - snowflake
  - multi
  - layered
  - cache
  - one
  - powerful
  - cost
  - saving
  - features
  source:
    doc: motherduck.com/videos/sql-ide-safari-harlequin-in-your-terminal.md
    quote: Snowflake's multi-layered cache is one of its most powerful cost-saving
      features.
    char_start: 0
    char_end: 81
- statement: Sometimes the best insight comes from looking at one customer.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - sometimes
  - best
  - insight
  - comes
  - looking
  - one
  - customer
  source:
    doc: motherduck.com/videos/duckdb-tutorial-for-beginners.md
    quote: 'Stancil''s point: Sometimes the best insight comes from looking at one
      customer.'
    char_start: 0
    char_end: 79
- statement: Stacksync's new MotherDuck connector allows for lightweight, in-process
    analytics and scalable cloud power.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - stacksync
  - new
  - motherduck
  - connector
  - allows
  - lightweight
  - process
  - analytics
  - scalable
  - cloud
  - power
  source:
    doc: motherduck.com/videos/ibis-one-library-to-query-any-backend.md
    quote: That's where Stacksync's new MotherDuck connector comes in, so you can
      quit ducking around with complex setups.
    char_start: 0
    char_end: 111
- statement: Startups can use a combination of MotherDuck's features to create robust,
    isolated environments.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - startups
  - use
  - combination
  - motherduck
  - features
  - create
  - robust
  - isolated
  - environments
  source:
    doc: motherduck.com/learn-more/secure-startup-data-warehouse.md
    quote: To handle use cases that traditionally require RLAC, such as multi-tenancy
      or departmental data segregation, startups can use a combination of MotherDuck's
      features.
    char_start: 0
    char_end: 165
- statement: Teams can collaborate effectively by using a central data warehouse like
    MotherDuck.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - teams
  - collaborate
  - effectively
  - using
  - central
  - data
  - warehouse
  - like
  - motherduck
  source:
    doc: motherduck.com/videos/simple-way-to-convert-csv-and-parquet-files.md
    quote: Teams can collaborate effectively by using a central data warehouse like
      MotherDuck...
    char_start: 0
    char_end: 86
- statement: The 'BI as code' workflow enables a highly efficient local development
    experience.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - bi
  - code
  - workflow
  - enables
  - highly
  - efficient
  - local
  - development
  - experience
  source:
    doc: motherduck.com/videos/why-use-duckdb-in-your-data-pipelines-ft-niels-claeys.md
    quote: One of the most powerful aspects of the 'BI as code' workflow is the local
      development experience.
    char_start: 0
    char_end: 98
- statement: The analytics operation runs at remarkably low cost due to careful engineering.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - analytics
  - operation
  - runs
  - remarkably
  - low
  - cost
  - due
  - careful
  - engineering
  source:
    doc: motherduck.com/learn-more/fix-slow-bi-dashboards.md
    quote: demonstrating the efficiency that careful engineering can achieve with
      DuckDB.
    char_start: 0
    char_end: 78
- statement: The Dual Execution model allows applications to write to both old and
    new databases simultaneously.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - dual
  - execution
  - model
  - allows
  - applications
  - write
  - both
  - old
  - new
  - databases
  - simultaneously
  source:
    doc: motherduck.com/learn-more/secure-startup-data-warehouse.md
    quote: The key to a smooth migration is MotherDuck's Dual Execution model.
    char_start: 0
    char_end: 67
- statement: The dual execution model makes it possible to balance local and cloud
    computing.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - dual
  - execution
  - model
  - makes
  - possible
  - balance
  - local
  - cloud
  - computing
  source:
    doc: motherduck.com/learn-more/self-service-analytics-startups.md
    quote: the innovative query model, known as dual execution, that makes this possible.
    char_start: 0
    char_end: 78
- statement: The dual-engine execution model optimizes query performance based on
    data locality.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - dual
  - engine
  - execution
  - model
  - optimizes
  - query
  - performance
  - based
  - data
  - locality
  source:
    doc: motherduck.com/quacking-around-the-web.md
    quote: The dual-engine execution model represents a breakthrough in query processing,
      elegantly balancing the decision of where to process queries—locally or in the
      cloud.
    char_start: 0
    char_end: 164
- statement: The expert panel discusses scaling strategies from single-node powerhouses
    to distributed architectures.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - expert
  - panel
  - discusses
  - scaling
  - strategies
  - single
  - node
  - powerhouses
  - distributed
  - architectures
  source:
    doc: motherduck.com/learn-more/no-etl-query-raw-files.md
    quote: They'll cut through the hype and discuss scaling strategies from single-node
      powerhouses to distributed architectures.
    char_start: 0
    char_end: 118
- statement: The free tier supports up to 10 GB of data with included compute each
    month.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - free
  - tier
  - supports
  - up
  - '10'
  - gb
  - data
  - included
  - compute
  - month
  source:
    doc: motherduck.com/videos/from-core-to-custom-unlocking-new-possibilities-with-duckdb-extensions.md
    quote: The free tier supports up to 10 GB of data with included compute each month.
    char_start: 0
    char_end: 76
- statement: The fundamental architecture of a traditional cloud data warehouse is
    client-server.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - fundamental
  - architecture
  - traditional
  - cloud
  - data
  - warehouse
  - client
  - server
  source:
    doc: motherduck.com/videos/duckdb-vs-pandas-vs-polars-for-python-devs.md
    quote: The fundamental architecture of a traditional cloud data warehouse is client-server.
    char_start: 0
    char_end: 84
- statement: The future of the data lake is simple, fast, and open.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - future
  - data
  - lake
  - simple
  - fast
  - open
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: The future of the data lake is simple, fast, and open. The future is DuckLake.
    char_start: 0
    char_end: 78
- statement: The isolation eliminates noisy neighbor problems.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - isolation
  - eliminates
  - noisy
  - neighbor
  - problems
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: The isolation eliminates noisy neighbor problems where one user's heavy
      query impacts others' performance.
    char_start: 0
    char_end: 106
- statement: The local-first approach provides immediate feedback needed for agile
    development.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - local
  - first
  - approach
  - provides
  - immediate
  - feedback
  - needed
  - agile
  - development
  source:
    doc: motherduck.com/learn-more/fix-slow-bi-dashboards.md
    quote: This 'local-first' approach provides the immediate feedback needed for
      agile development.
    char_start: 0
    char_end: 89
- statement: The mirrored dashboard in MotherDuck is live and updating in near real-time.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - mirrored
  - dashboard
  - motherduck
  - live
  - updating
  - near
  - real
  - time
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: The mirrored dashboard in MotherDuck is live and updating in near real-time.
    char_start: 0
    char_end: 76
- statement: The most significant risks often originate from simple, internal operational
    errors.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - significant
  - risks
  - often
  - originate
  - simple
  - internal
  - operational
  - errors
  source:
    doc: motherduck.com/privacy-policy.md
    quote: However, the most significant risks often originate from simple, internal
      operational errors.
    char_start: 0
    char_end: 93
- statement: The new data system costs roughly 5% of the old one.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - new
  - data
  - system
  - costs
  - roughly
  - old
  - one
  source:
    doc: motherduck.com/learn-more/star-schema-data-warehouse-guide.md
    quote: The bill for their MotherDuck data warehouse is approximately 20 times
      less than what they were paying AWS for their previous Postgres-based system.
    char_start: 0
    char_end: 148
- statement: The No-ETL approach used by MotherDuck removes the friction between your
    data and your decisions.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - etl
  - approach
  - used
  - motherduck
  - removes
  - friction
  - data
  - decisions
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: The modern, No-ETL approach used by MotherDuck removes the friction between
      your data and your decisions.
    char_start: 0
    char_end: 105
- statement: The platform provides clear visibility into compute seconds consumed
    and data stored.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - platform
  - provides
  - clear
  - visibility
  - compute
  - seconds
  - consumed
  - data
  - stored
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: The platform provides clear visibility into compute seconds consumed and
      data stored.
    char_start: 0
    char_end: 85
- statement: The platform's simplified pricing with free tiers and flat-rate plans
    provides more predictability than complex credit systems used elsewhere.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - platform
  - simplified
  - pricing
  - free
  - tiers
  - flat
  - rate
  - plans
  - provides
  - predictability
  - complex
  - credit
  - systems
  - used
  - elsewhere
  source:
    doc: motherduck.com/videos/why-should-you-care-about-duckdb-ft-mihai-bojin.md
    quote: The platform's simplified pricing with free tiers and flat-rate plans provides
      more predictability than complex credit systems used elsewhere.
    char_start: 0
    char_end: 142
- statement: The release enables deep and metadata-only copies between DuckLake and
    Iceberg.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - release
  - enables
  - deep
  - metadata
  - copies
  - ducklake
  - iceberg
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: The release enables deep and metadata-only copies between DuckLake and
      Iceberg via the Iceberg extension.
    char_start: 0
    char_end: 105
- statement: 'The rise of serverless architectures and hyper-fast analytical engines
    like DuckDB has created a new category: the lean, modern data warehouse.'
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - rise
  - serverless
  - architectures
  - hyper
  - fast
  - analytical
  - engines
  - like
  - duckdb
  - created
  - new
  - category
  - lean
  - modern
  - data
  - warehouse
  source:
    doc: motherduck.com/videos/how-to-bootstrap-a-data-warehouse-with-duckdb.md
    quote: 'The rise of serverless architectures and hyper-fast analytical engines
      like DuckDB has created a new category: the lean, modern data warehouse.'
    char_start: 0
    char_end: 143
- statement: The risk of vendor lock-in with MotherDuck is very low.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - risk
  - vendor
  - lock
  - motherduck
  - low
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: The risk is very low. MotherDuck is designed to prevent vendor lock-in
      through its 'Dual Execution' model.
    char_start: 0
    char_end: 106
- statement: The schema-on-read approach allows exploration and understanding of data
    before committing to a transformation pipeline.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - schema
  - read
  - approach
  - allows
  - exploration
  - understanding
  - data
  - committing
  - transformation
  - pipeline
  source:
    doc: motherduck.com/learn-more/ducklake-guide.md
    quote: The schema-on-read approach is powerful because it lets you explore and
      understand your data before committing to a rigid transformation pipeline.
    char_start: 0
    char_end: 146
- statement: The shift empowered non-technical team members.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - shift
  - empowered
  - non
  - technical
  - team
  - members
  source:
    doc: motherduck.com/learn-more/star-schema-data-warehouse-guide.md
    quote: The most profound change was the empowerment of non-technical team members.
    char_start: 0
    char_end: 75
- statement: The shift to MotherDuck delivered transformative results, enabling DoSomething
    to remain a sustainable, data-driven organization.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - shift
  - motherduck
  - delivered
  - transformative
  - results
  - enabling
  - dosomething
  - remain
  - sustainable
  - data
  - driven
  - organization
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: The shift to MotherDuck delivered transformative results, enabling DoSomething
      to remain a sustainable, data-driven organization.
    char_start: 0
    char_end: 129
- statement: The small files problem causes significant latency in lakehouse architectures.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - small
  - files
  - problem
  - causes
  - significant
  - latency
  - lakehouse
  - architectures
  source:
    doc: motherduck.com/videos/duckfooding-at-motherduck.md
    quote: The primary culprit is the [ "small files problem."]
    char_start: 0
    char_end: 52
- statement: The traditional data warehouse remains the central 'hub' or 'cold' storage
    layer.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - traditional
  - data
  - warehouse
  - remains
  - central
  - hub
  - cold
  - storage
  - layer
  source:
    doc: motherduck.com/videos/one-data-tool-with-all-its-dependencies-duckdb-and-extensions.md
    quote: the traditional data warehouse (like Snowflake, BigQuery, or Redshift)
      remains the central 'hub' or 'cold' storage layer.
    char_start: 0
    char_end: 121
- statement: This combination frees data teams from tedious maintenance.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - combination
  - frees
  - data
  - teams
  - tedious
  - maintenance
  source:
    doc: motherduck.com/videos/why-csvs-still-matter-the-indispensable-file-format.md
    quote: This combination frees data teams from tedious maintenance and unlocks
      deeper customization, transforming brittle dashboards into robust data applications.
    char_start: 0
    char_end: 155
- statement: This instant feedback loop brings SQL development in line with modern
    development practices.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - instant
  - feedback
  - loop
  - brings
  - sql
  - development
  - line
  - modern
  - practices
  source:
    doc: motherduck.com/learn-more/duckdb-vs-sqlite-databases.md
    quote: This instant feedback loop brings SQL development in line with modern development
      practices.
    char_start: 0
    char_end: 92
- statement: Today's laptops and single servers often feature dozens of cores and
    hundreds of gigabytes of RAM.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - today
  - laptops
  - single
  - servers
  - often
  - feature
  - dozens
  - cores
  - hundreds
  - gigabytes
  - ram
  source:
    doc: motherduck.com/videos/4-lightning-talks-on-practical-ai-workflows-from-notion-1password-motherduck-evidence.md
    quote: Today's laptops and single servers often feature dozens of cores and hundreds
      of gigabytes of RAM.
    char_start: 0
    char_end: 98
- statement: Traditional data warehouses are poorly suited for operational analytics
    due to high query latency and data freshness lag.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - traditional
  - data
  - warehouses
  - poorly
  - suited
  - operational
  - analytics
  - due
  - high
  - query
  - latency
  - freshness
  - lag
  source:
    doc: motherduck.com/videos/duckdb-tutorial-for-beginners.md
    quote: 'Traditional data warehouses are poorly suited for operational analytics
      for several reasons. Their high query latency means dashboards can take minutes
      to load. The data freshness lag, often measured '
    char_start: 0
    char_end: 280
- statement: Users confirm the new dashboard is significantly faster and accurate.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - users
  - confirm
  - new
  - dashboard
  - significantly
  - faster
  - accurate
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: Users confirm the new dashboard is significantly faster and accurate.
    char_start: 0
    char_end: 69
- statement: We may transfer personal information from the EEA or the UK to the U.S.
    and other third countries based on European Commission-approved or UK Government-approved
    Standard Contractual Clauses.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - transfer
  - personal
  - information
  - eea
  - uk
  - third
  - countries
  - based
  - european
  - commission
  - approved
  - government
  - standard
  - contractual
  - clauses
  source:
    doc: motherduck.com/videos/take-flight-with-dbt-and-duckdb-dropping-dev-warehouse-costs-to-zero.md
    quote: We may transfer personal information from the EEA or the UK to the U.S.
      and other third countries based on European Commission-approved or UK Government-approved
      Standard Contractual Clauses...
    char_start: 0
    char_end: 193
- statement: We store the personal information we collect as described in this Privacy
    Policy for as long as you use our Website.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - store
  - personal
  - information
  - collect
  - described
  - privacy
  - policy
  - long
  - use
  - website
  source:
    doc: motherduck.com/videos/take-flight-with-dbt-and-duckdb-dropping-dev-warehouse-costs-to-zero.md
    quote: We store the personal information we collect as described in this Privacy
      Policy for as long as you use our Website, or as necessary to fulfill the purpose(s)
      for which it was collected...
    char_start: 0
    char_end: 188
- statement: What If SQL Queries Returned Results Instantly?
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - what
  - sql
  - queries
  - returned
  - results
  - instantly
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: What If SQL Queries Returned Results Instantly?
    char_start: 0
    char_end: 47
- statement: When data is deleted, it enters a 'Failsafe' stage where it is retained
    as a system backup for 7 days.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - data
  - deleted
  - enters
  - failsafe
  - stage
  - retained
  - system
  - backup
  - days
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: When data is deleted, it enters a 'Failsafe' stage where it is retained
      as a system backup for 7 days.
    char_start: 0
    char_end: 102
- statement: With a serverless platform, you can start querying almost instantly.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - serverless
  - platform
  - start
  - querying
  - almost
  - instantly
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: With a serverless platform, you can start querying almost instantly.
    char_start: 0
    char_end: 68
- statement: With MotherDuck, you don't need a complex pipeline to do this.
  type: feature
  entity: DuckLake
  keywords:
  - feature
  - motherduck
  - don
  - need
  - complex
  - pipeline
  source:
    doc: motherduck.com/videos/duckdb-tutorial-for-beginners.md
    quote: With MotherDuck, you don't need a complex pipeline to do this.
    char_start: 0
    char_end: 62
- statement: You can achieve real-time insights without overloading your production
    systems.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - achieve
  - real
  - time
  - insights
  - without
  - overloading
  - production
  - systems
  source:
    doc: motherduck.com/videos/using-sql-in-your-data-lake-with-duckdb-iceberg-dbt-and-motherduck.md
    quote: Learn how to move from stale, batch-updated data to sub-second freshness
      without overloading your production systems.
    char_start: 0
    char_end: 117
- statement: You can quickly parse and filter even large datasets directly from your
    local machine using familiar SQL syntax.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - quickly
  - parse
  - filter
  - even
  - large
  - datasets
  - directly
  - local
  - machine
  - using
  - familiar
  - sql
  - syntax
  source:
    doc: motherduck.com/videos/cultivating-growth-how-gardyn-scaled-its-data-operations-with-motherduck.md
    quote: You'll learn how to quickly parse and filter even large datasets directly
      from your local machine, using familiar SQL syntax.
    char_start: 0
    char_end: 125
- statement: You can write a single SQL query that joins local files with data in
    cloud storage.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - write
  - single
  - sql
  - query
  - joins
  - local
  - files
  - data
  - cloud
  - storage
  source:
    doc: motherduck.com/videos/ducklake-big-data-small-coalesce-2025.md
    quote: Yes. With a hybrid analytics platform like MotherDuck, you can write a
      single SQL query that joins local files (e.g., CSVs) with data in cloud storage
      (e.g., Parquet files in S3).
    char_start: 0
    char_end: 179
- statement: You can write a single SQL query that seamlessly joins a local CSV or
    Parquet file on your laptop with a large dataset stored in the MotherDuck cloud.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - write
  - single
  - sql
  - query
  - seamlessly
  - joins
  - local
  - csv
  - parquet
  - file
  - laptop
  - large
  - dataset
  - stored
  - motherduck
  - cloud
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: Yes. This is a key innovation of the modern, hybrid data stack. With DuckDB
      and MotherDuck, you can write a single SQL query that seamlessly joins a local
      CSV or Parquet file on your laptop with a lar
    char_start: 0
    char_end: 242
- statement: You could analyze a new batch of log files locally on your laptop and
    join them against a massive historical log table stored in MotherDuck to find
    trends.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - analyze
  - new
  - batch
  - log
  - files
  - locally
  - laptop
  - join
  - them
  - against
  - massive
  - historical
  - table
  - stored
  - motherduck
  - find
  - trends
  source:
    doc: motherduck.com/quacking-around-the-web.md
    quote: You could analyze a new batch of log files locally on your laptop and join
      them against a massive historical log table stored in MotherDuck to find trends.
    char_start: 0
    char_end: 155
- statement: Your own workload is the only benchmark that truly matters.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - workload
  - benchmark
  - truly
  - matters
  source:
    doc: motherduck.com/learn-more/fix-slow-bi-dashboards.md
    quote: why your own workload is the only benchmark that truly matters.
    char_start: 0
    char_end: 63
- statement: Zero-copy database cloning for read-only access comes at no additional
    storage cost.
  type: definition
  entity: DuckLake
  keywords:
  - definition
  - zero
  - copy
  - database
  - cloning
  - read
  - access
  - comes
  - additional
  - storage
  - cost
  source:
    doc: motherduck.com/learn-more/secure-startup-data-warehouse.md
    quote: Features like zero-copy database cloning for read-only access come at no
      additional storage cost.
    char_start: 0
    char_end: 97
- statement: Ducklings are isolated, serverless compute instances for team members.
  type: definition
  entity: ducklings
  keywords:
  - definition
  - ducklings
  - isolated
  - serverless
  - compute
  - instances
  - team
  - members
  source:
    doc: motherduck.com/learn-more/hybrid-analytics-guide.md
    quote: Each team member gets their own isolated, serverless compute instance called
      a Duckling.
    char_start: 0
    char_end: 88
- statement: '''Duckplyr'' enables data analysts to perform complex transformations
    directly on their data frames.'
  type: definition
  entity: duckplyr
  keywords:
  - definition
  - duckplyr
  - enables
  - data
  - analysts
  - perform
  - complex
  - transformations
  - directly
  - frames
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2024.md
    quote: '''Duckplyr'' enables data analysts to perform complex transformations
      directly on their data frames.'
    char_start: 0
    char_end: 98
- statement: Durability guarantees that once a transaction has been successfully committed,
    its changes are permanent.
  type: definition
  entity: Durability
  keywords:
  - definition
  - durability
  - guarantees
  - transaction
  - successfully
  - committed
  - changes
  - permanent
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: Durability guarantees that once a transaction has been successfully committed,
      its changes are permanent and will survive system failures like power outages
      or server crashes.
    char_start: 0
    char_end: 175
- statement: Transactional databases are not optimized for analytical queries.
  type: definition
  entity: e-commerce application
  keywords:
  - definition
  - transactional
  - databases
  - optimized
  - analytical
  - queries
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: we quickly realize transactional databases are not optimized for these
      sorts of queries.
    char_start: 0
    char_end: 88
- statement: Countries in Eastern Europe have an average population of 5,426,538.
  type: definition
  entity: EASTERN EUROPE
  keywords:
  - definition
  - countries
  - eastern
  - europe
  - average
  - population
  - '426'
  - '538'
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: EASTERN EUROPE │             9 │ 5426538
    char_start: 0
    char_end: 40
- statement: Eclipse is used by 9.4% of developers.
  type: definition
  entity: Eclipse
  keywords:
  - definition
  - eclipse
  - used
  - '9.4'
  - developers
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: Eclipse (9.4%)
    char_start: 0
    char_end: 14
- statement: Edge Computing reduces latency and bandwidth usage, enabling faster insights
    for IoT and mobile applications.
  type: definition
  entity: Edge Computing
  keywords:
  - definition
  - edge
  - computing
  - reduces
  - latency
  - bandwidth
  - usage
  - enabling
  - faster
  - insights
  - iot
  - mobile
  - applications
  source:
    doc: motherduck.com/learn-more/data-application.md
    quote: Processing data closer to its source reduces latency and bandwidth usage,
      enabling faster insights for IoT and mobile applications.
    char_start: 0
    char_end: 131
- statement: Processing data closer to its source reduces latency and bandwidth usage,
    enabling faster insights for IoT and mobile applications.
  type: definition
  entity: Edge Computing
  keywords:
  - definition
  - processing
  - data
  - closer
  - source
  - reduces
  - latency
  - bandwidth
  - usage
  - enabling
  - faster
  - insights
  - iot
  - mobile
  - applications
  source:
    doc: motherduck.com/ecosystem.md
    quote: Edge Computing Processing data closer to its source reduces latency and
      bandwidth usage, enabling faster insights for IoT and mobile applications.
    char_start: 0
    char_end: 146
- statement: Effy Xue Li introduced innovative approaches using LLMs.
  type: definition
  entity: Effy Xue Li
  keywords:
  - definition
  - effy
  - xue
  - li
  - introduced
  - innovative
  - approaches
  - using
  - llms
  source:
    doc: motherduck.com/blog/log-processing-savings-bacalhau-motherduck.md
    quote: Effy Xue Li, PhD Intern, introduced innovative approaches through her research,
      'Towards Efficient Data Wrangling with LLMs using Code Generation'.
    char_start: 0
    char_end: 147
- statement: We compute the elapsed time running queries in each bucket.
  type: definition
  entity: Elapsed Time
  keywords:
  - definition
  - compute
  - elapsed
  - time
  - running
  - queries
  - bucket
  source:
    doc: motherduck.com/blog/redshift-files-hunt-for-big-data.md
    quote: We then figure out what percentage of queries are in each bucket. Furthermore,
      we compute the elapsed time running queries in each bucket.
    char_start: 0
    char_end: 138
- statement: The elasticity_query_task analyzes price elasticity from recent e-commerce
    data.
  type: definition
  entity: elasticity_query_task
  keywords:
  - definition
  - elasticity
  - query
  - task
  - analyzes
  - price
  - recent
  - commerce
  - data
  source:
    doc: motherduck.com/blog/estuary-streaming-cdc-replication.md
    quote: A task that analyzes price elasticity from recent e-commerce data.
    char_start: 0
    char_end: 66
- statement: The blog discusses creating a heatmap about Electric vehicle charging
    spots.
  type: definition
  entity: Electric vehicle charging spots
  keywords:
  - definition
  - blog
  - discusses
  - creating
  - heatmap
  - about
  - electric
  - vehicle
  - charging
  - spots
  source:
    doc: motherduck.com/blog/python-faker-duckdb-exploration.md
    quote: creating this heatmap about Electric vehicle charging spots using DuckDB
    char_start: 0
    char_end: 72
- statement: Elliana is building a SQLAlchemy driver for DuckDB.
  type: definition
  entity: Elliana May
  keywords:
  - definition
  - elliana
  - building
  - sqlalchemy
  - driver
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md
    quote: She's also building a SQLAlchemy driver for DuckDB.
    char_start: 0
    char_end: 51
- statement: Elliana May contributes to DuckDB.
  type: definition
  entity: Elliana May
  keywords:
  - definition
  - elliana
  - contributes
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2024.md
    quote: a contributor to DuckDB
    char_start: 0
    char_end: 23
- statement: Elliana May is a part-time contractor for DuckDB Labs.
  type: definition
  entity: Elliana May
  keywords:
  - definition
  - elliana
  - part
  - time
  - contractor
  - duckdb
  - labs
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2024.md
    quote: a part-time contractor for DuckDB Labs.
    char_start: 0
    char_end: 39
- statement: Elliana May is a Sr Software Engineer at Bankwest.
  type: definition
  entity: Elliana May
  keywords:
  - definition
  - elliana
  - sr
  - software
  - engineer
  - bankwest
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2024.md
    quote: Elliana is a Sr Software Engineer at Bankwest in Australia.
    char_start: 0
    char_end: 59
- statement: As your company matures, certain triggers justify introducing a more
    formalized EL(T) process.
  type: definition
  entity: ELT
  keywords:
  - definition
  - company
  - matures
  - certain
  - triggers
  - justify
  - introducing
  - formalized
  - el
  - process
  source:
    doc: motherduck.com/learn-more/hybrid-analytics-guide.md
    quote: However, 'No-ETL' does not mean 'Never-ETL.'
    char_start: 0
    char_end: 44
- statement: ELT allows for greater flexibility, as analysts can transform data on-demand.
  type: definition
  entity: ELT
  keywords:
  - definition
  - elt
  - allows
  - greater
  - flexibility
  - analysts
  - transform
  - data
  - demand
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part1.md
    quote: This approach allows for greater flexibility, as analysts can transform
      data on-demand and iterate on transformations without re-extracting or re-loading.
    char_start: 0
    char_end: 154
- statement: ELT is a modern data integration process that reverses the order of traditional
    ETL workflows.
  type: definition
  entity: ELT
  keywords:
  - definition
  - elt
  - modern
  - data
  - integration
  - process
  - reverses
  - order
  - traditional
  - etl
  - workflows
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part1.md
    quote: ELT (Extract, Load, Transform) is a modern data integration process that
      reverses the order of traditional ETL (Extract, Transform, Load) workflows.
    char_start: 0
    char_end: 148
- statement: ELT is particularly well-suited for cloud-based data warehouses like
    Snowflake, BigQuery, or Redshift.
  type: definition
  entity: ELT
  keywords:
  - definition
  - elt
  - particularly
  - well
  - suited
  - cloud
  - based
  - data
  - warehouses
  - like
  - snowflake
  - bigquery
  - redshift
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part1.md
    quote: ELT is particularly well-suited for cloud-based data warehouses like Snowflake,
      BigQuery, or Redshift.
    char_start: 0
    char_end: 102
- statement: Embedded analytics is a powerful differentiator for SaaS startups.
  type: feature
  entity: embedded analytics
  keywords:
  - feature
  - embedded
  - analytics
  - powerful
  - differentiator
  - saas
  - startups
  source:
    doc: motherduck.com/videos/taming-file-zoos-data-science-with-duckdb-database-files.md
    quote: Embedded analytics is a powerful differentiator for SaaS startups.
    char_start: 0
    char_end: 66
- statement: The embedding() function enables vector search in SQL.
  type: definition
  entity: embedding()
  keywords:
  - definition
  - embedding
  - function
  - enables
  - vector
  - search
  - sql
  source:
    doc: motherduck.com/blog/introducing-instant-sql.md
    quote: And, did you know that we also have an embedding() function to generate
      vector embeddings for text, enabling vector search in SQL?
    char_start: 0
    char_end: 130
- statement: The embedding() function will create an embedding for each review.
  type: definition
  entity: embedding()
  keywords:
  - definition
  - embedding
  - function
  - create
  - review
  source:
    doc: motherduck.com/blog/log-processing-savings-bacalhau-motherduck.md
    quote: The embedding() function will create an embedding for each review.
    char_start: 0
    char_end: 66
- statement: Embedding Search is crucial for semantic understanding in search queries.
  type: definition
  entity: embedding-based search
  keywords:
  - definition
  - embedding
  - search
  - crucial
  - semantic
  - understanding
  - queries
  source:
    doc: motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md
    quote: In embedding-based search, semantic understanding and similarities is key
      to ranking the documents.
    char_start: 0
    char_end: 99
- statement: The last row for Larry Mccray with employees=30618 is the only valid
    entry.
  type: definition
  entity: employees
  keywords:
  - definition
  - last
  - row
  - larry
  - mccray
  - employees
  - '30618'
  - valid
  - entry
  source:
    doc: motherduck.com/blog/duckdb-versus-pandas-versus-polars.md
    quote: the last row has cc_rec_start_date=2002-01-01 and cc_rec_end_date=NULL,
      meaning only that the last row with employees=30618 is correct
    char_start: 0
    char_end: 134
- statement: Endangered species are at risk of extinction.
  type: definition
  entity: endangered species
  keywords:
  - definition
  - endangered
  - species
  - risk
  - extinction
  source:
    doc: motherduck.com/case-studies/reflex-careers-gig-economy-retail.md
    quote: Species that are at risk of extinction.
    char_start: 0
    char_end: 39
- statement: The dataset has very little information about the species.
  type: definition
  entity: endangered species
  keywords:
  - definition
  - dataset
  - little
  - information
  - about
  - species
  source:
    doc: motherduck.com/learn-more/big-data.md
    quote: The dataset has very little information about the species.
    char_start: 0
    char_end: 58
- statement: Endeavor Labs helps organizations realize the potential of data and AI
    to power digital transformation.
  type: definition
  entity: Endeavor Labs
  keywords:
  - definition
  - endeavor
  - labs
  - helps
  - organizations
  - realize
  - potential
  - data
  - ai
  - power
  - digital
  - transformation
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: Endeavor Labs helps organizations realize the potential of data and AI
      to power digital transformation.
    char_start: 0
    char_end: 103
- statement: Enterprises struggle with change management and managing complexity in
    data.
  type: definition
  entity: enterprise data integration
  keywords:
  - definition
  - enterprises
  - struggle
  - change
  - management
  - managing
  - complexity
  - data
  source:
    doc: motherduck.com/blog/semantic-layer-duckdb-tutorial.md
    quote: lots of what enterprises struggle with in data is change management and
      managing complexity.
    char_start: 0
    char_end: 92
- statement: ENUMs are more memory-efficient than storing strings and can improve
    query performance.
  type: definition
  entity: ENUM
  keywords:
  - definition
  - enums
  - memory
  - efficient
  - storing
  - strings
  - improve
  - query
  - performance
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: ENUMs are more memory-efficient than storing strings and can improve query
      performance.
    char_start: 0
    char_end: 87
- statement: ENUMs provide type safety, ensuring that only predefined values can be
    inserted into the column.
  type: definition
  entity: ENUM
  keywords:
  - definition
  - enums
  - provide
  - type
  - safety
  - ensuring
  - predefined
  - values
  - inserted
  - column
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: ENUMs provide type safety, ensuring that only predefined values can be
      inserted into the column.
    char_start: 0
    char_end: 96
- statement: Error Logs are critical for troubleshooting failed data jobs.
  type: definition
  entity: Error Logs
  keywords:
  - definition
  - error
  - logs
  - critical
  - troubleshooting
  - failed
  - data
  - jobs
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: 'Error Logs: Critical for troubleshooting failed data jobs and pipelines.'
    char_start: 0
    char_end: 72
- statement: ESSENCE is a sponsor of the Small Data SF event.
  type: definition
  entity: Essence
  keywords:
  - definition
  - essence
  - sponsor
  - small
  - data
  - sf
  - event
  source:
    doc: motherduck.com/blog/pgduckdb-beta-release-duckdb-postgres.md
    quote: Special thanks to our Sponsors and our friends at ESSENCE for their support
      in adding 8 hands-on workshops to Small Data SF.
    char_start: 0
    char_end: 124
- statement: ESTIMATE_TYPE is a category used to differentiate types of estimates
    in the dataset.
  type: definition
  entity: ESTIMATE_TYPE
  keywords:
  - definition
  - estimate
  - type
  - category
  - used
  - differentiate
  - types
  - estimates
  - dataset
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md
    quote: A category used to differentiate types of estimates in the dataset.
    char_start: 0
    char_end: 67
- statement: CDC tools like Estuary or Streamkap monitor the database's internal transaction
    log.
  type: definition
  entity: Estuary
  keywords:
  - definition
  - cdc
  - tools
  - like
  - estuary
  - streamkap
  - monitor
  - database
  - internal
  - transaction
  - log
  source:
    doc: motherduck.com/videos/from-curiosity-to-impact-how-dosomething-democratized-data.md
    quote: CDC tools like Estuary or Streamkap monitor the database's internal transaction
      log.
    char_start: 0
    char_end: 84
- statement: Estuary can handle all kinds of integrations, whether you need real-time
    sub-second latency or batch analytics and reporting.
  type: definition
  entity: Estuary
  keywords:
  - definition
  - estuary
  - handle
  - kinds
  - integrations
  - whether
  - need
  - real
  - time
  - sub
  - second
  - latency
  - batch
  - analytics
  - reporting
  source:
    doc: motherduck.com/blog/motherduck-union-orchestration.md
    quote: Estuary can handle all kinds of integrations, whether you need real-time
      sub-second latency or batch analytics and reporting.
    char_start: 0
    char_end: 125
- statement: Estuary can integrate directly with MotherDuck-hosted databases.
  type: definition
  entity: Estuary
  keywords:
  - definition
  - estuary
  - integrate
  - directly
  - motherduck
  - hosted
  - databases
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: Data pipeline platforms like Estuary can integrate directly with MotherDuck-hosted
      databases.
    char_start: 0
    char_end: 93
- statement: Estuary intelligently handles schema evolution to minimize manual tinkering
    with data systems.
  type: definition
  entity: Estuary
  keywords:
  - definition
  - estuary
  - intelligently
  - handles
  - schema
  - evolution
  - minimize
  - manual
  - tinkering
  - data
  - systems
  source:
    doc: motherduck.com/learn-more/bigquery-alternative-motherduck.md
    quote: If your data changes, Estuary intelligently handles schema evolution to
      minimize manual tinkering with data systems.
    char_start: 0
    char_end: 116
- statement: Estuary is a platform for data streaming and change data capture (CDC).
  type: definition
  entity: Estuary
  keywords:
  - definition
  - estuary
  - platform
  - data
  - streaming
  - change
  - capture
  - cdc
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md
    quote: A platform for data streaming and change data capture (CDC).
    char_start: 0
    char_end: 60
- statement: Estuary is a reliable, low-cost way to transfer and transform data between
    systems.
  type: definition
  entity: Estuary
  keywords:
  - definition
  - estuary
  - reliable
  - low
  - cost
  - way
  - transfer
  - transform
  - data
  - systems
  source:
    doc: motherduck.com/blog/summer-data-engineering-roadmap.md
    quote: A data pipeline platform, Estuary is a reliable, low-cost way to transfer
      and transform data between systems.
    char_start: 0
    char_end: 109
- statement: Estuary requires a properly-permissioned user for Oracle database access.
  type: definition
  entity: Estuary
  keywords:
  - definition
  - estuary
  - requires
  - properly
  - permissioned
  - user
  - oracle
  - database
  - access
  source:
    doc: motherduck.com/blog/summer-data-engineering-roadmap.md
    quote: you want to have a properly-permissioned user for Estuary to access your
      database
    char_start: 0
    char_end: 81
- statement: Estuary uses an Amazon S3 bucket to stage data loads.
  type: definition
  entity: Estuary
  keywords:
  - definition
  - estuary
  - uses
  - amazon
  - s3
  - bucket
  - stage
  - data
  - loads
  source:
    doc: motherduck.com/blog/estuary-streaming-cdc-replication.md
    quote: For Estuary’s MotherDuck connector, Estuary uses an Amazon S3 bucket to
      stage data loads.
    char_start: 0
    char_end: 89
- statement: Estuary will have backfilled Motherduck and started to load the incremental
    changes.
  type: definition
  entity: Estuary
  keywords:
  - definition
  - estuary
  - backfilled
  - motherduck
  - started
  - load
  - incremental
  - changes
  source:
    doc: motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md
    quote: And that's it! Estuary will have backfilled Motherduck and started to load
      the incremental changes as well.
    char_start: 0
    char_end: 107
- statement: You need an Estuary account.
  type: requirement
  entity: Estuary
  keywords:
  - requirement
  - need
  - estuary
  - account
  source:
    doc: motherduck.com/blog/vibe-coding-sql-cursor.md
    quote: An Estuary account ( [sign up for free](https://dashboard.estuary.dev/))
    char_start: 0
    char_end: 72
- statement: Creating an optimized data layout is a data engineering task performed
    during ETL/ELT.
  type: definition
  entity: ETL
  keywords:
  - definition
  - creating
  - optimized
  - data
  - layout
  - engineering
  - task
  - performed
  - etl
  - elt
  source:
    doc: motherduck.com/blog/streamlining-ai-agents-duckdb-rag-solutions.md
    quote: Creating an optimized data layout is a data engineering task performed
      during ETL/ELT.
    char_start: 0
    char_end: 86
- statement: ETL processes are crucial for maintaining data in star schemas.
  type: definition
  entity: ETL
  keywords:
  - definition
  - etl
  - processes
  - crucial
  - maintaining
  - data
  - star
  - schemas
  source:
    doc: motherduck.com/learn-more/star-schema-data-warehouse-guide.md
    quote: This is where solid ETL/ELT processes become crucial.
    char_start: 0
    char_end: 53
- statement: ETL processes are often fraught with challenges.
  type: definition
  entity: ETL
  keywords:
  - definition
  - etl
  - processes
  - often
  - fraught
  - challenges
  source:
    doc: motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md
    quote: This route is often fraught with challenges, requiring developing and managing
      intricate ETL pipelines.
    char_start: 0
    char_end: 103
- statement: ETL stands for Extract, Transform, Load.
  type: definition
  entity: ETL
  keywords:
  - definition
  - etl
  - stands
  - extract
  - transform
  - load
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2024.md
    quote: Extract, Transform, Load - a data integration process.
    char_start: 0
    char_end: 54
- statement: Modern data platforms often use ELT instead of ETL.
  type: definition
  entity: ETL
  keywords:
  - definition
  - modern
  - data
  - platforms
  - often
  - use
  - elt
  - instead
  - etl
  source:
    doc: motherduck.com/blog/why-everybody-hates-databases.md
    quote: While traditional ETL tools like Informatica required data to be transformed
      before loading, modern data platforms often use ELT (Extract, Load, Transform)
      instead.
    char_start: 0
    char_end: 164
- statement: Transitioning data from SQL databases to graph formats involves intricate
    ETL processes.
  type: definition
  entity: ETL
  keywords:
  - definition
  - transitioning
  - data
  - sql
  - databases
  - graph
  - formats
  - involves
  - intricate
  - etl
  - processes
  source:
    doc: motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md
    quote: Transitioning data from SQL databases to graph formats involves intricate
      ETL processes that are both resource-intensive and time-consuming to establish
      and maintain.
    char_start: 0
    char_end: 166
- statement: Event-Driven Architecture focuses on producing, detecting, and reacting
    to events.
  type: definition
  entity: Event-Driven Architecture
  keywords:
  - definition
  - event
  - driven
  - architecture
  - focuses
  - producing
  - detecting
  - reacting
  - events
  source:
    doc: motherduck.com/learn-more/data-application-architecture.md
    quote: Event-Driven Architecture Focuses on producing, detecting, and reacting
      to events.
    char_start: 0
    char_end: 82
- statement: event_count is a metric representing the number of events recorded.
  type: definition
  entity: event_count
  keywords:
  - definition
  - event
  - count
  - metric
  - representing
  - number
  - events
  - recorded
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: A metric representing the number of events recorded in a specific category.
    char_start: 0
    char_end: 75
- statement: A code-based workflow allows teams to track changes in Git.
  type: definition
  entity: Evidence
  keywords:
  - definition
  - code
  - based
  - workflow
  - allows
  - teams
  - track
  - changes
  - git
  source:
    doc: motherduck.com/learn-more/self-service-analytics-startups.md
    quote: By defining reports and visualizations in code, teams can track every change
      in Git.
    char_start: 0
    char_end: 84
- statement: DuckDBstats.com combines Evidence with MotherDuck.
  type: definition
  entity: Evidence
  keywords:
  - definition
  - duckdbstats
  - com
  - combines
  - evidence
  - motherduck
  source:
    doc: motherduck.com/learn-more/hybrid-analytics-guide.md
    quote: A powerful pattern is exemplified by the DuckDBstats.com project, which
      combines Evidence with MotherDuck.
    char_start: 0
    char_end: 106
- statement: Evidence allows developers to craft dynamic data stories without extensive
    technical expertise.
  type: definition
  entity: Evidence
  keywords:
  - definition
  - evidence
  - allows
  - developers
  - craft
  - dynamic
  - data
  - stories
  - without
  - extensive
  - technical
  - expertise
  source:
    doc: motherduck.com/quacking-around-the-web.md
    quote: This simplicity in dashboard creation democratizes data visualization,
      allowing developers and analysts alike to craft dynamic data stories without
      the need for extensive technical expertise in data s
    char_start: 0
    char_end: 207
- statement: Evidence allows SQL queries to be embedded directly into markdown files.
  type: definition
  entity: Evidence
  keywords:
  - definition
  - evidence
  - allows
  - sql
  - queries
  - embedded
  - directly
  - markdown
  - files
  source:
    doc: motherduck.com/quacking-around-the-web.md
    quote: By allowing SQL queries to be embedded directly into markdown files, Evidence
      lowers the barrier to dynamic data visualization.
    char_start: 0
    char_end: 127
- statement: Evidence empowers organizations to harness the full potential of their
    data.
  type: definition
  entity: Evidence
  keywords:
  - definition
  - evidence
  - empowers
  - organizations
  - harness
  - full
  - potential
  - data
  source:
    doc: motherduck.com/quacking-around-the-web.md
    quote: The democratization of data visualization represents one of Evidence's
      most compelling contributions to the field of data science.
    char_start: 0
    char_end: 130
- statement: Evidence enables users to build sophisticated data apps using only SQL
    queries and Markdown files.
  type: definition
  entity: Evidence
  keywords:
  - definition
  - evidence
  - enables
  - users
  - build
  - sophisticated
  - data
  - apps
  - using
  - sql
  - queries
  - markdown
  - files
  source:
    doc: motherduck.com/videos/bringing-duckdb-to-the-cloud-dual-execution-explained.md
    quote: Evidence enables users to build sophisticated data apps using only SQL
      queries and Markdown files.
    char_start: 0
    char_end: 98
- statement: Evidence generates a static website consisting of HTML, CSS, and JavaScript
    files.
  type: definition
  entity: Evidence
  keywords:
  - definition
  - evidence
  - generates
  - static
  - website
  - consisting
  - html
  - css
  - javascript
  - files
  source:
    doc: motherduck.com/learn-more/hybrid-analytics-guide.md
    quote: When a project is built, Evidence generates a static website consisting
      of HTML, CSS, and JavaScript files.
    char_start: 0
    char_end: 107
- statement: Evidence generates a static website when a project is built.
  type: definition
  entity: Evidence
  keywords:
  - definition
  - evidence
  - generates
  - static
  - website
  - project
  - built
  source:
    doc: motherduck.com/videos/simple-way-to-convert-csv-and-parquet-files.md
    quote: When a project is built, Evidence generates a static website.
    char_start: 0
    char_end: 61
- statement: Evidence is an open source, code-based alternative to drag-and-drop BI
    tools.
  type: definition
  entity: Evidence
  keywords:
  - definition
  - evidence
  - open
  - source
  - code
  - based
  - alternative
  - drag
  - drop
  - bi
  - tools
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: Evidence, an open source, code-based alternative to drag-and-drop BI tools.
    char_start: 0
    char_end: 75
- statement: Evidence is an open-source framework designed to abstract away the complexities
    of web development.
  type: definition
  entity: Evidence
  keywords:
  - definition
  - evidence
  - open
  - source
  - framework
  - designed
  - abstract
  - away
  - complexities
  - web
  - development
  source:
    doc: motherduck.com/videos/bringing-duckdb-to-the-cloud-dual-execution-explained.md
    quote: Evidence is an open-source framework designed to abstract away the complexities
      of web development.
    char_start: 0
    char_end: 99
- statement: Evidence is an open-source framework for building dashboards using Markdown
    and SQL.
  type: definition
  entity: Evidence
  keywords:
  - definition
  - evidence
  - open
  - source
  - framework
  - building
  - dashboards
  - using
  - markdown
  - sql
  source:
    doc: motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud.md
    quote: Evidence is an open-source framework for building dashboards using Markdown
      and SQL.
    char_start: 0
    char_end: 84
- statement: The dashboard will be versioned and will have a clear view of the source's
    queries.
  type: definition
  entity: Evidence
  keywords:
  - definition
  - dashboard
  - versioned
  - clear
  - view
  - source
  - queries
  source:
    doc: motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud.md
    quote: It's great because it helps you enforce software engineering best practices.
      Our dashboard will be versioned.
    char_start: 0
    char_end: 109
- statement: The deployment model is inherently secure, scalable, and cost-effective.
  type: definition
  entity: Evidence
  keywords:
  - definition
  - deployment
  - model
  - inherently
  - secure
  - scalable
  - cost
  - effective
  source:
    doc: motherduck.com/learn-more/hybrid-analytics-guide.md
    quote: this model is inherently secure, scalable, and cost-effective.
    char_start: 0
    char_end: 62
- statement: The Evidence framework abstracts away complexities of web development.
  type: definition
  entity: Evidence
  keywords:
  - definition
  - evidence
  - framework
  - abstracts
  - away
  - complexities
  - web
  - development
  source:
    doc: motherduck.com/learn-more/self-service-analytics-startups.md
    quote: Evidence is an open-source framework designed to abstract away the complexities
      of web development.
    char_start: 0
    char_end: 99
- statement: This approach dramatically lowers the barrier to entry for creating custom,
    narrative-driven reports.
  type: definition
  entity: Evidence
  keywords:
  - definition
  - approach
  - dramatically
  - lowers
  - barrier
  - entry
  - creating
  - custom
  - narrative
  - driven
  - reports
  source:
    doc: motherduck.com/videos/bringing-duckdb-to-the-cloud-dual-execution-explained.md
    quote: This approach dramatically lowers the barrier to entry for creating custom,
      narrative-driven reports.
    char_start: 0
    char_end: 101
- statement: We will use Evidence, a BI-as-code tool, to create our dashboard.
  type: definition
  entity: Evidence
  keywords:
  - definition
  - use
  - evidence
  - bi
  - code
  - tool
  - create
  - dashboard
  source:
    doc: motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md
    quote: We will use Evidence, a BI-as-code tool, to create our dashboard.
    char_start: 0
    char_end: 65
- statement: Archie is building evidence.dev.
  type: definition
  entity: Evidence.dev
  keywords:
  - definition
  - archie
  - building
  - evidence
  - dev
  source:
    doc: motherduck.com/videos.md
    quote: Archie, who is building evidence.dev, will join us to share his wisdom
      on charts.
    char_start: 0
    char_end: 81
- statement: Excel is the mother of BI tools.
  type: definition
  entity: Excel
  keywords:
  - definition
  - excel
  - mother
  - bi
  - tools
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: 'Excel: Mother of BI tools.'
    char_start: 0
    char_end: 26
- statement: Excel remains the universal tool of choice in business environments.
  type: definition
  entity: Excel
  keywords:
  - definition
  - excel
  - remains
  - universal
  - tool
  - choice
  - business
  - environments
  source:
    doc: motherduck.com/blog/data-engineers-answer-10-top-reddit-questions.md
    quote: Yet this request is ubiquitous in business environments where Excel remains
      the universal tool of choice.
    char_start: 0
    char_end: 105
- statement: The newly-improved Excel extension provides support for reading and writing
    Excel files.
  type: feature
  entity: Excel
  keywords:
  - feature
  - newly
  - improved
  - excel
  - extension
  - provides
  - support
  - reading
  - writing
  - files
  source:
    doc: motherduck.com/blog/analyze-data-in-azure-with-duckdb.md
    quote: we want to highlight the newly-improved Excel extension, which now provides
      support for reading and writing Excel files.
    char_start: 0
    char_end: 120
- statement: The read_xlsx function allows for reading specific sheets and handling
    datatype issues.
  type: definition
  entity: Excel Extension
  keywords:
  - definition
  - read
  - xlsx
  - function
  - allows
  - reading
  - specific
  - sheets
  - handling
  - datatype
  - issues
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: Where this comes in handy most often with reading Excel sheet is for **(1)**
      choosing a sheet that's not the first sheet (which is the default behavior),
      and **(2)** handling datatype issues with `all
    char_start: 0
    char_end: 236
- statement: The EXPLAIN command can now be used in Jupyter notebooks to render results
    in HTML format.
  type: definition
  entity: EXPLAIN
  keywords:
  - definition
  - explain
  - command
  - now
  - used
  - jupyter
  - notebooks
  - render
  - results
  - html
  - format
  source:
    doc: motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md
    quote: when using a Jupyter notebook, the explain() method of the DuckDBPyRelation
      will automatically use the HTML format.
    char_start: 0
    char_end: 115
- statement: Explo is an embedded analytics platform that lets companies turn data
    into interactive dashboards.
  type: definition
  entity: Explo
  keywords:
  - definition
  - explo
  - embedded
  - analytics
  - platform
  - lets
  - companies
  - turn
  - data
  - interactive
  - dashboards
  source:
    doc: motherduck.com/ecosystem.md
    quote: Explo is an embedded analytics platform that lets companies turn data into
      interactive dashboards and reports inside their products.
    char_start: 0
    char_end: 132
- statement: Traditional ETL is a bottleneck for startups.
  type: definition
  entity: Extract, Transform, Load (ETL)
  keywords:
  - definition
  - traditional
  - etl
  - bottleneck
  - startups
  source:
    doc: motherduck.com/learn-more/ducklake-guide.md
    quote: you can use simple SQL to query your raw data files directly where they
      live, on your laptop or in cloud storage.
    char_start: 0
    char_end: 113
- statement: This allows easy subsequent analysis, for example, identifying the top
    scoring teams in the constructors championship each year.
  type: definition
  entity: F1 data
  keywords:
  - definition
  - allows
  - easy
  - subsequent
  - analysis
  - example
  - identifying
  - top
  - scoring
  - teams
  - constructors
  - championship
  - year
  source:
    doc: motherduck.com/blog/fabi-ai-llm-prompt-analysis.md
    quote: This allows easy subsequent analysis, for example, identifying the top
      scoring teams in the [constructors championship each year](https://en.wikipedia.org/wiki/List_of_Formula_One_World_Constructors%2
    char_start: 0
    char_end: 213
- statement: Fabi.ai has an integrated AI assistant that can write both SQL and Python.
  type: definition
  entity: Fabi.ai
  keywords:
  - definition
  - fabi
  - ai
  - integrated
  - assistant
  - write
  - both
  - sql
  - python
  source:
    doc: motherduck.com/blog/making-pyspark-code-faster-with-duckdb.md
    quote: Fabi.ai has an integrated AI assistant that can write both SQL and Python.
    char_start: 0
    char_end: 74
- statement: Fabi.ai is a platform for data analysis and visualization.
  type: definition
  entity: Fabi.ai
  keywords:
  - definition
  - fabi
  - ai
  - platform
  - data
  - analysis
  - visualization
  source:
    doc: motherduck.com/blog/fabi-ai-llm-prompt-analysis.md
    quote: Fabi.ai is a platform for data analysis and visualization.
    char_start: 0
    char_end: 58
- statement: Fabi.ai is a small language model used for sentiment analysis.
  type: definition
  entity: Fabi.ai
  keywords:
  - definition
  - fabi
  - ai
  - small
  - language
  - model
  - used
  - sentiment
  - analysis
  source:
    doc: motherduck.com/blog/fabi-ai-llm-prompt-analysis.md
    quote: 'Meet prompt(): MotherDuck’s built-in small language model'
    char_start: 0
    char_end: 57
- statement: Fabi.ai uses Plotly for creating visualizations.
  type: definition
  entity: Fabi.ai
  keywords:
  - definition
  - fabi
  - ai
  - uses
  - plotly
  - creating
  - visualizations
  source:
    doc: motherduck.com/blog/fabi-ai-llm-prompt-analysis.md
    quote: Fabi.ai uses Plotly for creating visualizations.
    char_start: 0
    char_end: 48
- statement: Fabi.ai uses SQL for querying data.
  type: definition
  entity: Fabi.ai
  keywords:
  - definition
  - fabi
  - ai
  - uses
  - sql
  - querying
  - data
  source:
    doc: motherduck.com/blog/fabi-ai-llm-prompt-analysis.md
    quote: Fabi.ai uses SQL for querying data.
    char_start: 0
    char_end: 35
- statement: You can use the Free Tier of the product for this.
  type: definition
  entity: Fabi.ai
  keywords:
  - definition
  - use
  - free
  - tier
  - product
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-four.md
    quote: You can use the Free Tier of the product for this.
    char_start: 0
    char_end: 50
- statement: FactSales captures quantitative data about each sale.
  type: definition
  entity: FactSales
  keywords:
  - definition
  - factsales
  - captures
  - quantitative
  - data
  - about
  - sale
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: 'This table records each sales line item: Purpose: Capture quantitative
      data about each sale.'
    char_start: 0
    char_end: 92
- statement: Foreign key constraints ensure referential integrity.
  type: definition
  entity: FactSales
  keywords:
  - definition
  - foreign
  - key
  - constraints
  - ensure
  - referential
  - integrity
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: These constraints explicitly define the relationships between the fact
      table and dimension tables, ensuring referential integrity.
    char_start: 0
    char_end: 130
- statement: The FactSales table holds metrics related to sales.
  type: definition
  entity: FactSales
  keywords:
  - definition
  - factsales
  - table
  - holds
  - metrics
  - related
  - sales
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: 'Now for the central table that links everything together and holds our
      metrics:'
    char_start: 0
    char_end: 79
- statement: The fake duck game allows players to compete to identify AI-generated
    ducks.
  type: definition
  entity: Fake Duck Game
  keywords:
  - definition
  - fake
  - duck
  - game
  - allows
  - players
  - compete
  - identify
  - ai
  - generated
  - ducks
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: Spot the fake (AI generated) duck to win!
    char_start: 0
    char_end: 41
- statement: Faker generates fake data for testing.
  type: definition
  entity: Faker
  keywords:
  - definition
  - faker
  - generates
  - fake
  - data
  - testing
  source:
    doc: motherduck.com/blog/getting-started-gis-duckdb.md
    quote: What generated data will you make using Faker?
    char_start: 0
    char_end: 46
- statement: Faker is a Python package for generating fake data.
  type: definition
  entity: Faker
  keywords:
  - definition
  - faker
  - python
  - package
  - generating
  - fake
  - data
  source:
    doc: motherduck.com/blog/simplifying-iot-analytics-motherduck.md
    quote: Faker is a Python package for generating fake data.
    char_start: 0
    char_end: 51
- statement: FastAPI generates semi-structured JSON data with controlled randomness
    to simulate conditions.
  type: definition
  entity: FastAPI
  keywords:
  - definition
  - fastapi
  - generates
  - semi
  - structured
  - json
  - data
  - controlled
  - randomness
  - simulate
  - conditions
  source:
    doc: motherduck.com/blog/python-faker-duckdb-exploration.md
    quote: I created a FastAPI service that generates semi-structured JSON data with
      controlled randomness.
    char_start: 0
    char_end: 96
- statement: FastAPI is a modern, fast web framework for building APIs with Python.
  type: definition
  entity: FastAPI
  keywords:
  - definition
  - fastapi
  - modern
  - fast
  - web
  - framework
  - building
  - apis
  - python
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: FastAPI is a modern, fast (high-performance), web framework for building
      APIs with Python 3.6+ based on standard Python type hints.
    char_start: 0
    char_end: 131
- statement: The fastparquet library is used to write pandas DataFrames to parquet
    files.
  type: definition
  entity: fastparquet
  keywords:
  - definition
  - fastparquet
  - library
  - used
  - write
  - pandas
  - dataframes
  - parquet
  - files
  source:
    doc: motherduck.com/blog/redshift-files-hunt-for-big-data.md
    quote: The fastparquet library is used to write pandas DataFrames to parquet files.
    char_start: 0
    char_end: 76
- statement: Feature Adoption tracks how users are adopting new features.
  type: definition
  entity: Feature Adoption
  keywords:
  - definition
  - feature
  - adoption
  - tracks
  - users
  - adopting
  - new
  - features
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: Feature Adoption
    char_start: 0
    char_end: 16
- statement: Federated queries facilitate effortless retrieval and manipulation of
    data from diverse sources.
  type: definition
  entity: federated queries
  keywords:
  - definition
  - federated
  - queries
  - facilitate
  - effortless
  - retrieval
  - manipulation
  - data
  - diverse
  - sources
  source:
    doc: motherduck.com/blog/duckdb-the-great-federator.md
    quote: Federated queries present a robust resolution to the integration challenge.
    char_start: 0
    char_end: 75
- statement: Federated queries present a robust resolution to the integration challenge.
  type: definition
  entity: federated queries
  keywords:
  - definition
  - federated
  - queries
  - present
  - robust
  - resolution
  - integration
  - challenge
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2024.md
    quote: Federated queries present a robust resolution to the integration challenge.
    char_start: 0
    char_end: 75
- statement: The feature 'feed' is used by 338 distinct users.
  type: definition
  entity: feed
  keywords:
  - definition
  - feature
  - feed
  - used
  - '338'
  - distinct
  - users
  source:
    doc: motherduck.com/learn-more/pandas-dataframes-guide.md
    quote: '338'
    char_start: 0
    char_end: 3
- statement: FFmpeg.wasm enables video transcoding and processing directly in the
    browser.
  type: definition
  entity: FFmpeg.wasm
  keywords:
  - definition
  - ffmpeg
  - wasm
  - enables
  - video
  - transcoding
  - processing
  - directly
  - browser
  source:
    doc: motherduck.com/videos/is-bi-too-big-for-small-data.md
    quote: The popular media processing library FFmpeg has been compiled to Wasm,
      enabling video transcoding and processing directly in the browser.
    char_start: 0
    char_end: 137
- statement: Figma brought Photoshop into the browser and used WebAssembly to reduce
    load time by 3x.
  type: definition
  entity: Figma
  keywords:
  - definition
  - figma
  - brought
  - photoshop
  - browser
  - used
  - webassembly
  - reduce
  - load
  - time
  - 3x
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: In 2017, they brought Photoshop into the browser and used it to reduce
      the load by 3x.
    char_start: 0
    char_end: 86
- statement: The new FILL() window function makes it easy to interpolate missing values.
  type: definition
  entity: FILL
  keywords:
  - definition
  - new
  - fill
  - window
  - function
  - makes
  - easy
  - interpolate
  - missing
  - values
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eight.md
    quote: The new FILL() window function makes it easy to interpolate missing values.
    char_start: 0
    char_end: 75
- statement: Sports movies are the most popular in the Sakila database based on rental
    counts.
  type: definition
  entity: Film Categories
  keywords:
  - definition
  - sports
  - movies
  - popular
  - sakila
  - database
  - based
  - rental
  - counts
  source:
    doc: motherduck.com/blog/data-warehouse-feature-roundup-dec-2024.md
    quote: It looks like Sports movies are the most popular.
    char_start: 0
    char_end: 49
- statement: Good FinOps practices include alerting to catch unexpected spend early.
  type: definition
  entity: FinOps
  keywords:
  - definition
  - good
  - finops
  - practices
  - include
  - alerting
  - catch
  - unexpected
  - spend
  - early
  source:
    doc: motherduck.com/blog/data-warehouse-feature-roundup-oct-2024.md
    quote: 'Good FinOps practices: alerting to catch unexpected spend early.'
    char_start: 0
    char_end: 64
- statement: FinQore transformed 8-hour financial data pipelines into 8-minute automated
    workflows.
  type: definition
  entity: FinQore
  keywords:
  - definition
  - finqore
  - transformed
  - hour
  - financial
  - data
  - pipelines
  - minute
  - automated
  - workflows
  source:
    doc: motherduck.com/learn-more/bigquery-alternative-motherduck.md
    quote: Our data pipelines used to take eight hours. Now they’re taking eight minutes.
    char_start: 0
    char_end: 78
- statement: FinQore uses MotherDuck for everything on the front end.
  type: definition
  entity: FinQore
  keywords:
  - definition
  - finqore
  - uses
  - motherduck
  - everything
  - front
  - end
  source:
    doc: motherduck.com/learn-more/bigquery-alternative-motherduck.md
    quote: We use MotherDuck for everything on the front end.
    char_start: 0
    char_end: 50
- statement: Our data pipelines used to take eight hours. Now they're taking eight
    minutes.
  type: definition
  entity: FinQore
  keywords:
  - definition
  - data
  - pipelines
  - used
  - take
  - eight
  - hours
  - now
  - re
  - taking
  - minutes
  source:
    doc: motherduck.com/blog/analyze-data-in-azure-with-duckdb.md
    quote: Our data pipelines used to take eight hours. Now they're taking eight minutes,
      and I see a world where they take eight seconds.
    char_start: 0
    char_end: 127
- statement: Fire is used for CLI.
  type: definition
  entity: Fire
  keywords:
  - definition
  - fire
  - used
  - cli
  source:
    doc: motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md
    quote: We also saw interesting libraries like fire for CLI.
    char_start: 0
    char_end: 52
- statement: Fire will automatically parse any CLI parameters and see if they match
    the expected PypiJobParameters model.
  type: definition
  entity: Fire
  keywords:
  - definition
  - fire
  - automatically
  - parse
  - any
  - cli
  - parameters
  - see
  - match
  - expected
  - pypijobparameters
  - model
  source:
    doc: motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md
    quote: The beauty of this is that Fire will automatically parse any CLI parameters
      (with `--`) and see if they match the expected `PypiJobParameters` model.
    char_start: 0
    char_end: 149
- statement: Firebolt is for high-concurrency, sub-second analytics at scale.
  type: definition
  entity: Firebolt
  keywords:
  - definition
  - firebolt
  - high
  - concurrency
  - sub
  - second
  - analytics
  - scale
  source:
    doc: motherduck.com/learn-more/secure-startup-data-warehouse.md
    quote: High-concurrency, sub-second analytics at scale.
    char_start: 0
    char_end: 48
- statement: The Firefox extension displays the schema of Parquet files when hovered
    over.
  type: definition
  entity: Firefox extension
  keywords:
  - definition
  - firefox
  - extension
  - displays
  - schema
  - parquet
  - files
  - hovered
  - over
  source:
    doc: motherduck.com/blog/motherduck-kestra-etl-pipelines.md
    quote: we have created a Firefox extension that displays the schema of Parquet
      files when you hover your mouse over them
    char_start: 0
    char_end: 113
- statement: About 30% of most analytics workloads can be attributed to data ingest.
  type: definition
  entity: Fivetran
  keywords:
  - definition
  - about
  - '30'
  - analytics
  - workloads
  - attributed
  - data
  - ingest
  source:
    doc: motherduck.com/blog/duckdb-wasm-in-browser.md
    quote: about 30% of most analytics workloads can be attributed to data ingest.
    char_start: 0
    char_end: 71
- statement: Fivetran automates the process of extracting, loading, and transforming
    data from various sources into your data warehouse.
  type: definition
  entity: Fivetran
  keywords:
  - definition
  - fivetran
  - automates
  - process
  - extracting
  - loading
  - transforming
  - data
  - various
  - sources
  - warehouse
  source:
    doc: motherduck.com/hack-night.md
    quote: Fivetran is a data integration tool that automates the process of extracting,
      loading, and transforming data from various sources into your data warehouse.
    char_start: 0
    char_end: 155
- statement: Fivetran became the largest single line item in their data budget.
  type: definition
  entity: Fivetran
  keywords:
  - definition
  - fivetran
  - became
  - largest
  - single
  - line
  - item
  - data
  - budget
  source:
    doc: motherduck.com/learn-more/secure-startup-data-warehouse.md
    quote: Fivetran, used to ingest massive volumes of web event data... became the
      'largest single line item' in their data budget.
    char_start: 0
    char_end: 121
- statement: Fivetran integrates with MotherDuck by seamlessly connecting to it as
    a destination for data ingestion.
  type: integration
  entity: Fivetran
  keywords:
  - integration
  - fivetran
  - integrates
  - motherduck
  - seamlessly
  - connecting
  - destination
  - data
  - ingestion
  source:
    doc: motherduck.com/hack-night.md
    quote: Fivetran integrates with MotherDuck by seamlessly connecting to it as a
      destination for data ingestion.
    char_start: 0
    char_end: 103
- statement: Fivetran offers an extensive array of integrations spanning databases,
    file formats, and APIs.
  type: definition
  entity: Fivetran
  keywords:
  - definition
  - fivetran
  - offers
  - extensive
  - array
  - integrations
  - spanning
  - databases
  - file
  - formats
  - apis
  source:
    doc: motherduck.com/blog/motherduck-data-warehouse.md
    quote: Fivetran offers an extensive array of integrations spanning databases,
      file formats, and APIs.
    char_start: 0
    char_end: 94
- statement: Fivetran powers 5,000 customers.
  type: definition
  entity: Fivetran
  keywords:
  - definition
  - fivetran
  - powers
  - '000'
  - customers
  source:
    doc: motherduck.com/blog/announcing-motherduck-general-availability-data-warehousing-with-duckdb.md
    quote: Fivetran is the leader in data integration for the modern data stack, powering
      5,000 customers.
    char_start: 0
    char_end: 95
- statement: The function fix_single_line is used by FixIt to apply fixes.
  type: definition
  entity: fix_single_line
  keywords:
  - definition
  - function
  - fix
  - single
  - line
  - used
  - fixit
  - apply
  - fixes
  source:
    doc: motherduck.com/blog/duckdb-versus-pandas-versus-polars.md
    quote: The function fix_single_line is used by FixIt to apply fixes.
    char_start: 0
    char_end: 61
- statement: FixIt collapses all those tedious error-fixing steps into one.
  type: definition
  entity: FixIt
  keywords:
  - definition
  - fixit
  - collapses
  - tedious
  - error
  - fixing
  - steps
  - one
  source:
    doc: motherduck.com/blog/introducing-fixit-ai-sql-error-fixer.md
    quote: FixIt collapses all those tedious error-fixing steps into one.
    char_start: 0
    char_end: 62
- statement: FixIt does not do well in cases where your query is fundamentally wrong.
  type: definition
  entity: FixIt
  keywords:
  - definition
  - fixit
  - well
  - cases
  - query
  - fundamentally
  - wrong
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: Of course, FixIt does not do well in cases where your query is fundamentally
      wrong.
    char_start: 0
    char_end: 83
- statement: FixIt drastically reduces the cost of data work when queries are correct.
  type: definition
  entity: FixIt
  keywords:
  - definition
  - fixit
  - drastically
  - reduces
  - cost
  - data
  - work
  - queries
  - correct
  source:
    doc: motherduck.com/blog/duckdb-versus-pandas-versus-polars.md
    quote: DuckDB already drastically reduces this cost when queries are correct;
      we want FixIt to also feel just as effortless when queries have errors.
    char_start: 0
    char_end: 142
- statement: FixIt excels at simple one-line fixes, generating one line of SQL at
    a time.
  type: definition
  entity: FixIt
  keywords:
  - definition
  - fixit
  - excels
  - simple
  - one
  - line
  - fixes
  - generating
  - sql
  - time
  source:
    doc: motherduck.com/blog/duckdb-versus-pandas-versus-polars.md
    quote: Because FixIt excels at simple one-line fixes, it only needs to generate
      one line of SQL at a time.
    char_start: 0
    char_end: 99
- statement: FixIt helps you resolve common SQL errors by offering fixes in-line.
  type: definition
  entity: FixIt
  keywords:
  - definition
  - fixit
  - helps
  - resolve
  - common
  - sql
  - errors
  - offering
  - fixes
  - line
  source:
    doc: motherduck.com/blog/introducing-fixit-ai-sql-error-fixer.md
    quote: FixIt helps you resolve common SQL errors by offering fixes in-line.
    char_start: 0
    char_end: 68
- statement: FixIt is a feature within the MotherDuck UI.
  type: definition
  entity: FixIt
  keywords:
  - definition
  - fixit
  - feature
  - within
  - motherduck
  - ui
  source:
    doc: motherduck.com/blog/duckdb-versus-pandas-versus-polars.md
    quote: FixIt is a feature within the MotherDuck UI.
    char_start: 0
    char_end: 44
- statement: FixIt is a powerful yet non-intrusive improvement to your existing workflow.
  type: definition
  entity: FixIt
  keywords:
  - definition
  - fixit
  - powerful
  - yet
  - non
  - intrusive
  - improvement
  - existing
  - workflow
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: FixIt is a powerful yet non-intrusive improvement to your existing workflow.
    char_start: 0
    char_end: 76
- statement: FixIt is an AI tool designed to correct SQL errors.
  type: definition
  entity: FixIt
  keywords:
  - definition
  - fixit
  - ai
  - tool
  - designed
  - correct
  - sql
  - errors
  source:
    doc: motherduck.com/blog/ducklake-motherduck.md
    quote: FixIt is an AI tool designed to correct SQL errors.
    char_start: 0
    char_end: 51
- statement: FixIt is easier for users to validate changes to a single line compared
    to a completely rewritten query.
  type: definition
  entity: FixIt
  keywords:
  - definition
  - fixit
  - easier
  - users
  - validate
  - changes
  - single
  - line
  - compared
  - completely
  - rewritten
  - query
  source:
    doc: motherduck.com/blog/duckdb-versus-pandas-versus-polars.md
    quote: FixIt’s simplicity gives it another big advantage – it is a lot easier
      for users to validate changes to a single line compared to a completely rewritten
      query.
    char_start: 0
    char_end: 159
- statement: FixIt is fast.
  type: feature
  entity: FixIt
  keywords:
  - feature
  - fixit
  - fast
  source:
    doc: motherduck.com/blog/duckdb-versus-pandas-versus-polars.md
    quote: FixIt is fast.
    char_start: 0
    char_end: 14
- statement: FixIt strikes a nice balance between being actually useful for everyday
    SQL work, and fairly novel low-latency experience.
  type: definition
  entity: FixIt
  keywords:
  - definition
  - fixit
  - strikes
  - nice
  - balance
  - actually
  - useful
  - everyday
  - sql
  - work
  - fairly
  - novel
  - low
  - latency
  - experience
  source:
    doc: motherduck.com/blog/introducing-fixit-ai-sql-error-fixer.md
    quote: We think FixIt strikes a nice balance between being actually useful for
      everyday SQL work, and fairly novel low-latency experience.
    char_start: 0
    char_end: 131
- statement: FixIt uses a large language model (LLM) to generate suggestions.
  type: definition
  entity: FixIt
  keywords:
  - definition
  - fixit
  - uses
  - large
  - language
  - model
  - llm
  - generate
  - suggestions
  source:
    doc: motherduck.com/blog/duckdb-versus-pandas-versus-polars.md
    quote: FixIt uses a large language model (LLM) to generate suggestions.
    char_start: 0
    char_end: 64
- statement: FixIt will correct mistakes in your SQL queries based on the schema and
    DuckDB syntax.
  type: definition
  entity: FixIt
  keywords:
  - definition
  - fixit
  - correct
  - mistakes
  - sql
  - queries
  - based
  - schema
  - duckdb
  - syntax
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md
    quote: FixIt will correct mistakes in your SQL queries based on the schema and
      DuckDB syntax.
    char_start: 0
    char_end: 86
- statement: FixIt will only fix whatever line it thinks will resolve your SQL error.
  type: definition
  entity: FixIt
  keywords:
  - definition
  - fixit
  - fix
  - whatever
  - line
  - thinks
  - resolve
  - sql
  - error
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: FixIt will only fix whatever line it thinks will resolve your SQL error.
    char_start: 0
    char_end: 72
- statement: It's easy to verify the fix, making it more trustworthy.
  type: feature
  entity: FixIt
  keywords:
  - feature
  - easy
  - verify
  - fix
  - making
  - trustworthy
  source:
    doc: motherduck.com/blog/duckdb-versus-pandas-versus-polars.md
    quote: It's easy to verify the fix, making it more trustworthy.
    char_start: 0
    char_end: 56
- statement: Users are more likely to comprehend and accept small suggestions.
  type: definition
  entity: FixIt
  keywords:
  - definition
  - users
  - likely
  - comprehend
  - accept
  - small
  - suggestions
  source:
    doc: motherduck.com/blog/duckdb-versus-pandas-versus-polars.md
    quote: By providing small suggestions, users are much more likely to both comprehend
      and accept them.
    char_start: 0
    char_end: 94
- statement: FixIt AI is an AI-powered query correction feature in MotherDuck.
  type: definition
  entity: FixIt AI
  keywords:
  - definition
  - fixit
  - ai
  - powered
  - query
  - correction
  - feature
  - motherduck
  source:
    doc: motherduck.com/videos.md
    quote: FixIt AI-powered query correction
    char_start: 0
    char_end: 33
- statement: Flexibility allows systems to adapt to changing business requirements.
  type: definition
  entity: Flexibility
  keywords:
  - definition
  - flexibility
  - allows
  - systems
  - adapt
  - changing
  - business
  - requirements
  source:
    doc: motherduck.com/case-studies/atm-com-analytics-costs-sql-expressibility.md
    quote: Flexibility Create modular architectures that can adapt to changing business
      requirements and technological advancements.
    char_start: 0
    char_end: 121
- statement: Flexibility is the ability to adapt to changing requirements and environments.
  type: definition
  entity: Flexibility
  keywords:
  - definition
  - flexibility
  - ability
  - adapt
  - changing
  - requirements
  - environments
  source:
    doc: motherduck.com/learn-more/data-application-architecture.md
    quote: Flexibility ...
    char_start: 0
    char_end: 15
- statement: Flight RPC is built on top of gRPC.
  type: definition
  entity: Flight RPC
  keywords:
  - definition
  - flight
  - rpc
  - built
  - top
  - grpc
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-five.md
    quote: The flight protocol acts as an intermediate layer between different clients
      and the DuckDB Server instead of directly accessing DuckDB.
    char_start: 0
    char_end: 135
- statement: Flight SQL can speed up how you serve data with DuckDB.
  type: definition
  entity: Flight SQL
  keywords:
  - definition
  - flight
  - sql
  - speed
  - up
  - serve
  - data
  - duckdb
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: Understand how Flight SQL can speed up how your serve data with DuckDB
    char_start: 0
    char_end: 70
- statement: Flight SQL eliminates data format tax.
  type: performance
  entity: Flight SQL
  keywords:
  - performance
  - flight
  - sql
  - eliminates
  - data
  - format
  - tax
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: Zero data format tax → Arrow all the way down means no more format ping-pong
    char_start: 0
    char_end: 76
- statement: Flight SQL has a median round trip time of 18 ms.
  type: definition
  entity: Flight SQL
  keywords:
  - definition
  - flight
  - sql
  - median
  - round
  - trip
  - time
  - '18'
  - ms
  source:
    doc: motherduck.com/blog/flight-sql-vs-rest-vs-jdbc.md
    quote: Flight SQL | 18 ms | Arrow IPC (wow) | 20+ Gb/s
    char_start: 0
    char_end: 47
- statement: Flight SQL is the fastest, cleanest, most developer-friendly way to serve
    columnar data over the wire in 2025.
  type: definition
  entity: Flight SQL
  keywords:
  - definition
  - flight
  - sql
  - fastest
  - cleanest
  - developer
  - friendly
  - way
  - serve
  - columnar
  - data
  - over
  - wire
  - '2025'
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: It's just the fastest, cleanest, most developer-friendly way to serve columnar
      data over the wire in 2025.
    char_start: 0
    char_end: 106
- statement: Flight SQL powers real-time pipelines without breaking a sweat.
  type: definition
  entity: Flight SQL
  keywords:
  - definition
  - flight
  - sql
  - powers
  - real
  - time
  - pipelines
  - without
  - breaking
  - sweat
  source:
    doc: motherduck.com/blog/six-reasons-duckdb-slaps.md
    quote: how Flight SQL powers real-time pipelines without breaking a sweat.
    char_start: 0
    char_end: 67
- statement: Flight SQL reduces CPU overhead by 95%.
  type: performance
  entity: Flight SQL
  keywords:
  - performance
  - flight
  - sql
  - reduces
  - cpu
  - overhead
  - '95'
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: 95% less CPU overhead → Your machines can focus on compute, not conversion
    char_start: 0
    char_end: 74
- statement: Flight SQL takes Arrow Flight and slaps SQL semantics on it.
  type: definition
  entity: Flight SQL
  keywords:
  - definition
  - flight
  - sql
  - takes
  - arrow
  - slaps
  - semantics
  source:
    doc: motherduck.com/blog/flight-sql-vs-rest-vs-jdbc.md
    quote: Flight SQL takes Arrow Flight and slaps SQL semantics on it.
    char_start: 0
    char_end: 60
- statement: FlockMTL allows resource independence when updating models or prompts
    without changing application logic.
  type: definition
  entity: FlockMTL
  keywords:
  - definition
  - flockmtl
  - allows
  - resource
  - independence
  - updating
  - models
  - prompts
  - without
  - changing
  - application
  - logic
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md
    quote: The extension introduces two new first-class schema objects — MODEL and
      PROMPT — allowing resource independence when updating models or prompts without
      changing application logic.
    char_start: 0
    char_end: 179
- statement: FlockMTL introduces model-driven scalar and aggregate functions that
    enable SQL queries to perform semantic operations.
  type: definition
  entity: FlockMTL
  keywords:
  - definition
  - flockmtl
  - introduces
  - model
  - driven
  - scalar
  - aggregate
  - functions
  - enable
  - sql
  - queries
  - perform
  - semantic
  - operations
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md
    quote: FlockMTL introduces model-driven scalar and aggregate functions that enable
      SQL queries to perform semantic operations like classification, summarization,
      and re-ranking using LLMs.
    char_start: 0
    char_end: 181
- statement: Alibaba showcased Flux, a cloud-native workload auto-scaling platform
    designed for AnalyticDB.
  type: definition
  entity: Flux
  keywords:
  - definition
  - alibaba
  - showcased
  - flux
  - cloud
  - native
  - workload
  - auto
  - scaling
  - platform
  - designed
  - analyticdb
  source:
    doc: motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md
    quote: Alibaba showcased Flux, a cloud-native workload auto-scaling platform designed
      for AnalyticDB.
    char_start: 0
    char_end: 94
- statement: Flyte allows users to easily handle scalability, concurrency and resource
    requirements of workloads using its DuckDB plugin.
  type: definition
  entity: Flyte
  keywords:
  - definition
  - flyte
  - allows
  - users
  - easily
  - handle
  - scalability
  - concurrency
  - resource
  - requirements
  - workloads
  - using
  - duckdb
  - plugin
  source:
    doc: motherduck.com/blog/motherduck-union-orchestration.md
    quote: Flyte fits in here nicely, allowing users to easily handle scalability,
      concurrency and resource requirements of workloads using its DuckDB plugin.
    char_start: 0
    char_end: 147
- statement: Flyte is a cloud-native workflow automation platform for data and ML
    workflows.
  type: definition
  entity: Flyte
  keywords:
  - definition
  - flyte
  - cloud
  - native
  - workflow
  - automation
  - platform
  - data
  - ml
  - workflows
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: A cloud-native workflow automation platform for data and ML workflows.
    char_start: 0
    char_end: 70
- statement: The Flyte DuckDB plugin with MotherDuck integration is designed to be
    intuitive and easy to use.
  type: definition
  entity: Flyte
  keywords:
  - definition
  - flyte
  - duckdb
  - plugin
  - motherduck
  - integration
  - designed
  - intuitive
  - easy
  - use
  source:
    doc: motherduck.com/blog/motherduck-union-orchestration.md
    quote: The new Flyte DuckDB plugin with MotherDuck integration is designed to
      be intuitive and easy to use.
    char_start: 0
    char_end: 100
- statement: Folium is a Python wrapper for Leaflet.js that creates interactive maps
    with minimal code.
  type: definition
  entity: Folium
  keywords:
  - definition
  - folium
  - python
  - wrapper
  - leaflet
  - js
  - creates
  - interactive
  - maps
  - minimal
  - code
  source:
    doc: motherduck.com/blog/motherduck-duckdb-dbt.md
    quote: 'Folium: Python wrapper for Leaflet.js that creates interactive maps with
      minimal code'
    char_start: 0
    char_end: 85
- statement: Foreign Data Wrappers are used to achieve federated queries.
  type: definition
  entity: Foreign Data Wrappers
  keywords:
  - definition
  - foreign
  - data
  - wrappers
  - used
  - achieve
  - federated
  - queries
  source:
    doc: motherduck.com/blog/duckdb-the-great-federator.md
    quote: Achieving such queries often involves the utilization of addons or extensions
      known as Foreign Data Wrappers.
    char_start: 0
    char_end: 109
- statement: Foreign Data Wrappers eliminate the necessity for intricate ETL procedures
    or data migrations.
  type: definition
  entity: Foreign Data Wrappers
  keywords:
  - definition
  - foreign
  - data
  - wrappers
  - eliminate
  - necessity
  - intricate
  - etl
  - procedures
  - migrations
  source:
    doc: motherduck.com/blog/duckdb-the-great-federator.md
    quote: perspective eliminates the necessity for intricate ETL procedures or data
      migrations.
    char_start: 0
    char_end: 85
- statement: Forking allows creating a new database instance from an existing snapshot.
  type: definition
  entity: Forking
  keywords:
  - definition
  - forking
  - allows
  - creating
  - new
  - database
  - instance
  - existing
  - snapshot
  source:
    doc: motherduck.com/blog/announcing-motherduck-general-availability-data-warehousing-with-duckdb.md
    quote: we can implement 'forking' a database by applying a fixed snapshot.
    char_start: 0
    char_end: 67
- statement: Foursquare OS Places dataset is mentioned in the context of geospatial
    data.
  type: definition
  entity: Foursquare
  keywords:
  - definition
  - foursquare
  - os
  - places
  - dataset
  - mentioned
  - context
  - geospatial
  - data
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: Shifting to the released dataset of Foursquare OS Places.
    char_start: 0
    char_end: 57
- statement: Foursquare provides the SQLRooms framework.
  type: definition
  entity: Foursquare
  keywords:
  - definition
  - foursquare
  - provides
  - sqlrooms
  - framework
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eleven.md
    quote: we explore Foursquare's SQLRooms framework
    char_start: 0
    char_end: 42
- statement: The AI generates a correct SQL query for restaurants in Oakland, CA.
  type: definition
  entity: Foursquare
  keywords:
  - definition
  - ai
  - generates
  - correct
  - sql
  - query
  - restaurants
  - oakland
  - ca
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: Give me a SQL query for restaurants in Oakland, CA.
    char_start: 0
    char_end: 51
- statement: The count query on Foursquare OS Places dataset returned 104588312 records.
  type: definition
  entity: Foursquare
  keywords:
  - definition
  - count
  - query
  - foursquare
  - os
  - places
  - dataset
  - returned
  - '104588312'
  - records
  source:
    doc: motherduck.com/blog/read-scaling-preview.md
    quote: │    104588312 │
    char_start: 0
    char_end: 16
- statement: The fsq_os_places table contains place data.
  type: definition
  entity: fsq_os_places
  keywords:
  - definition
  - fsq
  - os
  - places
  - table
  - contains
  - place
  - data
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: D show tables; fsq_os_places
    char_start: 0
    char_end: 28
- statement: Full Text Search is effective for exact keyword matching.
  type: definition
  entity: Full Text Search
  keywords:
  - definition
  - full
  - text
  - search
  - effective
  - exact
  - keyword
  - matching
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: Lexical searches like Full Text Search are very effective in achieving
      this.
    char_start: 0
    char_end: 76
- statement: 'The typical data engineering lifecycle involves several stages: ingestion,
    transformation, storage, serving, and finally, analysis.'
  type: definition
  entity: Fundamentals of Data Engineering
  keywords:
  - definition
  - typical
  - data
  - engineering
  - lifecycle
  - involves
  - several
  - stages
  - ingestion
  - transformation
  - storage
  - serving
  - finally
  - analysis
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: 'The typical data engineering lifecycle involves several stages: ingestion,
      transformation, storage, serving, and finally, analysis as defined in the excellent
      book of Fundamentals of Data Engineering.'
    char_start: 0
    char_end: 200
- statement: The book 'Fundamentals of Metadata Management' discusses metadata in
    a deeper way.
  type: definition
  entity: Fundamentals of Metadata Management
  keywords:
  - definition
  - book
  - fundamentals
  - metadata
  - management
  - discusses
  - deeper
  - way
  source:
    doc: motherduck.com/blog/search-using-duckdb-part-2.md
    quote: see the book Fundamentals of Metadata Management by Ole Olesen-Bagneux
      that talks about metadata in a deeper way
    char_start: 0
    char_end: 112
- statement: galileo.world adopts a dual execution engine.
  type: definition
  entity: Galileo.world
  keywords:
  - definition
  - galileo
  - world
  - adopts
  - dual
  - execution
  - engine
  source:
    doc: motherduck.com/blog/introducing-motherduck-for-business-analytics.md
    quote: In order to display big datasets and still maintain analytical fidelity
      to the original data, galileo.world adopts a dual execution engine.
    char_start: 0
    char_end: 139
- statement: Galileo.world allows loading various data formats directly in the browser.
  type: feature
  entity: Galileo.world
  keywords:
  - feature
  - galileo
  - world
  - allows
  - loading
  - various
  - data
  - formats
  - directly
  - browser
  source:
    doc: motherduck.com/blog/motherduck-window-functions-in-sql.md
    quote: 'Simple file input: Load Parquet, GeoJSON, CSV, KML, SHP — directly in
      the browser'
    char_start: 0
    char_end: 81
- statement: Galileo.world integrates geospatial data with DuckDB.
  type: definition
  entity: Galileo.world
  keywords:
  - definition
  - galileo
  - world
  - integrates
  - geospatial
  - data
  - duckdb
  source:
    doc: motherduck.com/blog/log-processing-savings-bacalhau-motherduck.md
    quote: Galileo.world, a platform that integrates geospatial data with DuckDB.
    char_start: 0
    char_end: 70
- statement: Galileo.world is private by design, running everything in the browser.
  type: feature
  entity: Galileo.world
  keywords:
  - feature
  - galileo
  - world
  - private
  - design
  - running
  - everything
  - browser
  source:
    doc: motherduck.com/blog/motherduck-window-functions-in-sql.md
    quote: 'Galileo.world’s key features: - Private by design: Everything runs in
      your browser — no data leaves unless you share.'
    char_start: 0
    char_end: 117
- statement: Galileo.world is revolutionizing geospatial analysis.
  type: definition
  entity: Galileo.world
  keywords:
  - definition
  - galileo
  - world
  - revolutionizing
  - geospatial
  - analysis
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2024.md
    quote: Discover how Galileo.world is revolutionizing geospatial analysis.
    char_start: 0
    char_end: 66
- statement: Galileo.world leverages MotherDuck’s infrastructure for bigger datasets.
  type: definition
  entity: Galileo.world
  keywords:
  - definition
  - galileo
  - world
  - leverages
  - motherduck
  - infrastructure
  - bigger
  - datasets
  source:
    doc: motherduck.com/blog/log-processing-savings-bacalhau-motherduck.md
    quote: Galileo.world takes advantage of DuckDB-Wasm’s capabilities of running
      queries directly in the browser and MotherDuck’s infrastructure to leverage
      performance for bigger datasets.
    char_start: 0
    char_end: 179
- statement: The combination of MotherDuck and galileo.world is a powerful duo for
    data analysis.
  type: definition
  entity: Galileo.world
  keywords:
  - definition
  - combination
  - motherduck
  - galileo
  - world
  - powerful
  - duo
  - data
  - analysis
  source:
    doc: motherduck.com/blog/introducing-motherduck-for-business-analytics.md
    quote: the combination of MotherDuck and galileo.world is a powerful duo to make
      your data analysis, visualization and project sharing faster, simpler and more
      secure.
    char_start: 0
    char_end: 160
- statement: Before MotherDuck, our daily data pipeline took more than 24 hours to
    run.
  type: definition
  entity: Gardyn
  keywords:
  - definition
  - motherduck
  - daily
  - data
  - pipeline
  - took
  - '24'
  - hours
  - run
  source:
    doc: motherduck.com/case-studies/trunkrs-same-day-delivery-motherduck-from-redshift.md
    quote: Before MotherDuck, our daily data pipeline took more than 24 hours to run.
    char_start: 0
    char_end: 74
- statement: Executives were running queries directly against the production MySQL
    database.
  type: definition
  entity: Gardyn
  keywords:
  - definition
  - executives
  - running
  - queries
  - directly
  - against
  - production
  - mysql
  - database
  source:
    doc: motherduck.com/learn-more/duckdb-struct-nested-data.md
    quote: Executives were running queries directly against the production MySQL database.
    char_start: 0
    char_end: 79
- statement: Gardyn achieved a 24× performance improvement after migrating to MotherDuck.
  type: definition
  entity: Gardyn
  keywords:
  - definition
  - gardyn
  - achieved
  - '24'
  - performance
  - improvement
  - migrating
  - motherduck
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: After migrating to MotherDuck, the same pipeline runs in under one hour—a
      24× performance improvement.
    char_start: 0
    char_end: 102
- statement: Gardyn cut pipeline time from over 24 hours to under 1 hour.
  type: definition
  entity: Gardyn
  keywords:
  - definition
  - gardyn
  - cut
  - pipeline
  - time
  - over
  - '24'
  - hours
  - hour
  source:
    doc: motherduck.com/learn-more/no-etl-query-raw-files.md
    quote: Gardyn (IoT / AgTech)[Pipeline time cut from](https://motherduck.com/case-studies/gardyn/)
      at 10x lower cost than other data warehouses.**over 24 hours to under 1 hour****
    char_start: 0
    char_end: 171
- statement: Gardyn faced a critical challenge as they scaled their operations.
  type: definition
  entity: Gardyn
  keywords:
  - definition
  - gardyn
  - faced
  - critical
  - challenge
  - scaled
  - operations
  source:
    doc: motherduck.com/learn-more/duckdb-struct-nested-data.md
    quote: Gardyn, the innovative indoor hydroponic gardening company, faced a critical
      challenge as they scaled their operations.
    char_start: 0
    char_end: 119
- statement: Gardyn found MotherDuck 10× cheaper for their IoT analytics needs.
  type: definition
  entity: Gardyn
  keywords:
  - definition
  - gardyn
  - found
  - motherduck
  - '10'
  - cheaper
  - iot
  - analytics
  - needs
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: Gardyn found MotherDuck 10× cheaper for their IoT analytics needs.
    char_start: 0
    char_end: 66
- statement: Gardyn found this model to be 10 times more cost-effective for its analytics.
  type: definition
  entity: Gardyn
  keywords:
  - definition
  - gardyn
  - found
  - model
  - '10'
  - times
  - cost
  - effective
  - analytics
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: 'Case studies demonstrate the impact: Gardyn, an IoT company, found this
      model to be 10 times more cost-effective for its analytics.'
    char_start: 0
    char_end: 131
- statement: Gardyn transformed its data platform from MySQL to a modern stack.
  type: definition
  entity: Gardyn
  keywords:
  - definition
  - gardyn
  - transformed
  - data
  - platform
  - mysql
  - modern
  - stack
  source:
    doc: motherduck.com/videos.md
    quote: Discover how Gardyn transformed its data platform from MySQL to a modern
      stack.
    char_start: 0
    char_end: 79
- statement: Gardyn's data team is now focused on modeling customer journeys in greater
    detail.
  type: definition
  entity: Gardyn
  keywords:
  - definition
  - gardyn
  - data
  - team
  - now
  - focused
  - modeling
  - customer
  - journeys
  - greater
  - detail
  source:
    doc: motherduck.com/videos/using-sql-in-your-data-lake-with-duckdb-iceberg-dbt-and-motherduck.md
    quote: Gardyn's data team is now focused on modeling customer journeys in greater
      detail.
    char_start: 0
    char_end: 82
- statement: Gardyn's new solution met all requirements at 10× lower cost than alternative
    options.
  type: definition
  entity: Gardyn
  keywords:
  - definition
  - gardyn
  - new
  - solution
  - met
  - requirements
  - '10'
  - lower
  - cost
  - alternative
  - options
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: the new MotherDuck-based solution met all requirements at 10× lower cost
      than alternative cloud data warehouse options.
    char_start: 0
    char_end: 119
- statement: The journey from production database queries to a modern data platform
    illustrates how thoughtful architecture choices can transform a company's ability
    to leverage its data assets effectively.
  type: definition
  entity: Gardyn
  keywords:
  - definition
  - journey
  - production
  - database
  - queries
  - modern
  - data
  - platform
  - illustrates
  - thoughtful
  - architecture
  - choices
  - transform
  - company
  - ability
  - leverage
  - assets
  - effectively
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: The journey from production database queries to a modern data platform
      illustrates how thoughtful architecture choices and the right tool selection
      can transform a company's ability to leverage its da
    char_start: 0
    char_end: 222
- statement: The new platform enabled Gardyn to finally integrate data from multiple
    sources.
  type: definition
  entity: Gardyn
  keywords:
  - definition
  - new
  - platform
  - enabled
  - gardyn
  - finally
  - integrate
  - data
  - multiple
  - sources
  source:
    doc: motherduck.com/learn-more/duckdb-struct-nested-data.md
    quote: The new platform enabled Gardyn to finally integrate data from multiple
      sources.
    char_start: 0
    char_end: 80
- statement: Today, it’s less than an hour.
  type: definition
  entity: Gardyn
  keywords:
  - definition
  - today
  - less
  - hour
  source:
    doc: motherduck.com/case-studies/trunkrs-same-day-delivery-motherduck-from-redshift.md
    quote: Today, it’s less than an hour.
    char_start: 0
    char_end: 30
- statement: GCP is a suite of cloud computing services.
  type: definition
  entity: GCP
  keywords:
  - definition
  - gcp
  - suite
  - cloud
  - computing
  - services
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-seven.md
    quote: GCP_PROJECT=devrel-playground-400508
    char_start: 0
    char_end: 36
- statement: A lean, modern data warehouse represents a different approach to data
    management.
  type: definition
  entity: GCP Cloud Storage
  keywords:
  - definition
  - lean
  - modern
  - data
  - warehouse
  - represents
  - different
  - approach
  - management
  source:
    doc: motherduck.com/videos/duckdb-vs-pandas-vs-polars-for-python-devs.md
    quote: A lean, modern data warehouse is not simply a smaller version of the old
      model.
    char_start: 0
    char_end: 79
- statement: Definite saw a 70% cost reduction by moving from a provisioned warehouse
    to a DuckDB-based architecture.
  type: definition
  entity: GCP Cloud Storage
  keywords:
  - definition
  - definite
  - saw
  - '70'
  - cost
  - reduction
  - moving
  - provisioned
  - warehouse
  - duckdb
  - based
  - architecture
  source:
    doc: motherduck.com/videos/from-curiosity-to-impact-how-dosomething-democratized-data.md
    quote: Definite saw a 70% cost reduction by moving from a provisioned warehouse
      to a DuckDB-based architecture.
    char_start: 0
    char_end: 104
- statement: GCS is Google Cloud Storage, a service for storing and accessing data
    on Google Cloud.
  type: definition
  entity: GCP Cloud Storage
  keywords:
  - definition
  - gcs
  - google
  - cloud
  - storage
  - service
  - storing
  - accessing
  - data
  source:
    doc: motherduck.com/videos/duckfooding-at-motherduck.md
    quote: GCS is Google Cloud Storage, a service for storing and accessing data on
      Google Cloud.
    char_start: 0
    char_end: 86
- statement: Migrating to Spark improved performance but was still complex and expensive.
  type: performance
  entity: GCP Cloud Storage
  keywords:
  - migrating
  - spark
  - improved
  - performance
  - still
  - complex
  - expensive
  source:
    doc: motherduck.com/videos/duckdb-run-dbt-build-with-sub-second-execution-times.md
    quote: We migrated it to Spark, hoping for an improvement. While it was a step
      up, it was still complex and, more painfully, expensive.
    char_start: 0
    char_end: 128
- statement: The row function can create unnamed STRUCTs.
  type: definition
  entity: GCP Cloud Storage
  keywords:
  - definition
  - row
  - function
  - create
  - unnamed
  - structs
  source:
    doc: motherduck.com/webinar/data-discoverability-secoda-motherduck.md
    quote: The row function itself returns an unnamed struct.
    char_start: 0
    char_end: 50
- statement: Using a native SDK like the DuckDB Python SDK allows direct querying
    of the data warehouse.
  type: definition
  entity: GCP Cloud Storage
  keywords:
  - definition
  - using
  - native
  - sdk
  - like
  - duckdb
  - python
  - allows
  - direct
  - querying
  - data
  - warehouse
  source:
    doc: motherduck.com/webinar/scaling-duckdb-panel-ondemand.md
    quote: An application framework like Streamlit, Retool, or a simple Flask API
      can use a native SDK, like the DuckDB Python SDK, to query the lean data warehouse
      directly.
    char_start: 0
    char_end: 163
- statement: GDAL is primarily a transformation library for location-based data.
  type: definition
  entity: GDAL
  keywords:
  - definition
  - gdal
  - primarily
  - transformation
  - library
  - location
  - based
  - data
  source:
    doc: motherduck.com/blog/pg_duckdb-postgresql-extension-for-duckdb-motherduck.md
    quote: GDAL is primarily a transformation library that helps you read, convert,
      and process different types of location-based data.
    char_start: 0
    char_end: 124
- statement: The GeekWire awards recognize top innovators and companies in Seattle
    and the Pacific Northwest.
  type: definition
  entity: GeekWire
  keywords:
  - definition
  - geekwire
  - awards
  - recognize
  - top
  - innovators
  - companies
  - seattle
  - pacific
  - northwest
  source:
    doc: motherduck.com/videos/from-core-to-custom-unlocking-new-possibilities-with-duckdb-extensions.md
    quote: This is an annual event recognizing the top innovators and companies in
      Seattle and the Pacific Northwest.
    char_start: 0
    char_end: 106
- statement: Generative AI has arrived in the data management world and is here to
    stay.
  type: definition
  entity: Generative AI
  keywords:
  - definition
  - generative
  - ai
  - arrived
  - data
  - management
  - world
  - stay
  source:
    doc: motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md
    quote: Generative AI has arrived in the data management world and is here to stay.
    char_start: 0
    char_end: 75
- statement: The AI can understand context and generate relevant SQL queries.
  type: definition
  entity: generative AI feature
  keywords:
  - definition
  - ai
  - understand
  - context
  - generate
  - relevant
  - sql
  - queries
  source:
    doc: motherduck.com/blog/ducklake-motherduck.md
    quote: It’s nice that it detects that PostTypeId = 1 are questions.
    char_start: 0
    char_end: 60
- statement: The AI returns different results on each run.
  type: definition
  entity: generative AI feature
  keywords:
  - definition
  - ai
  - returns
  - different
  - results
  - run
  source:
    doc: motherduck.com/blog/ducklake-motherduck.md
    quote: As expected from probabilistic models it returns different results on each
      run.
    char_start: 0
    char_end: 79
- statement: The generative AI feature can generate and fix SQL statements.
  type: definition
  entity: generative AI feature
  keywords:
  - definition
  - generative
  - ai
  - feature
  - generate
  - fix
  - sql
  - statements
  source:
    doc: motherduck.com/blog/ducklake-motherduck.md
    quote: It allows you to generate and fix SQL statements.
    char_start: 0
    char_end: 49
- statement: Geneva has 42 chocolate stores, which is 0.53 stores per km.
  type: definition
  entity: Geneva
  keywords:
  - definition
  - geneva
  - '42'
  - chocolate
  - stores
  - which
  - '0.53'
  - per
  - km
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Geneva has 42 chocolate stores, which is 0.53 stores per km.
    char_start: 0
    char_end: 60
- statement: Geneva has a higher density of chocolate stores than Zurich and Basel.
  type: definition
  entity: Geneva
  keywords:
  - definition
  - geneva
  - higher
  - density
  - chocolate
  - stores
  - zurich
  - basel
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Geneva has a higher density of chocolate stores than Zurich and Basel.
    char_start: 0
    char_end: 70
- statement: Geobase and MotherDuck offer greater possibilities, such as identifying
    high-density areas.
  type: definition
  entity: Geobase
  keywords:
  - definition
  - geobase
  - motherduck
  - offer
  - greater
  - possibilities
  - identifying
  - high
  - density
  - areas
  source:
    doc: motherduck.com/blog/getting-started-ducklake-table-format.md
    quote: Our example is just one highlight of the available tools and functionality
      in Geobase and MotherDuck, which offer greater possibilities, such as identifying
      high-density areas.
    char_start: 0
    char_end: 176
- statement: Geobase can process the data to create vector tiles in response to the
    front end.
  type: definition
  entity: Geobase
  keywords:
  - definition
  - geobase
  - process
  - data
  - create
  - vector
  - tiles
  - response
  - front
  - end
  source:
    doc: motherduck.com/blog/getting-started-ducklake-table-format.md
    quote: Geobase can also process the data to create vector tiles in response to
      the front end.
    char_start: 0
    char_end: 86
- statement: Geobase excels at spatial-temporal queries for movement analytics.
  type: definition
  entity: Geobase
  keywords:
  - definition
  - geobase
  - excels
  - spatial
  - temporal
  - queries
  - movement
  - analytics
  source:
    doc: motherduck.com/blog/estuary-streaming-cdc-replication.md
    quote: Geobase excels at spatial-temporal queries for movement analytics.
    char_start: 0
    char_end: 66
- statement: Geobase handles both external and internal tables.
  type: definition
  entity: Geobase
  keywords:
  - definition
  - geobase
  - handles
  - both
  - external
  - internal
  - tables
  source:
    doc: motherduck.com/blog/semantic-layer-duckdb-tutorial.md
    quote: 'Geobase Platform: Handles both external (''big data'' at cloud scale)
      and internal tables.'
    char_start: 0
    char_end: 88
- statement: Geospatial analysis powers countless daily applications.
  type: definition
  entity: Geographic Information Systems
  keywords:
  - definition
  - geospatial
  - analysis
  - powers
  - countless
  - daily
  - applications
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: Geospatial analysis powers countless daily applications—from delivery services
      to store locators—often invisibly enhancing our digital experiences.
    char_start: 0
    char_end: 147
- statement: GIS is a specialized data infrastructure that handles geographic datasets.
  type: definition
  entity: Geographic Information Systems
  keywords:
  - definition
  - gis
  - specialized
  - data
  - infrastructure
  - handles
  - geographic
  - datasets
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: GIS is a specialized data infrastructure that handles geographic datasets.
    char_start: 0
    char_end: 74
- statement: GIS is the specific technology stack used to capture, analyze, and visualize
    spatial data.
  type: definition
  entity: Geographic Information Systems
  keywords:
  - definition
  - gis
  - specific
  - technology
  - stack
  - used
  - capture
  - analyze
  - visualize
  - spatial
  - data
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: Meanwhile, GIS (Geographic Information Systems) is the specific technology
      stack used to capture, analyze, and visualize this spatial data.
    char_start: 0
    char_end: 139
- statement: GIS is the toolkit used to work with geospatial data.
  type: definition
  entity: Geographic Information Systems
  keywords:
  - definition
  - gis
  - toolkit
  - used
  - work
  - geospatial
  - data
  source:
    doc: motherduck.com/blog/pg-duckdb-release.md
    quote: Think of geospatial as the broader domain of geographic information, with
      GIS being the toolkit used to work with it.
    char_start: 0
    char_end: 117
- statement: You can export data to GeoJSON format easily.
  type: definition
  entity: GeoJSON
  keywords:
  - definition
  - export
  - data
  - geojson
  - format
  - easily
  source:
    doc: motherduck.com/blog/faster-data-pipelines-with-mcp-duckdb-ai.md
    quote: 'To export into a flat file, for instance GeoJSON, it''s a simple as :'
    char_start: 0
    char_end: 68
- statement: Understanding geometries can include points, lines, polygons, or collections
    of them.
  type: definition
  entity: geometries (Topic)
  keywords:
  - definition
  - understanding
  - geometries
  - include
  - points
  - lines
  - polygons
  - collections
  - them
  source:
    doc: motherduck.com/blog/faster-data-pipelines-with-mcp-duckdb-ai.md
    quote: In short, these can be points, lines, polygons, or collections of them.
    char_start: 0
    char_end: 71
- statement: GeoPandas extends pandas to work with geospatial data and includes basic
    plotting capabilities.
  type: definition
  entity: GeoPandas
  keywords:
  - definition
  - geopandas
  - extends
  - pandas
  - work
  - geospatial
  - data
  - includes
  - basic
  - plotting
  - capabilities
  source:
    doc: motherduck.com/blog/motherduck-duckdb-dbt.md
    quote: 'GeoPandas: Extends pandas to work with geospatial data and includes basic
      plotting capabilities'
    char_start: 0
    char_end: 95
- statement: George Fraser leads one of the most successful data integration companies.
  type: definition
  entity: George Fraser
  keywords:
  - definition
  - george
  - fraser
  - leads
  - one
  - successful
  - data
  - integration
  - companies
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eight.md
    quote: Leading one of the most successful data integration companies, George has
      unique insights into how data actually moves through organizations.
    char_start: 0
    char_end: 141
- statement: Geospatial refers to all aspects of location-based data and geographic
    relationships.
  type: definition
  entity: Geospatial
  keywords:
  - definition
  - geospatial
  - refers
  - aspects
  - location
  - based
  - data
  - geographic
  - relationships
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: Geospatial refers to all aspects of location-based data and geographic
      relationships.
    char_start: 0
    char_end: 85
- statement: Geospatial technology is helpful for maps to quickly find the nearest
    points or all within a region.
  type: definition
  entity: geospatial data
  keywords:
  - definition
  - geospatial
  - technology
  - helpful
  - maps
  - quickly
  - find
  - nearest
  - points
  - within
  - region
  source:
    doc: motherduck.com/blog/read-scaling-preview.md
    quote: Geospatial technology is helpful for maps to quickly find the nearest points
      or all within a region.
    char_start: 0
    char_end: 100
- statement: Geospatial processing is the analysis and visualization of data related
    to geographic locations.
  type: definition
  entity: Geospatial Processing
  keywords:
  - definition
  - geospatial
  - processing
  - analysis
  - visualization
  - data
  - related
  - geographic
  - locations
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: Geospatial processing is the analysis and visualization of data related
      to geographic locations.
    char_start: 0
    char_end: 96
- statement: Auto-scaling operates independently for each Duckling.
  type: definition
  entity: Giga Ducklings
  keywords:
  - definition
  - auto
  - scaling
  - operates
  - independently
  - duckling
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: Auto-scaling operates independently for each Duckling, ensuring users pay
      for high-performance instances only when their specific workloads require it.
    char_start: 0
    char_end: 151
- statement: Dual Execution technology enables quick aggregation and filtering of
    data.
  type: definition
  entity: Giga Ducklings
  keywords:
  - definition
  - dual
  - execution
  - technology
  - enables
  - quick
  - aggregation
  - filtering
  - data
  source:
    doc: motherduck.com/blog/scaling-duckdb-with-ducklings.md
    quote: We call this Dual Execution and we wrote a CIDR paper on this technology...
    char_start: 0
    char_end: 75
- statement: Duckling enhances data warehousing and analytics.
  type: definition
  entity: Giga Ducklings
  keywords:
  - definition
  - duckling
  - enhances
  - data
  - warehousing
  - analytics
  source:
    doc: motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md
    quote: Ducklings, a component of the MotherDuck platform, which enhances data
      warehousing and analytics.
    char_start: 0
    char_end: 97
- statement: Ducklings are instances of DuckDB.
  type: definition
  entity: Giga Ducklings
  keywords:
  - definition
  - ducklings
  - instances
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: MotherDuck's DuckDB instances became Ducklings.
    char_start: 0
    char_end: 47
- statement: Ducklings can start almost instantly and shut down when not in use.
  type: definition
  entity: Giga Ducklings
  keywords:
  - definition
  - ducklings
  - start
  - almost
  - instantly
  - shut
  - down
  - use
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-1.md
    quote: The Duckling starts almost instantly (generally less than 200 ms), can
      auto-scale, and shuts down when it isn’t being used.
    char_start: 0
    char_end: 123
- statement: Each customer can have their own Duckling(s) with isolated data.
  type: definition
  entity: Giga Ducklings
  keywords:
  - definition
  - customer
  - duckling
  - isolated
  - data
  source:
    doc: motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md
    quote: Each customer can have their own Duckling(s) with isolated data.
    char_start: 0
    char_end: 64
- statement: Each Duckling can be scaled up or down to meet the needs of the user.
  type: definition
  entity: Giga Ducklings
  keywords:
  - definition
  - duckling
  - scaled
  - up
  - down
  - meet
  - needs
  - user
  source:
    doc: motherduck.com/blog/scaling-duckdb-with-ducklings.md
    quote: Each Duckling can be scaled up or down to meet the needs of the user.
    char_start: 0
    char_end: 69
- statement: Each user gets their own Duckling which handles their workload and automatically
    shuts down if not being used.
  type: definition
  entity: Giga Ducklings
  keywords:
  - definition
  - user
  - gets
  - duckling
  - which
  - handles
  - workload
  - automatically
  - shuts
  - down
  - used
  source:
    doc: motherduck.com/blog/scaling-duckdb-with-ducklings.md
    quote: Each user gets their own Duckling which handles their workload and automatically
      shuts down if not being used.
    char_start: 0
    char_end: 110
- statement: Giga ducklings are our largest instance sizes, purpose-built for the
    toughest of transformations.
  type: definition
  entity: Giga Ducklings
  keywords:
  - definition
  - giga
  - ducklings
  - largest
  - instance
  - sizes
  - purpose
  - built
  - toughest
  - transformations
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: Giga ducklings are our largest instance sizes, purpose-built for **the
      toughest of transformations**.
    char_start: 0
    char_end: 101
- statement: Giga gives DuckDB an environment with maximum compute and memory.
  type: definition
  entity: Giga Ducklings
  keywords:
  - definition
  - giga
  - gives
  - duckdb
  - environment
  - maximum
  - compute
  - memory
  source:
    doc: motherduck.com/blog.md
    quote: Giga gives DuckDB an environment with maximum compute and memory — ideal
      for very complex joins.
    char_start: 0
    char_end: 96
- statement: Megas and Gigas will help scale up compute needs.
  type: definition
  entity: Giga Ducklings
  keywords:
  - definition
  - megas
  - gigas
  - help
  - scale
  - up
  - compute
  - needs
  source:
    doc: motherduck.com/blog/just-enough-sql-for-ai.md
    quote: Need more compute to scale up? Megas and Gigas will help!
    char_start: 0
    char_end: 57
- statement: You can choose from several instance types to match the job at hand,
    optimizing for either cost or performance.
  type: definition
  entity: Giga Ducklings
  keywords:
  - definition
  - choose
  - several
  - instance
  - types
  - match
  - job
  - hand
  - optimizing
  - either
  - cost
  - performance
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: You can choose from several instance types to match the job at hand, optimizing
      for either cost or performance.
    char_start: 0
    char_end: 111
- statement: The GIS stack is a collection of tools and technologies used for geographic
    information systems.
  type: definition
  entity: GIS Stack
  keywords:
  - definition
  - gis
  - stack
  - collection
  - tools
  - technologies
  - used
  - geographic
  - information
  - systems
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: The GIS stack is a collection of tools and technologies used for geographic
      information systems.
    char_start: 0
    char_end: 96
- statement: Git for data is harder than version control for code because we're not
    just tracking changes but managing state.
  type: definition
  entity: Git
  keywords:
  - definition
  - git
  - data
  - harder
  - version
  - control
  - code
  - re
  - tracking
  - changes
  - managing
  - state
  source:
    doc: motherduck.com/blog/getting-started-ducklake-table-format.md
    quote: We learned that Git for data is harder than version control for code because
      we're not just tracking changes but managing state.
    char_start: 0
    char_end: 128
- statement: Git is a version control system for tracking changes in source code during
    software development.
  type: definition
  entity: Git
  keywords:
  - definition
  - git
  - version
  - control
  - system
  - tracking
  - changes
  - source
  - code
  - software
  - development
  source:
    doc: motherduck.com/glossary/ELT.md
    quote: A version control system for tracking changes in source code during software
      development.
    char_start: 0
    char_end: 89
- statement: Git is probably the most used version control in data engineering nowadays.
  type: definition
  entity: Git
  keywords:
  - definition
  - git
  - probably
  - used
  - version
  - control
  - data
  - engineering
  - nowadays
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: Git is probably the most used version control in data engineering nowadays.
    char_start: 0
    char_end: 75
- statement: Git was not designed for large binary files or datasets.
  type: definition
  entity: Git
  keywords:
  - definition
  - git
  - designed
  - large
  - binary
  - files
  - datasets
  source:
    doc: motherduck.com/blog/semantic-layer-duckdb-tutorial.md
    quote: Git is not made for data because it was designed with code versioning in
      mind, not large binary files or datasets.
    char_start: 0
    char_end: 114
- statement: Git workflows can bring branching, testing, and deploying to data management.
  type: definition
  entity: Git
  keywords:
  - definition
  - git
  - workflows
  - bring
  - branching
  - testing
  - deploying
  - data
  - management
  source:
    doc: motherduck.com/blog/announcing-mega-giga-instance-sizes-huge-scale.md
    quote: This article explores how to bring Git style workflows like branching,
      testing, and deploying to your data stack.
    char_start: 0
    char_end: 113
- statement: The promise of Git-like workflows for data is to borrow Git-like concepts
    of branching, rollback, and isolated environments.
  type: definition
  entity: Git
  keywords:
  - definition
  - promise
  - git
  - like
  - workflows
  - data
  - borrow
  - concepts
  - branching
  - rollback
  - isolated
  - environments
  source:
    doc: motherduck.com/blog/getting-started-ducklake-table-format.md
    quote: The promise of Git-like workflows for data is to borrow Git-like concepts
      of branching, rollback, and isolated environments.
    char_start: 0
    char_end: 124
- statement: Git for data provides a framework for consistent rollback mechanisms
    across data storage solutions.
  type: definition
  entity: Git for data
  keywords:
  - definition
  - git
  - data
  - provides
  - framework
  - consistent
  - rollback
  - mechanisms
  - across
  - storage
  - solutions
  source:
    doc: motherduck.com/blog/getting-started-ducklake-table-format.md
    quote: the main goal of Git for data is giving the data engineer peace of mind
      during production runs.
    char_start: 0
    char_end: 95
- statement: A working demo & instruction that can be found in this GitHub repo.
  type: definition
  entity: GitHub
  keywords:
  - definition
  - working
  - demo
  - instruction
  - found
  - github
  - repo
  source:
    doc: motherduck.com/blog/introducing-instant-sql.md
    quote: A working demo & instruction that can be found in this GitHub repo.
    char_start: 0
    char_end: 67
- statement: All the source code is available on GitHub.
  type: definition
  entity: GitHub
  keywords:
  - definition
  - source
  - code
  - available
  - github
  source:
    doc: motherduck.com/blog/duckdb-dbt-e2e-data-engineering-project-part-2.md
    quote: All the source code is available on GitHub.
    char_start: 0
    char_end: 43
- statement: GitHub is a platform for version control and collaboration.
  type: definition
  entity: GitHub
  keywords:
  - definition
  - github
  - platform
  - version
  - control
  - collaboration
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-two.md
    quote: GitHub is a platform for version control and collaboration.
    char_start: 0
    char_end: 59
- statement: The author shares their solutions for Advent of Code on GitHub.
  type: definition
  entity: GitHub
  keywords:
  - definition
  - author
  - shares
  - solutions
  - advent
  - code
  - github
  source:
    doc: motherduck.com/blog/getting-started-ducklake-table-format.md
    quote: I recommend joining or creating a private leaderboard for some friendly
      competition among friends or those with similar interests.
    char_start: 0
    char_end: 130
- statement: The tool for converting SQL-Server Dump XML files to CSV is available
    on GitHub.
  type: definition
  entity: GitHub
  keywords:
  - definition
  - tool
  - converting
  - sql
  - server
  - dump
  - xml
  - files
  - csv
  - available
  - github
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: I used a tool I wrote a few years ago, which you can find on GitHub.
    char_start: 0
    char_end: 68
- statement: GitHub Actions is a native GitHub CI/CD platform with an extensive marketplace
    ecosystem for automated testing and deployment workflows.
  type: definition
  entity: GitHub Actions
  keywords:
  - definition
  - github
  - actions
  - native
  - ci
  - cd
  - platform
  - extensive
  - marketplace
  - ecosystem
  - automated
  - testing
  - deployment
  - workflows
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: Native GitHub CI/CD platform with an extensive marketplace ecosystem for
      automated testing and deployment workflows
    char_start: 0
    char_end: 115
- statement: GitHub Codespaces allows developers to work in a consistent environment.
  type: definition
  entity: GitHub Codespaces
  keywords:
  - definition
  - github
  - codespaces
  - allows
  - developers
  - work
  - consistent
  - environment
  source:
    doc: motherduck.com/blog/analyze-x-data-nodejs-duckdb.md
    quote: A cloud-based development environment that allows developers to work in
      a consistent environment.
    char_start: 0
    char_end: 97
- statement: AI copilots like GitHub Copilot and Cursor have emerged as valuable tools
    for accelerating code generation.
  type: definition
  entity: GitHub Copilot
  keywords:
  - definition
  - ai
  - copilots
  - like
  - github
  - copilot
  - cursor
  - emerged
  - valuable
  - tools
  - accelerating
  - code
  - generation
  source:
    doc: motherduck.com/blog/simplifying-iot-analytics-motherduck.md
    quote: AI copilots like GitHub Copilot and Cursor have emerged as valuable tools
      for accelerating code generation.
    char_start: 0
    char_end: 107
- statement: GitKraken is a popular Git GUI client.
  type: definition
  entity: GitKraken
  keywords:
  - definition
  - gitkraken
  - popular
  - git
  - gui
  - client
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: Some popular options include GitKraken.
    char_start: 0
    char_end: 39
- statement: GitLab CI/CD is an integrated DevOps platform providing end-to-end automation
    from code to deployment with built-in security scanning.
  type: definition
  entity: GitLab CI/CD
  keywords:
  - definition
  - gitlab
  - ci
  - cd
  - integrated
  - devops
  - platform
  - providing
  - end
  - automation
  - code
  - deployment
  - built
  - security
  - scanning
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: Integrated DevOps platform providing end-to-end automation from code to
      deployment with built-in security scanning
    char_start: 0
    char_end: 114
- statement: Gitpod provides a complete development environment in the browser.
  type: definition
  entity: Gitpod
  keywords:
  - definition
  - gitpod
  - provides
  - complete
  - development
  - environment
  - browser
  source:
    doc: motherduck.com/blog/analyze-x-data-nodejs-duckdb.md
    quote: A cloud-based IDE that provides a complete development environment in the
      browser.
    char_start: 0
    char_end: 82
- statement: GizmoSQL allows SQL queries to be executed and returns results in Arrow
    format.
  type: definition
  entity: GizmoSQL
  keywords:
  - definition
  - gizmosql
  - allows
  - sql
  - queries
  - executed
  - returns
  - results
  - arrow
  - format
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: Just SQL in, Arrow out, running at memory speed.
    char_start: 0
    char_end: 48
- statement: GizmoSQL can be integrated with Superset and Metabase for data visualization.
  type: definition
  entity: GizmoSQL
  keywords:
  - definition
  - gizmosql
  - integrated
  - superset
  - metabase
  - data
  - visualization
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: Point Superset or Metabase at your GizmoSQL server.
    char_start: 0
    char_end: 51
- statement: GizmoSQL is a full Arrow Flight SQL server with support for both DuckDB
    and SQLite as pluggable backends.
  type: definition
  entity: GizmoSQL
  keywords:
  - definition
  - gizmosql
  - full
  - arrow
  - flight
  - sql
  - server
  - support
  - both
  - duckdb
  - sqlite
  - pluggable
  - backends
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-one.md
    quote: GizmoSQL is a full Arrow Flight SQL server with support for both DuckDB
      and SQLite as pluggable backends.
    char_start: 0
    char_end: 105
- statement: GizmoSQL is built in C++ and extended from Voltron Data's sqlflite.
  type: definition
  entity: GizmoSQL
  keywords:
  - definition
  - gizmosql
  - built
  - extended
  - voltron
  - data
  - sqlflite
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-one.md
    quote: Built in C++ and extended from Voltron Data's sqlflite.
    char_start: 0
    char_end: 55
- statement: GizmoSQL supports Docker-first deployment.
  type: definition
  entity: GizmoSQL
  keywords:
  - definition
  - gizmosql
  - supports
  - docker
  - first
  - deployment
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-one.md
    quote: Docker-first deployment → Instant setup with production-grade defaults.
    char_start: 0
    char_end: 71
- statement: GNU Parallel can run multiple jobs in parallel for data generation.
  type: definition
  entity: GNU Parallel
  keywords:
  - definition
  - gnu
  - parallel
  - run
  - multiple
  - jobs
  - data
  - generation
  source:
    doc: motherduck.com/blog/python-faker-duckdb-exploration.md
    quote: By default, GNU Parallel only runs 1 job in parallel for each CPU core.
    char_start: 0
    char_end: 71
- statement: I generated a billion people in 1k parquet files.
  type: definition
  entity: GNU Parallel
  keywords:
  - definition
  - generated
  - billion
  - people
  - 1k
  - parquet
  - files
  source:
    doc: motherduck.com/blog/redshift-files-hunt-for-big-data.md
    quote: I used the GNU Parallel technique discussed above with a hefty m6i.32xlarge
      instance on Amazon EC2, though generated a billion people in 1k parquet files.
    char_start: 0
    char_end: 154
- statement: Using GNU Parallel can significantly reduce execution time for Python
    scripts.
  type: definition
  entity: GNU Parallel
  keywords:
  - definition
  - using
  - gnu
  - parallel
  - significantly
  - reduce
  - execution
  - time
  - python
  - scripts
  source:
    doc: motherduck.com/blog/python-faker-duckdb-exploration.md
    quote: It takes only 33 seconds on the wall clock to execute on a 10 core machine.
    char_start: 0
    char_end: 75
- statement: GoodData enables organizations to transform raw data into actionable
    insights.
  type: definition
  entity: GoodData
  keywords:
  - definition
  - gooddata
  - enables
  - organizations
  - transform
  - raw
  - data
  - actionable
  - insights
  source:
    doc: motherduck.com/learn-more/data-application.md
    quote: GoodData is a cloud-based analytics platform that enables organizations
      and data product builders to transform raw data into actionable insights.
    char_start: 0
    char_end: 145
- statement: GoodData is known for superior concurrent user performance using DuckDB.
  type: definition
  entity: GoodData
  keywords:
  - definition
  - gooddata
  - known
  - superior
  - concurrent
  - user
  - performance
  - using
  - duckdb
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: GoodData's superior concurrent user performance further validate DuckDB's
      versatility.
    char_start: 0
    char_end: 86
- statement: The integration allows GoodData users to seamlessly query and visualize
    data stored in MotherDuck.
  type: definition
  entity: GoodData
  keywords:
  - definition
  - integration
  - allows
  - gooddata
  - users
  - seamlessly
  - query
  - visualize
  - data
  - stored
  - motherduck
  source:
    doc: motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md
    quote: The integration allows GoodData users to seamlessly query and visualize
      data stored in MotherDuck.
    char_start: 0
    char_end: 98
- statement: Google has a Python SDK for BigQuery which supports fast data transfer
    into Arrow tables.
  type: definition
  entity: Google
  keywords:
  - definition
  - google
  - python
  - sdk
  - bigquery
  - which
  - supports
  - fast
  - data
  - transfer
  - arrow
  - tables
  source:
    doc: motherduck.com/blog/bigquery-to-duckdb-motherduck.md
    quote: Google has a Python SDK for BigQuery which supports fast data transfer
      into Arrow tables.
    char_start: 0
    char_end: 89
- statement: Google BigQuery's on-demand pricing can be cost-effective for sporadic
    forensic queries.
  type: definition
  entity: Google BigQuery
  keywords:
  - definition
  - google
  - bigquery
  - demand
  - pricing
  - cost
  - effective
  - sporadic
  - forensic
  - queries
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: Its on-demand, per-terabyte-scanned pricing can be cost-effective for sporadic
      forensic queries.
    char_start: 0
    char_end: 96
- statement: Google Cloud provides the BigQuery service.
  type: definition
  entity: Google Cloud
  keywords:
  - definition
  - google
  - cloud
  - provides
  - bigquery
  - service
  source:
    doc: motherduck.com/blog/data-engineers-answer-10-top-reddit-questions.md
    quote: A suite of cloud computing services that runs on the same infrastructure
      that Google uses internally for its end-user products.
    char_start: 0
    char_end: 127
- statement: Google Cloud’s Serverless dataproc has roughly the same numbers.
  type: definition
  entity: Google Cloud Dataproc
  keywords:
  - definition
  - google
  - cloud
  - serverless
  - dataproc
  - roughly
  - numbers
  source:
    doc: motherduck.com/blog/local-duckdb-ui-visual-data-analysis.md
    quote: Google Cloud’s Serverless dataproc has roughly the same numbers.
    char_start: 0
    char_end: 64
- statement: Google Colab provides free access to GPU and TPU computing resources.
  type: definition
  entity: Google Colab
  keywords:
  - definition
  - google
  - colab
  - provides
  - free
  - access
  - gpu
  - tpu
  - computing
  - resources
  source:
    doc: motherduck.com/learn-more/data-application.md
    quote: Google Colab is a free cloud-based Jupyter notebook environment that allows
      users to write and execute Python code through the browser.
    char_start: 0
    char_end: 135
- statement: Managed Kubernetes services provide another abstraction layer.
  type: definition
  entity: Google GKE
  keywords:
  - definition
  - managed
  - kubernetes
  - services
  - provide
  - another
  - abstraction
  - layer
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: Managed Kubernetes services, such as Google GKE, Azure AKS, and AWS EKS,
      provide another abstraction layer.
    char_start: 0
    char_end: 107
- statement: Extracting the sheet data is as simple as using the read_csv function
    and passing the URL.
  type: definition
  entity: Google Sheets
  keywords:
  - definition
  - extracting
  - sheet
  - data
  - simple
  - using
  - read
  - csv
  - function
  - passing
  - url
  source:
    doc: motherduck.com/blog/fabi-ai-llm-prompt-analysis.md
    quote: For Google Sheets that are shared with a public link, extracting the sheet
      data is as simple as using the [read_csv](https://duckdb.org/docs/data/csv/overview.html)
      function and passing the URL.
    char_start: 0
    char_end: 194
- statement: Google Sheets is a web-based spreadsheet application.
  type: definition
  entity: Google Sheets
  keywords:
  - definition
  - google
  - sheets
  - web
  - based
  - spreadsheet
  - application
  source:
    doc: motherduck.com/blog/motherduck-in-europe.md
    quote: Google Sheets is a web-based spreadsheet application that allows users
      to create, update, and modify spreadsheets.
    char_start: 0
    char_end: 114
- statement: You can extract the sheet id and tab id from the URL.
  type: definition
  entity: Google Sheets
  keywords:
  - definition
  - extract
  - sheet
  - id
  - tab
  - url
  source:
    doc: motherduck.com/blog/fabi-ai-llm-prompt-analysis.md
    quote: As a practical example, you can extract the sheet id and tab id from the
      URL, as seen in the screenshot below.
    char_start: 0
    char_end: 110
- statement: GPT is a model developed by OpenAI.
  type: definition
  entity: GPT
  keywords:
  - definition
  - gpt
  - model
  - developed
  - openai
  source:
    doc: motherduck.com/blog/motherduck-union-orchestration.md
    quote: GPT is a model developed by OpenAI.
    char_start: 0
    char_end: 35
- statement: Grafana is an open-source platform for monitoring and observability.
  type: definition
  entity: Grafana
  keywords:
  - definition
  - grafana
  - open
  - source
  - platform
  - monitoring
  - observability
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: Grafana is an open-source platform for monitoring and observability.
    char_start: 0
    char_end: 68
- statement: Gran Hotel del Sella is one of the hotels listed in the dataset.
  type: definition
  entity: Gran Hotel del Sella
  keywords:
  - definition
  - gran
  - hotel
  - del
  - sella
  - one
  - hotels
  - listed
  - dataset
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: │ 209224 │ POINT (-5.06419388654615 43.46594466895118)   │ Gran Hotel del
      Sella                          │
    char_start: 0
    char_end: 106
- statement: A graph database is built to manage data structured as a graph.
  type: definition
  entity: graph database
  keywords:
  - definition
  - graph
  - database
  - built
  - manage
  - data
  - structured
  source:
    doc: motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md
    quote: As the name implies, a graph database is built to manage data structured
      as a graph.
    char_start: 0
    char_end: 84
- statement: Effective use of graph databases necessitates a solid grasp of graph
    theory.
  type: definition
  entity: graph database
  keywords:
  - definition
  - effective
  - use
  - graph
  - databases
  - necessitates
  - solid
  - grasp
  - theory
  source:
    doc: motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md
    quote: Effective use of graph databases necessitates a solid grasp of graph theory
      and the specific architectures of graph databases.
    char_start: 0
    char_end: 126
- statement: Graph databases excel in environments where the emphasis is on the relationships
    and networks within the data.
  type: definition
  entity: graph database
  keywords:
  - definition
  - graph
  - databases
  - excel
  - environments
  - emphasis
  - relationships
  - networks
  - within
  - data
  source:
    doc: motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md
    quote: Graph databases genuinely excel in environments where the emphasis is on
      the relationships and networks within the data.
    char_start: 0
    char_end: 120
- statement: Graph databases face notorious challenges in scaling.
  type: definition
  entity: graph database
  keywords:
  - definition
  - graph
  - databases
  - face
  - notorious
  - challenges
  - scaling
  source:
    doc: motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md
    quote: Graph databases face notorious challenges in scaling.
    char_start: 0
    char_end: 53
- statement: Graph querying offers capabilities beyond traditional SQL infrastructures.
  type: definition
  entity: graph database
  keywords:
  - definition
  - graph
  - querying
  - offers
  - capabilities
  - beyond
  - traditional
  - sql
  - infrastructures
  source:
    doc: motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md
    quote: newcomers to graph technology look forward to exploring the advantages
      of performant graph queries, which offer capabilities beyond traditional SQL
      infrastructures.
    char_start: 0
    char_end: 164
- statement: In a graph database, the data is represented through nodes and edges.
  type: definition
  entity: graph database
  keywords:
  - definition
  - graph
  - database
  - data
  - represented
  - nodes
  - edges
  source:
    doc: motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md
    quote: In a graph database, the data is represented through nodes and edges.
    char_start: 0
    char_end: 69
- statement: Graph query engines offer a path to accessing graph analytics without
    these extensive hurdles.
  type: definition
  entity: graph query engines
  keywords:
  - definition
  - graph
  - query
  - engines
  - offer
  - path
  - accessing
  - analytics
  - without
  - extensive
  - hurdles
  source:
    doc: motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md
    quote: However, alternatives like graph query engines offer a path to accessing
      graph analytics without these extensive hurdles.
    char_start: 0
    char_end: 121
- statement: Graph-Based Data Models adopt graph databases and processing engines
    for complex relationship analyses and recommendations.
  type: definition
  entity: Graph-Based Data Models
  keywords:
  - definition
  - graph
  - based
  - data
  - models
  - adopt
  - databases
  - processing
  - engines
  - complex
  - relationship
  - analyses
  - recommendations
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: Graph-Based Data Models Adopting graph databases and processing engines
      for complex relationship analyses and recommendations.
    char_start: 0
    char_end: 126
- statement: Great Expectations provides a powerful framework for data quality.
  type: definition
  entity: Great Expectations
  keywords:
  - definition
  - great
  - expectations
  - provides
  - powerful
  - framework
  - data
  - quality
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: Great Expectations provides an Open Source Python-based powerful framework
      for it.
    char_start: 0
    char_end: 82
- statement: Implementing robust data quality frameworks and testing strategies is
    crucial for maintaining a stable data platform.
  type: definition
  entity: Great Expectations
  keywords:
  - definition
  - implementing
  - robust
  - data
  - quality
  - frameworks
  - testing
  - strategies
  - crucial
  - maintaining
  - stable
  - platform
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: Implementing robust data quality frameworks and testing strategies is crucial
      for maintaining a stable data platform.
    char_start: 0
    char_end: 117
- statement: ps is used to check current processes.
  type: definition
  entity: grep
  keywords:
  - definition
  - ps
  - used
  - check
  - current
  - processes
  source:
    doc: motherduck.com/blog/data-warehouse-feature-roundup-oct-2024.md
    quote: To check the current process. Ps is also handy in combination with grep.
    char_start: 0
    char_end: 72
- statement: GROUP is a classification used to color the scatter plot based on demographic
    data.
  type: definition
  entity: GROUP
  keywords:
  - definition
  - group
  - classification
  - used
  - color
  - scatter
  - plot
  - based
  - demographic
  - data
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md
    quote: A classification used to color the scatter plot based on demographic data.
    char_start: 0
    char_end: 74
- statement: Aggregate functions like AVG(), MIN(), MAX(), and COUNT() let you perform
    a calculation across many rows.
  type: definition
  entity: GROUP BY
  keywords:
  - definition
  - aggregate
  - functions
  - like
  - avg
  - min
  - max
  - count
  - let
  - perform
  - calculation
  - across
  - many
  - rows
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md
    quote: Aggregate functions like AVG(), MIN(), MAX(), and COUNT() let you perform
      a calculation across many rows.
    char_start: 0
    char_end: 105
- statement: gspread allows you to work with Google Sheets through Python API.
  type: definition
  entity: gspread
  keywords:
  - definition
  - gspread
  - allows
  - work
  - google
  - sheets
  - python
  - api
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: Work with Google Sheets through Python API.
    char_start: 0
    char_end: 43
- statement: 'Gábor Szárnyas is the #1 contributor with over 2.5k commits on one of
    the most critical DuckDB repositories.'
  type: definition
  entity: Gábor Szárnyas
  keywords:
  - definition
  - bor
  - sz
  - rnyas
  - contributor
  - over
  - '2.5'
  - commits
  - one
  - critical
  - duckdb
  - repositories
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: 'If I tell you he''s the #1 contributor with over 2.5k commits on one of
      the most critical DuckDB repositories...'
    char_start: 0
    char_end: 111
- statement: Hacker News is a social news website that focuses on computer science
    and entrepreneurship.
  type: definition
  entity: Hacker News
  keywords:
  - definition
  - hacker
  - news
  - social
  - website
  - focuses
  - computer
  - science
  - entrepreneurship
  source:
    doc: motherduck.com/blog/big-data-is-dead.md
    quote: Hacker News is a social news website that focuses on computer science and
      entrepreneurship.
    char_start: 0
    char_end: 91
- statement: Posting more on Hacker News does not necessarily favor those who post
    more.
  type: definition
  entity: Hacker News
  keywords:
  - definition
  - posting
  - hacker
  - news
  - necessarily
  - favor
  - who
  - post
  source:
    doc: motherduck.com/blog/fabi-ai-llm-prompt-analysis.md
    quote: As you can see, there's no need to worry about under-posting on Hacker
      News, as the algorithm doesn't necessarily favor those who post more.
    char_start: 0
    char_end: 140
- statement: The dataset contains Hacker News data from 2006 to 2022.
  type: definition
  entity: Hacker News
  keywords:
  - definition
  - dataset
  - contains
  - hacker
  - news
  - data
  - '2006'
  - '2022'
  source:
    doc: motherduck.com/blog/duckdb-versus-pandas-versus-polars.md
    quote: Our dataset contains Hacker News data from 2006 to 2022.
    char_start: 0
    char_end: 56
- statement: The dataset fits into 1 parquet file compressed of ~5 GB data and it’s
    about 33M rows.
  type: definition
  entity: Hacker News
  keywords:
  - definition
  - dataset
  - fits
  - parquet
  - file
  - compressed
  - gb
  - data
  - about
  - 33m
  - rows
  source:
    doc: motherduck.com/blog/duckdb-versus-pandas-versus-polars.md
    quote: It fits into 1 parquet file compressed of ~5 GB data and it’s about 33M
      rows.
    char_start: 0
    char_end: 77
- statement: The dataset from Hacker News is about 1GB in size.
  type: definition
  entity: Hacker News
  keywords:
  - definition
  - dataset
  - hacker
  - news
  - about
  - 1gb
  - size
  source:
    doc: motherduck.com/blog/google-sheets-motherduck.md
    quote: Size is about 1GB.
    char_start: 0
    char_end: 18
- statement: Users who post more stories tend to have higher average scores.
  type: definition
  entity: Hacker News
  keywords:
  - definition
  - users
  - who
  - post
  - stories
  - tend
  - higher
  - average
  - scores
  source:
    doc: motherduck.com/blog/local-duckdb-ui-visual-data-analysis.md
    quote: In this pipeline, we are looking if posting more on Hacker News gets you
      more score on average.
    char_start: 0
    char_end: 95
- statement: The document will create a table called demo_embedding containing popular
    posts with a specific keyword.
  type: definition
  entity: Hacker News Posts
  keywords:
  - definition
  - document
  - create
  - table
  - called
  - demo
  - embedding
  - containing
  - popular
  - posts
  - specific
  - keyword
  source:
    doc: motherduck.com/blog/announcing-series-seed-and-a.md
    quote: We'll create a table called demo_embedding containing popular posts with
      a specific keyword.
    char_start: 0
    char_end: 92
- statement: hafenkran is a Berlin-based software engineer.
  type: definition
  entity: hafenkran
  keywords:
  - definition
  - hafenkran
  - berlin
  - based
  - software
  - engineer
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: hafenkran is a Berlin-based software engineer
    char_start: 0
    char_end: 45
- statement: hafenkran is the author of the BigQuery community extension for DuckDB.
  type: definition
  entity: hafenkran
  keywords:
  - definition
  - hafenkran
  - author
  - bigquery
  - community
  - extension
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: hafenkran is a Berlin-based software engineer and the author of the BigQuery
      community extension for DuckDB.
    char_start: 0
    char_end: 108
- statement: Hannes and Mehdi will speak at the Data Engineering for AI/ML conference.
  type: definition
  entity: Hannes
  keywords:
  - definition
  - hannes
  - mehdi
  - speak
  - data
  - engineering
  - ai
  - ml
  - conference
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: Hannes (co-creator of DuckDB) and Mehdi (data engineer & developer relations
      at MotherDuck) will each have their own talk about data.
    char_start: 0
    char_end: 133
- statement: Hannes believes that the impact of research is measured by widespread
    use.
  type: definition
  entity: Hannes Mühleisen
  keywords:
  - definition
  - hannes
  - believes
  - impact
  - research
  - measured
  - widespread
  - use
  source:
    doc: motherduck.com/blog/why-everybody-hates-databases.md
    quote: My definition of success as a researcher is not to write papers but to
      have an impact.
    char_start: 0
    char_end: 86
- statement: Hannes Mühleisen is a researcher at CWI.
  type: definition
  entity: Hannes Mühleisen
  keywords:
  - definition
  - hannes
  - hleisen
  - researcher
  - cwi
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: Hannes is a researcher at the Dutch research institute for computer science
      and mathematics, CWI.
    char_start: 0
    char_end: 97
- statement: Hannes Mühleisen is the co-creator of DuckDB.
  type: definition
  entity: Hannes Mühleisen
  keywords:
  - definition
  - hannes
  - hleisen
  - co
  - creator
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md
    quote: Interview with co-creator of DuckDB Hannes
    char_start: 0
    char_end: 42
- statement: Hannes Mühleisen will be a speaker at the meetup.
  type: definition
  entity: Hannes Mühleisen
  keywords:
  - definition
  - hannes
  - hleisen
  - speaker
  - meetup
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-six.md
    quote: "C\uFEFFo-creator of DuckDB Hannes Mühleisen will join us."
    char_start: 0
    char_end: 52
- statement: Hannes will be giving a keynote at the Data + AI Summit.
  type: definition
  entity: Hannes Mühleisen
  keywords:
  - definition
  - hannes
  - giving
  - keynote
  - data
  - ai
  - summit
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: Hannes will be giving a keynote at this 10-track data conference hosted
      by Databricks.
    char_start: 0
    char_end: 86
- statement: By 2023, he went on to develop harlequin, a terminal-based SQL IDE for
    DuckDB.
  type: definition
  entity: Harlequin
  keywords:
  - definition
  - '2023'
  - went
  - develop
  - harlequin
  - terminal
  - based
  - sql
  - ide
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2024.md
    quote: By 2023, he went on to develop harlequin, a terminal-based SQL IDE for
      DuckDB.
    char_start: 0
    char_end: 78
- statement: Harlequin uses SQL for database management.
  type: definition
  entity: Harlequin
  keywords:
  - definition
  - harlequin
  - uses
  - sql
  - database
  - management
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-use-cases.md
    quote: Harlequin uses SQL for database management.
    char_start: 0
    char_end: 43
- statement: Harlequin SQL IDE runs in your terminal.
  type: definition
  entity: Harlequin SQL IDE
  keywords:
  - definition
  - harlequin
  - sql
  - ide
  - runs
  - terminal
  source:
    doc: motherduck.com/learn-more/self-service-analytics-startups.md
    quote: Ted built the amazing Harlequin SQL IDE which runs in your terminal!
    char_start: 0
    char_end: 68
- statement: HashiCorp Vault is a dynamic secrets management system for secure storage
    and access to tokens, passwords, and certificates.
  type: definition
  entity: HashiCorp Vault
  keywords:
  - definition
  - hashicorp
  - vault
  - dynamic
  - secrets
  - management
  - system
  - secure
  - storage
  - access
  - tokens
  - passwords
  - certificates
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: A dynamic secrets management system for secure storage and access to tokens,
      passwords, and certificates
    char_start: 0
    char_end: 104
- statement: Hatch features OpenTelemetry tracing and config hot-reloading.
  type: feature
  entity: Hatch
  keywords:
  - feature
  - hatch
  - features
  - opentelemetry
  - tracing
  - config
  - hot
  - reloading
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: Hatch features OpenTelemetry tracing and config hot-reloading.
    char_start: 0
    char_end: 62
- statement: Hatch is Go-based, Arrow-native, and built for people who think 'composable'
    is a personality trait.
  type: feature
  entity: Hatch
  keywords:
  - feature
  - hatch
  - go
  - based
  - arrow
  - native
  - built
  - people
  - who
  - think
  - composable
  - personality
  - trait
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: Hatch is Go-based, Arrow-native, and built for people who think 'composable'
      is a personality trait.
    char_start: 0
    char_end: 100
- statement: HDBSCAN is a clustering algorithm that identifies clusters in data based
    on density.
  type: definition
  entity: HDBSCAN
  keywords:
  - definition
  - hdbscan
  - clustering
  - algorithm
  - identifies
  - clusters
  - data
  - based
  - density
  source:
    doc: motherduck.com/blog/announcing-small-data-sf-2025.md
    quote: A clustering algorithm that identifies clusters in data based on density.
    char_start: 0
    char_end: 73
- statement: HDBSCAN is a clustering algorithm that works well with large datasets.
  type: definition
  entity: HDBSCAN
  keywords:
  - definition
  - hdbscan
  - clustering
  - algorithm
  - works
  - well
  - large
  - datasets
  source:
    doc: motherduck.com/blog/announcing-small-data-sf-2025.md
    quote: A clustering algorithm that works well with large datasets.
    char_start: 0
    char_end: 59
- statement: HDFS logs are available for handling big data.
  type: definition
  entity: HDFS
  keywords:
  - definition
  - hdfs
  - logs
  - available
  - handling
  - big
  - data
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: Another example is the [HDFS Logs]...
    char_start: 0
    char_end: 37
- statement: The NameSystem manages the most operations in HDFS logs.
  type: definition
  entity: HDFS
  keywords:
  - definition
  - namesystem
  - manages
  - operations
  - hdfs
  - logs
  source:
    doc: motherduck.com/blog/flight-sql-vs-rest-vs-jdbc.md
    quote: it reveals the distribution of block operations across different HDFS components,
      with the NameSystem managing the most operations.
    char_start: 0
    char_end: 131
- statement: The feature 'help_center' is used by 374 distinct users.
  type: definition
  entity: help_center
  keywords:
  - definition
  - feature
  - help
  - center
  - used
  - '374'
  - distinct
  - users
  source:
    doc: motherduck.com/learn-more/pandas-dataframes-guide.md
    quote: '374'
    char_start: 0
    char_end: 3
- statement: Hevo data is a no-code, fully managed data integration platform.
  type: definition
  entity: Hevo
  keywords:
  - definition
  - hevo
  - data
  - code
  - fully
  - managed
  - integration
  - platform
  source:
    doc: motherduck.com/case-studies/trunkrs-same-day-delivery-motherduck-from-redshift.md
    quote: Hevo data is a no-code, fully managed data integration platform that empowers
      teams to extract, load, and transform data from different sources to their destinations
      in just a few clicks.
    char_start: 0
    char_end: 187
- statement: Hevo enables teams to extract, load, and transform data from different
    sources to their destinations in just a few clicks.
  type: definition
  entity: Hevo
  keywords:
  - definition
  - hevo
  - enables
  - teams
  - extract
  - load
  - transform
  - data
  - different
  - sources
  - destinations
  - clicks
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: Hevo data is a no-code, fully managed data integration platform that empowers
      teams to extract, load, and transform data from different sources to their destinations
      in just a few clicks.
    char_start: 0
    char_end: 187
- statement: Hevo integrates with MotherDuck by moving data from 150+ sources via
    Amazon S3 into MotherDuck’s cloud data warehouse.
  type: definition
  entity: Hevo
  keywords:
  - definition
  - hevo
  - integrates
  - motherduck
  - moving
  - data
  - '150'
  - sources
  - via
  - amazon
  - s3
  - cloud
  - warehouse
  source:
    doc: motherduck.com/case-studies/trunkrs-same-day-delivery-motherduck-from-redshift.md
    quote: Hevo integrates with MotherDuck by moving data from 150+ sources via Amazon
      S3 into MotherDuck’s cloud data warehouse.
    char_start: 0
    char_end: 118
- statement: AI isn't here to replace data work, it's here to make it better.
  type: definition
  entity: Hex
  keywords:
  - definition
  - ai
  - isn
  - replace
  - data
  - work
  - make
  - better
  source:
    doc: motherduck.com/learn-more/fix-slow-bi-dashboards.md
    quote: AI isn't here to replace data work, it's here to make it better.
    char_start: 0
    char_end: 64
- statement: Hex allows users to run SQL queries on MotherDuck's DuckDB-based backend.
  type: definition
  entity: Hex
  keywords:
  - definition
  - hex
  - allows
  - users
  - run
  - sql
  - queries
  - motherduck
  - duckdb
  - based
  - backend
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: This integration enables users to run SQL queries on MotherDuck's DuckDB-based
      backend.
    char_start: 0
    char_end: 87
- statement: Hex and MotherDuck build AI workflows that prioritize context, iteration,
    and real-world impact.
  type: definition
  entity: Hex
  keywords:
  - definition
  - hex
  - motherduck
  - build
  - ai
  - workflows
  - prioritize
  - context
  - iteration
  - real
  - world
  - impact
  source:
    doc: motherduck.com/videos.md
    quote: Hex and MotherDuck build AI workflows that prioritize context, iteration,
      and real-world impact.
    char_start: 0
    char_end: 96
- statement: Hex is a closed-source notebook for data analysis.
  type: definition
  entity: Hex
  keywords:
  - definition
  - hex
  - closed
  - source
  - notebook
  - data
  - analysis
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: 'Hex: Closed-source notebook for data analysis.'
    char_start: 0
    char_end: 46
- statement: Hex offers real-time multiplayer editing and integrates SQL, Python,
    and spreadsheets.
  type: feature
  entity: Hex
  keywords:
  - feature
  - hex
  - offers
  - real
  - time
  - multiplayer
  - editing
  - integrates
  - sql
  - python
  - spreadsheets
  source:
    doc: motherduck.com/videos/taming-file-zoos-data-science-with-duckdb-database-files.md
    quote: Hex offers real-time multiplayer editing and integrates SQL, Python, and
      spreadsheets.
    char_start: 0
    char_end: 86
- statement: MotherDuck collaborates with Hex to enhance AI workflows.
  type: definition
  entity: Hex
  keywords:
  - definition
  - motherduck
  - collaborates
  - hex
  - enhance
  - ai
  - workflows
  source:
    doc: motherduck.com/videos/a-new-paradigm-for-data-visualization-with-just-sql-markdown.md
    quote: MotherDuck collaborates with Hex to enhance AI workflows.
    char_start: 0
    char_end: 57
- statement: Hive Partitioning improves query performance on large datasets.
  type: definition
  entity: Hive Partitioning
  keywords:
  - definition
  - hive
  - partitioning
  - improves
  - query
  - performance
  - large
  - datasets
  source:
    doc: motherduck.com/videos.md
    quote: This capability, known as filter pushdown or partition pruning, can improve
      query performance on large datasets.
    char_start: 0
    char_end: 112
- statement: Holden Karau is deeply involved in one of the most popular big data frameworks.
  type: definition
  entity: Holden Karau
  keywords:
  - definition
  - holden
  - karau
  - deeply
  - involved
  - one
  - popular
  - big
  - data
  - frameworks
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eight.md
    quote: As someone deeply involved in one of the most popular big data frameworks,
      Holden brings a nuanced perspective.
    char_start: 0
    char_end: 111
- statement: You don’t need a Spark cluster if you can load your data into an Excel
    workbook.
  type: definition
  entity: Holden Karau
  keywords:
  - definition
  - don
  - need
  - spark
  - cluster
  - load
  - data
  - excel
  - workbook
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: no, you don’t need a Spark cluster if you can load your data into an Excel
      workbook.
    char_start: 0
    char_end: 84
- statement: HoloViews and GeoViews are high-level tools for easy visualization of
    complex data.
  type: definition
  entity: HoloViews
  keywords:
  - definition
  - holoviews
  - geoviews
  - high
  - level
  - tools
  - easy
  - visualization
  - complex
  - data
  source:
    doc: motherduck.com/blog/motherduck-duckdb-dbt.md
    quote: 'HoloViews: High-level tools for easy visualization of complex data.'
    char_start: 0
    char_end: 67
- statement: The feature 'homepage' is used by 352 distinct users.
  type: definition
  entity: homepage
  keywords:
  - definition
  - feature
  - homepage
  - used
  - '352'
  - distinct
  - users
  source:
    doc: motherduck.com/learn-more/pandas-dataframes-guide.md
    quote: '352'
    char_start: 0
    char_end: 3
- statement: We should focus more on the immediate task at hand.
  type: definition
  entity: Hot Data
  keywords:
  - definition
  - focus
  - immediate
  - task
  - hand
  source:
    doc: motherduck.com/videos.md
    quote: we should focus more on the immediate task at hand.
    char_start: 0
    char_end: 51
- statement: Hotel Cangas de Onis Center is one of the hotels listed in the dataset.
  type: definition
  entity: Hotel Cangas de Onis Center
  keywords:
  - definition
  - hotel
  - cangas
  - de
  - onis
  - center
  - one
  - hotels
  - listed
  - dataset
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: │ 194441 │ POINT (-5.129921424610529 43.348744254371155) │ Hotel Cangas
      de Onis Center                   │
    char_start: 0
    char_end: 106
- statement: Hotel Rural La Curva is one of the hotels listed in the dataset.
  type: definition
  entity: Hotel Rural La Curva
  keywords:
  - definition
  - hotel
  - rural
  - la
  - curva
  - one
  - hotels
  - listed
  - dataset
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: │ 203362 │ POINT (-5.075207325926755 43.448421243964304) │ Hotel Rural
      La Curva                          │
    char_start: 0
    char_end: 106
- statement: Hotel Villa Rosario is one of the hotels listed in the dataset.
  type: definition
  entity: Hotel Villa Rosario
  keywords:
  - definition
  - hotel
  - villa
  - rosario
  - one
  - hotels
  - listed
  - dataset
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: │ 299450 │ POINT (-5.06783854990374 43.465030087046614)  │ Hotel Villa
      Rosario                           │
    char_start: 0
    char_end: 106
- statement: Hoyt is passionate about the full analytics stack.
  type: definition
  entity: Hoyt Emerson
  keywords:
  - definition
  - hoyt
  - passionate
  - about
  - full
  - analytics
  - stack
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md
    quote: Hoyt is passionate about the full analytics stack, from SQL and Python
      to Polars, Streamlit, and DuckDB.
    char_start: 0
    char_end: 104
- statement: rg is used to search through files.
  type: definition
  entity: htop
  keywords:
  - definition
  - rg
  - used
  - search
  - files
  source:
    doc: motherduck.com/blog/data-warehouse-feature-roundup-oct-2024.md
    quote: Ripgrep (rg) is a recursive line-oriented search tool that searches through
      all files.
    char_start: 0
    char_end: 86
- statement: The HTTP API Server Extension allows for on-demand server deployment.
  type: feature
  entity: HTTP API Server Extension
  keywords:
  - feature
  - http
  - api
  - server
  - extension
  - allows
  - demand
  - deployment
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: With the HTTP API Server Extension, we can quickly spawn a server as part
      of our analytics environment when needed.
    char_start: 0
    char_end: 115
- statement: The httpfs extension allows reading/writing remote files over HTTPS and
    S3.
  type: definition
  entity: httpfs
  keywords:
  - definition
  - httpfs
  - extension
  - allows
  - reading
  - writing
  - remote
  - files
  - over
  - https
  - s3
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: the popular httpfs extension that allows reading/writing remote files over
      HTTPS and S3.
    char_start: 0
    char_end: 88
- statement: Hudi is a data management framework that provides capabilities for managing
    large datasets.
  type: definition
  entity: Hudi
  keywords:
  - definition
  - hudi
  - data
  - management
  - framework
  - provides
  - capabilities
  - managing
  - large
  - datasets
  source:
    doc: motherduck.com/blog/motherduck-dbt-pipelines.md
    quote: Now that everyone seems to have stopped squabbling about whether to use
      Iceberg or Hudi.
    char_start: 0
    char_end: 88
- statement: HuggingFace is known for its work in natural language processing.
  type: definition
  entity: Hugging Face
  keywords:
  - definition
  - huggingface
  - known
  - work
  - natural
  - language
  - processing
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2024.md
    quote: like the LLM and embedding model.
    char_start: 0
    char_end: 33
- statement: HuggingFace provides access to a large repository of embedding models.
  type: definition
  entity: Hugging Face
  keywords:
  - definition
  - huggingface
  - provides
  - access
  - large
  - repository
  - embedding
  - models
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: HuggingFace provides access to a large repository of embedding models.
    char_start: 0
    char_end: 70
- statement: The team trained a model using Hugging Face's Accelerate and Transformers
    library.
  type: definition
  entity: Hugging Face
  keywords:
  - definition
  - team
  - trained
  - model
  - using
  - hugging
  - face
  - accelerate
  - transformers
  - library
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: The team trained a model using Hugging Face's Accelerate and Transformers
      library to predict winning headlines.
    char_start: 0
    char_end: 111
- statement: Hybrid analytics can end slow queries and high cloud costs by analyzing
    huge local files and joining them with cloud data.
  type: definition
  entity: Hybrid Analytics
  keywords:
  - definition
  - hybrid
  - analytics
  - end
  - slow
  - queries
  - high
  - cloud
  - costs
  - analyzing
  - huge
  - local
  - files
  - joining
  - them
  - data
  source:
    doc: motherduck.com/blog/why-web-developers-should-care-about-analytical-databases.md
    quote: End slow queries & high cloud costs with hybrid analytics.
    char_start: 0
    char_end: 58
- statement: This is the reality of the hybrid analytics workflow, a powerful approach
    that unifies your local machine and the cloud into a single, unified data environment.
  type: definition
  entity: Hybrid Analytics
  keywords:
  - definition
  - reality
  - hybrid
  - analytics
  - workflow
  - powerful
  - approach
  - unifies
  - local
  - machine
  - cloud
  - single
  - unified
  - data
  - environment
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: This is the reality of the hybrid analytics workflow, a powerful approach
      that unifies your local machine and the cloud into a single, unified data environment.
    char_start: 0
    char_end: 160
- statement: The hybrid execution model provides local processing speed with cloud
    scalability.
  type: definition
  entity: hybrid execution model
  keywords:
  - definition
  - hybrid
  - execution
  - model
  - provides
  - local
  - processing
  - speed
  - cloud
  - scalability
  source:
    doc: motherduck.com/learn-more/fix-slow-bi-dashboards.md
    quote: This architecture provides the best of both worlds – local processing speed
      with cloud scalability when needed.
    char_start: 0
    char_end: 111
- statement: Hybrid search provides flexibility to adapt to a vast lookup space.
  type: definition
  entity: Hybrid Search
  keywords:
  - definition
  - hybrid
  - search
  - provides
  - flexibility
  - adapt
  - vast
  - lookup
  - space
  source:
    doc: motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md
    quote: By leveraging both lexical matching using full text search and semantic
      understanding using vector search, hybrid search provides the flexibility to
      adapt to a vast lookup space.
    char_start: 0
    char_end: 178
- statement: Hydra has contributed to building Postgres extensions.
  type: definition
  entity: Hydra
  keywords:
  - definition
  - hydra
  - contributed
  - building
  - postgres
  - extensions
  source:
    doc: motherduck.com/blog/perf-is-not-enough.md
    quote: Hydra originally kicked off the effort and has lent their know-how building
      Postgres extensions and storage.
    char_start: 0
    char_end: 108
- statement: This project is a collaborative effort between Hydra and MotherDuck.
  type: definition
  entity: Hydra
  keywords:
  - definition
  - project
  - collaborative
  - effort
  - hydra
  - motherduck
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: This project is a collaborative effort between Hydra and MotherDuck.
    char_start: 0
    char_end: 68
- statement: The benefits of hyper-tenancy include data isolation, performance isolation,
    and cost attribution.
  type: definition
  entity: hyper-tenancy
  keywords:
  - definition
  - benefits
  - hyper
  - tenancy
  - include
  - data
  - isolation
  - performance
  - cost
  - attribution
  source:
    doc: motherduck.com/videos.md
    quote: 'This provides three key benefits: Data Isolation, Performance Isolation,
      Cost Attribution.'
    char_start: 0
    char_end: 90
- statement: The I4i instance only has 75 Gigabits/sec of networking capacity.
  type: definition
  entity: I4i instance
  keywords:
  - definition
  - i4i
  - instance
  - '75'
  - gigabits
  - sec
  - networking
  - capacity
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: the I4i instance only has 75 Gigabits/sec of networking capacity
    char_start: 0
    char_end: 64
- statement: You can create an IAM user with S3 permissions.
  type: definition
  entity: IAM
  keywords:
  - definition
  - create
  - iam
  - user
  - s3
  - permissions
  source:
    doc: motherduck.com/blog/estuary-streaming-cdc-replication.md
    quote: You can create an IAM user with S3 permissions and then share the user’s
      credentials with both systems.
    char_start: 0
    char_end: 103
- statement: DuckDB provides insights into its query execution process and offers
    tips for troubleshooting common issues.
  type: definition
  entity: Ibis
  keywords:
  - definition
  - duckdb
  - provides
  - insights
  - query
  - execution
  - process
  - offers
  - tips
  - troubleshooting
  - common
  - issues
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: The article also addresses performance optimization, providing insights
      into DuckDB's query execution process and offering tips for troubleshooting
      common issues.
    char_start: 0
    char_end: 162
- statement: Ibis can be used as an interface to interact with DuckDB.
  type: definition
  entity: Ibis
  keywords:
  - definition
  - ibis
  - used
  - interface
  - interact
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: He showcases how Ibis can be used as an interface to interact with DuckDB.
    char_start: 0
    char_end: 74
- statement: Ibis enables a single library to query many backends, including DuckDB,
    Snowflake, Spark, Polars and more.
  type: definition
  entity: Ibis
  keywords:
  - definition
  - ibis
  - enables
  - single
  - library
  - query
  - many
  - backends
  - including
  - duckdb
  - snowflake
  - spark
  - polars
  source:
    doc: motherduck.com/quacking-around-the-web.md
    quote: Ibis enables a single library to query many backends, including DuckDB,
      Snowflake, Spark, Polars and more.
    char_start: 0
    char_end: 106
- statement: Ibis integrates with DuckDB to provide SQL capabilities in Python.
  type: definition
  entity: Ibis
  keywords:
  - definition
  - ibis
  - integrates
  - duckdb
  - provide
  - sql
  - capabilities
  - python
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Gil teaches us about the beautiful world of Ibis and how it integrates
      with DuckDB.
    char_start: 0
    char_end: 83
- statement: Ibis is a Python library for data analysis that provides a high-level
    interface for working with data.
  type: definition
  entity: Ibis
  keywords:
  - definition
  - ibis
  - python
  - library
  - data
  - analysis
  - provides
  - high
  - level
  - interface
  - working
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: Ibis, a Python library for data analysis that provides a high-level interface
      for working with data.
    char_start: 0
    char_end: 100
- statement: Ibis is dropping Pandas support in favor of DuckDB.
  type: definition
  entity: Ibis
  keywords:
  - definition
  - ibis
  - dropping
  - pandas
  - support
  - favor
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-five.md
    quote: 'Ibis is a portable Python dataframe that enables you to write your pipeline
      and use different engines like DuckDB, Polars, DataFusion, or PySpark. They
      used to support Pandas but are dropping support '
    char_start: 0
    char_end: 219
- statement: Ibis provides a high-level interface for analytics.
  type: definition
  entity: Ibis
  keywords:
  - definition
  - ibis
  - provides
  - high
  - level
  - interface
  - analytics
  source:
    doc: motherduck.com/blog.md
    quote: Ibis using just YAML and Python...
    char_start: 0
    char_end: 34
- statement: Migrating your Iceberg data lake to MotherDuck-managed DuckLake just
    got a lot easier.
  type: definition
  entity: Iceberg
  keywords:
  - definition
  - migrating
  - iceberg
  - data
  - lake
  - motherduck
  - managed
  - ducklake
  - got
  - lot
  - easier
  source:
    doc: motherduck.com/blog/announcing-series-seed-and-a.md
    quote: Thanks to the DuckDB iceberg extension, migrating your Iceberg data lake
      to MotherDuck-managed DuckLake just got a lot easier.
    char_start: 0
    char_end: 126
- statement: An IDE provides comprehensive facilities to programmers for software
    development.
  type: definition
  entity: IDE
  keywords:
  - definition
  - ide
  - provides
  - comprehensive
  - facilities
  - programmers
  - software
  - development
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-essential-tools.md
    quote: An integrated development environment (IDE) is where we program our code
      and get code completion, linters, and AI assistance to make us (hopefully) more
      productive.
    char_start: 0
    char_end: 164
- statement: Inecta ETL provides a comprehensive set of pre-configured data transformations
    from Microsoft Business Central.
  type: definition
  entity: Inecta ETL
  keywords:
  - definition
  - inecta
  - etl
  - provides
  - comprehensive
  - set
  - pre
  - configured
  - data
  - transformations
  - microsoft
  - business
  - central
  source:
    doc: motherduck.com/case-studies/dosomething-non-profit-tco-cost-savings.md
    quote: inectaETL provides a comprehensive set of pre-configured data transformations
      from Microsoft Business Central.
    char_start: 0
    char_end: 110
- statement: Inecta ETL provides a comprehensive set of pre-configured data transformations
    quickly pipelined into MotherDuck.
  type: definition
  entity: Inecta ETL
  keywords:
  - definition
  - inecta
  - etl
  - provides
  - comprehensive
  - set
  - pre
  - configured
  - data
  - transformations
  - quickly
  - pipelined
  - motherduck
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: inectaETL provides a comprehensive set of pre-configured data transformations
      from Microsoft Business Central, quickly pipelined into MotherDuck.
    char_start: 0
    char_end: 145
- statement: Infera integrates machine learning inference directly into SQL queries
    using ONNX models.
  type: definition
  entity: Infera
  keywords:
  - definition
  - infera
  - integrates
  - machine
  - learning
  - inference
  - directly
  - sql
  - queries
  - using
  - onnx
  - models
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: Infera is a new DuckDB extension, developed in Rust, that integrates machine
      learning inference directly into SQL queries using ONNX models via the Tract
      inference engine.
    char_start: 0
    char_end: 171
- statement: This capability allows data practitioners to perform predictions without
    moving data out of the database.
  type: definition
  entity: Infera
  keywords:
  - definition
  - capability
  - allows
  - data
  - practitioners
  - perform
  - predictions
  - without
  - moving
  - out
  - database
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: This capability allows data practitioners to perform predictions without
      moving data out of the database, streamlining ML workflows.
    char_start: 0
    char_end: 132
- statement: InfinyOn and MotherDuck announce a strategic partnership to drive end-to-end
    data streaming and analytics pipelines.
  type: definition
  entity: InfinyOn (Service)
  keywords:
  - definition
  - infinyon
  - motherduck
  - announce
  - strategic
  - partnership
  - drive
  - end
  - data
  - streaming
  - analytics
  - pipelines
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: InfinyOn and MotherDuck announce a strategic partnership to drive end-to-end
      data streaming and analytics pipelines.
    char_start: 0
    char_end: 116
- statement: Infrastructure as Code and DevOps principles transform server management
    into elegant configurations.
  type: definition
  entity: Infrastructure as Code
  keywords:
  - definition
  - infrastructure
  - code
  - devops
  - principles
  - transform
  - server
  - management
  - elegant
  - configurations
  source:
    doc: motherduck.com/blog/announcing-duckdb-13-on-motherduck-cdw.md
    quote: The secret? Infrastructure as Code and DevOps principles that transform
      scattered server management into elegant, declarative configurations.
    char_start: 0
    char_end: 141
- statement: Infrastructure management and deploying new software typically occurs
    through Infrastructure as Code (IaC) using Kubernetes.
  type: definition
  entity: Infrastructure as Code
  keywords:
  - definition
  - infrastructure
  - management
  - deploying
  - new
  - software
  - typically
  - occurs
  - code
  - iac
  - using
  - kubernetes
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: Infrastructure management and deploying new software in an automated fashion
      typically occurs through Infrastructure as Code (IaC) using Kubernetes or a
      similar platform.
    char_start: 0
    char_end: 170
- statement: An INNER JOIN combines rows only when there is a match in both tables.
  type: definition
  entity: INNER JOIN
  keywords:
  - definition
  - inner
  - join
  - combines
  - rows
  - match
  - both
  - tables
  source:
    doc: motherduck.com/blog/small-data-sf-workshops-agenda.md
    quote: An INNER JOIN (the default, so you can just write JOIN) combines rows only
      when there is a match in both tables.
    char_start: 0
    char_end: 112
- statement: Changes made to a CTE are immediately reflected in all dependent select
    nodes.
  type: feature
  entity: Instant SQL
  keywords:
  - feature
  - changes
  - made
  - cte
  - immediately
  - reflected
  - dependent
  - select
  - nodes
  source:
    doc: motherduck.com/blog/effortless-etl-unstructured-data-unstructuredio-motherduck.md
    quote: Even better, changes you make to a CTE are immediately reflected in all
      dependent select nodes.
    char_start: 0
    char_end: 95
- statement: Instant SQL allows users to break apart complex column expressions in
    their result table.
  type: feature
  entity: Instant SQL
  keywords:
  - feature
  - instant
  - sql
  - allows
  - users
  - break
  - apart
  - complex
  - column
  - expressions
  - result
  - table
  source:
    doc: motherduck.com/blog/pg-mooncake-columnstore.md
    quote: Instant SQL lets you break apart your column expressions in your result
      table to pinpoint exactly what's happening.
    char_start: 0
    char_end: 115
- statement: Instant SQL allows users to receive AI-powered edit suggestions for SQL
    queries.
  type: feature
  entity: Instant SQL
  keywords:
  - feature
  - instant
  - sql
  - allows
  - users
  - receive
  - ai
  - powered
  - edit
  - suggestions
  - queries
  source:
    doc: motherduck.com/blog/motherduck-kestra-etl-pipelines.md
    quote: Today, we're also releasing a new inline prompt editing feature for MotherDuck
      users.
    char_start: 0
    char_end: 85
- statement: Instant SQL allows you to click around and instantly visualize any CTE
    in seconds.
  type: feature
  entity: Instant SQL
  keywords:
  - feature
  - instant
  - sql
  - allows
  - click
  - around
  - instantly
  - visualize
  - any
  - cte
  - seconds
  source:
    doc: motherduck.com/blog/effortless-etl-unstructured-data-unstructuredio-motherduck.md
    quote: With Instant SQL, you can now click around and instantly visualize any
      CTE in seconds.
    char_start: 0
    char_end: 86
- statement: Instant SQL is now in Preview in MotherDuck and the DuckDB Local UI.
  type: definition
  entity: Instant SQL
  keywords:
  - definition
  - instant
  - sql
  - now
  - preview
  - motherduck
  - duckdb
  - local
  - ui
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: Instant SQL is now in Preview in MotherDuck and the DuckDB Local UI.
    char_start: 0
    char_end: 68
- statement: Instant SQL Mode eliminates the traditional write-run-debug cycle.
  type: definition
  entity: Instant SQL
  keywords:
  - definition
  - instant
  - sql
  - mode
  - eliminates
  - traditional
  - write
  - run
  - debug
  - cycle
  source:
    doc: motherduck.com/videos/what-if-sql-queries-returned-results-instantly.md
    quote: Instant SQL Mode eliminates the traditional write-run-debug cycle through
      client-side parsing and DuckDB-WASM caching.
    char_start: 0
    char_end: 118
- statement: Instant SQL speeds up query building and debugging by providing result
    set previews that update instantly.
  type: definition
  entity: Instant SQL
  keywords:
  - definition
  - instant
  - sql
  - speeds
  - up
  - query
  - building
  - debugging
  - providing
  - result
  - set
  - previews
  - update
  - instantly
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-nine.md
    quote: Instant SQL speeds up query building and debugging by providing result
      set previews that update instantly.
    char_start: 0
    char_end: 106
- statement: MotherDuck introduces Instant SQL, a feature for real-time query result
    previews as you type.
  type: definition
  entity: Instant SQL
  keywords:
  - definition
  - motherduck
  - introduces
  - instant
  - sql
  - feature
  - real
  - time
  - query
  - result
  - previews
  - type
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-nine.md
    quote: MotherDuck introduces Instant SQL, a feature for real-time query result
      previews as you type.
    char_start: 0
    char_end: 93
- statement: Using SQL with DuckDB, Iceberg, and dbt enhances data exploration.
  type: definition
  entity: Instant SQL
  keywords:
  - definition
  - using
  - sql
  - duckdb
  - iceberg
  - dbt
  - enhances
  - data
  - exploration
  source:
    doc: motherduck.com/learn-more/star-schema-data-warehouse-guide.md
    quote: practical examples of how to read from Iceberg using dbt, DuckDB, and MotherDuck
    char_start: 0
    char_end: 80
- statement: IntelliJ IDEA is used by 26.8% of developers.
  type: definition
  entity: IntelliJ IDEA
  keywords:
  - definition
  - intellij
  - idea
  - used
  - '26.8'
  - developers
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: IntelliJ IDEA (26.8%)
    char_start: 0
    char_end: 21
- statement: IoT Logs capture data from IoT devices.
  type: definition
  entity: IoT Logs
  keywords:
  - definition
  - iot
  - logs
  - capture
  - data
  - devices
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: 'IoT Logs: Capture data from Internet of Things devices and sensors.'
    char_start: 0
    char_end: 67
- statement: ipyleaflet provides interactive maps in Jupyter notebooks.
  type: definition
  entity: ipyleaflet
  keywords:
  - definition
  - ipyleaflet
  - provides
  - interactive
  - maps
  - jupyter
  - notebooks
  source:
    doc: motherduck.com/blog/motherduck-duckdb-dbt.md
    quote: 'ipyleaflet: Interactive maps in Jupyter notebooks.'
    char_start: 0
    char_end: 50
- statement: Databases implement isolation using mechanisms like locking or multiversion
    concurrency control (MVCC).
  type: definition
  entity: Isolation
  keywords:
  - definition
  - databases
  - implement
  - isolation
  - using
  - mechanisms
  - like
  - locking
  - multiversion
  - concurrency
  - control
  - mvcc
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: Databases implement isolation using mechanisms like locking or multiversion
      concurrency control (MVCC).
    char_start: 0
    char_end: 103
- statement: Isolation ensures that concurrent transactions don't interfere with each
    other.
  type: definition
  entity: Isolation
  keywords:
  - definition
  - isolation
  - ensures
  - concurrent
  - transactions
  - don
  - interfere
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: Isolation ensures that concurrent transactions don't interfere with each
      other.
    char_start: 0
    char_end: 79
- statement: Jacob Matson does SMB analytics consulting via his agency, Elliot Point
    LLC.
  type: definition
  entity: Jacob Matson
  keywords:
  - definition
  - jacob
  - matson
  - smb
  - analytics
  - consulting
  - via
  - agency
  - elliot
  - point
  - llc
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: He also does SMB analytics consulting via his agency, Elliot Point LLC.
    char_start: 0
    char_end: 71
- statement: Jacob Matson is the VP of Finance & Operations at Simetric.
  type: definition
  entity: Jacob Matson
  keywords:
  - definition
  - jacob
  - matson
  - vp
  - finance
  - operations
  - simetric
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: He is working today as the VP of Finance & Operations at Simetric.
    char_start: 0
    char_end: 66
- statement: Jacob Matson is the writer of the Modern Data Stack in a Box with DuckDB.
  type: definition
  entity: Jacob Matson
  keywords:
  - definition
  - jacob
  - matson
  - writer
  - modern
  - data
  - stack
  - box
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Jacob is the writer of the Modern Data Stack in a Box with DuckDB.
    char_start: 0
    char_end: 66
- statement: Jacob Matson presented a workshop on DuckLake.
  type: definition
  entity: Jacob Matson
  keywords:
  - definition
  - jacob
  - matson
  - presented
  - workshop
  - ducklake
  source:
    doc: motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md
    quote: run by Jacob Matson of MotherDuck
    char_start: 0
    char_end: 33
- statement: Jacob Matson transitioned from a hands-on operator to a Developer Advocate
    at MotherDuck.
  type: definition
  entity: Jacob Matson
  keywords:
  - definition
  - jacob
  - matson
  - transitioned
  - hands
  - operator
  - developer
  - advocate
  - motherduck
  source:
    doc: motherduck.com/learn-more/what-is-a-data-warehouse.md
    quote: This transition is not merely a career shift but a testament to the transformative
      power of DuckDB.
    char_start: 0
    char_end: 99
- statement: Jacob Matson's career evolution marks a significant shift in the data
    technology landscape.
  type: definition
  entity: Jacob Matson
  keywords:
  - definition
  - jacob
  - matson
  - career
  - evolution
  - marks
  - significant
  - shift
  - data
  - technology
  - landscape
  source:
    doc: motherduck.com/videos/cultivating-growth-how-gardyn-scaled-its-data-operations-with-motherduck.md
    quote: Jacob Matson's career evolution from an experienced operator in data management
      tools...
    char_start: 0
    char_end: 88
- statement: jaffle_shop is a sample dbt project used for demonstrating dbt functionalities.
  type: definition
  entity: jaffle_shop
  keywords:
  - definition
  - jaffle
  - shop
  - sample
  - dbt
  - project
  - used
  - demonstrating
  - functionalities
  source:
    doc: motherduck.com/blog/introducing-instant-sql.md
    quote: jaffle_shop is a sample dbt project used for demonstrating dbt functionalities.
    char_start: 0
    char_end: 79
- statement: Jake shares data collections on the Bluesky platform.
  type: definition
  entity: Jake
  keywords:
  - definition
  - jake
  - shares
  - data
  - collections
  - bluesky
  - platform
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: A user on the Bluesky platform who shares data collections.
    char_start: 0
    char_end: 59
- statement: Jake Thomas is a guest speaker from Okta with expertise in scaling DuckDB.
  type: definition
  entity: Jake Thomas
  keywords:
  - definition
  - jake
  - thomas
  - guest
  - speaker
  - okta
  - expertise
  - scaling
  - duckdb
  source:
    doc: motherduck.com/videos.md
    quote: 'Medhi is joined by three fascinating guests, each with unique experience
      in scaling DuckDB: Jake Thomas from Okta'
    char_start: 0
    char_end: 113
- statement: Jake Thomas providing the first R2 catalog.
  type: definition
  entity: Jake Thomas
  keywords:
  - definition
  - jake
  - thomas
  - providing
  - first
  - r2
  - catalog
  source:
    doc: motherduck.com/blog/duckdb-wasm-in-browser.md
    quote: Jake Thomas providing the first R2 catalog, see [his post](https://bsky.app/profile/jakthom.bsky.social/post/3lb4y65z24k2q)
    char_start: 0
    char_end: 123
- statement: JavaScript can be used in data engineering.
  type: definition
  entity: JavaScript
  keywords:
  - definition
  - javascript
  - used
  - data
  - engineering
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: can also run Python and JavaScript inside cells.
    char_start: 0
    char_end: 48
- statement: Bugs in our JDBC driver were killing performance.
  type: definition
  entity: JDBC
  keywords:
  - definition
  - bugs
  - jdbc
  - driver
  - killing
  - performance
  source:
    doc: motherduck.com/blog/secoda-motherduck-integration-modern-duck-stack.md
    quote: A few years later, after numerous customer complaints, we realized that
      bugs in our JDBC driver were killing performance.
    char_start: 0
    char_end: 121
- statement: Jelte worked for 5 years at Microsoft on Citus.
  type: definition
  entity: Jelte Fennema-Nio
  keywords:
  - definition
  - jelte
  - worked
  - years
  - microsoft
  - citus
  source:
    doc: motherduck.com/videos.md
    quote: Before that, Jelte worked for 5 years at Microsoft on Citus.
    char_start: 0
    char_end: 60
- statement: Jenkins is an open-source automation server with controller/agent architecture
    ideal for complex, customizable build and deployment pipelines.
  type: definition
  entity: Jenkins
  keywords:
  - definition
  - jenkins
  - open
  - source
  - automation
  - server
  - controller
  - agent
  - architecture
  - ideal
  - complex
  - customizable
  - build
  - deployment
  - pipelines
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: Open-source automation server with controller/agent architecture ideal
      for complex, customizable build and deployment pipelines
    char_start: 0
    char_end: 127
- statement: Joe Reis discussed the shift from pipelines to agents in data engineering.
  type: definition
  entity: Joe Reis
  keywords:
  - definition
  - joe
  - reis
  - discussed
  - shift
  - pipelines
  - agents
  - data
  - engineering
  source:
    doc: motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md
    quote: Joe Reis kicked us off with The Great Data Engineering Reset, talking about
      the shift from pipelines to agents
    char_start: 0
    char_end: 110
- statement: The future of data engineering is shifting from pipelines to agents.
  type: definition
  entity: Joe Reis
  keywords:
  - definition
  - future
  - data
  - engineering
  - shifting
  - pipelines
  - agents
  source:
    doc: motherduck.com/blog/search-using-duckdb-part-3.md
    quote: talking about the shift from pipelines to agents and beyond.
    char_start: 0
    char_end: 60
- statement: John Mashey popularized the term, describing the challenges of managing
    rapidly growing volumes of digital information.
  type: definition
  entity: John Mashey
  keywords:
  - definition
  - john
  - mashey
  - popularized
  - term
  - describing
  - challenges
  - managing
  - rapidly
  - growing
  - volumes
  - digital
  - information
  source:
    doc: motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md
    quote: Silicon Graphics founder John Mashey popularized the term, describing the
      challenges of managing rapidly growing volumes of digital information.
    char_start: 0
    char_end: 144
- statement: The fact that you've got a Petabyte of logs sitting on disk doesn't matter
    if all you're looking at is the last seven days.
  type: definition
  entity: Jordan Ti...
  keywords:
  - definition
  - fact
  - ve
  - got
  - petabyte
  - logs
  - sitting
  - disk
  - doesn
  - matter
  - re
  - looking
  - last
  - seven
  - days
  source:
    doc: motherduck.com/blog/motherduck-data-warehouse.md
    quote: “How big are your actual queries? The fact that you've got a Petabyte of
      logs sitting on disk doesn't matter if all you're looking at is the last seven
      days.” - Jordan Ti...
    char_start: 0
    char_end: 173
- statement: Big Data is Dead.
  type: definition
  entity: Jordan Tigani
  keywords:
  - definition
  - big
  - data
  - dead
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-two.md
    quote: Jordan Tigani, CEO + Founder of MotherDuck and one of the founding engineers
      on Google BigQuery, recently wrote a blog post called 'Big Data is Dead' which
      took the internet by storm.
    char_start: 0
    char_end: 183
- statement: Jordan Tigani and Colin Zima discuss modern data tools.
  type: definition
  entity: Jordan Tigani
  keywords:
  - definition
  - jordan
  - tigani
  - colin
  - zima
  - discuss
  - modern
  - data
  - tools
  source:
    doc: motherduck.com/videos/duckfooding-at-motherduck.md
    quote: Watch Jordan Tigani (MotherDuck) and Colin Zima (Omni) for a candid discussion
      about what the last generation of data tools got right and wrong.
    char_start: 0
    char_end: 144
- statement: Jordan Tigani challenges the decade-long dominance of Big Data.
  type: definition
  entity: Jordan Tigani
  keywords:
  - definition
  - jordan
  - tigani
  - challenges
  - decade
  - long
  - dominance
  - big
  - data
  source:
    doc: motherduck.com/videos.md
    quote: Jordan Tigani challenges the decade-long dominance of Big Data.
    char_start: 0
    char_end: 63
- statement: Jordan Tigani is a guest speaker from MotherDuck with expertise in scaling
    DuckDB.
  type: definition
  entity: Jordan Tigani
  keywords:
  - definition
  - jordan
  - tigani
  - guest
  - speaker
  - motherduck
  - expertise
  - scaling
  - duckdb
  source:
    doc: motherduck.com/videos.md
    quote: Jordan Tigani from MotherDuck
    char_start: 0
    char_end: 29
- statement: Jordan Tigani is the CEO of MotherDuck.
  type: definition
  entity: Jordan Tigani
  keywords:
  - definition
  - jordan
  - tigani
  - ceo
  - motherduck
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: MotherDuck CEO Jordan Tigani is speaking.
    char_start: 0
    char_end: 41
- statement: Jordan Tigani speaks about data analytics and MotherDuck in an era where
    Big Data is Dead.
  type: definition
  entity: Jordan Tigani
  keywords:
  - definition
  - jordan
  - tigani
  - speaks
  - about
  - data
  - analytics
  - motherduck
  - era
  - big
  - dead
  source:
    doc: motherduck.com/privacy-policy.md
    quote: Jordan Tigani, CEO of MotherDuck, speaks about data analytics and MotherDuck
      in an era where Big Data is Dead.
    char_start: 0
    char_end: 110
- statement: Jordan Tigani's presentation revisited the small data movement.
  type: definition
  entity: Jordan Tigani
  keywords:
  - definition
  - jordan
  - tigani
  - presentation
  - revisited
  - small
  - data
  - movement
  source:
    doc: motherduck.com/blog/search-using-duckdb-part-3.md
    quote: 'from the pen that spawned the small data movement, Jordan Tigani''s Small
      Data: The Embiggening took a renewed look at th...'
    char_start: 0
    char_end: 123
- statement: Jordan transitioned from Big Data to Small Data.
  type: definition
  entity: Jordan Tigani
  keywords:
  - definition
  - jordan
  - transitioned
  - big
  - data
  - small
  source:
    doc: motherduck.com/videos/duckdb-run-dbt-build-with-sub-second-execution-times.md
    quote: Jordan’s transition from Big Data to Small Data is particularly fascinating.
    char_start: 0
    char_end: 76
- statement: We should actually think about data system design in two dimensions,
    the compute size required for a workload and the size of the data within an organization.
  type: definition
  entity: Jordan Tigani
  keywords:
  - definition
  - actually
  - think
  - about
  - data
  - system
  - design
  - two
  - dimensions
  - compute
  - size
  - required
  - workload
  - within
  - organization
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: 'Jordan laid out his argument for the crowd: we should actually think about
      data system design in two dimensions, the compute size required for a workload
      and the size of the data within an organizatio'
    char_start: 0
    char_end: 202
- statement: Josh Wills is a prominent figure in Data Analytics.
  type: definition
  entity: Josh Wills
  keywords:
  - definition
  - josh
  - wills
  - prominent
  - figure
  - data
  - analytics
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-five.md
    quote: If you have been in the Data Analytics space for a while, you know very
      well who Josh Wills is.
    char_start: 0
    char_end: 95
- statement: Josh Wills is the author of dbt-duckdb.
  type: definition
  entity: Josh Wills
  keywords:
  - definition
  - josh
  - wills
  - author
  - dbt
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: Josh Wills, author of dbt-duckdb.
    char_start: 0
    char_end: 33
- statement: JSON is a lightweight data format.
  type: definition
  entity: JSON
  keywords:
  - definition
  - json
  - lightweight
  - data
  - format
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: JSON, which stands for JavaScript Object Notation, is a lightweight data
      format.
    char_start: 0
    char_end: 80
- statement: JSON is designed to be fairly easy for humans to read and write, and
    easy for machines to parse and generate.
  type: definition
  entity: JSON
  keywords:
  - definition
  - json
  - designed
  - fairly
  - easy
  - humans
  - read
  - write
  - machines
  - parse
  - generate
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: JSON, which stands for JavaScript Object Notation, is a lightweight data
      format. It is designed to be fairly easy for humans to read and write, and easy
      for machines to parse and gen...
    char_start: 0
    char_end: 185
- statement: JSON provides a hierarchical structure with nested objects and arrays,
    making it ideal for complex logging needs.
  type: definition
  entity: JSON
  keywords:
  - definition
  - json
  - provides
  - hierarchical
  - structure
  - nested
  - objects
  - arrays
  - making
  - ideal
  - complex
  - logging
  - needs
  source:
    doc: motherduck.com/blog/sql-keyboard-shortcuts-for-joyful-querying.md
    quote: JSON provides a hierarchical structure with nested objects and arrays,
      making it ideal for complex logging needs.
    char_start: 0
    char_end: 113
- statement: JSON's nested, schema-less nature makes it notoriously difficult to analyze
    with traditional SQL.
  type: definition
  entity: JSON
  keywords:
  - definition
  - json
  - nested
  - schema
  - less
  - nature
  - makes
  - notoriously
  - difficult
  - analyze
  - traditional
  - sql
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: JSON's nested, schema-less nature makes it notoriously difficult to analyze
      with traditional SQL.
    char_start: 0
    char_end: 97
- statement: The X archive data files are not in JSON format.
  type: definition
  entity: JSON
  keywords:
  - definition
  - archive
  - data
  - files
  - json
  - format
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: the X archive data files are not in JSON format.
    char_start: 0
    char_end: 48
- statement: You can instantly navigate the nested structure using simple dot notation.
  type: definition
  entity: JSON
  keywords:
  - definition
  - instantly
  - navigate
  - nested
  - structure
  - using
  - simple
  - dot
  - notation
  source:
    doc: motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse.md
    quote: You can instantly navigate the nested structure using simple dot notation.
    char_start: 0
    char_end: 74
- statement: JSON Log Analytics is a feature for analyzing logs using JSON format.
  type: definition
  entity: JSON Log Analytics
  keywords:
  - definition
  - json
  - log
  - analytics
  - feature
  - analyzing
  - logs
  - using
  - format
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: JSON Log Analytics is a feature for analyzing logs using JSON format.
    char_start: 0
    char_end: 69
- statement: JSONBench is a benchmark for data analytics on JSON.
  type: definition
  entity: JSONBench
  keywords:
  - definition
  - jsonbench
  - benchmark
  - data
  - analytics
  - json
  source:
    doc: motherduck.com/blog/flight-sql-vs-rest-vs-jdbc.md
    quote: These data sets are from JSONBench, a benchmark for data analytics on JSON
      with Bluesky JSON dataset provided in different sizes.
    char_start: 0
    char_end: 129
- statement: Julien Hurault is an experienced data engineering consultant specializing
    in modern data platforms.
  type: definition
  entity: Julien Hurault
  keywords:
  - definition
  - julien
  - hurault
  - experienced
  - data
  - engineering
  - consultant
  - specializing
  - modern
  - platforms
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md
    quote: Julien, based in Geneva, is a experienced data engineering consultant specializing
      in the development of modern data platforms for organizations aiming to become
      AI-ready.
    char_start: 0
    char_end: 171
- statement: Jumbo is built for production-scale analytics with heavy concurrent queries.
  type: definition
  entity: Jumbo
  keywords:
  - definition
  - jumbo
  - built
  - production
  - scale
  - analytics
  - heavy
  - concurrent
  - queries
  source:
    doc: motherduck.com/blog/galileo-world-geospatial.md
    quote: 'Jumbo: Built for production-scale analytics with heavy concurrent queries'
    char_start: 0
    char_end: 73
- statement: Business intelligence tools are essential for data visualization.
  type: definition
  entity: Jupyter Notebook
  keywords:
  - definition
  - business
  - intelligence
  - tools
  - essential
  - data
  - visualization
  source:
    doc: motherduck.com/blog/streaming-oracle-to-motherduck.md
    quote: Visualizing your data and showing it in a way that makes sense immediately
      is hard; that's where BI tools and data visualization come into play.
    char_start: 0
    char_end: 144
- statement: Jupyter is used by 12.8% of developers.
  type: definition
  entity: Jupyter Notebook
  keywords:
  - definition
  - jupyter
  - used
  - '12.8'
  - developers
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: Jupyter (12.8%)
    char_start: 0
    char_end: 15
- statement: Jupyter Notebook is an open-source notebook for data analysis.
  type: definition
  entity: Jupyter Notebook
  keywords:
  - definition
  - jupyter
  - notebook
  - open
  - source
  - data
  - analysis
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: 'Jupyter Notebook: Open-source notebook for data analysis.'
    char_start: 0
    char_end: 57
- statement: Notebooks are generally more flexible and allow you to visualize results
    and document the code.
  type: definition
  entity: Jupyter Notebook
  keywords:
  - definition
  - notebooks
  - generally
  - flexible
  - allow
  - visualize
  - results
  - document
  - code
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-essential-tools.md
    quote: This option is generally more flexible and allows you to visualize results
      and document the code.
    char_start: 0
    char_end: 97
- statement: Airflow is used to orchestrate workflows.
  type: definition
  entity: k9s
  keywords:
  - definition
  - airflow
  - used
  - orchestrate
  - workflows
  source:
    doc: motherduck.com/blog/data-warehouse-feature-roundup-oct-2024.md
    quote: We use data orchestrators (Airflow).
    char_start: 0
    char_end: 36
- statement: k9s is a terminal UI for managing Kubernetes clusters that simplifies
    command usage and navigation.
  type: definition
  entity: k9s
  keywords:
  - definition
  - k9s
  - terminal
  - ui
  - managing
  - kubernetes
  - clusters
  - simplifies
  - command
  - usage
  - navigation
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: A terminal UI for managing Kubernetes clusters that simplifies command
      usage and navigation
    char_start: 0
    char_end: 91
- statement: Data ingestion capabilities are crucial for cloud data warehouses.
  type: definition
  entity: Kafka
  keywords:
  - definition
  - data
  - ingestion
  - capabilities
  - crucial
  - cloud
  - warehouses
  source:
    doc: motherduck.com/learn-more/star-schema-data-warehouse-guide.md
    quote: How easily can you get data into the warehouse? Look for robust connectors
      to a wide variety of data sources, including databases, SaaS applications, streaming
      platforms (like Kafka), and cloud storag
    char_start: 0
    char_end: 202
- statement: It supports a set of Kafka connection parameters and enables multi-threaded
    consumption of topics across partitions.
  type: definition
  entity: Kafka
  keywords:
  - definition
  - supports
  - set
  - kafka
  - connection
  - parameters
  - enables
  - multi
  - threaded
  - consumption
  - topics
  - across
  - partitions
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: It supports a set of Kafka connection parameters and enables multi-threaded
      consumption of topics across partitions.
    char_start: 0
    char_end: 116
- statement: Kafka is a distributed event streaming platform.
  type: definition
  entity: Kafka
  keywords:
  - definition
  - kafka
  - distributed
  - event
  - streaming
  - platform
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: Kafka is a distributed event streaming platform.
    char_start: 0
    char_end: 48
- statement: The dataset from Kaggle contains daily Netflix Top 10 Movie/TV Show data
    for the United States from 2020 to March 2022.
  type: definition
  entity: Kaggle
  keywords:
  - definition
  - dataset
  - kaggle
  - contains
  - daily
  - netflix
  - top
  - '10'
  - movie
  - tv
  - show
  - data
  - united
  - states
  - '2020'
  - march
  - '2022'
  source:
    doc: motherduck.com/blog/read-scaling-preview.md
    quote: We'll use a small dataset from Kaggle containing daily Netflix Top 10 Movie/TV
      Show data for the United States from 2020 to March 2022.
    char_start: 0
    char_end: 135
- statement: The Kaggle Movies dataset can be loaded using MotherDuck or from an AWS
    S3 bucket.
  type: definition
  entity: Kaggle Movies dataset
  keywords:
  - definition
  - kaggle
  - movies
  - dataset
  - loaded
  - using
  - motherduck
  - aws
  - s3
  - bucket
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: 'To load the dataset you have two options: Using MotherDuck public datasets
      through shares... Read from a public AWS S3 bucket...'
    char_start: 0
    char_end: 128
- statement: Kappa Architecture is the Shift Left Foundation.
  type: definition
  entity: Kappa Architecture
  keywords:
  - definition
  - kappa
  - architecture
  - shift
  - left
  - foundation
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part2.md
    quote: 'Kappa Architecture: The Shift Left Foundation'
    char_start: 0
    char_end: 45
- statement: Kappa Architecture simplifies the Lambda architecture by treating all
    data as streams.
  type: definition
  entity: Kappa Architecture
  keywords:
  - definition
  - kappa
  - architecture
  - simplifies
  - lambda
  - treating
  - data
  - streams
  source:
    doc: motherduck.com/learn-more/data-application-architecture.md
    quote: Kappa Architecture Simplifies the Lambda architecture by treating all data
      as streams.
    char_start: 0
    char_end: 86
- statement: Kappa Architecture unifies batch and streaming into a single data processing
    paradigm.
  type: definition
  entity: Kappa Architecture
  keywords:
  - definition
  - kappa
  - architecture
  - unifies
  - batch
  - streaming
  - single
  - data
  - processing
  - paradigm
  source:
    doc: motherduck.com/case-studies/layers-multi-tenant-data-warehouse.md
    quote: Kappa Architecture unifies batch and streaming into a single data processing
      paradigm.
    char_start: 0
    char_end: 86
- statement: Kestra automates complex data workflows and integrates with MotherDuck.
  type: definition
  entity: Kestra
  keywords:
  - definition
  - kestra
  - automates
  - complex
  - data
  - workflows
  - integrates
  - motherduck
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: Kestra integrates with MotherDuck by leveraging its flexible plugin system
      to connect with the cloud data warehouse capabilities of MotherDuck.
    char_start: 0
    char_end: 143
- statement: Kestra can be leveraged to send reports and schedule them.
  type: definition
  entity: Kestra
  keywords:
  - definition
  - kestra
  - leveraged
  - send
  - reports
  - schedule
  - them
  source:
    doc: motherduck.com/blog/motherduck-kestra-etl-pipelines.md
    quote: To send that final result as an email report and schedule it to run every
      first day of the month, you can leverage an open-source orchestration tool such
      as Kestra.
    char_start: 0
    char_end: 164
- statement: Kestra is a declarative data orchestration platform.
  type: definition
  entity: Kestra
  keywords:
  - definition
  - kestra
  - declarative
  - data
  - orchestration
  - platform
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-six.md
    quote: Kestra is a declarative data orchestration platform.
    char_start: 0
    char_end: 52
- statement: Kestra triggers are used in conjunction with MotherDuck queries for anomaly
    detection.
  type: definition
  entity: Kestra
  keywords:
  - definition
  - kestra
  - triggers
  - used
  - conjunction
  - motherduck
  - queries
  - anomaly
  - detection
  source:
    doc: motherduck.com/blog/effortless-etl-unstructured-data-unstructuredio-motherduck.md
    quote: Event-driven anomaly detection using MotherDuck queries and Kestra triggers
    char_start: 0
    char_end: 75
- statement: Keyboard shortcuts are about more than just speed, they're about maintaining
    an uninterrupted analytical flow.
  type: definition
  entity: Keyboard Shortcuts
  keywords:
  - definition
  - keyboard
  - shortcuts
  - about
  - speed
  - re
  - maintaining
  - uninterrupted
  - analytical
  - flow
  source:
    doc: motherduck.com/blog/duckdb-excel-extension.md
    quote: Keyboard shortcuts are about more than just speed, they're about maintaining
      an uninterrupted analytical flow that feels good to use.
    char_start: 0
    char_end: 133
- statement: Khalil Muhammad is a speaker at the DuckDB meetup.
  type: definition
  entity: Khalil Muhammad
  keywords:
  - definition
  - khalil
  - muhammad
  - speaker
  - duckdb
  - meetup
  source:
    doc: motherduck.com/videos.md
    quote: Khalil Muhammad at the DuckDB meetup in Dublin on 23 January 2024!
    char_start: 0
    char_end: 66
- statement: Kubernetes has significant advantages for deployment.
  type: definition
  entity: Kubernetes
  keywords:
  - definition
  - kubernetes
  - significant
  - advantages
  - deployment
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: Kubernetes has significant advantages.
    char_start: 0
    char_end: 38
- statement: Kubernetes is the de facto standard for cloud-agnostic deployment.
  type: definition
  entity: Kubernetes
  keywords:
  - definition
  - kubernetes
  - de
  - facto
  - standard
  - cloud
  - agnostic
  - deployment
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: Kubernetes matches that and ramps the right amount of server, CPU, memory,
      etc., to make it runnable and scalable on any cloud.
    char_start: 0
    char_end: 127
- statement: Kuzu is a knowledge graph storage system used in cognee.
  type: definition
  entity: Kuzu
  keywords:
  - definition
  - kuzu
  - knowledge
  - graph
  - storage
  - system
  - used
  - cognee
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: Kuzu (knowledge graphs) store it.
    char_start: 0
    char_end: 33
- statement: Cloning allows creating a copy of a dataset without duplicating data.
  type: definition
  entity: lakeFS
  keywords:
  - definition
  - cloning
  - allows
  - creating
  - copy
  - dataset
  - without
  - duplicating
  - data
  source:
    doc: motherduck.com/blog/semantic-layer-duckdb-tutorial.md
    quote: 'We can say that the difference is: Cloning = Can you create a copy?'
    char_start: 0
    char_end: 67
- statement: LakeFS implements Git-like features for data versioning.
  type: definition
  entity: lakeFS
  keywords:
  - definition
  - lakefs
  - implements
  - git
  - like
  - features
  - data
  - versioning
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: The LakeFS solution (more on how it works later down) and its implemented
      Git-like features.
    char_start: 0
    char_end: 92
- statement: lakeFS provides branch-based isolation for data lakes.
  type: definition
  entity: lakeFS
  keywords:
  - definition
  - lakefs
  - provides
  - branch
  - based
  - isolation
  - data
  - lakes
  source:
    doc: motherduck.com/blog/motherduck-union-orchestration.md
    quote: layered with lakeFS for branch-based isolation across your entire data
      lake.
    char_start: 0
    char_end: 76
- statement: LakeFS, Nessie, and Bauplan are tools that facilitate Git-like workflows
    for data management.
  type: definition
  entity: lakeFS
  keywords:
  - definition
  - lakefs
  - nessie
  - bauplan
  - tools
  - facilitate
  - git
  - like
  - workflows
  - data
  - management
  source:
    doc: motherduck.com/blog/getting-started-ducklake-table-format.md
    quote: that's where tools such as LakeFS, Nessie, Bauplan and approaches like
      branching found a way to do it for a dedicated spot or across the stack.
    char_start: 0
    char_end: 143
- statement: The most efficient approach uses metadata/catalog-based versioning.
  type: definition
  entity: lakeFS
  keywords:
  - definition
  - efficient
  - approach
  - uses
  - metadata
  - catalog
  - based
  - versioning
  source:
    doc: motherduck.com/blog/git-for-data-part-1.md
    quote: The most efficient approach uses metadata/catalog-based versioning.
    char_start: 0
    char_end: 67
- statement: Lakehouse architecture combines elements of data lakes and data warehouses.
  type: definition
  entity: Lakehouse
  keywords:
  - definition
  - lakehouse
  - architecture
  - combines
  - elements
  - data
  - lakes
  - warehouses
  source:
    doc: motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md
    quote: A data management architecture that combines elements of data lakes and
      data warehouses.
    char_start: 0
    char_end: 88
- statement: Lakehouse architectures often suffer from high latency because they query
    data directly on cloud object storage like S3.
  type: definition
  entity: lakehouse architectures
  keywords:
  - definition
  - lakehouse
  - architectures
  - often
  - suffer
  - high
  - latency
  - query
  - data
  - directly
  - cloud
  - object
  - storage
  - like
  - s3
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: Lakehouse architectures often suffer from high latency because they query
      data directly on cloud object storage like S3.
    char_start: 0
    char_end: 120
- statement: The open data platform architecture represents the next evolution of
    or extends the Lakehouse core principle.
  type: definition
  entity: Lakehouses
  keywords:
  - definition
  - open
  - data
  - platform
  - architecture
  - represents
  - next
  - evolution
  - extends
  - lakehouse
  - core
  - principle
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: The open data platform architecture, with its open table formats, represents
      the next evolution of or extends the Lakehouse core principle.
    char_start: 0
    char_end: 139
- statement: Lambda Architecture combines batch processing for comprehensive results
    with stream processing for real-time insights.
  type: definition
  entity: Lambda Architecture
  keywords:
  - definition
  - lambda
  - architecture
  - combines
  - batch
  - processing
  - comprehensive
  - results
  - stream
  - real
  - time
  - insights
  source:
    doc: motherduck.com/learn-more/data-application-architecture.md
    quote: Lambda Architecture Combines batch processing for comprehensive results
      with stream processing for real-time insights.
    char_start: 0
    char_end: 118
- statement: Lance focuses on machine learning workloads with random access performance.
  type: definition
  entity: Lance
  keywords:
  - definition
  - lance
  - focuses
  - machine
  - learning
  - workloads
  - random
  - access
  - performance
  source:
    doc: motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md
    quote: Lance, as the newcomer, focuses explicitly on ML workloads with random
      access performance.
    char_start: 0
    char_end: 90
- statement: LangChain is a framework for building applications with language models.
  type: definition
  entity: LangChain
  keywords:
  - definition
  - langchain
  - framework
  - building
  - applications
  - language
  - models
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: A framework for building applications with language models.
    char_start: 0
    char_end: 59
- statement: The systems evolve from simple chains to dynamic, context-aware agents.
  type: definition
  entity: LangChain
  keywords:
  - definition
  - systems
  - evolve
  - simple
  - chains
  - dynamic
  - context
  - aware
  - agents
  source:
    doc: motherduck.com/videos.md
    quote: evolving from simple chains to dynamic, context-aware agents for real-world
      AI applications.
    char_start: 0
    char_end: 92
- statement: Language models can understand context, handle subtleties like sarcasm,
    and generalize across domains.
  type: definition
  entity: language models
  keywords:
  - definition
  - language
  - models
  - understand
  - context
  - handle
  - subtleties
  - like
  - sarcasm
  - generalize
  - across
  - domains
  source:
    doc: motherduck.com/blog/motherduck-in-europe.md
    quote: Language models overcome these challenges. They can understand context,
      handle subtleties like sarcasm, and generalize across domains.
    char_start: 0
    char_end: 134
- statement: Large Language Models (LLMs) need business context to understand the
    business.
  type: definition
  entity: Large Language Models (LLMs)
  keywords:
  - definition
  - large
  - language
  - models
  - llms
  - need
  - business
  - context
  - understand
  source:
    doc: motherduck.com/blog/pushing-geo-boundaries-with-motherduck-geobase.md
    quote: Internal Large Language Models (LLMs) or Retrieval-Augmented Generation
      (RAG) systems need business context to understand the business.
    char_start: 0
    char_end: 135
- statement: Layers avoided a projected 1,000x cost increase by re-architecting their
    stack around MotherDuck.
  type: definition
  entity: Layers
  keywords:
  - definition
  - layers
  - avoided
  - projected
  - 000x
  - cost
  - increase
  - re
  - architecting
  - stack
  - around
  - motherduck
  source:
    doc: motherduck.com/videos.md
    quote: The retail analytics platform Layers was facing a projected 1,000x cost
      increase from their data vendor. To avoid this, they re-architected their stack
      around MotherDuck.
    char_start: 0
    char_end: 170
- statement: Layers faced concurrency issues with their analytics running on PostgreSQL.
  type: definition
  entity: Layers
  keywords:
  - definition
  - layers
  - faced
  - concurrency
  - issues
  - analytics
  - running
  - postgresql
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: Their analytics, running on PostgreSQL, were overwhelmed when their BI
      tool masked 73 simultaneous users behind a single service account.
    char_start: 0
    char_end: 137
- statement: Layers improved dashboard loading times to 110 ms.
  type: definition
  entity: Layers
  keywords:
  - definition
  - layers
  - improved
  - dashboard
  - loading
  - times
  - '110'
  - ms
  source:
    doc: motherduck.com/learn-more/no-etl-query-raw-files.md
    quote: '[dashboards loading in](https://motherduck.com/case-studies/layers-multi-tenant-data-warehouse/).**110
      ms**'
    char_start: 0
    char_end: 107
- statement: Migrating to MotherDuck improved query timeouts to virtually zero.
  type: definition
  entity: Layers
  keywords:
  - definition
  - migrating
  - motherduck
  - improved
  - query
  - timeouts
  - virtually
  - zero
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: The result was a dramatic improvement in stability, with BI query timeouts
      dropping to virtually zero.
    char_start: 0
    char_end: 102
- statement: The retail analytics platform Layers avoided a 1,000x cost increase with
    MotherDuck.
  type: definition
  entity: Layers
  keywords:
  - definition
  - retail
  - analytics
  - platform
  - layers
  - avoided
  - 000x
  - cost
  - increase
  - motherduck
  source:
    doc: motherduck.com/videos.md
    quote: The retail analytics platform [**Layers**](https://motherduck.com/case-studies/layers-multi-tenant-data-warehouse/)
      was fac...
    char_start: 0
    char_end: 126
- statement: Lazygit is a terminal UI for Git that simplifies command usage and navigation.
  type: definition
  entity: Lazygit
  keywords:
  - definition
  - lazygit
  - terminal
  - ui
  - git
  - simplifies
  - command
  - usage
  - navigation
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: A terminal UI for Git that simplifies command usage and navigation
    char_start: 0
    char_end: 66
- statement: A modern stack delivers speed at every stage of the data lifecycle.
  type: definition
  entity: Lean Data Stack
  keywords:
  - definition
  - modern
  - stack
  - delivers
  - speed
  - every
  - stage
  - data
  - lifecycle
  source:
    doc: motherduck.com/videos/whats-new-in-data-small-data-big-impact.md
    quote: A modern stack delivers speed at every stage of the data lifecycle.
    char_start: 0
    char_end: 67
- statement: A LEFT JOIN keeps all the rows from the first table, even if there's
    no match in the second table.
  type: definition
  entity: LEFT JOIN
  keywords:
  - definition
  - left
  - join
  - keeps
  - rows
  - first
  - table
  - even
  - match
  - second
  source:
    doc: motherduck.com/blog/small-data-sf-workshops-agenda.md
    quote: What if you want to keep all the rows from the first (or 'left') table,
      even if there's no match in the second table? For that, you use a LEFT JOIN.
    char_start: 0
    char_end: 148
- statement: Lightdash instantly turns your dbt project into a full-stack BI platform.
  type: definition
  entity: Lightdash
  keywords:
  - definition
  - lightdash
  - instantly
  - turns
  - dbt
  - project
  - full
  - stack
  - bi
  - platform
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: 'Lightdash: Instantly turn your dbt project into a full-stack BI platform.'
    char_start: 0
    char_end: 73
- statement: 'Lindsay Murphy and Mehdi tackle a big challenge for data professionals:
    dealing with old SQL scripts.'
  type: definition
  entity: Lindsay Murphy
  keywords:
  - definition
  - lindsay
  - murphy
  - mehdi
  - tackle
  - big
  - challenge
  - data
  - professionals
  - dealing
  - old
  - sql
  - scripts
  source:
    doc: motherduck.com/videos/simple-way-to-convert-csv-and-parquet-files.md
    quote: 'Lindsay Murphy and Mehdi tackle a big challenge for data professionals:
      dealing with old SQL scripts.'
    char_start: 0
    char_end: 101
- statement: Basic terminal navigation and Bash are needed, and learned through practical
    experience rather than formal study.
  type: definition
  entity: Linux
  keywords:
  - definition
  - basic
  - terminal
  - navigation
  - bash
  - needed
  - learned
  - practical
  - experience
  - rather
  - formal
  - study
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eleven.md
    quote: Basic terminal navigation and Bash are needed, and learned through practical
      experience rather than formal study.
    char_start: 0
    char_end: 113
- statement: Linux fundamentals are key to elevating your data engineering skills.
  type: definition
  entity: Linux
  keywords:
  - definition
  - linux
  - fundamentals
  - key
  - elevating
  - data
  - engineering
  - skills
  source:
    doc: motherduck.com/learn-more/bigquery-alternative-motherduck.md
    quote: That's why Linux fundamentals are key to elevating your data engineering
      skills.
    char_start: 0
    char_end: 80
- statement: Linux is a better option for command line work compared to Windows.
  type: definition
  entity: Linux
  keywords:
  - definition
  - linux
  - better
  - option
  - command
  - line
  - work
  - compared
  - windows
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: Linux or MacOS are still the better option.
    char_start: 0
    char_end: 43
- statement: Linux is an open-source operating system.
  type: definition
  entity: Linux
  keywords:
  - definition
  - linux
  - open
  - source
  - operating
  - system
  source:
    doc: motherduck.com/blog/analyze-x-data-nodejs-duckdb.md
    quote: Linux DE Fundamentals
    char_start: 0
    char_end: 21
- statement: Linux is key to a data engineer.
  type: definition
  entity: Linux
  keywords:
  - definition
  - linux
  - key
  - data
  - engineer
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: Linux is key to a data engineer.
    char_start: 0
    char_end: 32
- statement: Most data platforms that run on a server will run on a Linux-based OS
    system.
  type: definition
  entity: Linux
  keywords:
  - definition
  - data
  - platforms
  - run
  - server
  - linux
  - based
  - os
  - system
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-essential-tools.md
    quote: most data platforms that run on a server will run on a Linux-based OS system.
    char_start: 0
    char_end: 77
- statement: Navigating your local laptop using the terminal is essential.
  type: definition
  entity: Linux
  keywords:
  - definition
  - navigating
  - local
  - laptop
  - using
  - terminal
  - essential
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eleven.md
    quote: I would say that navigating your local laptop using the terminal (creating,
      editing, and deleting files) are the basics.
    char_start: 0
    char_end: 120
- statement: Llama models provided the best results for industry classification.
  type: definition
  entity: Llama models
  keywords:
  - definition
  - llama
  - models
  - provided
  - best
  - results
  - industry
  - classification
  source:
    doc: motherduck.com/learn-more/duckdb-vs-sqlite-databases.md
    quote: Llama models provided the best results for industry classification.
    char_start: 0
    char_end: 67
- statement: The llama2 model is used in this project.
  type: definition
  entity: llama2
  keywords:
  - definition
  - llama2
  - model
  - used
  - project
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2024.md
    quote: In this project, we use the ‘llama2’ model.
    char_start: 0
    char_end: 43
- statement: Llama-Index is easy to integrate with other parts of an AI assistant.
  type: definition
  entity: LlamaIndex
  keywords:
  - definition
  - llama
  - index
  - easy
  - integrate
  - parts
  - ai
  - assistant
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2024.md
    quote: the Llama-Index integration is easy to integrate with the other parts of
      an AI assistant.
    char_start: 0
    char_end: 89
- statement: LlamaIndex has a convenient integration for Ollama.
  type: definition
  entity: LlamaIndex
  keywords:
  - definition
  - llamaindex
  - convenient
  - integration
  - ollama
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2024.md
    quote: LlamaIndex has a convenient integration for Ollama.
    char_start: 0
    char_end: 51
- statement: LlamaIndex is a data framework for LLMs.
  type: definition
  entity: LlamaIndex
  keywords:
  - definition
  - llamaindex
  - data
  - framework
  - llms
  source:
    doc: motherduck.com/blog/log-processing-savings-bacalhau-motherduck.md
    quote: using LlamaIndex, a data framework for LLMs...
    char_start: 0
    char_end: 46
- statement: Large Language Models are a type of AI model designed to understand and
    generate human language.
  type: definition
  entity: LLMs
  keywords:
  - definition
  - large
  - language
  - models
  - type
  - ai
  - model
  - designed
  - understand
  - generate
  - human
  source:
    doc: motherduck.com/videos.md
    quote: Large Language Models, a type of AI model designed to understand and generate
      human language.
    char_start: 0
    char_end: 93
- statement: LLMs are leveraged for faster, more flexible analytics.
  type: definition
  entity: LLMs
  keywords:
  - definition
  - llms
  - leveraged
  - faster
  - flexible
  - analytics
  source:
    doc: motherduck.com/videos.md
    quote: leveraging LLMs, DuckDB, and local development for faster, more flexible
      analytics.
    char_start: 0
    char_end: 83
- statement: LLMs are used in AI applications.
  type: definition
  entity: LLMs
  keywords:
  - definition
  - llms
  - used
  - ai
  - applications
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md
    quote: 'A new standard for AI: llms.txt'
    char_start: 0
    char_end: 31
- statement: 'The `llms.txt` spec introduces two files: `/llms.txt` and `/llms-full.txt`.'
  type: definition
  entity: llms.txt
  keywords:
  - definition
  - llms
  - txt
  - spec
  - introduces
  - two
  - files
  - full
  source:
    doc: motherduck.com/blog/read-scaling-preview.md
    quote: 'The `llms.txt` spec introduces two files: `/llms.txt` and `/llms-full.txt`.'
    char_start: 0
    char_end: 75
- statement: We infer your general location information using your IP address.
  type: definition
  entity: Location Information
  keywords:
  - definition
  - infer
  - general
  - location
  - information
  - using
  - ip
  - address
  source:
    doc: motherduck.com/videos/duckdb-run-dbt-build-with-sub-second-execution-times.md
    quote: When you use our Website, we infer your general location information, for
      example, by using your internet protocol (IP) address.
    char_start: 0
    char_end: 128
- statement: Efficient log management is a competitive advantage.
  type: definition
  entity: log
  keywords:
  - definition
  - efficient
  - log
  - management
  - competitive
  - advantage
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: Efficiently is a competitive advantage in today's data-driven world.
    char_start: 0
    char_end: 68
- statement: 'Log files hold various data types, but two are always present: timestamp
    and some log, error or message.'
  type: definition
  entity: log
  keywords:
  - definition
  - log
  - files
  - hold
  - various
  - data
  - types
  - two
  - always
  - present
  - timestamp
  - error
  - message
  source:
    doc: motherduck.com/blog/sql-keyboard-shortcuts-for-joyful-querying.md
    quote: 'Log files hold various data types, but two are always present: timestamp
      and some log, error or message.'
    char_start: 0
    char_end: 104
- statement: Effective log analysis is a competitive advantage in today's data-driven
    world.
  type: definition
  entity: log analysis
  keywords:
  - definition
  - effective
  - log
  - analysis
  - competitive
  - advantage
  - today
  - data
  - driven
  - world
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: Knowing how to analyze logs straightforwardly and efficiently is a competitive
      advantage in today's data-driven world.
    char_start: 0
    char_end: 118
- statement: Much of the log data isn't immediately useful.
  type: definition
  entity: log data
  keywords:
  - definition
  - much
  - log
  - data
  - isn
  - immediately
  - useful
  source:
    doc: motherduck.com/blog/motherduck-window-functions-in-sql.md
    quote: The truth is, much of this data isn't immediately useful.
    char_start: 0
    char_end: 57
- statement: Log-based CDC reads changes directly from a database transaction log.
  type: definition
  entity: log-based CDC
  keywords:
  - definition
  - log
  - based
  - cdc
  - reads
  - changes
  - directly
  - database
  - transaction
  source:
    doc: motherduck.com/blog/summer-data-engineering-roadmap.md
    quote: the most common method (and the one we’ll be focusing on) is log-based
      CDC.
    char_start: 0
    char_end: 75
- statement: Loghub provides a large collection of system logs and datasets for log
    analytics.
  type: definition
  entity: Loghub
  keywords:
  - definition
  - loghub
  - provides
  - large
  - collection
  - system
  - logs
  - datasets
  - log
  - analytics
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2024.md
    quote: Loghub that provides a large collection of system logs and datasets for
      log analytics.
    char_start: 0
    char_end: 86
- statement: loguru is a library for logging in Python, designed to be simple and
    easy to use.
  type: definition
  entity: loguru
  keywords:
  - definition
  - loguru
  - library
  - logging
  - python
  - designed
  - simple
  - easy
  - use
  source:
    doc: motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md
    quote: loguru is a library for logging in Python, designed to be simple and easy
      to use.
    char_start: 0
    char_end: 81
- statement: Loguru is used for logging.
  type: definition
  entity: loguru
  keywords:
  - definition
  - loguru
  - used
  - logging
  source:
    doc: motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md
    quote: We also saw interesting libraries like loguru for logging.
    char_start: 0
    char_end: 58
- statement: Lonboard is a geo visualization tool used for mapping.
  type: definition
  entity: Lonboard
  keywords:
  - definition
  - lonboard
  - geo
  - visualization
  - tool
  - used
  - mapping
  source:
    doc: motherduck.com/blog/simplifying-iot-analytics-motherduck.md
    quote: A geo visualization tool used for mapping.
    char_start: 0
    char_end: 42
- statement: Lonboard is a library for fast, interactive geospatial vector data visualization
    in Jupyter.
  type: definition
  entity: Lonboard
  keywords:
  - definition
  - lonboard
  - library
  - fast
  - interactive
  - geospatial
  - vector
  - data
  - visualization
  - jupyter
  source:
    doc: motherduck.com/blog/motherduck-duckdb-dbt.md
    quote: 'Lonboard: library for fast, interactive geospatial vector data visualization
      in Jupyter.'
    char_start: 0
    char_end: 88
- statement: Lonboard is performant because it doesn't use GeoJSON as an intermediate
    step.
  type: feature
  entity: Lonboard
  keywords:
  - feature
  - lonboard
  - performant
  - doesn
  - use
  - geojson
  - intermediate
  - step
  source:
    doc: motherduck.com/blog/simplifying-iot-analytics-motherduck.md
    quote: It's performant because it doesn't use GeoJSON as an intermediate step
      to transfer the data to the front end.
    char_start: 0
    char_end: 109
- statement: MotherDuck is organizing the London low key data meetup.
  type: definition
  entity: London low key data meetup
  keywords:
  - definition
  - motherduck
  - organizing
  - london
  - low
  - key
  - data
  - meetup
  source:
    doc: motherduck.com/blog/search-using-duckdb-part-3.md
    quote: Join MotherDuck and LEIT Data for a low-key data meetup.
    char_start: 0
    char_end: 56
- statement: Looker introduced Measures in SQL, allowing context-sensitive expressions.
  type: definition
  entity: Looker
  keywords:
  - definition
  - looker
  - introduced
  - measures
  - sql
  - allowing
  - context
  - sensitive
  - expressions
  source:
    doc: motherduck.com/blog/duckdb-enterprise-5-key-categories.md
    quote: Looker by Google introduced Measures in SQL, which brings composable calculations
      to SQL.
    char_start: 0
    char_end: 89
- statement: Querying the logs directly takes about 3 seconds on a MacBook M1.
  type: definition
  entity: MacBook M1
  keywords:
  - definition
  - querying
  - logs
  - directly
  - takes
  - about
  - seconds
  - macbook
  - m1
  source:
    doc: motherduck.com/blog/flight-sql-vs-rest-vs-jdbc.md
    quote: querying this directly takes about 3 seconds on my MacBook M1.
    char_start: 0
    char_end: 62
- statement: Machine Learning is a subset of AI focused on algorithms and statistical
    models.
  type: definition
  entity: Machine Learning
  keywords:
  - definition
  - machine
  - learning
  - subset
  - ai
  - focused
  - algorithms
  - statistical
  - models
  source:
    doc: motherduck.com/videos.md
    quote: Machine Learning, a subset of AI focused on algorithms and statistical
      models.
    char_start: 0
    char_end: 78
- statement: Machine Learning is a field of artificial intelligence.
  type: definition
  entity: Machine Learning (ML)
  keywords:
  - definition
  - machine
  - learning
  - field
  - artificial
  - intelligence
  source:
    doc: motherduck.com/videos/a-new-paradigm-for-data-visualization-with-just-sql-markdown.md
    quote: Machine Learning is a field of artificial intelligence.
    char_start: 0
    char_end: 55
- statement: Machine Learning often involves data analysis techniques.
  type: definition
  entity: Machine Learning (ML)
  keywords:
  - definition
  - machine
  - learning
  - often
  - involves
  - data
  - analysis
  - techniques
  source:
    doc: motherduck.com/videos.md
    quote: Machine Learning often involves data analysis techniques.
    char_start: 0
    char_end: 57
- statement: Mage is a tool for building data pipelines and workflows.
  type: definition
  entity: Mage
  keywords:
  - definition
  - mage
  - tool
  - building
  - data
  - pipelines
  - workflows
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: A tool for building data pipelines and workflows.
    char_start: 0
    char_end: 49
- statement: Makefiles let us store a combination of commands.
  type: definition
  entity: Makefile
  keywords:
  - definition
  - makefiles
  - let
  - us
  - store
  - combination
  - commands
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: 'Makefiles let us store a combination of commands like this:'
    char_start: 0
    char_end: 59
- statement: MapLibre GL JS provides interactive vector tile maps in the browser.
  type: definition
  entity: MapLibre GL JS
  keywords:
  - definition
  - maplibre
  - gl
  - js
  - provides
  - interactive
  - vector
  - tile
  - maps
  - browser
  source:
    doc: motherduck.com/blog/motherduck-duckdb-dbt.md
    quote: 'MapLibre GL JS: Interactive vector tile maps in the browser.'
    char_start: 0
    char_end: 60
- statement: Marcos creates newsletters about data gigs and AWS graviton.
  type: definition
  entity: Marcos
  keywords:
  - definition
  - marcos
  - creates
  - newsletters
  - about
  - data
  - gigs
  - aws
  - graviton
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: 'By night, I create newsletters for a few topics I''m passionate about:
      helping folks find data gigs and AWS graviton.'
    char_start: 0
    char_end: 116
- statement: Marcos creates newsletters for topics he is passionate about.
  type: definition
  entity: Marcos
  keywords:
  - definition
  - marcos
  - creates
  - newsletters
  - topics
  - passionate
  - about
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md
    quote: By night, I create newsletters for a few topics I'm passionate about.
    char_start: 0
    char_end: 69
- statement: Marcos has retired from writing the DuckDB Ecosystem Monthly newsletter.
  type: definition
  entity: Marcos
  keywords:
  - definition
  - marcos
  - retired
  - writing
  - duckdb
  - ecosystem
  - monthly
  - newsletter
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md
    quote: The last issue was the end of an era - Marcos has retired from writing
      the DuckDB Ecosystem Monthly newsletter.
    char_start: 0
    char_end: 111
- statement: Marcos is a data engineer by day at X-Team, working for Riot Games.
  type: definition
  entity: Marcos
  keywords:
  - definition
  - marcos
  - data
  - engineer
  - day
  - team
  - working
  - riot
  - games
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md
    quote: I'm a data engineer by day at X-Team, working for Riot Games.
    char_start: 0
    char_end: 61
- statement: Marcos is the DuckDB News Reporter.
  type: definition
  entity: Marcos
  keywords:
  - definition
  - marcos
  - duckdb
  - news
  - reporter
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: Marcos, aka 'DuckDB News Reporter'.
    char_start: 0
    char_end: 35
- statement: Marcos partners with the MotherDuck team to share DuckDB news.
  type: definition
  entity: Marcos
  keywords:
  - definition
  - marcos
  - partners
  - motherduck
  - team
  - share
  - duckdb
  - news
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: I saw a great opportunity to partner with the MotherDuck team to share
      all the amazing things happening in the DuckDB ecosystem.
    char_start: 0
    char_end: 128
- statement: Marcos Ortiz provides updates on the DuckDB ecosystem.
  type: definition
  entity: Marcos Ortiz
  keywords:
  - definition
  - marcos
  - ortiz
  - provides
  - updates
  - duckdb
  - ecosystem
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md
    quote: This month in the DuckDB Ecosystem, by Marcos Ortiz.
    char_start: 0
    char_end: 52
- statement: marimo is a library for text analysis and embedding.
  type: definition
  entity: marimo
  keywords:
  - definition
  - marimo
  - library
  - text
  - analysis
  - embedding
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eight.md
    quote: marimo locally installed. First, create a new virtual environment...
    char_start: 0
    char_end: 68
- statement: Marimo is a library used for creating interactive applications and visualizations.
  type: definition
  entity: marimo
  keywords:
  - definition
  - marimo
  - library
  - used
  - creating
  - interactive
  - applications
  - visualizations
  source:
    doc: motherduck.com/blog/announcing-small-data-sf-2025.md
    quote: The marimo library is used for creating interactive applications.
    char_start: 0
    char_end: 65
- statement: marimo is a reactive Python and SQL notebook that keeps track of the
    dependencies between cells.
  type: definition
  entity: marimo
  keywords:
  - definition
  - marimo
  - reactive
  - python
  - sql
  - notebook
  - keeps
  - track
  - dependencies
  - cells
  source:
    doc: motherduck.com/blog/dosomething-motherduck-data-warehouse-ROI.md
    quote: For those new to marimo, marimo is a reactive Python and SQL notebook that
      keeps track of the dependencies between cells.
    char_start: 0
    char_end: 121
- statement: Marimo is an open-source notebook for data analysis.
  type: definition
  entity: marimo
  keywords:
  - definition
  - marimo
  - open
  - source
  - notebook
  - data
  - analysis
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: 'Marimo: Open-source notebook for data analysis.'
    char_start: 0
    char_end: 47
- statement: marimo supports both Python and SQL cells, making database operations
    straightforward.
  type: definition
  entity: marimo
  keywords:
  - definition
  - marimo
  - supports
  - both
  - python
  - sql
  - cells
  - making
  - database
  - operations
  - straightforward
  source:
    doc: motherduck.com/blog/announcing-series-seed-and-a.md
    quote: marimo supports both Python and SQL cells, making database operations straightforward.
    char_start: 0
    char_end: 86
- statement: The marimo tool is used for visualizing text embeddings.
  type: definition
  entity: marimo
  keywords:
  - definition
  - marimo
  - tool
  - used
  - visualizing
  - text
  - embeddings
  source:
    doc: motherduck.com/blog/big-data-is-dead.md
    quote: 'By the end of this tutorial, you''ll have: - An interactive visualization
      of text embeddings in 2D...'
    char_start: 0
    char_end: 100
- statement: Mark demonstrated DuckDB function chaining.
  type: definition
  entity: Mark Needham
  keywords:
  - definition
  - mark
  - demonstrated
  - duckdb
  - function
  - chaining
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: Mark Needham shows us in this video how to make your long SQL script...
    char_start: 0
    char_end: 71
- statement: Mark Needham has a blog and YouTube channel about data analytics.
  type: definition
  entity: Mark Needham
  keywords:
  - definition
  - mark
  - needham
  - blog
  - youtube
  - channel
  - about
  - data
  - analytics
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: it’s highly likely you have found his amazing blog and YouTube channel.
    char_start: 0
    char_end: 71
- statement: Mark Needham is a skilled blogger and video creator at LearnDataWithMark.
  type: definition
  entity: Mark Needham
  keywords:
  - definition
  - mark
  - needham
  - skilled
  - blogger
  - video
  - creator
  - learndatawithmark
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md
    quote: Mark Needham is not only a skilled blogger and video creator at @LearnDataWithMark,
      but he's also an avid educator in the data community.
    char_start: 0
    char_end: 137
- statement: Mark Needham is a top committer on DuckDB.
  type: definition
  entity: Mark Needham
  keywords:
  - definition
  - mark
  - needham
  - top
  - committer
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-two.md
    quote: Oh, and he's still the top committer on DuckDB.
    char_start: 0
    char_end: 47
- statement: Mark Raasveldt is one of the co-creators of DuckDB.
  type: definition
  entity: Mark Raasveldt
  keywords:
  - definition
  - mark
  - raasveldt
  - one
  - co
  - creators
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-two.md
    quote: Mark as one of the co-creators of DuckDB.
    char_start: 0
    char_end: 41
- statement: Mark Raasveldt was pivotal in getting DuckDB to 1.0.0.
  type: definition
  entity: Mark Raasveldt
  keywords:
  - definition
  - mark
  - raasveldt
  - pivotal
  - getting
  - duckdb
  - 1.0.0
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: He was pivotal in getting DuckDB to 1.0.0.
    char_start: 0
    char_end: 42
- statement: matplotlib is a plotting library for the Python programming language.
  type: definition
  entity: matplotlib
  keywords:
  - definition
  - matplotlib
  - plotting
  - library
  - python
  - programming
  - language
  source:
    doc: motherduck.com/blog/the-future-of-bi-bi-as-code-duckdb-impact.md
    quote: matplotlib is a plotting library for the Python programming language.
    char_start: 0
    char_end: 69
- statement: Matt Forrest is a guest speaker featured in the video discussing spatial
    data management.
  type: definition
  entity: Matt Forrest
  keywords:
  - definition
  - matt
  - forrest
  - guest
  - speaker
  - featured
  - video
  - discussing
  - spatial
  - data
  - management
  source:
    doc: motherduck.com/videos.md
    quote: Matt Forrest is a guest speaker featured in the video discussing spatial
      data management.
    char_start: 0
    char_end: 89
- statement: Matt Martin is a highly experienced data architect and ETL practitioner.
  type: definition
  entity: Matt Martin
  keywords:
  - definition
  - matt
  - martin
  - highly
  - experienced
  - data
  - architect
  - etl
  - practitioner
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: Matt Martin is a Staff Engineer at State Farm. He is a highly experienced
      data architect and ETL practitioner with strong BI expertise.
    char_start: 0
    char_end: 135
- statement: Max Gabrielsson is a Junior Software engineer at DuckDB labs.
  type: definition
  entity: Max Gabrielsson
  keywords:
  - definition
  - max
  - gabrielsson
  - junior
  - software
  - engineer
  - duckdb
  - labs
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-seven.md
    quote: Max Gabrielsson is a Junior Software engineer at DuckDB labs but he has
      already made some impressive waves!
    char_start: 0
    char_end: 107
- statement: MCP can connect to MotherDuck for querying.
  type: definition
  entity: MCP
  keywords:
  - definition
  - mcp
  - connect
  - motherduck
  - querying
  source:
    doc: motherduck.com/blog/how-to-extract-analytics-from-bluesky.md
    quote: While the MCP can connect to MotherDuck, you can also use it without any
      connection to the Cloud for pure DuckDB actions.
    char_start: 0
    char_end: 121
- statement: MCP can help building data pipelines using a DuckDB+ dbt stack.
  type: definition
  entity: MCP
  keywords:
  - definition
  - mcp
  - help
  - building
  - data
  - pipelines
  - using
  - duckdb
  - dbt
  - stack
  source:
    doc: motherduck.com/blog/getting-started-gis-duckdb.md
    quote: MCP can help building data pipelines, specifically using a DuckDB+ [dbt]
      stack.
    char_start: 0
    char_end: 79
- statement: MCP connects to various storage systems including AWS S3 and Azure Blob
    Storage.
  type: definition
  entity: MCP
  keywords:
  - definition
  - mcp
  - connects
  - various
  - storage
  - systems
  - including
  - aws
  - s3
  - azure
  - blob
  source:
    doc: motherduck.com/videos/duckdb-tutorial-for-beginners.md
    quote: Connects to various storage systems (AWS S3, Azure Blob Storage)
    char_start: 0
    char_end: 64
- statement: MCP provides fast schema retrieval for Parquet files.
  type: definition
  entity: MCP
  keywords:
  - definition
  - mcp
  - provides
  - fast
  - schema
  - retrieval
  - parquet
  - files
  source:
    doc: motherduck.com/videos/duckdb-tutorial-for-beginners.md
    quote: Provides fast schema retrieval for Parquet files
    char_start: 0
    char_end: 48
- statement: MCP represents a significant step forward for data pipeline development.
  type: definition
  entity: MCP
  keywords:
  - definition
  - mcp
  - represents
  - significant
  - step
  - forward
  - data
  - pipeline
  - development
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: MCP represents a significant step forward for data pipeline development.
    char_start: 0
    char_end: 72
- statement: Schema inspection should be prioritized when using MCP.
  type: definition
  entity: MCP
  keywords:
  - definition
  - schema
  - inspection
  - prioritized
  - using
  - mcp
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: Explicitly instruct the AI to use MCP for retrieving schema metadata before
      attempting complex data transformations.
    char_start: 0
    char_end: 116
- statement: The DuckDB/MotherDuck MCP server allows the AI copilot to run queries
    against local DuckDB databases.
  type: definition
  entity: MCP
  keywords:
  - definition
  - duckdb
  - motherduck
  - mcp
  - server
  - allows
  - ai
  - copilot
  - run
  - queries
  - against
  - local
  - databases
  source:
    doc: motherduck.com/blog/getting-started-gis-duckdb.md
    quote: The DuckDB/MotherDuck MCP server allows the AI copilot (Cursor) to directly
      run queries against local DuckDB databases.
    char_start: 0
    char_end: 119
- statement: The MCP can accelerate data engineering workflows by connecting AI copilots
    directly to data tools like DuckDB.
  type: definition
  entity: MCP
  keywords:
  - definition
  - mcp
  - accelerate
  - data
  - engineering
  - workflows
  - connecting
  - ai
  - copilots
  - directly
  - tools
  - like
  - duckdb
  source:
    doc: motherduck.com/blog/scaling-duckdb-with-ducklings.md
    quote: How the MCP can accelerate data engineering workflows by connecting AI
      copilots directly to data tools like DuckDB
    char_start: 0
    char_end: 114
- statement: The md_active_server_connections function lists all server-side connections
    with active transactions.
  type: definition
  entity: md_active_server_connections
  keywords:
  - definition
  - md
  - active
  - server
  - connections
  - function
  - lists
  - side
  - transactions
  source:
    doc: motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw.md
    quote: md_active_server_connections is a table function that lists all server-side
      connections with active transactions.
    char_start: 0
    char_end: 113
- statement: A read-only MD_INFORMATION_SCHEMA is available for metadata.
  type: definition
  entity: MD_INFORMATION_SCHEMA
  keywords:
  - definition
  - read
  - md
  - information
  - schema
  - available
  - metadata
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: a read-only MD_INFORMATION_SCHEMA for metadata.
    char_start: 0
    char_end: 47
- statement: MD_INFORMATION_SCHEMA provides SQL-based access to metadata about your
    MotherDuck objects.
  type: definition
  entity: MD_INFORMATION_SCHEMA
  keywords:
  - definition
  - md
  - information
  - schema
  - provides
  - sql
  - based
  - access
  - metadata
  - about
  - motherduck
  - objects
  source:
    doc: motherduck.com/blog/duckdb-cognee-sql-analytics-graph-rag.md
    quote: We have recently introduced the MD_INFORMATION_SCHEMA, a read-only, system-defined
      view that provides SQL-based access to metadata about your MotherDuck objects.
    char_start: 0
    char_end: 161
- statement: The md_interrupt_server_connection function allows users to interrupt
    active transactions.
  type: definition
  entity: md_interrupt_server_connection
  keywords:
  - definition
  - md
  - interrupt
  - server
  - connection
  - function
  - allows
  - users
  - active
  - transactions
  source:
    doc: motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw.md
    quote: users can now interrupt active transactions on a server-side connection
      with the md_interrupt_server_connection scalar function.
    char_start: 0
    char_end: 128
- statement: The MDCuRe stack includes React.
  type: definition
  entity: MDCuRe stack
  keywords:
  - definition
  - mdcure
  - stack
  - includes
  - react
  source:
    doc: motherduck.com/videos.md
    quote: 'The MDCuRe stack for building data apps: MotherDuck, Cube, React.'
    char_start: 0
    char_end: 65
- statement: The MDCuRe stack provides reduced unit costs and better ease of use for
    developers.
  type: definition
  entity: MDCuRe stack
  keywords:
  - definition
  - mdcure
  - stack
  - provides
  - reduced
  - unit
  - costs
  - better
  - ease
  - use
  - developers
  source:
    doc: motherduck.com/quacking-around-the-web.md
    quote: illustrated how developers stand to benefit from reduced unit costs and
      better ease of use.
    char_start: 0
    char_end: 91
- statement: The MDS-in-a-box pattern has been a game changer for applying software
    engineering principles to local data development.
  type: definition
  entity: MDS-in-a-box
  keywords:
  - definition
  - mds
  - box
  - pattern
  - game
  - changer
  - applying
  - software
  - engineering
  - principles
  - local
  - data
  - development
  source:
    doc: motherduck.com/learn-more/self-service-analytics-startups.md
    quote: This panel explores the MDS-in-a-box pattern, which has been a game changer
      for applying software engineering principles to local data development.
    char_start: 0
    char_end: 147
- statement: Mega and Giga instances are built for the largest, toughest, most complex
    data transformations DuckDB can handle.
  type: definition
  entity: Mega Ducklings
  keywords:
  - definition
  - mega
  - giga
  - instances
  - built
  - largest
  - toughest
  - complex
  - data
  - transformations
  - duckdb
  - handle
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: These new instance sizes are built for the largest, toughest, most complex
      data transformations DuckDB can handle — and then some.
    char_start: 0
    char_end: 130
- statement: Mega ducklings are designed for when your workloads have outgrown Jumbo.
  type: definition
  entity: Mega Ducklings
  keywords:
  - definition
  - mega
  - ducklings
  - designed
  - workloads
  - outgrown
  - jumbo
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: Mega ducklings are designed for when your workloads have outgrown Jumbo
      and you need more power — not eventually, but right now.
    char_start: 0
    char_end: 128
- statement: Mega instances are available for demanding workloads.
  type: definition
  entity: Mega instances
  keywords:
  - definition
  - mega
  - instances
  - available
  - demanding
  - workloads
  source:
    doc: motherduck.com/blog/announcing-mega-giga-instance-sizes-huge-scale.md
    quote: These new duckling sizes are available on the instance plan. Megas are
      completely self-serve.
    char_start: 0
    char_end: 93
- statement: Fundamentals and principles are more important than the latest tools.
  type: definition
  entity: Mehdi
  keywords:
  - definition
  - fundamentals
  - principles
  - important
  - latest
  - tools
  source:
    doc: motherduck.com/blog/big-data-is-dead.md
    quote: The TLDR; Fundamentals and principles beat the latest tool or technology.
    char_start: 0
    char_end: 73
- statement: Mehdi focuses on making data engineering education fun and accessible
    for everyone.
  type: definition
  entity: Mehdi
  keywords:
  - definition
  - mehdi
  - focuses
  - making
  - data
  - engineering
  - education
  - fun
  - accessible
  - everyone
  source:
    doc: motherduck.com/blog/MotherDuck-Visualize-Embeddings-Marimo.md
    quote: As the first Developer Advocate at MotherDuck (DuckDB in the cloud), he
      focuses on making data engineering education fun and accessible for everyone.
    char_start: 0
    char_end: 149
- statement: Understanding the technical stack of the company is crucial for interview
    preparation.
  type: definition
  entity: Mehdi
  keywords:
  - definition
  - understanding
  - technical
  - stack
  - company
  - crucial
  - interview
  - preparation
  source:
    doc: motherduck.com/blog/big-data-is-dead.md
    quote: Mehdi emphasized a focused approach on understanding the technical stack.
    char_start: 0
    char_end: 73
- statement: Mehdi Ouazza is a Data Engineer and Developer Advocate with nearly a
    decade of experience.
  type: definition
  entity: Mehdi Ouazza
  keywords:
  - definition
  - mehdi
  - ouazza
  - data
  - engineer
  - developer
  - advocate
  - nearly
  - decade
  - experience
  source:
    doc: motherduck.com/blog/big-data-is-dead.md
    quote: Mehdi, aka mehdio, is a Data Engineer and Developer Advocate with nearly
      a decade of experience in the data field.
    char_start: 0
    char_end: 114
- statement: Open-source software alternatives like Meltano, Airbyte, or dlt have
    emerged as viable solutions.
  type: definition
  entity: Meltano
  keywords:
  - definition
  - open
  - source
  - software
  - alternatives
  - like
  - meltano
  - airbyte
  - dlt
  - emerged
  - viable
  - solutions
  source:
    doc: motherduck.com/blog/duckdb-wasm-in-browser.md
    quote: open-source software (OSS) alternatives like Meltano, Airbyte, or dlt have
      emerged as viable solutions.
    char_start: 0
    char_end: 103
- statement: The feature 'messages' is used by 353 distinct users.
  type: definition
  entity: messages
  keywords:
  - definition
  - feature
  - messages
  - used
  - '353'
  - distinct
  - users
  source:
    doc: motherduck.com/learn-more/pandas-dataframes-guide.md
    quote: '353'
    char_start: 0
    char_end: 3
- statement: Meta Grid is a new emerging term in metadata management.
  type: definition
  entity: Meta Grid
  keywords:
  - definition
  - meta
  - grid
  - new
  - emerging
  - term
  - metadata
  - management
  source:
    doc: motherduck.com/blog/search-using-duckdb-part-2.md
    quote: 'A new emerging term: Meta Grid'
    char_start: 0
    char_end: 30
- statement: Business intelligence tools can incur hidden costs when executing expensive
    queries.
  type: definition
  entity: Metabase
  keywords:
  - definition
  - business
  - intelligence
  - tools
  - incur
  - hidden
  - costs
  - executing
  - expensive
  - queries
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: A hidden cost source occurs when dashboards execute expensive queries.
    char_start: 0
    char_end: 70
- statement: Metabase is an open-source business intelligence tool.
  type: definition
  entity: Metabase
  keywords:
  - definition
  - metabase
  - open
  - source
  - business
  - intelligence
  - tool
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: An open-source business intelligence tool.
    char_start: 0
    char_end: 42
- statement: Reflex could email automated Metabase reports to customers.
  type: definition
  entity: Metabase
  keywords:
  - definition
  - reflex
  - email
  - automated
  - metabase
  - reports
  - customers
  source:
    doc: motherduck.com/learn-more.md
    quote: For the first time, Reflex could email automated Metabase reports to customers.
    char_start: 0
    char_end: 79
- statement: Michael Hunger has been pioneering product innovation at Neo4j.
  type: definition
  entity: Michael Hunger
  keywords:
  - definition
  - michael
  - hunger
  - pioneering
  - product
  - innovation
  - neo4j
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md
    quote: Michael Hunger has been pioneering product innovation at Neo4j, a leader
      in graph databases.
    char_start: 0
    char_end: 92
- statement: Michael Hunger will give a talk at the meetup.
  type: definition
  entity: Michael Hunger
  keywords:
  - definition
  - michael
  - hunger
  - give
  - talk
  - meetup
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-six.md
    quote: Michael Hunger author of 'DuckDB in action' will give a talk!
    char_start: 0
    char_end: 61
- statement: Michael Ritchie is a guest speaker from Definite with expertise in scaling
    DuckDB.
  type: definition
  entity: Michael Ritchie
  keywords:
  - definition
  - michael
  - ritchie
  - guest
  - speaker
  - definite
  - expertise
  - scaling
  - duckdb
  source:
    doc: motherduck.com/videos.md
    quote: Michael Ritchie from Definite
    char_start: 0
    char_end: 29
- statement: Michael Simons is a Java Champion and Engineer at Neo4j.
  type: definition
  entity: Michael Simons
  keywords:
  - definition
  - michael
  - simons
  - java
  - champion
  - engineer
  - neo4j
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md
    quote: Michael Simons, a Java Champion and Engineer at Neo4j, adds his profound
      expertise to the mix.
    char_start: 0
    char_end: 94
- statement: Micro-batching provides a near-fresh alternative to nightly ETL.
  type: definition
  entity: Micro-batching
  keywords:
  - definition
  - micro
  - batching
  - provides
  - near
  - fresh
  - alternative
  - nightly
  - etl
  source:
    doc: motherduck.com/learn-more/what-is-duckdb.md
    quote: Micro-batching provides a near-fresh alternative to nightly ETL.
    char_start: 0
    char_end: 64
- statement: Microservices Architecture decomposes the data application into smaller,
    loosely coupled services.
  type: definition
  entity: Microservices Architecture
  keywords:
  - definition
  - microservices
  - architecture
  - decomposes
  - data
  - application
  - smaller
  - loosely
  - coupled
  - services
  source:
    doc: motherduck.com/learn-more/data-application-architecture.md
    quote: Microservices Architecture Decomposes the data application into smaller,
      loosely coupled services.
    char_start: 0
    char_end: 98
- statement: Microsoft has expertise in Postgres and is participating in the project.
  type: definition
  entity: Microsoft
  keywords:
  - definition
  - microsoft
  - expertise
  - postgres
  - participating
  - project
  source:
    doc: motherduck.com/blog/perf-is-not-enough.md
    quote: Microsoft has a ton of Postgres know-how including several Postgres committers
      and are also participating in the project.
    char_start: 0
    char_end: 121
- statement: BI tools like Tableau or Looker often use a single service account, which
    can overwhelm a database.
  type: definition
  entity: Microsoft Azure Blob Storage
  keywords:
  - definition
  - bi
  - tools
  - like
  - tableau
  - looker
  - often
  - use
  - single
  - service
  - account
  - which
  - overwhelm
  - database
  source:
    doc: motherduck.com/sql-duckdb-book-form.md
    quote: Tools like Tableau or Looker often use a single service account, funneling
      queries from dozens of users through one connection. This can quickly overwhelm
      a database.
    char_start: 0
    char_end: 166
- statement: The match_events table is defined to store event details using STRUCTs.
  type: definition
  entity: Microsoft Azure Blob Storage
  keywords:
  - definition
  - match
  - events
  - table
  - defined
  - store
  - event
  - details
  - using
  - structs
  source:
    doc: motherduck.com/webinar/data-discoverability-secoda-motherduck.md
    quote: This table now has a column event_details where each entry holds a nested
      STRUCT.
    char_start: 0
    char_end: 81
- statement: The talk includes ETL, data pipelines, dashboard visualization, and sharing
    via the cloud.
  type: definition
  entity: Microsoft Azure Blob Storage
  keywords:
  - definition
  - talk
  - includes
  - etl
  - data
  - pipelines
  - dashboard
  - visualization
  - sharing
  - via
  - cloud
  source:
    doc: motherduck.com/videos/duckdb-dbt-accelerating-the-developer-experience-with-local-power.md
    quote: including ETL, data pipelines, dashboard visualization, and sharing via
      the cloud.
    char_start: 0
    char_end: 82
- statement: Mihai Bojin and Marcelo Cenerino have over 15 years of experience in
    tech.
  type: definition
  entity: Mihai Bojin
  keywords:
  - definition
  - mihai
  - bojin
  - marcelo
  - cenerino
  - over
  - '15'
  - years
  - experience
  - tech
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: 'Mihai, with a background as a technical leader at big names like Salesforce,
      MongoDB, and now Google. Marcelo''s career is equally luminous, having contributed
      his expertise to giants such as Ericsson '
    char_start: 0
    char_end: 270
- statement: Mihai Bojin and Marcelo Cenerino hosted Dublin's first DuckDB meetup.
  type: definition
  entity: Mihai Bojin
  keywords:
  - definition
  - mihai
  - bojin
  - marcelo
  - cenerino
  - hosted
  - dublin
  - first
  - duckdb
  - meetup
  source:
    doc: motherduck.com/blog/just-enough-sql-for-ai.md
    quote: Interestingly, they're both located in Dublin. But there's more that brings
      them together. They successfully hosted Dublin's first DuckDB meetup!
    char_start: 0
    char_end: 145
- statement: The article demonstrates modifying data source files to read from and
    write to local storage using the MinIO S3 API.
  type: definition
  entity: MinIO
  keywords:
  - definition
  - article
  - demonstrates
  - modifying
  - data
  - source
  - files
  - read
  - write
  - local
  - storage
  - using
  - minio
  - s3
  - api
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: The article demonstrates modifying data source files to read from and write
      to local storage using the MinIO S3 API.
    char_start: 0
    char_end: 116
- statement: Modal is a cloud function platform that lets you run any code remotely
    within seconds.
  type: definition
  entity: Modal
  keywords:
  - definition
  - modal
  - cloud
  - function
  - platform
  - lets
  - run
  - any
  - code
  - remotely
  - within
  - seconds
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: A cloud function platform that lets you run any code remotely within seconds.
    char_start: 0
    char_end: 77
- statement: MCP can enable AI copilots to perform tasks ranging from running SQL
    queries against databases to understanding complex schemas and metadata.
  type: definition
  entity: Model Context Protocol
  keywords:
  - definition
  - mcp
  - enable
  - ai
  - copilots
  - perform
  - tasks
  - ranging
  - running
  - sql
  - queries
  - against
  - databases
  - understanding
  - complex
  - schemas
  - metadata
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md
    quote: In the context of data engineering, this means MCP can enable AI copilots
      to perform tasks ranging from running SQL queries against databases to understanding
      complex schemas and metadata.
    char_start: 0
    char_end: 188
- statement: MCP enables LLMs to execute queries directly against data sources.
  type: definition
  entity: Model Context Protocol
  keywords:
  - definition
  - mcp
  - enables
  - llms
  - execute
  - queries
  - directly
  - against
  - data
  - sources
  source:
    doc: motherduck.com/videos.md
    quote: 'MCP enables LLMs to: Execute queries directly against data sources'
    char_start: 0
    char_end: 66
- statement: MCP functions as a specialized API layer or translator for language models.
  type: definition
  entity: Model Context Protocol
  keywords:
  - definition
  - mcp
  - functions
  - specialized
  - api
  - layer
  - translator
  - language
  - models
  source:
    doc: motherduck.com/videos/faster-data-pipelines-development-with-mcp-and-duckdb.md
    quote: MCP functions as a specialized API layer or translator for language models.
    char_start: 0
    char_end: 75
- statement: MCP is a language protocol between an AI and an IDE.
  type: definition
  entity: Model Context Protocol
  keywords:
  - definition
  - mcp
  - language
  - protocol
  - ai
  - ide
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: Model Context Protocol (MCP) is the language protocol between an AI and
      an IDE.
    char_start: 0
    char_end: 79
- statement: MCP is primarily used to accelerate AI workflows within development environments.
  type: definition
  entity: Model Context Protocol
  keywords:
  - definition
  - mcp
  - primarily
  - used
  - accelerate
  - ai
  - workflows
  - within
  - development
  - environments
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md
    quote: Today, MCP is primarily used to accelerate AI workflows within development
      environments or through automated agents.
    char_start: 0
    char_end: 116
- statement: MCP was launched by Anthropic in 2024.
  type: definition
  entity: Model Context Protocol
  keywords:
  - definition
  - mcp
  - launched
  - anthropic
  - '2024'
  source:
    doc: motherduck.com/learn-more/product-analytics-motherduck-duckdb.md
    quote: Launched by Anthropic in 2024, MCP functions as a specialized...
    char_start: 0
    char_end: 64
- statement: The Model Context Protocol (MCP) has been a hot topic lately.
  type: definition
  entity: Model Context Protocol
  keywords:
  - definition
  - model
  - context
  - protocol
  - mcp
  - hot
  - topic
  - lately
  source:
    doc: motherduck.com/blog/simplifying-iot-analytics-motherduck.md
    quote: The Model Context Protocol (MCP) has been a hot topic lately.
    char_start: 0
    char_end: 61
- statement: The Model Context Protocol (MCP) is an emerging open protocol designed
    to connect AI copilots to local and cloud-based tools.
  type: definition
  entity: Model Context Protocol
  keywords:
  - definition
  - model
  - context
  - protocol
  - mcp
  - emerging
  - open
  - designed
  - connect
  - ai
  - copilots
  - local
  - cloud
  - based
  - tools
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md
    quote: The Model Context Protocol (MCP) is an emerging open protocol designed
      to connect AI copilots (like Cursor, GitHub Copilot, or Claude) to local and
      cloud-based tools.
    char_start: 0
    char_end: 166
- statement: The Model Context Protocol accelerates data pipeline development.
  type: definition
  entity: Model Context Protocol
  keywords:
  - definition
  - model
  - context
  - protocol
  - accelerates
  - data
  - pipeline
  - development
  source:
    doc: motherduck.com/videos.md
    quote: Discover how the Model Context Protocol (MCP) accelerates data pipeline
      development with AI tools, DuckDB, and MotherDuck.
    char_start: 0
    char_end: 122
- statement: The Modern Data Infra Summit will feature discussions on modern data
    infrastructure.
  type: definition
  entity: Modern Data Infra Summit
  keywords:
  - definition
  - modern
  - data
  - infra
  - summit
  - feature
  - discussions
  - infrastructure
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: Ryan Boyd, co-founder at MotherDuck, speaking about DuckLake.
    char_start: 0
    char_end: 61
- statement: Choosing the wrong tool for your scale can burn your budget and kill
    productivity.
  type: definition
  entity: modern data stack
  keywords:
  - definition
  - choosing
  - wrong
  - tool
  - scale
  - burn
  - budget
  - kill
  - productivity
  source:
    doc: motherduck.com/blog/streaming-oracle-to-motherduck.md
    quote: Choosing the wrong tool for your scale can burn your budget and kill productivity.
    char_start: 0
    char_end: 82
- statement: A modern warehouse should function more like a utility that is always
    available and works reliably.
  type: definition
  entity: modern data warehouse
  keywords:
  - definition
  - modern
  - warehouse
  - function
  - like
  - utility
  - always
  - available
  - works
  - reliably
  source:
    doc: motherduck.com/videos/from-curiosity-to-impact-how-dosomething-democratized-data.md
    quote: A modern warehouse should function more like a utility that is always available
      and works reliably.
    char_start: 0
    char_end: 99
- statement: The fundamental difference between a traditional and a modern data warehouse
    is not just speed, but a shift in purpose.
  type: definition
  entity: modern data warehouse
  keywords:
  - definition
  - fundamental
  - difference
  - traditional
  - modern
  - data
  - warehouse
  - speed
  - shift
  - purpose
  source:
    doc: motherduck.com/videos/faster-data-pipelines-development-with-mcp-and-duckdb.md
    quote: The fundamental difference between a traditional and a modern data warehouse
      is not just speed, but a shift in purpose.
    char_start: 0
    char_end: 119
- statement: The lean, modern data warehouse inverts this model.
  type: definition
  entity: modern data warehouse
  keywords:
  - definition
  - lean
  - modern
  - data
  - warehouse
  - inverts
  - model
  source:
    doc: motherduck.com/videos/faster-data-pipelines-development-with-mcp-and-duckdb.md
    quote: The lean, modern data warehouse inverts this model.
    char_start: 0
    char_end: 51
- statement: Traditional warehouses were architected around provisioned clusters and
    batch ETL processes.
  type: definition
  entity: modern data warehouse
  keywords:
  - definition
  - traditional
  - warehouses
  - architected
  - around
  - provisioned
  - clusters
  - batch
  - etl
  - processes
  source:
    doc: motherduck.com/videos/faster-data-pipelines-development-with-mcp-and-duckdb.md
    quote: Traditional warehouses were architected around provisioned clusters and
      batch ETL processes.
    char_start: 0
    char_end: 92
- statement: A modern warehouse provides a clean architectural solution for customer-facing
    analytics.
  type: definition
  entity: modern warehouse
  keywords:
  - definition
  - modern
  - warehouse
  - provides
  - clean
  - architectural
  - solution
  - customer
  - facing
  - analytics
  source:
    doc: motherduck.com/videos/pg_duckdb-postgres-analytics-just-got-faster-with-duckdb.md
    quote: A modern warehouse provides a clean architectural solution.
    char_start: 0
    char_end: 59
- statement: The serverless nature of the modern warehouse handles concurrency and
    scalability challenges automatically.
  type: definition
  entity: modern warehouse
  keywords:
  - definition
  - serverless
  - nature
  - modern
  - warehouse
  - handles
  - concurrency
  - scalability
  - challenges
  - automatically
  source:
    doc: motherduck.com/videos/pg_duckdb-postgres-analytics-just-got-faster-with-duckdb.md
    quote: The serverless nature of the modern warehouse handles the concurrency and
      scalability challenges automatically.
    char_start: 0
    char_end: 111
- statement: MongoDB is the highest ranked NoSQL database.
  type: definition
  entity: MongoDB
  keywords:
  - definition
  - mongodb
  - highest
  - ranked
  - nosql
  - database
  source:
    doc: motherduck.com/blog/announcing-small-data-sf-2025.md
    quote: MongoDB is the highest ranked NoSQL or otherwise scale-out database.
    char_start: 0
    char_end: 68
- statement: MongoDB now offers full ACID compliance.
  type: definition
  entity: MongoDB
  keywords:
  - definition
  - mongodb
  - now
  - offers
  - full
  - acid
  - compliance
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: many modern NoSQL databases, such as MongoDB, now offer full ACID compliance.
    char_start: 0
    char_end: 77
- statement: Monte Carlo allows customers to monitor their databases and look for
    anomalies.
  type: definition
  entity: Monte Carlo
  keywords:
  - definition
  - monte
  - carlo
  - allows
  - customers
  - monitor
  - databases
  - look
  - anomalies
  source:
    doc: motherduck.com/blog/announcing-motherduck-general-availability-data-warehousing-with-duckdb.md
    quote: Monte Carlo, the leader in data observability, has built a MotherDuck integration.
      It allows our customers to monitor their databases and look for anomalies through
      custom SQL rules.
    char_start: 0
    char_end: 182
- statement: Monte Carlo is enterprise-ready with extensive data lake integrations.
  type: definition
  entity: Monte Carlo
  keywords:
  - definition
  - monte
  - carlo
  - enterprise
  - ready
  - extensive
  - data
  - lake
  - integrations
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: Enterprise-ready with extensive data lake integrations
    char_start: 0
    char_end: 54
- statement: Monthly Recurring Revenue (MRR) is a key product analytics metric.
  type: definition
  entity: Monthly Recurring Revenue (MRR)
  keywords:
  - definition
  - monthly
  - recurring
  - revenue
  - mrr
  - key
  - product
  - analytics
  - metric
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: Monthly Recurring Revenue (MRR)
    char_start: 0
    char_end: 31
- statement: MRR is a key metric for subscription businesses, representing the predictable
    revenue generated each month from subscriptions.
  type: definition
  entity: Monthly Recurring Revenue (MRR)
  keywords:
  - definition
  - mrr
  - key
  - metric
  - subscription
  - businesses
  - representing
  - predictable
  - revenue
  - generated
  - month
  - subscriptions
  source:
    doc: motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse.md
    quote: MRR is a key metric for subscription businesses, representing the predictable
      revenue generated each month from subscriptions.
    char_start: 0
    char_end: 126
- statement: This query calculates the total MRR for each month.
  type: definition
  entity: Monthly Recurring Revenue (MRR)
  keywords:
  - definition
  - query
  - calculates
  - total
  - mrr
  - month
  source:
    doc: motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse.md
    quote: This query calculates the total MRR for each month.
    char_start: 0
    char_end: 51
- statement: Mooncake writes its columnstore tables in Delta or Iceberg format.
  type: definition
  entity: Mooncake
  keywords:
  - definition
  - mooncake
  - writes
  - columnstore
  - tables
  - delta
  - iceberg
  - format
  source:
    doc: motherduck.com/blog/redshift-files-hunt-for-big-data.md
    quote: Since Mooncake writes its columnstore tables in Delta or Iceberg format...
    char_start: 0
    char_end: 74
- statement: Mosaic can call a remote DuckDB server to execute expensive queries.
  type: definition
  entity: Mosaic
  keywords:
  - definition
  - mosaic
  - call
  - remote
  - duckdb
  - server
  - execute
  - expensive
  - queries
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: Luckily, Mosaic can call a remote DuckDB server to execute expensive queries.
    char_start: 0
    char_end: 77
- statement: Mosaic is a data visualization tool developed for interactive insights.
  type: definition
  entity: Mosaic
  keywords:
  - definition
  - mosaic
  - data
  - visualization
  - tool
  - developed
  - interactive
  - insights
  source:
    doc: motherduck.com/videos.md
    quote: Mosaic is a data visualization tool developed for interactive insights.
    char_start: 0
    char_end: 71
- statement: Mosaic is an extensible framework that leverages a database (usually
    DuckDB) for scalable processing.
  type: definition
  entity: Mosaic
  keywords:
  - definition
  - mosaic
  - extensible
  - framework
  - leverages
  - database
  - usually
  - duckdb
  - scalable
  - processing
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: Mosaic is an extensible framework that leverages a database (usually DuckDB)
      for scalable processing.
    char_start: 0
    char_end: 101
- statement: '"Fractions of a penny" incremental cost for small brands.'
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - fractions
  - penny
  - incremental
  - cost
  - small
  - brands
  source:
    doc: motherduck.com/learn-more/columnar-storage-guide.md
    quote: '"Fractions of a penny" incremental cost for small brands.'
    char_start: 0
    char_end: 57
- statement: A data pipeline is a series of interconnected processes that extract
    data from various sources, transform it into a usable format, and load it into
    a destination system for analysis or storage.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - data
  - pipeline
  - series
  - interconnected
  - processes
  - extract
  - various
  - sources
  - transform
  - usable
  - format
  - load
  - destination
  - system
  - analysis
  - storage
  source:
    doc: motherduck.com/case-studies/dosomething-non-profit-tco-cost-savings.md
    quote: A data pipeline is a series of interconnected processes that extract data
      from various sources, transform it into a usable format, and load it into a
      destination system for analysis or storage.
    char_start: 0
    char_end: 193
- statement: A database is a structured collection of data organized for efficient
    storage, retrieval, and management.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - database
  - structured
  - collection
  - data
  - organized
  - efficient
  - storage
  - retrieval
  - management
  source:
    doc: motherduck.com/learn-more/data-application.md
    quote: A database is a structured collection of data organized for efficient storage,
      retrieval, and management.
    char_start: 0
    char_end: 105
- statement: A lean serverless platform like MotherDuck provides a more cost-effective
    architecture that delivers fast analytics without the enterprise overhead.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - lean
  - serverless
  - platform
  - like
  - motherduck
  - provides
  - cost
  - effective
  - architecture
  - delivers
  - fast
  - analytics
  - without
  - enterprise
  - overhead
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: A lean serverless platform like MotherDuck provides a more cost-effective
      architecture that delivers fast analytics without the enterprise overhead.
    char_start: 0
    char_end: 148
- statement: A Lean, Serverless Warehouse like MotherDuck is often the ideal starting
    point for startups.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - lean
  - serverless
  - warehouse
  - like
  - motherduck
  - often
  - ideal
  - starting
  - point
  - startups
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: A Lean, Serverless Warehouse like MotherDuck is often the ideal starting
      point for startups.
    char_start: 0
    char_end: 92
- statement: A modern cloud data warehouse solution like MotherDuck provides a serverless,
    cost-effective platform tailored for the scale of most startups and small teams.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - modern
  - cloud
  - data
  - warehouse
  - solution
  - like
  - motherduck
  - provides
  - serverless
  - cost
  - effective
  - platform
  - tailored
  - scale
  - startups
  - small
  - teams
  source:
    doc: motherduck.com/learn-more/bigquery-alternative-motherduck.md
    quote: A modern cloud data warehouse solution like MotherDuck, built on the fast,
      in-process DuckDB engine, provides a serverless, cost-effective platform tailored
      for the scale of most startups and small te
    char_start: 0
    char_end: 204
- statement: A modern data warehouse like MotherDuck leverages the power of DuckDB
    to deliver near-instant results for such queries.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - modern
  - data
  - warehouse
  - like
  - motherduck
  - leverages
  - power
  - duckdb
  - deliver
  - near
  - instant
  - results
  - queries
  source:
    doc: motherduck.com/blog/streamlining-ai-agents-duckdb-rag-solutions.md
    quote: A modern data warehouse like MotherDuck leverages the power of DuckDB to
      deliver near-instant results for such queries.
    char_start: 0
    char_end: 119
- statement: A modern, serverless solution like MotherDuck is specifically designed
    for high-concurrency, low-latency workloads.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - modern
  - serverless
  - solution
  - like
  - motherduck
  - specifically
  - designed
  - high
  - concurrency
  - low
  - latency
  - workloads
  source:
    doc: motherduck.com/blog/streamlining-ai-agents-duckdb-rag-solutions.md
    quote: A modern, serverless solution like MotherDuck is specifically designed
      for these high-concurrency, low-latency workloads, ensuring consistently fast
      performance for all users without manual scaling.
    char_start: 0
    char_end: 198
- statement: A Smart Hub like MotherDuck allows fast, local-first development on Parquet
    files.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - smart
  - hub
  - like
  - motherduck
  - allows
  - fast
  - local
  - first
  - development
  - parquet
  - files
  source:
    doc: motherduck.com/blog/tableau-cloud-motherduck.md
    quote: A Smart Hub (like MotherDuck) allows fast, local-first development on Parquet
      files and easy ingestion of JSON from APIs without rigid schemas.
    char_start: 0
    char_end: 143
- statement: A truly serverless platform like MotherDuck eliminates the problem of
    managing clusters.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - truly
  - serverless
  - platform
  - like
  - motherduck
  - eliminates
  - problem
  - managing
  - clusters
  source:
    doc: motherduck.com/blog/tableau-cloud-motherduck.md
    quote: A truly serverless platform like MotherDuck eliminates this problem entirely,
      as you don't manage clusters and only pay for the resources you actively consume.
    char_start: 0
    char_end: 159
- statement: AI can empower you to 'vibe code'—using AI to write accurate SQL.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - ai
  - empower
  - vibe
  - code
  - using
  - write
  - accurate
  - sql
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-four.md
    quote: AI can empower you to 'vibe code'—using AI to write accurate SQL.
    char_start: 0
    char_end: 65
- statement: AI is changing how people interact with their data.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - ai
  - changing
  - people
  - interact
  - data
  source:
    doc: motherduck.com/blog/fix-outdated-llm-documentation-duckdb.md
    quote: It was pretty clear to us that AI was already changing how people interact
      with their data...
    char_start: 0
    char_end: 93
- statement: Airbyte is hosting a hackathon with MotherDuck.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - airbyte
  - hosting
  - hackathon
  - motherduck
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: we're thrilled to continue our partnership with MotherDuck by announcing
      our upcoming hackathon.
    char_start: 0
    char_end: 96
- statement: Anywhere you can Duck, you can MotherDuck.
  type: feature
  entity: MotherDuck
  keywords:
  - feature
  - anywhere
  - duck
  - motherduck
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: Anywhere you can Duck, you can MotherDuck
    char_start: 0
    char_end: 41
- statement: As of now, MotherDuck supports only one version of DuckDB.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - now
  - motherduck
  - supports
  - one
  - version
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: As of now, MotherDuck supports only one version of DuckDB.
    char_start: 0
    char_end: 58
- statement: Big Data is having a renaissance.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - big
  - data
  - having
  - renaissance
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-two.md
    quote: Aditya Parameswaran wrote a rebuttal called 'Big Data Is Dead… Long Live
      Big Data.'
    char_start: 0
    char_end: 83
- statement: Building on a fast, serverless platform like MotherDuck is crucial for
    product-led teams.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - building
  - fast
  - serverless
  - platform
  - like
  - motherduck
  - crucial
  - product
  - led
  - teams
  source:
    doc: motherduck.com/blog/streamlining-ai-agents-duckdb-rag-solutions.md
    quote: Building on a fast, serverless platform like MotherDuck is crucial for
      these teams, as it provides the performance foundation needed to deliver the
      snappy, interactive experiences users expect.
    char_start: 0
    char_end: 193
- statement: By going with MotherDuck, we've been able to give the team ownership
    and let them stay in Metabase.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - going
  - motherduck
  - ve
  - able
  - give
  - team
  - ownership
  - let
  - them
  - stay
  - metabase
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: By going with MotherDuck, we've been able to give the team ownership and
      let them stay in Metabase.
    char_start: 0
    char_end: 99
- statement: By the end of this article, you’ll know how to build an end-to-end sentiment
    analysis process.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - end
  - article
  - ll
  - know
  - build
  - sentiment
  - analysis
  - process
  source:
    doc: motherduck.com/blog/making-pyspark-code-faster-with-duckdb.md
    quote: 'By the end of this article, you’ll know how to build an end-to-end sentiment
      analysis process, including:'
    char_start: 0
    char_end: 105
- statement: By using a platform like MotherDuck, teams can eliminate these delays
    and empower analysts to find insights in seconds, not minutes.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - using
  - platform
  - like
  - motherduck
  - teams
  - eliminate
  - delays
  - empower
  - analysts
  - find
  - insights
  - seconds
  - minutes
  source:
    doc: motherduck.com/blog/streamlining-ai-agents-duckdb-rag-solutions.md
    quote: By using a platform like MotherDuck, which is optimized for rapid, interactive
      queries, teams can eliminate these delays and empower analysts to find insights
      in seconds, not minutes.
    char_start: 0
    char_end: 183
- statement: Choosing a database should be based on factors other than raw speed.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - choosing
  - database
  - based
  - factors
  - raw
  - speed
  source:
    doc: motherduck.com/blog/secoda-motherduck-integration-modern-duck-stack.md
    quote: if you’re choosing a database, you’re better off making sure you’re making
      your decision based on factors other than raw speed.
    char_start: 0
    char_end: 127
- statement: Choosing a truly serverless platform can minimize waste.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - choosing
  - truly
  - serverless
  - platform
  - minimize
  - waste
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: it is best to choose a truly serverless platform that bills only for actual
      usage...
    char_start: 0
    char_end: 84
- statement: CloudQuery is used to load data into MotherDuck.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - cloudquery
  - used
  - load
  - data
  - motherduck
  source:
    doc: motherduck.com/blog/analyze-sqlite-databases-duckdb.md
    quote: Load data from a variety of databases... into MotherDuck, using CloudQuery.
    char_start: 0
    char_end: 75
- statement: Continuous data quality checks can be configured in MotherDuck.
  type: feature
  entity: MotherDuck
  keywords:
  - feature
  - continuous
  - data
  - quality
  - checks
  - configured
  - motherduck
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part2.md
    quote: 'Continuous Data Quality Checks: A streaming pipeline enables continuous
      data quality monitoring.'
    char_start: 0
    char_end: 96
- statement: Coupled with MotherDuck, you get speed and scalability for large datasets.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - coupled
  - motherduck
  - get
  - speed
  - scalability
  - large
  - datasets
  source:
    doc: motherduck.com/blog/galileo-world-geospatial.md
    quote: Coupled with MotherDuck, you get speed and scalability for large datasets
      plus an easy path to real-time exploration.
    char_start: 0
    char_end: 117
- statement: Customers only pay for the cloud CPU time they actually use.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - customers
  - pay
  - cloud
  - cpu
  - time
  - actually
  - use
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: By billing at second-level granularity, you only pay for the cloud CPU
      time you actually use.
    char_start: 0
    char_end: 93
- statement: Data Day Texas 2023 is an event focused on data engineering and analytics.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - data
  - day
  - texas
  - '2023'
  - event
  - focused
  - engineering
  - analytics
  source:
    doc: motherduck.com/blog/pg-duckdb-release.md
    quote: Data Day Texas 2023 is an event focused on data engineering and analytics.
    char_start: 0
    char_end: 74
- statement: Data in MotherDuck exactly matches the source Postgres database at the
    recorded sync time.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - data
  - motherduck
  - exactly
  - matches
  - source
  - postgres
  - database
  - recorded
  - sync
  - time
  source:
    doc: motherduck.com/blog/small-data-sf-workshops-agenda.md
    quote: You can verify this process works by checking that data in MotherDuck exactly
      matches the source Postgres database at the recorded sync time.
    char_start: 0
    char_end: 141
- statement: Data pipelines are automated workflows that move and transform data from
    various sources to one or more destinations.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - data
  - pipelines
  - automated
  - workflows
  - move
  - transform
  - various
  - sources
  - one
  - destinations
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: Data pipelines are automated workflows that move and transform data from
      various sources to one or more destinations.
    char_start: 0
    char_end: 117
- statement: Data processing tasks completed in under two minutes within the Airflow
    pipeline.
  type: performance
  entity: MotherDuck
  keywords:
  - performance
  - data
  - processing
  - tasks
  - completed
  - two
  - minutes
  - within
  - airflow
  - pipeline
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: he observed that this data processing task completed in under two minutes
      within the Airflow pipeline.
    char_start: 0
    char_end: 102
- statement: Duckling is a component of MotherDuck's architecture.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - duckling
  - component
  - motherduck
  - architecture
  source:
    doc: motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md
    quote: This would ordinarily break the 'one-user-per-duckling' pattern.
    char_start: 0
    char_end: 64
- statement: Estuary requires an access token from MotherDuck.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - estuary
  - requires
  - access
  - token
  - motherduck
  source:
    doc: motherduck.com/blog/motherduck-union-orchestration.md
    quote: To create a MotherDuck access token for Estuary to use...
    char_start: 0
    char_end: 57
- statement: Estuary will start streaming your source data into your MotherDuck database.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - estuary
  - start
  - streaming
  - source
  - data
  - motherduck
  - database
  source:
    doc: motherduck.com/blog/git-for-data-part-1.md
    quote: Estuary will start streaming your source data into your MotherDuck database.
    char_start: 0
    char_end: 76
- statement: European companies like Trunkrs are already relying on MotherDuck for
    sub-second queries.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - european
  - companies
  - like
  - trunkrs
  - already
  - relying
  - motherduck
  - sub
  - second
  - queries
  source:
    doc: motherduck.com/blog/fabi-ai-llm-prompt-analysis.md
    quote: European companies like Trunkrs are already relying on MotherDuck for sub-second
      queries.
    char_start: 0
    char_end: 89
- statement: Every customer now has a private data warehouse.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - every
  - customer
  - now
  - private
  - data
  - warehouse
  source:
    doc: motherduck.com/learn-more.md
    quote: MotherDuck has let us just focus on the analytics and the roll up...
    char_start: 0
    char_end: 68
- statement: Evidence can connect to MotherDuck for cloud services.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - evidence
  - connect
  - motherduck
  - cloud
  - services
  source:
    doc: motherduck.com/blog/unstructured-analysis-tensorlake-motherduck.md
    quote: For a MotherDuck database, you will need to specify your MotherDuck Token.
    char_start: 0
    char_end: 74
- statement: Frances Perry has been asked to lead our engineering organization.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - frances
  - perry
  - asked
  - lead
  - engineering
  - organization
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: We’ve asked Frances Perry to lead our engineering organization.
    char_start: 0
    char_end: 63
- statement: GoodData found MotherDuck outperforming Snowflake and PostgreSQL in performance
    tests.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - gooddata
  - found
  - motherduck
  - outperforming
  - snowflake
  - postgresql
  - performance
  - tests
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: GoodData found MotherDuck outperforming Snowflake and PostgreSQL in performance
      tests.
    char_start: 0
    char_end: 86
- statement: Guen presented on bootstrapping a data warehouse with DuckDB.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - guen
  - presented
  - bootstrapping
  - data
  - warehouse
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: Guen from our ecosystem team delivered a pragmatic talk to demonstrate
      how you can bootstrap a data warehouse with DuckDB.
    char_start: 0
    char_end: 122
- statement: Hamm implemented the data pipeline in about 15 lines of code.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - hamm
  - implemented
  - data
  - pipeline
  - about
  - '15'
  - lines
  - code
  source:
    doc: motherduck.com/learn-more.md
    quote: Hamm implemented the data pipeline in about 15 lines of code.
    char_start: 0
    char_end: 61
- statement: HIPAA BAAs can be signed for healthcare customers.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - hipaa
  - baas
  - signed
  - healthcare
  - customers
  source:
    doc: motherduck.com/blog/motherduck-open-for-all-with-series-b.md
    quote: For healthcare customers, HIPAA BAAs can also be signed on request.
    char_start: 0
    char_end: 67
- statement: If you’re using DuckDB currently, just run `attach md:` and your DuckDB
    instance suddenly becomes MotherDuck-supercharged.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - re
  - using
  - duckdb
  - currently
  - run
  - attach
  - md
  - instance
  - suddenly
  - becomes
  - motherduck
  - supercharged
  source:
    doc: motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md
    quote: If you’re using DuckDB currently, just run `attach md:` and your DuckDB
      instance suddenly becomes MotherDuck-supercharged.
    char_start: 0
    char_end: 122
- statement: Incredibly fast query responses, often in milliseconds for typical BI/Analytical
    workloads.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - incredibly
  - fast
  - query
  - responses
  - often
  - milliseconds
  - typical
  - bi
  - analytical
  - workloads
  source:
    doc: motherduck.com/blog/summer-data-engineering-roadmap.md
    quote: Incredibly fast query responses, often in milliseconds for typical BI/Analytical
      workloads.
    char_start: 0
    char_end: 91
- statement: Instant SQL allows users to run ad-hoc queries in real-time.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - instant
  - sql
  - allows
  - users
  - run
  - ad
  - hoc
  - queries
  - real
  - time
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: Type, see, tweak, repeat! Instant SQL is now in Preview in MotherDuck and
      the DuckDB Local UI.
    char_start: 0
    char_end: 94
- statement: Integrating MotherDuck with Secoda takes two easy steps.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - integrating
  - motherduck
  - secoda
  - takes
  - two
  - easy
  - steps
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: Integrating MotherDuck with Secoda takes two easy steps.
    char_start: 0
    char_end: 56
- statement: It computes within 2-3 minutes on MotherDuck, even after more than doubling
    our column count to ~150 columns.
  type: performance
  entity: MotherDuck
  keywords:
  - performance
  - computes
  - within
  - minutes
  - motherduck
  - even
  - doubling
  - column
  - count
  - '150'
  - columns
  source:
    doc: motherduck.com/case-studies/trunkrs-same-day-delivery-motherduck-from-redshift.md
    quote: It computes within 2-3 minutes on MotherDuck, even after more than doubling
      our column count to ~150 columns.
    char_start: 0
    char_end: 109
- statement: Join us for Beers, Bites, & Good Ducking Fun at Big Data London!
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - join
  - us
  - beers
  - bites
  - good
  - ducking
  - fun
  - big
  - data
  - london
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: Join us for for Beers, Bites, & Good Ducking Fun at Big Data London!
    char_start: 0
    char_end: 68
- statement: Lightning-fast metadata operations powered by MotherDuck's infrastructure.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - lightning
  - fast
  - metadata
  - operations
  - powered
  - motherduck
  - infrastructure
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: Lightning-fast metadata operations powered by MotherDuck's infrastructure.
    char_start: 0
    char_end: 74
- statement: Live connections unlock the amazing query experience of MotherDuck.
  type: feature
  entity: MotherDuck
  keywords:
  - feature
  - live
  - connections
  - unlock
  - amazing
  - query
  - experience
  - motherduck
  source:
    doc: motherduck.com/learn-more/bigquery-alternative-motherduck.md
    quote: live connections unlock the amazing query experience of MotherDuck, directly
      in the Tableau interface.
    char_start: 0
    char_end: 102
- statement: LLMs can enhance the quality of firmographic data in CRM systems.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - llms
  - enhance
  - quality
  - firmographic
  - data
  - crm
  - systems
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-four.md
    quote: Inspired by some of the AI features integrated into MotherDuck, this article
      discusses leveraging Large Language Models (LLMs) within SQL queries to enhance
      the quality of firmographic data in Custome
    char_start: 0
    char_end: 240
- statement: Margaret Rosas has joined us at MotherDuck to lead our customer success
    team.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - margaret
  - rosas
  - joined
  - us
  - motherduck
  - lead
  - customer
  - success
  - team
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: Margaret has joined us at MotherDuck to lead our customer success team.
    char_start: 0
    char_end: 71
- statement: marimo integrates with MotherDuck to provide an interactive and seamless
    data analysis experience.
  type: integration
  entity: MotherDuck
  keywords:
  - integration
  - marimo
  - integrates
  - motherduck
  - provide
  - interactive
  - seamless
  - data
  - analysis
  - experience
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: marimo integrates with MotherDuck to provide an interactive and seamless
      data analysis experience.
    char_start: 0
    char_end: 98
- statement: MCP is a feature of MotherDuck for managing data pipelines.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - mcp
  - feature
  - motherduck
  - managing
  - data
  - pipelines
  source:
    doc: motherduck.com/blog/getting-started-gis-duckdb.md
    quote: 'MCP: Closing the Feedback Loop'
    char_start: 0
    char_end: 30
- statement: Meltano integrates with MotherDuck by utilizing its ability to connect
    to DuckDB-based data warehouses.
  type: integration
  entity: MotherDuck
  keywords:
  - integration
  - meltano
  - integrates
  - motherduck
  - utilizing
  - ability
  - connect
  - duckdb
  - based
  - data
  - warehouses
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: Meltano integrates with MotherDuck by utilizing its ability to connect
      to DuckDB-based data warehouses.
    char_start: 0
    char_end: 103
- statement: Metabase integrates with MotherDuck by connecting directly to the MotherDuck
    cloud data warehouse.
  type: integration
  entity: MotherDuck
  keywords:
  - integration
  - metabase
  - integrates
  - motherduck
  - connecting
  - directly
  - cloud
  - data
  - warehouse
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: Metabase integrates with MotherDuck by connecting directly to the MotherDuck
      cloud data warehouse.
    char_start: 0
    char_end: 98
- statement: Microsoft Power BI integrates with MotherDuck by connecting to the cloud
    data warehouse capabilities provided by MotherDuck.
  type: integration
  entity: MotherDuck
  keywords:
  - integration
  - microsoft
  - power
  - bi
  - integrates
  - motherduck
  - connecting
  - cloud
  - data
  - warehouse
  - capabilities
  - provided
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: Microsoft Power BI integrates with MotherDuck by connecting to the cloud
      data warehouse capabilities provided by MotherDuck.
    char_start: 0
    char_end: 124
- statement: Modern architectures like MotherDuck can process complex operations with
    greater efficiency.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - modern
  - architectures
  - like
  - motherduck
  - process
  - complex
  - operations
  - greater
  - efficiency
  source:
    doc: motherduck.com/blog/streamlining-ai-agents-duckdb-rag-solutions.md
    quote: Modern architectures like MotherDuck, which leverages DuckDB's state-of-the-art
      join algorithms, can process these complex operations with greater efficiency
      and less reliance on costly data shuffling
    char_start: 0
    char_end: 201
- statement: Monte Carlo integrates with MotherDuck to offer comprehensive data observability.
  type: integration
  entity: MotherDuck
  keywords:
  - integration
  - monte
  - carlo
  - integrates
  - motherduck
  - offer
  - comprehensive
  - data
  - observability
  source:
    doc: motherduck.com/blog/unstructured-analysis-tensorlake-motherduck.md
    quote: Monte Carlo integrates with MotherDuck to offer comprehensive data observability
      for data stored and processed within the MotherDuck cloud data warehouse.
    char_start: 0
    char_end: 154
- statement: MotherDuck allows free usage for small projects.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - allows
  - free
  - usage
  - small
  - projects
  source:
    doc: motherduck.com/blog/duckdb-the-great-federator.md
    quote: paddle Free Forever for small projects.
    char_start: 0
    char_end: 39
- statement: MotherDuck allows loading data in Parquet format.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - allows
  - loading
  - data
  - parquet
  - format
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-2.md
    quote: Today we explored the MotherDuck interface, created a database and populated
      it with tables using Parquet data on S3.
    char_start: 0
    char_end: 117
- statement: MotherDuck allows loading unstructured data into its platform.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - allows
  - loading
  - unstructured
  - data
  - platform
  source:
    doc: motherduck.com/blog/just-enough-sql-for-ai.md
    quote: In this tutorial, learn how to load unstructured data into MotherDuck with
      Unstructured.io...
    char_start: 0
    char_end: 93
- statement: MotherDuck allows querying Amazon S3 more securely.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - allows
  - querying
  - amazon
  - s3
  - securely
  source:
    doc: motherduck.com/blog/analyze-sqlite-databases-duckdb.md
    quote: Query Amazon S3 easier, faster, and more securely...
    char_start: 0
    char_end: 52
- statement: MotherDuck allows scaling workloads back to laptops to utilize local
    compute power.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - allows
  - scaling
  - workloads
  - back
  - laptops
  - utilize
  - local
  - compute
  - power
  source:
    doc: motherduck.com/blog/scaling-duckdb-with-ducklings.md
    quote: With MotherDuck, you can scale your workloads back to your laptop to take
      advantage of local compute power and zero-latency...
    char_start: 0
    char_end: 126
- statement: MotherDuck allows users to analyze data from Google Sheets.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - allows
  - users
  - analyze
  - data
  - google
  - sheets
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: MotherDuck allows users to analyze data from Google Sheets.
    char_start: 0
    char_end: 59
- statement: MotherDuck allows users to categorize product review sentiment.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - allows
  - users
  - categorize
  - product
  - review
  - sentiment
  source:
    doc: motherduck.com/blog/making-pyspark-code-faster-with-duckdb.md
    quote: Congrats, you’ve successfully categorized product review sentiment using
      MotherDuck!
    char_start: 0
    char_end: 84
- statement: MotherDuck allows users to create databases over the network using Foursquare
    datasets.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - allows
  - users
  - create
  - databases
  - over
  - network
  - using
  - foursquare
  - datasets
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Instead of downloading the full 11.05 GB locally, we can simply create
      a database over the network using the power of MotherDuck.
    char_start: 0
    char_end: 129
- statement: MotherDuck allows users to generate web app dashboards based on their
    data.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - allows
  - users
  - generate
  - web
  - app
  - dashboards
  - based
  - data
  source:
    doc: motherduck.com/blog/data-warehouse-feature-roundup-dec-2024.md
    quote: How to generate a web app dashboard based on your data
    char_start: 0
    char_end: 54
- statement: MotherDuck allows users to handle Excel files flexibly.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - allows
  - users
  - handle
  - excel
  - files
  - flexibly
  source:
    doc: motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md
    quote: This type of flexibility is core to MotherDuck and is critical to make
      sure that business value is never blocked by IT frameworks.
    char_start: 0
    char_end: 130
- statement: MotherDuck allows users to load and query StackOverflow data.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - allows
  - users
  - load
  - query
  - stackoverflow
  - data
  source:
    doc: motherduck.com/blog/duckdb-the-great-federator.md
    quote: MotherDuck allows users to load and query StackOverflow data.
    char_start: 0
    char_end: 61
- statement: MotherDuck allows workloads using reasonable-sized datasets to scale
    to lots of concurrent users.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - allows
  - workloads
  - using
  - reasonable
  - sized
  - datasets
  - scale
  - lots
  - concurrent
  - users
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-1.md
    quote: Read Scaling unlocks a big piece of the MotherDuck vision; it allows workloads
      using reasonable-sized datasets to scale to lots of concurrent users.
    char_start: 0
    char_end: 148
- statement: MotherDuck allows you to upload your data and share a named snapshot
    with your colleagues in two lines of SQL.
  type: feature
  entity: MotherDuck
  keywords:
  - feature
  - motherduck
  - allows
  - upload
  - data
  - share
  - named
  - snapshot
  - colleagues
  - two
  - lines
  - sql
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: MotherDuck allows you to upload your data and share a named snapshot with
      your colleagues in two lines of SQL.
    char_start: 0
    char_end: 110
- statement: MotherDuck and Ascend are platforms used in data engineering.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - ascend
  - platforms
  - used
  - data
  - engineering
  source:
    doc: motherduck.com/learn-more/columnar-storage-guide.md
    quote: Both are platforms used in data engineering.
    char_start: 0
    char_end: 44
- statement: MotherDuck and Bacalhau facilitate distributed data processing.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - bacalhau
  - facilitate
  - distributed
  - data
  - processing
  source:
    doc: motherduck.com/blog/preswald-health-data-analysis.md
    quote: This is where MotherDuck, powered by DuckDB, and Bacalhau come in handy.
    char_start: 0
    char_end: 72
- statement: MotherDuck and Dagster streamline data workflows.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - dagster
  - streamline
  - data
  - workflows
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md
    quote: Explore how MotherDuck and Dagster streamline data workflows.
    char_start: 0
    char_end: 61
- statement: MotherDuck and DuckDB have adopted the llms.txt standard.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - duckdb
  - adopted
  - llms
  - txt
  - standard
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: Luckily, both MotherDuck and DuckDB have adopted this standard.
    char_start: 0
    char_end: 63
- statement: MotherDuck and DuckDB make it easy to implement semantic search.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - duckdb
  - make
  - easy
  - implement
  - semantic
  - search
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: Doing RAG for LLMs or making semantic search results pop? MotherDuck and
      DuckDB make it easy!
    char_start: 0
    char_end: 93
- statement: MotherDuck and Fabi.ai can be used to build an interactive sentiment
    analysis dashboard.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - fabi
  - ai
  - used
  - build
  - interactive
  - sentiment
  - analysis
  - dashboard
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-2.md
    quote: Interactive, shareable sentiment analysis dashboard with MotherDuck & Fabi.ai
    char_start: 0
    char_end: 77
- statement: MotherDuck and Geobase can be integrated to visualize and build applications
    using spatial-temporal data.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - geobase
  - integrated
  - visualize
  - build
  - applications
  - using
  - spatial
  - temporal
  - data
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: Learn how to integrate MotherDuck and Geobase to visualize and build applications
      that have never been possible before using spatial-temporal data.
    char_start: 0
    char_end: 147
- statement: MotherDuck and Preswald provide faster health data analysis.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - preswald
  - provide
  - faster
  - health
  - data
  - analysis
  source:
    doc: motherduck.com/blog/git-for-data-part-1.md
    quote: Faster health data analysis with MotherDuck & Preswald
    char_start: 0
    char_end: 54
- statement: MotherDuck and Unstructured.io have a powerful new integration.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - unstructured
  - io
  - powerful
  - new
  - integration
  source:
    doc: motherduck.com/blog/motherduck-congratulates-duckdb-1.0-release.md
    quote: This blog post introduces a powerful new integration between MotherDuck
      and Unstructured.io.
    char_start: 0
    char_end: 92
- statement: MotherDuck and YData Profiling are used together for data management.
  type: integration
  entity: MotherDuck
  keywords:
  - integration
  - motherduck
  - ydata
  - profiling
  - used
  - together
  - data
  - management
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: MotherDuck and YData Profiling are used together for data management.
    char_start: 0
    char_end: 69
- statement: MotherDuck avoids both of these pitfalls, offering a more direct pay-for-what-you-use
    model.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - avoids
  - both
  - pitfalls
  - offering
  - direct
  - pay
  - what
  - use
  - model
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part1.md
    quote: A truly serverless platform like MotherDuck avoids both of these pitfalls,
      offering a more direct pay-for-what-you-use model.
    char_start: 0
    char_end: 125
- statement: MotherDuck blog readers get $100 off tickets with code 'Sheila100'.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - blog
  - readers
  - get
  - '100'
  - 'off'
  - tickets
  - code
  - sheila100
  source:
    doc: motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md
    quote: MotherDuck blog readers get $100 off tickets with code 'Sheila100'.
    char_start: 0
    char_end: 67
- statement: MotherDuck brings ACID transaction support.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - brings
  - acid
  - transaction
  - support
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: MotherDuck – the cloud service for DuckDB – brings ACID transaction support.
    char_start: 0
    char_end: 76
- statement: MotherDuck can be connected to applications for data analytics using
    Vercel.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - connected
  - applications
  - data
  - analytics
  - using
  - vercel
  source:
    doc: motherduck.com/blog/why-web-developers-should-care-about-analytical-databases.md
    quote: Let’s dive into an example of connecting your web application to an OLAP
      database in your data stack using Vercel.
    char_start: 0
    char_end: 114
- statement: MotherDuck can help reduce cloud data warehouse costs by 70% or more.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - help
  - reduce
  - cloud
  - data
  - warehouse
  - costs
  - '70'
  source:
    doc: motherduck.com/blog/streamkap-mysql-to-motherduck.md
    quote: Learn how to cut cloud data warehouse costs by 70% or more using DuckDB
      for local work & MotherDuck's serverless platform.
    char_start: 0
    char_end: 122
- statement: MotherDuck can natively ingest from CSV, Parquet, JSON, Iceberg, & Delta
    file formats.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - natively
  - ingest
  - csv
  - parquet
  - json
  - iceberg
  - delta
  - file
  - formats
  source:
    doc: motherduck.com/blog/python-duckdb-vs-dataframe-libraries.md
    quote: It can natively ingest from CSV, Parquet, JSON, Iceberg, & Delta file formats.
    char_start: 0
    char_end: 78
- statement: MotherDuck can simulate multi-writer by routing updates from multiple
    different users to the same instance.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - simulate
  - multi
  - writer
  - routing
  - updates
  - multiple
  - different
  - users
  - instance
  source:
    doc: motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md
    quote: Future work in MotherDuck will allow multi-writer by routing writes to
      a single backend.
    char_start: 0
    char_end: 88
- statement: MotherDuck can translate natural language questions directly into SQL.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - translate
  - natural
  - language
  - questions
  - directly
  - sql
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-nine.md
    quote: MotherDuck has built-in AI functions that can translate your natural language
      questions directly into SQL.
    char_start: 0
    char_end: 106
- statement: MotherDuck CEO Jordan Tigani is speaking at the AI Native Summit 2025.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - ceo
  - jordan
  - tigani
  - speaking
  - ai
  - native
  - summit
  - '2025'
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: This event brings together AI leaders across research, startups and global
      companies for a day of discussion about the state of enterprise AI. MotherDuck
      CEO Jordan Tigani is speaking.
    char_start: 0
    char_end: 184
- statement: MotherDuck collaborates with Dataroots for events.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - collaborates
  - dataroots
  - events
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: MotherDuck collaborates with Dataroots for events.
    char_start: 0
    char_end: 50
- statement: MotherDuck currently supports OpenAI’s text-embedding-3-small and text-embedding-3-large
    for embedding generation.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - currently
  - supports
  - openai
  - text
  - embedding
  - small
  - large
  - generation
  source:
    doc: motherduck.com/blog/effortless-etl-unstructured-data-unstructuredio-motherduck.md
    quote: MotherDuck currently supports OpenAI’s text-embedding-3-small (512 dimensions)
      and text-embedding-3-large (1024 dimensions) for embedding generation.
    char_start: 0
    char_end: 149
- statement: MotherDuck data apps utilize a novel 1.5-tier architecture.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - data
  - apps
  - utilize
  - novel
  - '1.5'
  - tier
  - architecture
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md
    quote: Motherduck data apps are special because they utilize a novel 1.5-tier
      architecture.
    char_start: 0
    char_end: 84
- statement: MotherDuck documentation can be found at specific URLs.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - documentation
  - found
  - specific
  - urls
  source:
    doc: motherduck.com/blog/duckdb-tutorial-for-beginners.md
    quote: 'For MotherDuck, you''ll find them at : - [https://motherduck.com/docs/llms.txt](https://motherduck.com/docs/llms.txt)'
    char_start: 0
    char_end: 116
- statement: MotherDuck does not allow importing of Excel extension files through
    its UI.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - allow
  - importing
  - excel
  - extension
  - files
  - ui
  source:
    doc: motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md
    quote: It should be noted that as of this writing, the MotherDuck UI does not
      allow importing of Excel extension files.
    char_start: 0
    char_end: 112
- statement: MotherDuck eliminates fighting over common resources by assigning separate,
    isolated compute instances to each user.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - eliminates
  - fighting
  - over
  - common
  - resources
  - assigning
  - separate
  - isolated
  - compute
  - instances
  - user
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: MotherDuck eliminates fighting over common resources by assigning separate,
      isolated compute instances to each user.
    char_start: 0
    char_end: 116
- statement: MotherDuck employs Git workflows for data management.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - employs
  - git
  - workflows
  - data
  - management
  source:
    doc: motherduck.com/blog/building-data-applications-with-motherduck.md
    quote: This article explores how to bring Git style workflows like branching,
      testing, and deploy...
    char_start: 0
    char_end: 93
- statement: MotherDuck enables retrieval using Vector Search based on cosine similarity
    functions.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - enables
  - retrieval
  - using
  - vector
  - search
  - based
  - cosine
  - similarity
  - functions
  source:
    doc: motherduck.com/blog/effortless-etl-unstructured-data-unstructuredio-motherduck.md
    quote: MotherDuck enables retrieval using Vector Search based on cosine similarity
      functions.
    char_start: 0
    char_end: 86
- statement: MotherDuck enables the multiplayer experience of having a single file
    without the need for tedious synchronization.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - enables
  - multiplayer
  - experience
  - having
  - single
  - file
  - without
  - need
  - tedious
  - synchronization
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: Moreover, MotherDuck enables the multiplayer experience of having a single
      file without the need for tedious synchronization with your team.
    char_start: 0
    char_end: 140
- statement: MotherDuck enhances text analysis using its prompt() function.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - enhances
  - text
  - analysis
  - using
  - prompt
  - function
  source:
    doc: motherduck.com/blog/ducklake-motherduck.md
    quote: Powered by DuckDB's blazing fast query engine and purpose built for analytics,
      it enables high-performance queries across numerical and textual data.
    char_start: 0
    char_end: 149
- statement: MotherDuck explores the sweet spot between simplicity and capability
    in data systems.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - explores
  - sweet
  - spot
  - simplicity
  - capability
  - data
  - systems
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-four.md
    quote: Exploring the sweet spot between simplicity and capability in data systems,
      one IoT hackathon at a time.
    char_start: 0
    char_end: 104
- statement: MotherDuck has a new Business Plan offering.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - new
  - business
  - plan
  - offering
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md
    quote: and a new Business Plan.
    char_start: 0
    char_end: 24
- statement: MotherDuck has a Web Assembly (Wasm) client which enables 1.5 tier applications.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - web
  - assembly
  - wasm
  - client
  - which
  - enables
  - '1.5'
  - tier
  - applications
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-1.md
    quote: MotherDuck has a Web Assembly (Wasm) client which enables 1.5 tier applications...
    char_start: 0
    char_end: 82
- statement: MotherDuck has closed a Series B funding round of $100 million.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - closed
  - series
  - funding
  - round
  - '100'
  - million
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-two.md
    quote: MotherDuck Now Open for All and closes Series B
    char_start: 0
    char_end: 47
- statement: MotherDuck has embedded a large language model inside SQL.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - embedded
  - large
  - language
  - model
  - inside
  - sql
  source:
    doc: motherduck.com/blog/duckdb-the-great-federator.md
    quote: we recently decided to jump into the fray here at MotherDuck by embedding
      a large language model inside SQL.
    char_start: 0
    char_end: 108
- statement: MotherDuck has given ATM.com's lean team the tools to compete with companies
    ten times their size.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - given
  - atm
  - com
  - lean
  - team
  - tools
  - compete
  - companies
  - ten
  - times
  - size
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: 'With MotherDuck, the destination is clear: a modern data stack that scales
      with the business, not the vendor''s revenue targets.'
    char_start: 0
    char_end: 127
- statement: MotherDuck has implemented a new storage solution, Differential Storage.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - implemented
  - new
  - storage
  - solution
  - differential
  source:
    doc: motherduck.com/blog/announcing-duckdb-13-on-motherduck-cdw.md
    quote: MotherDuck has implemented a new storage solution, Differential Storage,
      that solves a number of challenges...
    char_start: 0
    char_end: 110
- statement: MotherDuck has introduced tiered support and read scaling.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - introduced
  - tiered
  - support
  - read
  - scaling
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md
    quote: including tiered support, read scaling
    char_start: 0
    char_end: 38
- statement: MotherDuck has launched the ability to auto-join a MotherDuck Organization
    in the same email domain.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - launched
  - ability
  - auto
  - join
  - organization
  - email
  - domain
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: In our latest release, we’ve launched the ability to auto-join a MotherDuck
      Organization in the same email domain.
    char_start: 0
    char_end: 114
- statement: MotherDuck has opened its platform to anyone who wants to try it.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - opened
  - platform
  - anyone
  - who
  - wants
  - try
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: the opening of the platform to anyone who wants to try it.
    char_start: 0
    char_end: 58
- statement: 'MotherDuck has three Duckling sizes: Pulse, Standard and Jumbo.'
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - three
  - duckling
  - sizes
  - pulse
  - standard
  - jumbo
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: 'MotherDuck has three Duckling sizes: Pulse, Standard and Jumbo.'
    char_start: 0
    char_end: 63
- statement: MotherDuck has URL-based sharing, where a user can get a share URL and
    pass it onto another user for them to query.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - url
  - based
  - sharing
  - user
  - get
  - share
  - pass
  - onto
  - another
  - them
  - query
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: MotherDuck has URL-based sharing, where a user can get a share URL and
      pass it onto another user for them to query.
    char_start: 0
    char_end: 115
- statement: MotherDuck helps you handle data at the size you actually have.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - helps
  - handle
  - data
  - size
  - actually
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: you might be a good candidate for a new generation of data tools that help
      you handle data at the size you actually have
    char_start: 0
    char_end: 120
- statement: MotherDuck includes a web notebook and Git-style Collaboration.
  type: feature
  entity: MotherDuck
  keywords:
  - feature
  - motherduck
  - includes
  - web
  - notebook
  - git
  - style
  - collaboration
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: MotherDuck includes a web notebook and Git-style Collaboration
    char_start: 0
    char_end: 62
- statement: MotherDuck includes both fully-managed DuckLake support and ability to
    bring your own bucket.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - includes
  - both
  - fully
  - managed
  - ducklake
  - support
  - ability
  - bring
  - bucket
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Preview support of MotherDuck includes both fully-managed DuckLake support
      and ability to bring your own bucket.
    char_start: 0
    char_end: 112
- statement: MotherDuck includes the Column Explorer feature.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - includes
  - column
  - explorer
  - feature
  source:
    doc: motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md
    quote: check out MotherDuck’s Web UI with breakthrough features like [Column Explorer]
      delighting and simplifying long-standing workflow problems.
    char_start: 0
    char_end: 139
- statement: MotherDuck integrates seamlessly into an Apache Airflow data pipeline.
  type: integration
  entity: MotherDuck
  keywords:
  - integration
  - motherduck
  - integrates
  - seamlessly
  - apache
  - airflow
  - data
  - pipeline
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: Daniel demonstrates the integrating MotherDuck into an Apache Airflow data
      pipeline to process S3 data.
    char_start: 0
    char_end: 103
- statement: MotherDuck integrates vector search, full-text search, and hybrid retrieval
    into a single cloud data warehouse environment.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - integrates
  - vector
  - search
  - full
  - text
  - hybrid
  - retrieval
  - single
  - cloud
  - data
  - warehouse
  - environment
  source:
    doc: motherduck.com/blog/motherduck-congratulates-duckdb-1.0-release.md
    quote: With these capabilities, complete RAG applications can be built within
      MotherDuck that integrate vector search, full-text search, and hybrid retrieval
      into a single cloud data warehouse environment.
    char_start: 0
    char_end: 198
- statement: MotherDuck integrates with Python and other access libraries.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - integrates
  - python
  - access
  - libraries
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-2.md
    quote: MotherDuck also integrates with Python and all the other access libraries
      and integrations for DuckDB.
    char_start: 0
    char_end: 102
- statement: Motherduck integrates with Rill Data for dashboarding.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - integrates
  - rill
  - data
  - dashboarding
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eight.md
    quote: Motherduck integrates with Rill Data for dashboarding.
    char_start: 0
    char_end: 54
- statement: MotherDuck introduced a powerful new prompt() function.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - introduced
  - powerful
  - new
  - prompt
  - function
  source:
    doc: motherduck.com/blog/motherduck-in-europe.md
    quote: In the second half of 2024, MotherDuck introduced a powerful new prompt()
      function.
    char_start: 0
    char_end: 83
- statement: MotherDuck introduces new features designed to better support businesses
    looking for their first data warehouse.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - introduces
  - new
  - features
  - designed
  - better
  - support
  - businesses
  - looking
  - first
  - data
  - warehouse
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: Introducing new features designed to better support businesses looking
      for their first data warehouse, including SOC 2 Type II and GDPR compliance,
      tiered support, read scaling, and a new Business Pla
    char_start: 0
    char_end: 202
- statement: Motherduck is a cloud-based data platform for analytics.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - cloud
  - based
  - data
  - platform
  - analytics
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: A cloud-based data platform for analytics.
    char_start: 0
    char_end: 42
- statement: MotherDuck is a destination connector in Estuary.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - destination
  - connector
  - estuary
  source:
    doc: motherduck.com/blog/git-for-data-part-1.md
    quote: Since MotherDuck is a destination connector in Estuary...
    char_start: 0
    char_end: 57
- statement: MotherDuck is a participant at the dbt Coalesce 2024 conference.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - participant
  - dbt
  - coalesce
  - '2024'
  - conference
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: MotherDuck is a participant at the dbt Coalesce 2024 conference.
    char_start: 0
    char_end: 64
- statement: MotherDuck is a platform for creating interactive text embedding explorers.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - platform
  - creating
  - interactive
  - text
  - embedding
  - explorers
  source:
    doc: motherduck.com/blog/announcing-small-data-sf-2025.md
    quote: The document discusses the creation of an interactive text embedding explorer
      using the MotherDuck platform.
    char_start: 0
    char_end: 108
- statement: MotherDuck is associated with Bluesky.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - associated
  - bluesky
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: you can also say hello to both Mehdi and yours truly over there! (and,
      of course, MotherDuck's Bluesky account)
    char_start: 0
    char_end: 111
- statement: MotherDuck is bringing the fun to Las Vegas for Coalesce 2024.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - bringing
  - fun
  - las
  - vegas
  - coalesce
  - '2024'
  source:
    doc: motherduck.com/blog/introducing-instant-sql.md
    quote: Get ready to make a splash at Coalesce 2024! 🦆 MotherDuck is bringing the
      fun to Las Vegas.
    char_start: 0
    char_end: 91
- statement: MotherDuck is building a data app generator using Claude Artifacts.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - building
  - data
  - app
  - generator
  - using
  - claude
  - artifacts
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md
    quote: MotherDuck’s own Till Döhmen writes about experimenting with Claude Artifacts
      to build a MotherDuck data app generator.
    char_start: 0
    char_end: 119
- statement: MotherDuck is building a partner ecosystem.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - building
  - partner
  - ecosystem
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-six.md
    quote: Building the MotherDuck Ecosystem
    char_start: 0
    char_end: 33
- statement: MotherDuck is compliant with GDPR.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - compliant
  - gdpr
  source:
    doc: motherduck.com/blog/motherduck-duckdb-dbt.md
    quote: Earning and maintaining our customers’ trust is of the utmost importance
      to us at MotherDuck.
    char_start: 0
    char_end: 93
- statement: MotherDuck is currently free to use until we enable billing next year.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - currently
  - free
  - use
  - enable
  - billing
  - next
  - year
  source:
    doc: motherduck.com/blog/motherduck-duckdb-dbt.md
    quote: MotherDuck is currently free to use until we enable billing next year.
    char_start: 0
    char_end: 70
- statement: MotherDuck is hosting a party at the Data + AI Summit.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - hosting
  - party
  - data
  - ai
  - summit
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: Time to let loose and your feathers fly! Following Day 2 of Databricks
      Data + AI Summit, glide on over to the MotherDuck party.
    char_start: 0
    char_end: 127
- statement: MotherDuck is ideal for collaborative analytics among small-to-medium-sized
    teams.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - ideal
  - collaborative
  - analytics
  - among
  - small
  - medium
  - sized
  - teams
  source:
    doc: motherduck.com/learn-more/data-application-architecture.md
    quote: They're ideal for collaborative analytics among small-to-medium-sized teams
      when groups need to work on the same datasets without the complexity of a full-scale
      data warehouse.
    char_start: 0
    char_end: 176
- statement: MotherDuck is interested in Postgres.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - interested
  - postgres
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-1.md
    quote: Why, you might ask, does MotherDuck care about Postgres?
    char_start: 0
    char_end: 56
- statement: MotherDuck is introducing a new Business Plan with unlimited Organization
    members.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - introducing
  - new
  - business
  - plan
  - unlimited
  - organization
  - members
  source:
    doc: motherduck.com/blog/motherduck-open-for-all-with-series-b.md
    quote: We are introducing a new Business Plan with unlimited Organization members...
    char_start: 0
    char_end: 77
- statement: MotherDuck is landing in Europe.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - landing
  - europe
  source:
    doc: motherduck.com/blog/announcing-ducklake-support-motherduck-preview.md
    quote: MotherDuck is Landing in Europe! Announcing our EU Region
    char_start: 0
    char_end: 57
- statement: MotherDuck is now doing weekly releases.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - now
  - doing
  - weekly
  - releases
  source:
    doc: motherduck.com/blog/analyze-x-data-nodejs-duckdb.md
    quote: We are now doing weekly releases because we admire and want to emulate
      this speed of execution.
    char_start: 0
    char_end: 95
- statement: MotherDuck is open for all and closes Series B.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - open
  - closes
  - series
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2024.md
    quote: MotherDuck Now Open for All and closes Series B.
    char_start: 0
    char_end: 48
- statement: MotherDuck is open for all data analysts, data engineers, data scientists
    and their flocks.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - open
  - data
  - analysts
  - engineers
  - scientists
  - flocks
  source:
    doc: motherduck.com/blog/preswald-health-data-analysis.md
    quote: we’re excited to open MotherDuck for all data analysts, data engineers,
      data scientists and their flocks.
    char_start: 0
    char_end: 105
- statement: MotherDuck is sharing exciting news at booth B27.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - sharing
  - exciting
  - news
  - booth
  - b27
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: We've got some exciting news we'll be sharing that you won't want to miss!
    char_start: 0
    char_end: 74
- statement: 'MotherDuck is sponsoring DuckCon #5.'
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - sponsoring
  - duckcon
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-six.md
    quote: DuckDB Labs is excited to hold the next “DuckCon” DuckDB user group meeting
      in Seattle, WA, sponsored by MotherDuck.
    char_start: 0
    char_end: 116
- statement: MotherDuck is still under private beta.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - still
  - private
  - beta
  source:
    doc: motherduck.com/blog/preswald-health-data-analysis.md
    quote: 'Note : MotherDuck is still under private beta, but I heard you could get
      an invite if you join their community slack with a good duck pun.'
    char_start: 0
    char_end: 138
- statement: MotherDuck is used for retrieval-augmented generation applications.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - used
  - retrieval
  - augmented
  - generation
  - applications
  source:
    doc: motherduck.com/blog/ducklake-motherduck.md
    quote: before storing them in MotherDuck for retrieval-augmented generation (RAG)
      applications.
    char_start: 0
    char_end: 88
- statement: MotherDuck just got nearly 20% faster.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - got
  - nearly
  - '20'
  - faster
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: Benchmarks, efficiency, and how MotherDuck just got nearly 20% faster.
    char_start: 0
    char_end: 70
- statement: MotherDuck launched 'FixIt' to help analysts with SQL errors.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - launched
  - fixit
  - help
  - analysts
  - sql
  - errors
  source:
    doc: motherduck.com/blog/fix-outdated-llm-documentation-duckdb.md
    quote: Two weeks ago, in order to help analysts stay focused on their SQL, we
      launched 'FixIt'...
    char_start: 0
    char_end: 90
- statement: MotherDuck lets you analyze local data while still JOINing with data
    processed in the cloud.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - lets
  - analyze
  - local
  - data
  - still
  - joining
  - processed
  - cloud
  source:
    doc: motherduck.com/blog/duckdb-dashboard-e2e-data-engineering-project-part-3.md
    quote: MotherDuck lets you analyze this local data locally, while still JOINing
      with data processed in the cloud.
    char_start: 0
    char_end: 106
- statement: MotherDuck looks forward to seeing how innovations will shape the data
    management landscape.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - looks
  - forward
  - seeing
  - innovations
  - shape
  - data
  - management
  - landscape
  source:
    doc: motherduck.com/blog/making-pyspark-code-faster-with-duckdb.md
    quote: At MotherDuck, we look forward to seeing how these innovations will shape
      the data management landscape in the years to come.
    char_start: 0
    char_end: 125
- statement: MotherDuck makes it easy to scale from megabytes to terabytes.
  type: feature
  entity: MotherDuck
  keywords:
  - feature
  - motherduck
  - makes
  - easy
  - scale
  - megabytes
  - terabytes
  source:
    doc: motherduck.com/blog/sql-keyboard-shortcuts-for-joyful-querying.md
    quote: MotherDuck makes it easy to scale from megabytes to terabytes with a combination
      of per-user Duckling tenancy...
    char_start: 0
    char_end: 112
- statement: MotherDuck makes it simple to start uploading and querying your data.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - makes
  - simple
  - start
  - uploading
  - querying
  - data
  source:
    doc: motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md
    quote: MotherDuck makes it simple to start uploading and querying your data, whether
      it sits on your local machine, in blob storage or even on the web.
    char_start: 0
    char_end: 144
- statement: 'MotherDuck Mega instance is #1 overall in ClickBench.'
  type: performance
  entity: MotherDuck
  keywords:
  - performance
  - motherduck
  - mega
  - instance
  - overall
  - clickbench
  source:
    doc: motherduck.com/blog/getting-started-gis-duckdb.md
    quote: 'As of this morning, the MotherDuck Mega instance is #1 overall in ClickBench.'
    char_start: 0
    char_end: 77
- statement: MotherDuck now enables you to run larger queries in-memory.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - now
  - enables
  - run
  - larger
  - queries
  - memory
  source:
    doc: motherduck.com/blog/duckdb-cognee-sql-analytics-graph-rag.md
    quote: MotherDuck now enables you to run larger queries in-memory so you can handle
      more complex workloads and data-intensive queries with ease.
    char_start: 0
    char_end: 137
- statement: MotherDuck now saves you time when you only need to connect to a single
    database by allowing you to specify the attach mode when connecting.
  type: feature
  entity: MotherDuck
  keywords:
  - feature
  - motherduck
  - now
  - saves
  - time
  - need
  - connect
  - single
  - database
  - allowing
  - specify
  - attach
  - mode
  - connecting
  source:
    doc: motherduck.com/blog/duckdb-110-hidden-gems.md
    quote: MotherDuck now saves you time when you only need to connect to a single
      database by allowing you to specify the attach mode when connecting.
    char_start: 0
    char_end: 140
- statement: MotherDuck offers a 21-day free trial.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - offers
  - '21'
  - day
  - free
  - trial
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: Start using MotherDuck now! Try 21 Days Free
    char_start: 0
    char_end: 44
- statement: MotherDuck offers a fundamentally different approach to solving the cost
    problem associated with BigQuery.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - offers
  - fundamentally
  - different
  - approach
  - solving
  - cost
  - problem
  - associated
  - bigquery
  source:
    doc: motherduck.com/case-studies/trunkrs-same-day-delivery-motherduck-from-redshift.md
    quote: Now that we understand how BigQuery's architecture drives its cost model,
      let's explore a fundamentally different approach.
    char_start: 0
    char_end: 123
- statement: MotherDuck offers a more direct pay-for-what-you-use model that is better
    suited for bursty, interactive workloads.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - offers
  - direct
  - pay
  - what
  - use
  - model
  - better
  - suited
  - bursty
  - interactive
  - workloads
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part1.md
    quote: A truly serverless platform like MotherDuck avoids both of these pitfalls,
      offering a more direct pay-for-what-you-use model that is better suited for
      bursty, interactive workloads.
    char_start: 0
    char_end: 181
- statement: MotherDuck offers a new startup program with $10k in credits.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - offers
  - new
  - startup
  - program
  - 10k
  - credits
  source:
    doc: motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md
    quote: New Startup Program with $10k in Credits
    char_start: 0
    char_end: 40
- statement: MotherDuck offers a unique set of requirements to make Instant SQL work.
  type: feature
  entity: MotherDuck
  keywords:
  - feature
  - motherduck
  - offers
  - unique
  - set
  - requirements
  - make
  - instant
  - sql
  - work
  source:
    doc: motherduck.com/blog/motherduck-kestra-etl-pipelines.md
    quote: It turns out that you need a unique set of requirements to make Instant
      SQL work.
    char_start: 0
    char_end: 81
- statement: MotherDuck offers a very nice set of SQL functions that handles everything
    from simple aggregations to classical Machine Learning algorithms.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - offers
  - nice
  - set
  - sql
  - functions
  - handles
  - everything
  - simple
  - aggregations
  - classical
  - machine
  - learning
  - algorithms
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2024.md
    quote: MotherDuck offers a very nice set of SQL functions that handles everything
      from simple aggregations to classical Machine Learning algorithms.
    char_start: 0
    char_end: 141
- statement: MotherDuck offers Bruin for data engineering.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - offers
  - bruin
  - data
  - engineering
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: Bruin is an end-to-end data platform that brings together data ingestion,
      transformation using SQL and Python, data quality and governance.
    char_start: 0
    char_end: 139
- statement: MotherDuck offers configurable instances for users.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - offers
  - configurable
  - instances
  - users
  source:
    doc: motherduck.com/blog/announcing-mega-giga-instance-sizes-huge-scale.md
    quote: At the core of MotherDuck's architecture is per-user tenancy, in which
      each user gets their own duckling that's configurable in size.
    char_start: 0
    char_end: 133
- statement: MotherDuck offers Dual Query Execution.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - offers
  - dual
  - query
  - execution
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: MotherDuck, which offers Dual Query Execution.
    char_start: 0
    char_end: 46
- statement: MotherDuck offers Mega ducklings for demanding workloads.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - offers
  - mega
  - ducklings
  - demanding
  - workloads
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: 'Mega ducklings: For Demanding Workloads at a Larger Scale'
    char_start: 0
    char_end: 57
- statement: MotherDuck offers pricing that is often an order of magnitude lower than
    other alternatives.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - offers
  - pricing
  - often
  - order
  - magnitude
  - lower
  - alternatives
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: Because of the efficiency of DuckDB’s query engine and MotherDuck’s scale-up
      architecture, we’re able to offer pricing that is often an order of magnitude
      lower than other alternatives.
    char_start: 0
    char_end: 185
- statement: MotherDuck offers the FixIt feature to delight and simplify long-standing
    workflow problems.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - offers
  - fixit
  - feature
  - delight
  - simplify
  - long
  - standing
  - workflow
  - problems
  source:
    doc: motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md
    quote: check out MotherDuck’s Web UI with breakthrough features like [FixIt] delighting
      and simplifying long-standing workflow problems.
    char_start: 0
    char_end: 129
- statement: MotherDuck offloads the workload to the cloud.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - offloads
  - workload
  - cloud
  source:
    doc: motherduck.com/blog/redshift-files-hunt-for-big-data.md
    quote: MotherDuck offloads the workload to the cloud—allowing users to run the
      same queries...
    char_start: 0
    char_end: 87
- statement: MotherDuck optimizes the execution path for analytics.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - optimizes
  - execution
  - path
  - analytics
  source:
    doc: motherduck.com/blog/python-faker-duckdb-exploration.md
    quote: MotherDuck was optimizing the execution path without me having to think
      about it.
    char_start: 0
    char_end: 81
- statement: MotherDuck pairs well with Estuary, a data pipeline platform.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - pairs
  - well
  - estuary
  - data
  - pipeline
  - platform
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: Ducks and estuaries go together. So it’s no surprise that MotherDuck, a
      cloud data warehouse, pairs well with Estuary, a data pipeline platform.
    char_start: 0
    char_end: 144
- statement: MotherDuck performed well with denormalized tables that Looker preferred.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - performed
  - well
  - denormalized
  - tables
  - looker
  - preferred
  source:
    doc: motherduck.com/case-studies/trunkrs-same-day-delivery-motherduck-from-redshift.md
    quote: MotherDuck performed well with denormalized tables that Looker preferred.
    char_start: 0
    char_end: 73
- statement: MotherDuck plans to roll out full hosted support including fast cloud-proximate
    queries.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - plans
  - roll
  - out
  - full
  - hosted
  - support
  - including
  - fast
  - cloud
  - proximate
  - queries
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: MotherDuck's plans to roll out full hosted support, including fast cloud-proximate
      queries.
    char_start: 0
    char_end: 91
- statement: MotherDuck provides a portable data catalog solution.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - provides
  - portable
  - data
  - catalog
  - solution
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: A company providing a portable data catalog solution.
    char_start: 0
    char_end: 53
- statement: MotherDuck provides a secure and convenient way to store your Azure connection
    string.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - provides
  - secure
  - convenient
  - way
  - store
  - azure
  - connection
  - string
  source:
    doc: motherduck.com/blog/duckdb-110-hidden-gems.md
    quote: MotherDuck provides a secure and convenient way to store your Azure connection
      string so you can query Azure whenever you need.
    char_start: 0
    char_end: 127
- statement: MotherDuck provides a straightforward onboarding experience.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - provides
  - straightforward
  - onboarding
  - experience
  source:
    doc: motherduck.com/blog/MotherDuck-Visualize-Embeddings-Marimo.md
    quote: Onboarding to MotherDuck was refreshingly straightforward.
    char_start: 0
    char_end: 58
- statement: MotherDuck provides an analytics layer with features like automatic schema
    detection and anomaly detection.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - provides
  - analytics
  - layer
  - features
  - like
  - automatic
  - schema
  - detection
  - anomaly
  source:
    doc: motherduck.com/blog/simplifying-iot-analytics-motherduck.md
    quote: 'MotherDuck provides our analytics layer (duh!), highlights include: Automatic
      Schema Detection... Anomaly Detection...'
    char_start: 0
    char_end: 118
- statement: MotherDuck provides options for implementing real-time CDC and streaming
    ETL.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - provides
  - options
  - implementing
  - real
  - time
  - cdc
  - streaming
  - etl
  source:
    doc: motherduck.com/blog/streaming-data-to-motherduck.md
    quote: if you want to learn more about all the options you have for implementing
      real-time CDC and streaming ETL.
    char_start: 0
    char_end: 106
- statement: MotherDuck provides read scaling to enhance data warehouse performance.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - provides
  - read
  - scaling
  - enhance
  - data
  - warehouse
  - performance
  source:
    doc: motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md
    quote: MotherDuck’s read scaling is designed for these types of cases – providing
      an extra boost in compute through horizontal scaling.
    char_start: 0
    char_end: 128
- statement: MotherDuck provides solutions for building AI applications with unstructured
    data.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - provides
  - solutions
  - building
  - ai
  - applications
  - unstructured
  - data
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-2.md
    quote: Building AI applications with unstructured data can become unwieldy and
      cumbersome, especially when integrating multiple data sources.
    char_start: 0
    char_end: 134
- statement: MotherDuck provides the ability to monitor and interrupt active server
    connections.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - provides
  - ability
  - monitor
  - interrupt
  - active
  - server
  - connections
  source:
    doc: motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw.md
    quote: MotherDuck now provides the ability to monitor and interrupt active server
      connections with two new functions in Preview.
    char_start: 0
    char_end: 121
- statement: MotherDuck provides the embedding() function.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - provides
  - embedding
  - function
  source:
    doc: motherduck.com/blog/big-data-is-dead.md
    quote: 'You''ll need: - A [MotherDuck](https://motherduck.com/) account, with
      access to the `embedding()` function...'
    char_start: 0
    char_end: 108
- statement: MotherDuck provides tools for building AI assistants.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - provides
  - tools
  - building
  - ai
  - assistants
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2024.md
    quote: Start using MotherDuck now!
    char_start: 0
    char_end: 27
- statement: MotherDuck provides tools for data transformation using LLMs.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - provides
  - tools
  - data
  - transformation
  - using
  - llms
  source:
    doc: motherduck.com/blog/introducing-instant-sql.md
    quote: A platform that provides tools for data transformation and analysis using
      large language models.
    char_start: 0
    char_end: 96
- statement: MotherDuck provides white glove service during migration.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - provides
  - white
  - glove
  - service
  - migration
  source:
    doc: motherduck.com/learn-more/big-data.md
    quote: '"Everyone always bends over backwards to help.”'
    char_start: 0
    char_end: 47
- statement: MotherDuck published a blog to highlight some hidden gems from 1.1.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - published
  - blog
  - highlight
  - hidden
  - gems
  - '1.1'
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: MotherDuck also published a blog to highlight some hidden gems from 1.1.
    char_start: 0
    char_end: 72
- statement: MotherDuck queries are billed by the amount of CPU they consume.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - queries
  - billed
  - amount
  - cpu
  - consume
  source:
    doc: motherduck.com/blog/duckdb-tutorial-for-beginners.md
    quote: MotherDuck queries are billed by the amount of CPU they consume...
    char_start: 0
    char_end: 66
- statement: MotherDuck raised $47.5 million to enhance analytics.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - raised
  - '47.5'
  - million
  - enhance
  - analytics
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: MotherDuck Raises $47.5 Million to Make Analytics Fun, Frictionless and
      Ducking Awesome.
    char_start: 0
    char_end: 88
- statement: MotherDuck released a new generative AI feature that allows querying
    data using natural language.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - released
  - new
  - generative
  - ai
  - feature
  - allows
  - querying
  - data
  - using
  - natural
  - language
  source:
    doc: motherduck.com/blog/ducklake-motherduck.md
    quote: A while ago MotherDuck released a new generative AI feature that allows
      you to query your data using natural language.
    char_start: 0
    char_end: 118
- statement: MotherDuck released LLMs within SQL.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - released
  - llms
  - within
  - sql
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: MotherDuck released LLMs within SQL.
    char_start: 0
    char_end: 36
- statement: MotherDuck runs faster, more efficient queries through hypertenancy.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - runs
  - faster
  - efficient
  - queries
  - hypertenancy
  source:
    doc: motherduck.com/blog/local-duckdb-ui-visual-data-analysis.md
    quote: Through hypertenancy, MotherDuck runs faster, more efficient queries.
    char_start: 0
    char_end: 69
- statement: MotherDuck saves an enormous amount of money compared to centralized
    log aggregation solutions.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - saves
  - enormous
  - amount
  - money
  - compared
  - centralized
  - log
  - aggregation
  - solutions
  source:
    doc: motherduck.com/blog/log-processing-savings-bacalhau-motherduck.md
    quote: compared to a centralized log aggregation solution, you stand to save an
      enormous amount of money.
    char_start: 0
    char_end: 98
- statement: MotherDuck scales nearly linearly, allowing for better performance with
    increased spending.
  type: performance
  entity: MotherDuck
  keywords:
  - motherduck
  - scales
  - nearly
  - linearly
  - allowing
  - better
  - performance
  - increased
  - spending
  source:
    doc: motherduck.com/blog/llm-data-pipelines-prompt-motherduck-dbt.md
    quote: not only is it much less expensive to run, but it also scales nearly linearly.
    char_start: 0
    char_end: 78
- statement: MotherDuck scales nicely without requiring syntax changes or purchasing
    a new laptop.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - scales
  - nicely
  - without
  - requiring
  - syntax
  - changes
  - purchasing
  - new
  - laptop
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: For this job, I used MotherDuck. It scales nicely without requiring syntax
      changes or purchasing a new laptop 😉.
    char_start: 0
    char_end: 112
- statement: MotherDuck showcased contributions at SIGMOD/PODS 2024.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - showcased
  - contributions
  - sigmod
  - pods
  - '2024'
  source:
    doc: motherduck.com/blog/log-processing-savings-bacalhau-motherduck.md
    quote: MotherDuck showcased our contributions at SIGMOD/PODS 2024 with a series
      of presentations.
    char_start: 0
    char_end: 90
- statement: MotherDuck simplifies distribution and adds features to DuckDB.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - simplifies
  - distribution
  - adds
  - features
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: how MotherDuck simplifies distribution and adds features.
    char_start: 0
    char_end: 57
- statement: MotherDuck simplifies IoT analytics.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - simplifies
  - iot
  - analytics
  source:
    doc: motherduck.com/blog/faster-data-pipelines-with-mcp-duckdb-ai.md
    quote: This blog explores the surprising lessons learned about simplicity in data
      architecture, using DuckDB and MotherDuck as the foundation.
    char_start: 0
    char_end: 135
- statement: MotherDuck simplifies your development experience by eliminating the
    friction between local development and cloud production environments.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - simplifies
  - development
  - experience
  - eliminating
  - friction
  - local
  - cloud
  - production
  - environments
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: Join us to discover how MotherDuck simplifies your development experience
      by eliminating the friction between local development and cloud production environments.
    char_start: 0
    char_end: 162
- statement: MotherDuck Standard is faster than a Snowflake 3XL at only 1/100 of the
    price.
  type: performance
  entity: MotherDuck
  keywords:
  - performance
  - motherduck
  - standard
  - faster
  - snowflake
  - 3xl
  - '100'
  - price
  source:
    doc: motherduck.com/blog/getting-started-gis-duckdb.md
    quote: MotherDuck Standard is also faster than a Snowflake 3XL at only 1/100 of
      the price.
    char_start: 0
    char_end: 83
- statement: MotherDuck successfully underwent an audit for SOC 2 Type I.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - successfully
  - underwent
  - audit
  - soc
  - type
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: MotherDuck successfully underwent an audit for SOC 2 Type I.
    char_start: 0
    char_end: 60
- statement: MotherDuck supported 1.1.1 just two days after its release.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - supported
  - 1.1.1
  - two
  - days
  - release
  source:
    doc: motherduck.com/blog/analyze-data-in-azure-with-duckdb.md
    quote: MotherDuck supported `1.1.1` just two days after its release.
    char_start: 0
    char_end: 61
- statement: MotherDuck supports Azure Blob Storage.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - supports
  - azure
  - blob
  - storage
  source:
    doc: motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md
    quote: MotherDuck support for Azure Blob Storage
    char_start: 0
    char_end: 41
- statement: MotherDuck supports multiple other dashboarding tools.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - supports
  - multiple
  - dashboarding
  - tools
  source:
    doc: motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud.md
    quote: MotherDuck supports multiple other dashboarding tools.
    char_start: 0
    char_end: 54
- statement: MotherDuck supports two modes for users to publish changes to the data
    they have shared.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - supports
  - two
  - modes
  - users
  - publish
  - changes
  - data
  - shared
  source:
    doc: motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md
    quote: Today, MotherDuck supports two modes for users to publish changes to the
      data they have shared.
    char_start: 0
    char_end: 95
- statement: MotherDuck uses DuckDB as a backend for its serverless data solutions.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - uses
  - duckdb
  - backend
  - serverless
  - data
  - solutions
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: MotherDuck uses DuckDB as a backend for its serverless data solutions.
    char_start: 0
    char_end: 70
- statement: MotherDuck was founded on the idea that you can scale up a single node
    to handle virtually any workload.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - founded
  - idea
  - scale
  - up
  - single
  - node
  - handle
  - virtually
  - any
  - workload
  source:
    doc: motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md
    quote: MotherDuck was founded on the idea that you can scale up a single node
      to handle virtually any workload.
    char_start: 0
    char_end: 104
- statement: MotherDuck will have a booth in the 'activation hall' in San Diego.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - booth
  - activation
  - hall
  - san
  - diego
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2024.md
    quote: MotherDuck will have a booth in the 'activation hall' in San Diego.
    char_start: 0
    char_end: 67
- statement: MotherDuck will host a party celebrating ducks at 111 Minna.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - host
  - party
  - celebrating
  - ducks
  - '111'
  - minna
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: Following DuckCon, MotherDuck will host a party celebrating ducks at 111
      Minna.
    char_start: 0
    char_end: 79
- statement: MotherDuck will implement automatic data compaction and garbage collection.
  type: feature
  entity: MotherDuck
  keywords:
  - feature
  - motherduck
  - implement
  - automatic
  - data
  - compaction
  - garbage
  - collection
  source:
    doc: motherduck.com/blog/bigquery-to-duckdb-motherduck.md
    quote: MotherDuck will implement automatic data compaction and garbage collection,
      which can only be manually triggered in the preview release.
    char_start: 0
    char_end: 136
- statement: MotherDuck will prove to be very useful in creating a dashboard.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - prove
  - useful
  - creating
  - dashboard
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: MotherDuck will prove to be very useful.
    char_start: 0
    char_end: 40
- statement: MotherDuck's AI will analyze your question and run the SQL to get you
    the answer.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - ai
  - analyze
  - question
  - run
  - sql
  - get
  - answer
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md
    quote: MotherDuck's AI will analyze your question, look at the schema of the birds
      table, and run the SQL to get you the answer.
    char_start: 0
    char_end: 121
- statement: MotherDuck's dual execution takes the decision making burden off your
    shoulders.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - dual
  - execution
  - takes
  - decision
  - making
  - burden
  - 'off'
  - shoulders
  source:
    doc: motherduck.com/blog/python-faker-duckdb-exploration.md
    quote: MotherDuck's dual execution takes this decision making burden off your
      shoulders.
    char_start: 0
    char_end: 81
- statement: MotherDuck's embedding function generates these vectors.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - embedding
  - function
  - generates
  - vectors
  source:
    doc: motherduck.com/blog/announcing-small-data-sf-2025.md
    quote: We'll use MotherDuck's embedding() function to generate these vectors.
    char_start: 0
    char_end: 70
- statement: MotherDuck's first European cloud region is now in private preview.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - first
  - european
  - cloud
  - region
  - now
  - private
  - preview
  source:
    doc: motherduck.com/blog/fabi-ai-llm-prompt-analysis.md
    quote: MotherDuck's first European cloud region is now in private preview.
    char_start: 0
    char_end: 67
- statement: MotherDuck's hybrid execution model allows for faster data aggregation.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - hybrid
  - execution
  - model
  - allows
  - faster
  - data
  - aggregation
  source:
    doc: motherduck.com/blog/redshift-files-hunt-for-big-data.md
    quote: MotherDuck’s hybrid execution model allows us to exceed these expectations;
      because we run DuckDB both in the browser and on the server, we aggregate your
      data in whichever location gives you the fast
    char_start: 0
    char_end: 212
- statement: MotherDuck's latest features include real-time SQL feedback and natural
    language editing.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - latest
  - features
  - include
  - real
  - time
  - sql
  - feedback
  - natural
  - language
  - editing
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: Stay in flow with MotherDuck's latest features. Real-time SQL feedback
      and natural language editing.
    char_start: 0
    char_end: 100
- statement: MotherDuck's native integration is now available on Vercel Marketplace.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - native
  - integration
  - now
  - available
  - vercel
  - marketplace
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: MotherDuck's native integration is now available on Vercel Marketplace.
    char_start: 0
    char_end: 71
- statement: MotherDuck's Seattle office opened as one of four company hubs.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - seattle
  - office
  - opened
  - one
  - four
  - company
  - hubs
  source:
    doc: motherduck.com/blog/streamkap-mysql-to-motherduck.md
    quote: MotherDuck's Seattle office opened as one of four company hubs.
    char_start: 0
    char_end: 63
- statement: MotherDuck's sub-second query performance to petabyte-scale data lakes.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - sub
  - second
  - query
  - performance
  - petabyte
  - scale
  - data
  - lakes
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: Today we're launching a preview of DuckLake—bringing MotherDuck's sub-second
      query performance to petabyte-scale data lakes.
    char_start: 0
    char_end: 124
- statement: MotherDuck’s approach with Ducklings is very different.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - approach
  - ducklings
  - different
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: MotherDuck’s approach with Ducklings is very different.
    char_start: 0
    char_end: 55
- statement: MotherDuck’s per-user tenancy model is especially powerful for customer-facing
    applications.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - per
  - user
  - tenancy
  - model
  - especially
  - powerful
  - customer
  - facing
  - applications
  source:
    doc: motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md
    quote: MotherDuck’s per-user tenancy model is especially powerful for these types
      of applications.
    char_start: 0
    char_end: 91
- statement: MotherDuck’s vector embedding can offer a quick and easy way to build
    a clever search engine.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - vector
  - embedding
  - offer
  - quick
  - easy
  - way
  - build
  - clever
  - search
  - engine
  source:
    doc: motherduck.com/blog/log-processing-savings-bacalhau-motherduck.md
    quote: MotherDuck’s vector embedding can offer a quick and easy way to build a
      clever search engine.
    char_start: 0
    char_end: 93
- statement: Moving our production workloads to MotherDuck seemed relatively low-risk.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - moving
  - production
  - workloads
  - motherduck
  - seemed
  - relatively
  - low
  - risk
  source:
    doc: motherduck.com/blog/tableau-cloud-motherduck.md
    quote: Moving our production workloads to MotherDuck seemed relatively low-risk
      since we could experiment with it first.
    char_start: 0
    char_end: 113
- statement: Ollama can use MotherDuck as a backend for LLM results.
  type: integration
  entity: MotherDuck
  keywords:
  - integration
  - ollama
  - use
  - motherduck
  - backend
  - llm
  - results
  source:
    doc: motherduck.com/blog/unstructured-analysis-tensorlake-motherduck.md
    quote: Ollama can use MotherDuck as a DuckDB-based backend for Retrieval Augmented
      Generation of LLM results.
    char_start: 0
    char_end: 102
- statement: Omni integrates with MotherDuck for efficient querying and analysis.
  type: integration
  entity: MotherDuck
  keywords:
  - integration
  - omni
  - integrates
  - motherduck
  - efficient
  - querying
  - analysis
  source:
    doc: motherduck.com/blog/unstructured-analysis-tensorlake-motherduck.md
    quote: Omni integrates with MotherDuck by allowing users to connect directly to
      MotherDuck's cloud data warehouse.
    char_start: 0
    char_end: 107
- statement: OneSignal feeds events from MotherDuck to power notifications.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - onesignal
  - feeds
  - events
  - motherduck
  - power
  - notifications
  source:
    doc: motherduck.com/blog/unstructured-analysis-tensorlake-motherduck.md
    quote: OneSignal is a omnichannel solution that helps you improve conversion,
      boost engagement, and retain users.
    char_start: 0
    char_end: 106
- statement: Orchestra allows data teams to move data to MotherDuck easily.
  type: integration
  entity: MotherDuck
  keywords:
  - integration
  - orchestra
  - allows
  - data
  - teams
  - move
  - motherduck
  - easily
  source:
    doc: motherduck.com/blog/unstructured-analysis-tensorlake-motherduck.md
    quote: The Orchestra x Motherduck integration allows data teams to easily move
      data to Motherduck using duckdb/python.
    char_start: 0
    char_end: 111
- statement: Org-level sharing and discoverability have been added to MotherDuck to
    make sharing even easier.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - org
  - level
  - sharing
  - discoverability
  - added
  - motherduck
  - make
  - even
  - easier
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: Org-level sharing and discoverability have been added to MotherDuck to
      make sharing even easier.
    char_start: 0
    char_end: 96
- statement: Per-tenant engines and storage namespaces provide performance isolation.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - per
  - tenant
  - engines
  - storage
  - namespaces
  - provide
  - performance
  - isolation
  source:
    doc: motherduck.com/learn-more/columnar-storage-guide.md
    quote: Per-tenant engines and storage namespaces provide performance isolation.
    char_start: 0
    char_end: 72
- statement: Per-tenant retention windows (5, 90, 180+ days) configured on demand.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - per
  - tenant
  - retention
  - windows
  - '90'
  - '180'
  - days
  - configured
  - demand
  source:
    doc: motherduck.com/learn-more/columnar-storage-guide.md
    quote: Per-tenant retention windows (5, 90, 180+ days) configured on demand.
    char_start: 0
    char_end: 69
- statement: Performance should not be the only criterion you use to choose a database.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - performance
  - criterion
  - use
  - choose
  - database
  source:
    doc: motherduck.com/blog/introducing-instant-sql.md
    quote: I believe that performance should not be the only criterion you use to
      choose a database.
    char_start: 0
    char_end: 89
- statement: Persistent data is crucial for maintaining historical records and performing
    long-term trend analysis.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - persistent
  - data
  - crucial
  - maintaining
  - historical
  - records
  - performing
  - long
  - term
  - trend
  - analysis
  source:
    doc: motherduck.com/blog/solving-advent-code-duckdb-dbt.md
    quote: Persistent data, stored in solutions like MotherDuck, is crucial for maintaining
      historical records.
    char_start: 0
    char_end: 100
- statement: Platforms like MotherDuck, built on the high-performance DuckDB engine,
    are architected to maximize the benefits of a good data layout and minimize costly
    I/O operations.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - platforms
  - like
  - motherduck
  - built
  - high
  - performance
  - duckdb
  - engine
  - architected
  - maximize
  - benefits
  - good
  - data
  - layout
  - minimize
  - costly
  - operations
  source:
    doc: motherduck.com/blog/streamlining-ai-agents-duckdb-rag-solutions.md
    quote: Platforms like MotherDuck, built on the high-performance DuckDB engine,
      are architected to maximize the benefits of a good data layout and minimize
      costly I/O operations.
    char_start: 0
    char_end: 170
- statement: Pushing data from a local DuckDB table to a remote MotherDuck table is
    just another COPY command.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - pushing
  - data
  - local
  - duckdb
  - table
  - remote
  - motherduck
  - another
  - copy
  - command
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: Pushing data from a local DuckDB table to a remote MotherDuck table is
      just another COPY command.
    char_start: 0
    char_end: 97
- statement: Read scaling in MotherDuck prevents overload on single instances.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - read
  - scaling
  - motherduck
  - prevents
  - overload
  - single
  - instances
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-1.md
    quote: Read scaling solves this problem by allowing those workloads to be distributed
      dynamically across many instances.
    char_start: 0
    char_end: 113
- statement: Read Scaling makes metrics meetings more interactive.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - read
  - scaling
  - makes
  - metrics
  - meetings
  - interactive
  source:
    doc: motherduck.com/blog/duckdb-tutorial-for-beginners.md
    quote: our metrics meeting where we have a bunch of people all digging into the
      data at once got dramatically more interactive
    char_start: 0
    char_end: 119
- statement: Recent improvements make exploring large data sets, querying, and data
    sharing more efficient and intuitive.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - recent
  - improvements
  - make
  - exploring
  - large
  - data
  - sets
  - querying
  - sharing
  - efficient
  - intuitive
  source:
    doc: motherduck.com/blog/data-warehouse-feature-roundup-oct-2024.md
    quote: recently-launched features that make exploring large data sets, querying,
      and data sharing more efficient and intuitive.
    char_start: 0
    char_end: 120
- statement: Recently-launched features in the MotherDuck data warehouse include preview
    result cell contents UI, dual execution performance improvements, and auto update
    of data shared within your organization.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - recently
  - launched
  - features
  - motherduck
  - data
  - warehouse
  - include
  - preview
  - result
  - cell
  - contents
  - ui
  - dual
  - execution
  - performance
  - improvements
  - auto
  - update
  - shared
  - within
  source:
    doc: motherduck.com/blog/motherduck-duckdb-dbt.md
    quote: 'Recently-launched features in the MotherDuck data warehouse: preview result
      cell contents UI, dual execution performance improvements, auto update of data
      shared within your organization (or globally!'
    char_start: 0
    char_end: 201
- statement: Running the same query on MotherDuck UI took 1.8 seconds.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - running
  - query
  - motherduck
  - ui
  - took
  - '1.8'
  - seconds
  source:
    doc: motherduck.com/blog/read-scaling-preview.md
    quote: If I ran the same query on [MotherDuck UI](https://app.motherduck.com/)
      in `1.8`.
    char_start: 0
    char_end: 81
- statement: Ryan Boyd will be delivering a technical session at the Data + AI Summit.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - ryan
  - boyd
  - delivering
  - technical
  - session
  - data
  - ai
  - summit
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: Additionally, Ryan Boyd (co-founder at MotherDuck) will be delivering a
      technical session.
    char_start: 0
    char_end: 90
- statement: Ryan Boyd, co-founder at MotherDuck, is speaking about DuckLake at the
    Modern Data Infra Summit.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - ryan
  - boyd
  - co
  - founder
  - motherduck
  - speaking
  - about
  - ducklake
  - modern
  - data
  - infra
  - summit
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: Ryan Boyd, co-founder at MotherDuck, speaking about DuckLake.
    char_start: 0
    char_end: 61
- statement: Scaling up to larger instance sizes is one of the many ways MotherDuck
    scales data warehousing workloads.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - scaling
  - up
  - larger
  - instance
  - sizes
  - one
  - many
  - ways
  - motherduck
  - scales
  - data
  - warehousing
  - workloads
  source:
    doc: motherduck.com/blog.md
    quote: Scaling up to larger instance sizes (ducklings) is only one of the many
      ways MotherDuck scales data warehousing workloads.
    char_start: 0
    char_end: 122
- statement: Setting up MotherDuck proved remarkably straightforward.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - setting
  - up
  - motherduck
  - proved
  - remarkably
  - straightforward
  source:
    doc: motherduck.com/learn-more.md
    quote: Setting up MotherDuck proved remarkably straightforward.
    char_start: 0
    char_end: 56
- statement: Small Data SF 2024 challenges the 'bigger is always better' mentality
    in data and AI.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - small
  - data
  - sf
  - '2024'
  - challenges
  - bigger
  - always
  - better
  - mentality
  - ai
  source:
    doc: motherduck.com/acceptable-use-policy.md
    quote: that challenge the 'bigger is always better' mentality in data and AI.
    char_start: 0
    char_end: 70
- statement: Streaming data from Oracle to MotherDuck is beneficial.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - streaming
  - data
  - oracle
  - motherduck
  - beneficial
  source:
    doc: motherduck.com/blog/summer-data-engineering-roadmap.md
    quote: Why stream data from Oracle to MotherDuck?
    char_start: 0
    char_end: 42
- statement: TCO stands for Total Cost of Ownership.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - tco
  - stands
  - total
  - cost
  - ownership
  source:
    doc: motherduck.com/glossary/relational database.md
    quote: TCO stands for **Total Cost of Ownership**.
    char_start: 0
    char_end: 43
- statement: The 'Smart Hub' architecture is the best choice for most startups.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - smart
  - hub
  - architecture
  - best
  - choice
  - startups
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: For most startups, the 'Smart Hub' architecture is the best choice.
    char_start: 0
    char_end: 67
- statement: The 1.5 data architecture requires fewer intermediate operations between
    the presentation, the data app, and the underlying database.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - '1.5'
  - data
  - architecture
  - requires
  - fewer
  - intermediate
  - operations
  - presentation
  - app
  - underlying
  - database
  source:
    doc: motherduck.com/blog/perf-is-not-enough.md
    quote: Compared to the more classical tier architecture, this requires fewer intermediate
      operations between the presentation, the data app, and the underlying database
      or data tier.
    char_start: 0
    char_end: 175
- statement: The 4 TB of data on our previous platform magically compressed to 1 TB
    of MotherDuck storage.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - tb
  - data
  - previous
  - platform
  - magically
  - compressed
  - motherduck
  - storage
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eleven.md
    quote: the 4 TB of data on our previous platform magically compressed to 1 TB
      of MotherDuck storage
    char_start: 0
    char_end: 92
- statement: The AI will analyze your question and run the SQL to get you the answer.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - ai
  - analyze
  - question
  - run
  - sql
  - get
  - answer
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-nine.md
    quote: MotherDuck's AI will analyze your question, look at the schema of the birds
      table, and run the SQL to get you the answer.
    char_start: 0
    char_end: 121
- statement: The architecture is built around the power of scaling up with highly
    efficient and scalable single nodes.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - architecture
  - built
  - around
  - power
  - scaling
  - up
  - highly
  - efficient
  - scalable
  - single
  - nodes
  source:
    doc: motherduck.com/blog/duckdb-cognee-sql-analytics-graph-rag.md
    quote: MotherDuck’s architecture is built around the power of scaling up with
      highly efficient and scalable single nodes.
    char_start: 0
    char_end: 114
- statement: The Boundary between Small Data and Big Data is 10 TB.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - boundary
  - small
  - data
  - big
  - '10'
  - tb
  source:
    doc: motherduck.com/blog/python-faker-duckdb-exploration.md
    quote: 'The definition of “Big Data” has always been a bit vague, but the one
      I find most instructive is that Big Data starts when you need to scale out to
      multiple machines in order to process the data in a '
    char_start: 0
    char_end: 226
- statement: The full source code and documentation of our Data App Generator is available
    on GitHub.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - full
  - source
  - code
  - documentation
  - data
  - app
  - generator
  - available
  - github
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md
    quote: You can find the full source code and documentation of our Data App Generator
      on GitHub.
    char_start: 0
    char_end: 88
- statement: The future of data processing isn't about handling bigger datasets—it's
    about handling data more intelligently.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - future
  - data
  - processing
  - isn
  - about
  - handling
  - bigger
  - datasets
  - intelligently
  source:
    doc: motherduck.com/learn-more/columnar-storage-guide.md
    quote: The future of data processing isn't about handling bigger datasets—it's
      about handling data more intelligently.
    char_start: 0
    char_end: 111
- statement: The generator can utilize DuckDB for data management.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - generator
  - utilize
  - duckdb
  - data
  - management
  source:
    doc: motherduck.com/blog/data-app-generator.md
    quote: The generator generally proceeds into the right direction.
    char_start: 0
    char_end: 58
- statement: The generator generates SQL queries to fetch data.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - generator
  - generates
  - sql
  - queries
  - fetch
  - data
  source:
    doc: motherduck.com/blog/data-app-generator.md
    quote: It then adds a second plot and generates a SQL query to fetch the information
      from the database.
    char_start: 0
    char_end: 96
- statement: The immutable nature of the underlying storage makes it easy to add support
    for features like time travel and branching.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - immutable
  - nature
  - underlying
  - storage
  - makes
  - easy
  - add
  - support
  - features
  - like
  - time
  - travel
  - branching
  source:
    doc: motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md
    quote: Additionally, the immutable nature of the underlying storage makes it easy
      to add support for features like time travel and branching.
    char_start: 0
    char_end: 134
- statement: The improved performance from MotherDuck eliminated the need for expensive
    business intelligence tools like Tableau.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - improved
  - performance
  - motherduck
  - eliminated
  - need
  - expensive
  - business
  - intelligence
  - tools
  - like
  - tableau
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: The improved performance from MotherDuck eliminated that need.
    char_start: 0
    char_end: 62
- statement: The integration of Secoda with MotherDuck enables organizations to define
    and implement detailed governance policies efficiently.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - integration
  - secoda
  - motherduck
  - enables
  - organizations
  - define
  - implement
  - detailed
  - governance
  - policies
  - efficiently
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: The integration of Secoda with MotherDuck enables organizations to define
      and implement detailed governance policies efficiently.
    char_start: 0
    char_end: 129
- statement: The marginal cost for smaller tenants is now 'fractions of a penny.'
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - marginal
  - cost
  - smaller
  - tenants
  - now
  - fractions
  - penny
  source:
    doc: motherduck.com/learn-more/columnar-storage-guide.md
    quote: The marginal cost for smaller tenants is now 'fractions of a penny.'
    char_start: 0
    char_end: 68
- statement: The most effective way to improve report speed is to tackle bottlenecks
    in order, starting with I/O by optimizing your data layout through partitioning
    and sorting.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - effective
  - way
  - improve
  - report
  - speed
  - tackle
  - bottlenecks
  - order
  - starting
  - optimizing
  - data
  - layout
  - partitioning
  - sorting
  source:
    doc: motherduck.com/blog/streamlining-ai-agents-duckdb-rag-solutions.md
    quote: The most effective way to improve report speed is to tackle bottlenecks
      in order, starting with I/O by optimizing your data layout through partitioning
      and sorting.
    char_start: 0
    char_end: 164
- statement: The MotherDuck AI team continues to extend in the LLM space with Prompting,
    Embedding, and similarity functions.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - ai
  - team
  - continues
  - extend
  - llm
  - space
  - prompting
  - embedding
  - similarity
  - functions
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2024.md
    quote: The MotherDuck AI team continues to extend in the LLM space with Prompting,
      Embedding, and similarity functions.
    char_start: 0
    char_end: 112
- statement: The MotherDuck Data App Generator allows users to create dashboards for
    Hacker News posts.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - data
  - app
  - generator
  - allows
  - users
  - create
  - dashboards
  - hacker
  - news
  - posts
  source:
    doc: motherduck.com/blog/data-app-generator.md
    quote: To show how our Data App Generator works in practice, let's walk through
      creating a simple app that shows basic summary stats of our hacker news sample
      dataset.
    char_start: 0
    char_end: 160
- statement: The MotherDuck Data App Generator took less than 2 minutes to create
    and cost less than twenty cents in OpenRouter API credits.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - data
  - app
  - generator
  - took
  - less
  - minutes
  - create
  - cost
  - twenty
  - cents
  - openrouter
  - api
  - credits
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: 'The shown examples: - Took less than 2 minutes to create - Costed less
      than twenty cents in OpenRouter API credits!'
    char_start: 0
    char_end: 115
- statement: The MotherDuck UI allows you to move faster from raw data to insights.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - motherduck
  - ui
  - allows
  - move
  - faster
  - raw
  - data
  - insights
  source:
    doc: motherduck.com/blog/duckdb-cognee-sql-analytics-graph-rag.md
    quote: Our new Table Summary in the MotherDuck UI allows you to move faster from
      raw data to insights before writing a SELECT * query.
    char_start: 0
    char_end: 127
- statement: The pipeline ingests local documents from a specified folder.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - pipeline
  - ingests
  - local
  - documents
  - specified
  - folder
  source:
    doc: motherduck.com/blog/ducklake-motherduck.md
    quote: The pipeline below ingests local documents (PDFs) from a specified folder.
    char_start: 0
    char_end: 74
- statement: The prompt() function enables the transformation of unstructured data
    into structured data.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - prompt
  - function
  - enables
  - transformation
  - unstructured
  - data
  - structured
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: The new prompt() function enables the transformation of unstructured data
      sitting in a data warehouse into structured data that can be easily analyzed.
    char_start: 0
    char_end: 151
- statement: The Python script extracts data from a source system and loads it to
    an S3 bucket.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - python
  - script
  - extracts
  - data
  - source
  - system
  - loads
  - s3
  - bucket
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-three.md
    quote: the Python script below does just that — it extracts data from a source
      system and loads it to an S3 bucket
    char_start: 0
    char_end: 107
- statement: The research and implementation of this architecture has been a collaboration
    between MotherDuck, DuckDB Labs and Peter Boncz.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - research
  - implementation
  - architecture
  - collaboration
  - motherduck
  - duckdb
  - labs
  - peter
  - boncz
  source:
    doc: motherduck.com/blog/announcing-motherduck-general-availability-data-warehousing-with-duckdb.md
    quote: The research and implementation of this architecture has been a collaboration
      between MotherDuck, DuckDB Labs and myself as a visiting database researcher.
    char_start: 0
    char_end: 155
- statement: The Shift Left approach enhances the ability to utilize MySQL data effectively
    in MotherDuck.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - shift
  - left
  - approach
  - enhances
  - ability
  - utilize
  - mysql
  - data
  - effectively
  - motherduck
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part2.md
    quote: How does embracing a Shift Left approach specifically enhance our SaaS
      company's ability to utilize its MySQL data effectively in MotherDuck?
    char_start: 0
    char_end: 141
- statement: The smallest Ducklings, called Pulses, are used by the CEO to understand
    business operations.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - smallest
  - ducklings
  - called
  - pulses
  - used
  - ceo
  - understand
  - business
  - operations
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: our CEO, Jordan, is able to use the smallest Ducklings, called Pulses to
      understand what is going on in the business every day.
    char_start: 0
    char_end: 127
- statement: The storage buckets in this scenario will continue to be owned and managed
    by MotherDuck.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - storage
  - buckets
  - scenario
  - continue
  - owned
  - managed
  - motherduck
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: Although the storage buckets in this scenario will continue to be owned
      and managed by MotherDuck.
    char_start: 0
    char_end: 98
- statement: The support from MotherDuck's team proved crucial during implementation.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - support
  - motherduck
  - team
  - proved
  - crucial
  - implementation
  source:
    doc: motherduck.com/case-studies/trunkrs-same-day-delivery-motherduck-from-redshift.md
    quote: The support from MotherDuck's team proved crucial during implementation.
    char_start: 0
    char_end: 72
- statement: The team building MotherDuck hails from some of the top companies in
    data.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - team
  - building
  - motherduck
  - hails
  - top
  - companies
  - data
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: The team building MotherDuck hails from some of the top companies in data.
    char_start: 0
    char_end: 74
- statement: The team was particularly impressed by video tutorials on getting started
    with dbt and MotherDuck.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - team
  - particularly
  - impressed
  - video
  - tutorials
  - getting
  - started
  - dbt
  - motherduck
  source:
    doc: motherduck.com/case-studies/layers-multi-tenant-data-warehouse.md
    quote: The team was particularly impressed by video tutorials on getting started
      with dbt and MotherDuck.
    char_start: 0
    char_end: 98
- statement: The total cost of ownership (TCO) was significantly lower.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - total
  - cost
  - ownership
  - tco
  - significantly
  - lower
  source:
    doc: motherduck.com/ecosystem.md
    quote: the total cost of ownership (TCO) was significantly lower.
    char_start: 0
    char_end: 58
- statement: The user experience of MotherDuck is straightforward enough for non-technical
    users.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - user
  - experience
  - motherduck
  - straightforward
  - enough
  - non
  - technical
  - users
  source:
    doc: motherduck.com/blog/MotherDuck-Visualize-Embeddings-Marimo.md
    quote: The user experience is so straightforward that even our non-technical team
      members have organically started to use the product.
    char_start: 0
    char_end: 127
- statement: The workflow can be executed both locally and remotely.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - workflow
  - executed
  - both
  - locally
  - remotely
  source:
    doc: motherduck.com/blog/git-for-data-part-1.md
    quote: ~ union run motherduck_wf.py wf
    char_start: 0
    char_end: 31
- statement: The workflow can run automatically whenever new data is generated.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - workflow
  - run
  - automatically
  - whenever
  - new
  - data
  - generated
  source:
    doc: motherduck.com/blog/solving-advent-code-duckdb-dbt.md
    quote: We can use Artifacts and Launch Plans to have the workflow run automatically
      whenever new data is generated.
    char_start: 0
    char_end: 108
- statement: These compute instances individually scale up to handle workloads of
    many terabytes for some of our customers.
  type: feature
  entity: MotherDuck
  keywords:
  - feature
  - compute
  - instances
  - individually
  - scale
  - up
  - handle
  - workloads
  - many
  - terabytes
  - customers
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: These compute instances individually scale up to handle workloads of many
      terabytes for some of our customers.
    char_start: 0
    char_end: 110
- statement: This approach is particularly valuable for processing thousands of free
    text reviews.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - approach
  - particularly
  - valuable
  - processing
  - thousands
  - free
  - text
  - reviews
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: This approach is particularly valuable for processing thousands of free
      text reviews with varying attributes.
    char_start: 0
    char_end: 109
- statement: This includes setting up role-based access controls, identifying and
    tagging personally identifiable information (PII), and ensuring all data assets
    comply with governance standards.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - includes
  - setting
  - up
  - role
  - based
  - access
  - controls
  - identifying
  - tagging
  - personally
  - identifiable
  - information
  - pii
  - ensuring
  - data
  - assets
  - comply
  - governance
  - standards
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: This includes setting up role-based access controls, identifying and tagging
      personally identifiable information (PII), and ensuring all data assets comply
      with governance standards.
    char_start: 0
    char_end: 182
- statement: Time travel features are on MotherDuck’s near-term roadmap.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - time
  - travel
  - features
  - motherduck
  - near
  - term
  - roadmap
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: Stay tuned, as time travel features are on MotherDuck’s near-term roadmap!
    char_start: 0
    char_end: 74
- statement: To allow for your DuckDB queries to now access MotherDuck, you just need
    to specify the MotherDuck DuckDBProvider.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - allow
  - duckdb
  - queries
  - now
  - access
  - motherduck
  - need
  - specify
  - duckdbprovider
  source:
    doc: motherduck.com/blog/git-for-data-part-1.md
    quote: To allow for your DuckDB queries to now access MotherDuck, you just need
      to specify the MotherDuck DuckDBProvider.
    char_start: 0
    char_end: 114
- statement: To connect to MotherDuck is like installing another DuckDB extension.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - connect
  - motherduck
  - like
  - installing
  - another
  - duckdb
  - extension
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: To connect to MotherDuck is like installing another DuckDB extension.
    char_start: 0
    char_end: 69
- statement: Use MotherDuck to power your Tableau Cloud, Server, and Desktop dashboards.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - use
  - motherduck
  - power
  - tableau
  - cloud
  - server
  - desktop
  - dashboards
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: Use MotherDuck to power your Tableau Cloud, Server, and Desktop dashboards.
    char_start: 0
    char_end: 75
- statement: Users can select the database they want to develop an app on from a dropdown
    menu.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - users
  - select
  - database
  - want
  - develop
  - app
  - dropdown
  - menu
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md
    quote: Users can select the database they want to develop an app on from a dropdown
      menu.
    char_start: 0
    char_end: 82
- statement: Users in your MotherDuck organization can analyze data, build machine
    learning models and more with the same shared dataset.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - users
  - motherduck
  - organization
  - analyze
  - data
  - build
  - machine
  - learning
  - models
  - shared
  - dataset
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: Now all the users in your MotherDuck organization can analyze data, build
      machine learning models and more with the same shared dataset.
    char_start: 0
    char_end: 136
- statement: Using MotherDuck reduces network latency when accessing S3 data.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - using
  - motherduck
  - reduces
  - network
  - latency
  - accessing
  - s3
  - data
  source:
    doc: motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md
    quote: You can avoid some of the network latency from your local machine to wherever
      your S3 sits by using MotherDuck.
    char_start: 0
    char_end: 111
- statement: Valentina has added support for MotherDuck in their Valentina Studio
    product.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - valentina
  - added
  - support
  - motherduck
  - studio
  - product
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: They have recently added support in their Valentina Studio product to allow
      users to seamlessly connect to MotherDuck.
    char_start: 0
    char_end: 118
- statement: Violating this policy may result in suspension or termination of your
    account.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - violating
  - policy
  - result
  - suspension
  - termination
  - account
  source:
    doc: motherduck.com/blog/data-engineers-answer-10-top-reddit-questions.md
    quote: Violating this policy may result in suspension or termination of your account.
    char_start: 0
    char_end: 78
- statement: We are now SOC 2 certified.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - now
  - soc
  - certified
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: We know that trust and security are critical as you choose a data warehouse
      to power your business.
    char_start: 0
    char_end: 99
- statement: You agree to use MotherDuck's services for lawful purposes only.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - agree
  - use
  - motherduck
  - services
  - lawful
  - purposes
  source:
    doc: motherduck.com/blog/data-engineers-answer-10-top-reddit-questions.md
    quote: You agree to use MotherDuck's services for lawful purposes only.
    char_start: 0
    char_end: 64
- statement: You can connect to MotherDuck using your MotherDuck token.
  type: instruction
  entity: MotherDuck
  keywords:
  - instruction
  - connect
  - motherduck
  - using
  - token
  source:
    doc: motherduck.com/blog/just-enough-sql-for-ai.md
    quote: You can connect to MotherDuck using your MotherDuck token.
    char_start: 0
    char_end: 58
- statement: You can create new databases, specifying the blobstore to use to store
    the database.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - create
  - new
  - databases
  - specifying
  - blobstore
  - use
  - store
  - database
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: Simply configure a SECRET in MotherDuck to specify permissions for that
      blobstore, and then you can create new databases, specifying the blobstore to
      use to store the database.
    char_start: 0
    char_end: 176
- statement: You can securely store your MotherDuck authentication token on Union
    as a secret.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - securely
  - store
  - motherduck
  - authentication
  - token
  - union
  - secret
  source:
    doc: motherduck.com/blog/git-for-data-part-1.md
    quote: Securely store your MotherDuck authentication token on Union as a secret.
    char_start: 0
    char_end: 73
- statement: You need a MotherDuck account with your service token.
  type: requirement
  entity: MotherDuck
  keywords:
  - requirement
  - need
  - motherduck
  - account
  - service
  - token
  source:
    doc: motherduck.com/blog/vibe-coding-sql-cursor.md
    quote: A MotherDuck account ( [sign up for free](https://app.motherduck.com/?auth_flow=signup))
      with your service token.
    char_start: 0
    char_end: 113
- statement: You should now have data in MotherDuck.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - now
  - data
  - motherduck
  source:
    doc: motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md
    quote: You should now have data in [MotherDuck](https://app.motherduck.com/).
    char_start: 0
    char_end: 70
- statement: Your analytical queries on data in MotherDuck will also be much faster
    than if the data is stored in regular PostgreSQL tables.
  type: definition
  entity: MotherDuck
  keywords:
  - definition
  - analytical
  - queries
  - data
  - motherduck
  - also
  - much
  - faster
  - stored
  - regular
  - postgresql
  - tables
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: Your analytical queries on data in MotherDuck will also be much faster
      than if the data is stored in regular PostgreSQL tables.
    char_start: 0
    char_end: 127
- statement: MotherDuck Notebook is a closed-source notebook for data analysis.
  type: definition
  entity: MotherDuck Notebook
  keywords:
  - definition
  - motherduck
  - notebook
  - closed
  - source
  - data
  - analysis
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: 'MotherDuck Notebook: Closed-source notebook for data analysis.'
    char_start: 0
    char_end: 62
- statement: The MotherDuck Wasm SDK introduces game-changing performance and developer
    ergonomics for data applications.
  type: definition
  entity: MotherDuck Wasm SDK
  keywords:
  - definition
  - motherduck
  - wasm
  - sdk
  - introduces
  - game
  - changing
  - performance
  - developer
  - ergonomics
  - data
  - applications
  source:
    doc: motherduck.com/blog/announcing-duckdb-141-motherduck.md
    quote: The MotherDuck Wasm SDK introduces game-changing performance and developer
      ergonomics for data applications.
    char_start: 0
    char_end: 108
- statement: The SDK allows clients to use SQL for data analytics.
  type: definition
  entity: MotherDuck Wasm SDK
  keywords:
  - definition
  - sdk
  - allows
  - clients
  - use
  - sql
  - data
  - analytics
  source:
    doc: motherduck.com/blog/announcing-duckdb-141-motherduck.md
    quote: 'Just install the SDK, and suddenly your client speaks the lingua franca
      of analytics: SQL.'
    char_start: 0
    char_end: 90
- statement: Expect pints aplenty and flocking-fun game.
  type: definition
  entity: MotherDuck'ing Big Data London Party
  keywords:
  - definition
  - expect
  - pints
  - aplenty
  - flocking
  - fun
  - game
  source:
    doc: motherduck.com/blog/from-data-lake-to-lakehouse-duckdb-portable-catalog.md
    quote: Expect pints aplenty and flocking-fun game.
    char_start: 0
    char_end: 43
- statement: A motherduck_token is needed to connect to MotherDuck.
  type: definition
  entity: motherduck_token
  keywords:
  - definition
  - motherduck
  - token
  - needed
  - connect
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-2.md
    quote: Once you have an account you get a motherduck_token, which you need to
      connect to MotherDuck.
    char_start: 0
    char_end: 93
- statement: The movies dataset is searchable using Full Text Search.
  type: definition
  entity: movies dataset
  keywords:
  - definition
  - movies
  - dataset
  - searchable
  - using
  - full
  - text
  - search
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md
    quote: The movies dataset is searchable using Full Text Search.
    char_start: 0
    char_end: 56
- statement: Myoung Kang has joined the company full-time as Head of Operations.
  type: definition
  entity: Myoung Kang
  keywords:
  - definition
  - myoung
  - kang
  - joined
  - company
  - full
  - time
  - head
  - operations
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: Myoung Kang has joined the company full-time as Head of Operations.
    char_start: 0
    char_end: 67
- statement: Build real-time MySQL to MotherDuck pipelines with Streamkap.
  type: definition
  entity: MySQL
  keywords:
  - definition
  - build
  - real
  - time
  - mysql
  - motherduck
  - pipelines
  - streamkap
  source:
    doc: motherduck.com/blog/spark-ducklake-getting-started.md
    quote: Build real-time MySQL to MotherDuck pipelines with Streamkap.
    char_start: 0
    char_end: 61
- statement: Early detection of schema drift is a key advantage of the Shift Left
    approach.
  type: definition
  entity: MySQL
  keywords:
  - definition
  - early
  - detection
  - schema
  - drift
  - key
  - advantage
  - shift
  - left
  - approach
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part2.md
    quote: 'Early Detection of Schema Drift: MySQL schemas are dynamic...'
    char_start: 0
    char_end: 61
- statement: MySQL and BigQuery can be integrated for data transfer.
  type: definition
  entity: MySQL
  keywords:
  - definition
  - mysql
  - bigquery
  - integrated
  - data
  - transfer
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-2.md
    quote: Moving data between MySQL and BigQuery
    char_start: 0
    char_end: 38
- statement: MySQL integrates with HeatWave for vector storage.
  type: definition
  entity: MySQL
  keywords:
  - definition
  - mysql
  - integrates
  - heatwave
  - vector
  - storage
  source:
    doc: motherduck.com/learn-more/data-warehouse-tco.md
    quote: MySQL integrates with HeatWave for vector storage.
    char_start: 0
    char_end: 50
- statement: Rob's first steps involved creating a MySQL replica for analytics.
  type: definition
  entity: MySQL
  keywords:
  - definition
  - rob
  - first
  - steps
  - involved
  - creating
  - mysql
  - replica
  - analytics
  source:
    doc: motherduck.com/learn-more/duckdb-struct-nested-data.md
    quote: Rob's first steps involved creating a MySQL replica for analytics.
    char_start: 0
    char_end: 66
- statement: Streaming data directly from MySQL to MotherDuck ensures users see up-to-date
    insights.
  type: definition
  entity: MySQL
  keywords:
  - definition
  - streaming
  - data
  - directly
  - mysql
  - motherduck
  - ensures
  - users
  - see
  - up
  - date
  - insights
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: By streaming data directly from MySQL to MotherDuck, the company ensures
      its users always see up-to-date insights.
    char_start: 0
    char_end: 114
- statement: Named Windows are used for query optimization.
  type: definition
  entity: Named Windows
  keywords:
  - definition
  - named
  - windows
  - used
  - query
  - optimization
  source:
    doc: motherduck.com/blog/preswald-health-data-analysis.md
    quote: Named Windows for query optimization
    char_start: 0
    char_end: 36
- statement: Nano is recommended for editing files.
  type: definition
  entity: Nano
  keywords:
  - definition
  - nano
  - recommended
  - editing
  - files
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: Recommended is Nano, which displays the shortcuts to save or exit.
    char_start: 0
    char_end: 66
- statement: nao is an AI-enhanced editor specifically for data engineers.
  type: definition
  entity: nao
  keywords:
  - definition
  - nao
  - ai
  - enhanced
  - editor
  - specifically
  - data
  - engineers
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: An AI-enhanced editor specifically for data engineers.
    char_start: 0
    char_end: 54
- statement: Nathan Hamm took on the initiative to explore more robust data solutions.
  type: definition
  entity: Nathan Hamm
  keywords:
  - definition
  - nathan
  - hamm
  - took
  - initiative
  - explore
  - robust
  - data
  - solutions
  source:
    doc: motherduck.com/case-studies/layers-multi-tenant-data-warehouse.md
    quote: '''This was a great project to dip my toes in, and MotherDuck provided
      an accessible yet powerful platform to get started quickly.'''
    char_start: 0
    char_end: 129
- statement: Natural language processing (NLP) is an interdisciplinary subfield of
    computer science and information retrieval.
  type: definition
  entity: Natural Language Processing (NLP)
  keywords:
  - definition
  - natural
  - language
  - processing
  - nlp
  - interdisciplinary
  - subfield
  - computer
  - science
  - information
  - retrieval
  source:
    doc: motherduck.com/blog/building-motherduck-partner-ecosystem.md
    quote: Natural language processing (NLP) is an interdisciplinary subfield of computer
      science and information retrieval.
    char_start: 0
    char_end: 113
- statement: AI-powered Natural Language-to-SQL technology allows users to ask questions
    in plain English.
  type: definition
  entity: Natural Language-to-SQL
  keywords:
  - definition
  - ai
  - powered
  - natural
  - language
  - sql
  - technology
  - allows
  - users
  - ask
  - questions
  - plain
  - english
  source:
    doc: motherduck.com/learn-more/self-service-analytics-startups.md
    quote: The most transformative trend is the rise of AI-powered Natural Language-to-SQL
      (NL-to-SQL).
    char_start: 0
    char_end: 92
- statement: Effective strategies include providing intuitive tools with features
    like Natural Language-to-SQL.
  type: definition
  entity: Natural Language-to-SQL
  keywords:
  - definition
  - effective
  - strategies
  - include
  - providing
  - intuitive
  - tools
  - features
  - like
  - natural
  - language
  - sql
  source:
    doc: motherduck.com/videos/simple-way-to-convert-csv-and-parquet-files.md
    quote: Effective strategies include providing intuitive tools with features like
      Natural Language-to-SQL (NL-to-SQL)...
    char_start: 0
    char_end: 112
- statement: Neon provides insights on running DuckDB within Postgres.
  type: definition
  entity: Neon
  keywords:
  - definition
  - neon
  - provides
  - insights
  - running
  - duckdb
  - within
  - postgres
  source:
    doc: motherduck.com/blog/perf-is-not-enough.md
    quote: Neon has been building serverless managed Postgres and is lending experience
      about what will run well in production and how to make DuckDB work with Postgres
      Storage.
    char_start: 0
    char_end: 166
- statement: Neovim is used by 12.5% of developers.
  type: definition
  entity: Neovim
  keywords:
  - definition
  - neovim
  - used
  - '12.5'
  - developers
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: Neovim (12.5%)
    char_start: 0
    char_end: 14
- statement: Net Promoter Score (NPS) measures customer loyalty and satisfaction.
  type: definition
  entity: Net Promoter Score
  keywords:
  - definition
  - net
  - promoter
  - score
  - nps
  - measures
  - customer
  - loyalty
  - satisfaction
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: Net Promoter Score (NPS)
    char_start: 0
    char_end: 24
- statement: Net Promoter Score measures customer loyalty and satisfaction based on
    a single question.
  type: definition
  entity: Net Promoter Score
  keywords:
  - definition
  - net
  - promoter
  - score
  - measures
  - customer
  - loyalty
  - satisfaction
  - based
  - single
  - question
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-use-cases.md
    quote: Measures customer loyalty and satisfaction based on a single question.
    char_start: 0
    char_end: 70
- statement: Netflix data is analyzed using DuckDB.
  type: definition
  entity: Netflix
  keywords:
  - definition
  - netflix
  - data
  - analyzed
  - using
  - duckdb
  source:
    doc: motherduck.com/blog/pgduckdb-beta-release-duckdb-postgres.md
    quote: Netflix data is analyzed using DuckDB.
    char_start: 0
    char_end: 38
- statement: Network Logs track data movement across systems.
  type: definition
  entity: Network Logs
  keywords:
  - definition
  - network
  - logs
  - track
  - data
  - movement
  - across
  - systems
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: 'Network Logs: Track data movement across systems.'
    char_start: 0
    char_end: 49
- statement: The New South Wales Department of Education features DuckDB in their
    new data portal.
  type: definition
  entity: New South Wales Department of Education
  keywords:
  - definition
  - new
  - south
  - wales
  - department
  - education
  - features
  - duckdb
  - data
  - portal
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: Another exciting one is by the New South Wales Department of Education,
      which features DuckDB, Dagster, dbt, dlt, and Evidence to power their new data
      portal.
    char_start: 0
    char_end: 158
- statement: ngrok creates a secure tunnel allowing AirByte to access my locally-hosted
    simulation API.
  type: definition
  entity: Ngrok
  keywords:
  - definition
  - ngrok
  - creates
  - secure
  - tunnel
  - allowing
  - airbyte
  - access
  - my
  - locally
  - hosted
  - simulation
  - api
  source:
    doc: motherduck.com/blog/simplifying-iot-analytics-motherduck.md
    quote: I used ngrok to create a secure tunnel allowing AirByte (running in the
      cloud) to access my locally-hosted simulation API.
    char_start: 0
    char_end: 122
- statement: Niño Francisco Liwa used DuckDB in an IoT platform project.
  type: definition
  entity: Niño Francisco Liwa
  keywords:
  - definition
  - ni
  - francisco
  - liwa
  - used
  - duckdb
  - iot
  - platform
  - project
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md
    quote: A good example of a end-to-end project done by Niño Francisco Liwa using
      DuckDB.
    char_start: 0
    char_end: 80
- statement: A modern, 'No-ETL' approach allows you to query raw data files directly.
  type: definition
  entity: No-ETL
  keywords:
  - definition
  - modern
  - etl
  - approach
  - allows
  - query
  - raw
  - data
  - files
  - directly
  source:
    doc: motherduck.com/learn-more/ducklake-guide.md
    quote: A modern, 'No-ETL' approach allows you to do just that.
    char_start: 0
    char_end: 55
- statement: The 'No-ETL' approach is a better starting point for most startups.
  type: definition
  entity: No-ETL
  keywords:
  - definition
  - etl
  - approach
  - better
  - starting
  - point
  - startups
  source:
    doc: motherduck.com/learn-more/hybrid-analytics-guide.md
    quote: For a lean team, building a full-blown ETL pipeline too early is a strategic
      error.
    char_start: 0
    char_end: 83
- statement: Noa Tamir covers the story about the confusion of data roles.
  type: definition
  entity: Noa Tamir
  keywords:
  - definition
  - noa
  - tamir
  - covers
  - story
  - about
  - confusion
  - data
  - roles
  source:
    doc: motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw.md
    quote: In this talk, Noa Tamir covers the story about the confusion of data roles.
    char_start: 0
    char_end: 75
- statement: Evidence can be set up using Node.js.
  type: definition
  entity: Node.js
  keywords:
  - definition
  - evidence
  - set
  - up
  - using
  - node
  - js
  source:
    doc: motherduck.com/blog/unstructured-analysis-tensorlake-motherduck.md
    quote: You can do this either by using Node.js and `degit` package.
    char_start: 0
    char_end: 60
- statement: Node.js and DuckDB can be used to analyze X data.
  type: definition
  entity: Node.js
  keywords:
  - definition
  - node
  - js
  - duckdb
  - used
  - analyze
  - data
  source:
    doc: motherduck.com/blog/data-app-generator.md
    quote: And, while the archive includes a 'readme' document that describes the
      data, the data itself is not in a format you can easily query and analyze. Node.js
      and DuckDB to the rescue!
    char_start: 0
    char_end: 179
- statement: Node.js is a JavaScript runtime built on Chrome's V8 JavaScript engine.
  type: definition
  entity: Node.js
  keywords:
  - definition
  - node
  - js
  - javascript
  - runtime
  - built
  - chrome
  - v8
  - engine
  source:
    doc: motherduck.com/blog/data-app-generator.md
    quote: Node.js is a JavaScript runtime built on Chrome's V8 JavaScript engine.
    char_start: 0
    char_end: 71
- statement: Node.js is a minimal software development framework based on the JavaScript
    language.
  type: definition
  entity: Node.js
  keywords:
  - definition
  - node
  - js
  - minimal
  - software
  - development
  - framework
  - based
  - javascript
  - language
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: Node.js is a minimal software development framework based on the JavaScript
      language.
    char_start: 0
    char_end: 85
- statement: Node.js is a powerful software development environment that uses JavaScript.
  type: definition
  entity: Node.js
  keywords:
  - definition
  - node
  - js
  - powerful
  - software
  - development
  - environment
  - uses
  - javascript
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: Node.js is a powerful software development environment that uses JavaScript
      for building all kinds of applications.
    char_start: 0
    char_end: 115
- statement: Node.js is used to convert tweets to a CSV file.
  type: definition
  entity: Node.js
  keywords:
  - definition
  - node
  - js
  - used
  - convert
  - tweets
  - csv
  - file
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-essential-tools.md
    quote: If everything is set up correctly, your tweets archive will be converted
      to a CSV file.
    char_start: 0
    char_end: 87
- statement: Many NoSQL databases now offer ACID guarantees for operations within
    a single document or record.
  type: definition
  entity: NoSQL
  keywords:
  - definition
  - many
  - nosql
  - databases
  - now
  - offer
  - acid
  - guarantees
  - operations
  - within
  - single
  - document
  - record
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: Many NoSQL databases now offer ACID guarantees for operations within a
      single document or record.
    char_start: 0
    char_end: 97
- statement: Several modern NoSQL systems support multi-document ACID transactions.
  type: definition
  entity: NoSQL
  keywords:
  - definition
  - several
  - modern
  - nosql
  - systems
  - support
  - multi
  - document
  - acid
  - transactions
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: Several modern NoSQL systems (MongoDB, RavenDB, FaunaDB, certain DynamoDB
      configurations) support multi-document ACID transactions.
    char_start: 0
    char_end: 131
- statement: Notepad++ is used by 23.9% of developers.
  type: definition
  entity: Notepad++
  keywords:
  - definition
  - notepad
  - used
  - '23.9'
  - developers
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: Notepad++ (23.9%)
    char_start: 0
    char_end: 17
- statement: The feature 'notifications' is used by 354 distinct users.
  type: definition
  entity: notifications
  keywords:
  - definition
  - feature
  - notifications
  - used
  - '354'
  - distinct
  - users
  source:
    doc: motherduck.com/learn-more/pandas-dataframes-guide.md
    quote: '354'
    char_start: 0
    char_end: 3
- statement: If you have your local server running (`npm run dev`), you should see
    your big value chart when visiting `localhost:3000`.
  type: definition
  entity: npm
  keywords:
  - definition
  - local
  - server
  - running
  - npm
  - run
  - dev
  - see
  - big
  - value
  - chart
  - visiting
  - localhost
  - '3000'
  source:
    doc: motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud.md
    quote: If you have your local server running (`npm run dev`), you should see your
      big value chart when visiting `localhost:3000`.
    char_start: 0
    char_end: 122
- statement: The ntile() Function is used for data distribution.
  type: definition
  entity: ntile() Function
  keywords:
  - definition
  - ntile
  - function
  - used
  - data
  - distribution
  source:
    doc: motherduck.com/blog/preswald-health-data-analysis.md
    quote: The ntile() Function for data distribution
    char_start: 0
    char_end: 42
- statement: A Broadcast Join is used when one table is small.
  type: definition
  entity: null_padding
  keywords:
  - definition
  - broadcast
  - join
  - used
  - one
  - table
  - small
  source:
    doc: motherduck.com/case-studies/finqore.md
    quote: A Broadcast Join is used when one table is small (e.g., under a 10 MB default
      in Spark).
    char_start: 0
    char_end: 88
- statement: A Python script can automate the extraction of the schema from DuckDB.
  type: definition
  entity: null_padding
  keywords:
  - definition
  - python
  - script
  - automate
  - extraction
  - schema
  - duckdb
  source:
    doc: motherduck.com/glossary/ETL.md
    quote: We can automate this with a simple Python script that connects to our local
      DuckDB file, extracts the schema, and saves it as an XML file.
    char_start: 0
    char_end: 138
- statement: CDC is a great way to keep track of your changing data.
  type: definition
  entity: null_padding
  keywords:
  - definition
  - cdc
  - great
  - way
  - keep
  - track
  - changing
  - data
  source:
    doc: motherduck.com/ecosystem/dagster.md
    quote: Whether your data starts out in Oracle, PostgreSQL, or another database,
      CDC is a great way to keep track of your changing data.
    char_start: 0
    char_end: 128
- statement: Corail Analytics is your partner for driving transformation towards a
    more data-driven organization.
  type: definition
  entity: null_padding
  keywords:
  - definition
  - corail
  - analytics
  - partner
  - driving
  - transformation
  - towards
  - data
  - driven
  - organization
  source:
    doc: motherduck.com/glossary/Apache Arrow.md
    quote: Nous sommes votre partenaire pour conduire la transformation vers une organisation
      plus data-driven.
    char_start: 0
    char_end: 100
- statement: Snowflake and BigQuery can scale out compute to handle massive batch
    reporting workloads.
  type: performance
  entity: null_padding
  keywords:
  - performance
  - snowflake
  - bigquery
  - scale
  - out
  - compute
  - handle
  - massive
  - batch
  - reporting
  - workloads
  source:
    doc: motherduck.com/ecosystem/artie.md
    quote: MPP Warehouse (Snowflake, BigQuery)Can scale out compute to handle massive
      batch reporting workloads.
    char_start: 0
    char_end: 101
- statement: The introduction of Apache Spark marked a milestone in big data processing.
  type: definition
  entity: null_padding
  keywords:
  - definition
  - introduction
  - apache
  - spark
  - marked
  - milestone
  - big
  - data
  - processing
  source:
    doc: motherduck.com/glossary/CLI.md
    quote: The introduction of Apache Spark from UC Berkeley marked another milestone.
    char_start: 0
    char_end: 75
- statement: The NYC taxi dataset can be queried using SQL.
  type: definition
  entity: NYC Taxi Dataset
  keywords:
  - definition
  - nyc
  - taxi
  - dataset
  - queried
  - using
  - sql
  source:
    doc: motherduck.com/blog/scaling-duckdb-with-ducklings.md
    quote: we'll use the yellow taxi trip data in the sample_data database.
    char_start: 0
    char_end: 64
- statement: The NYC Taxi Dataset is available via HTTPS.
  type: definition
  entity: NYC Taxi Dataset
  keywords:
  - definition
  - nyc
  - taxi
  - dataset
  - available
  - via
  - https
  source:
    doc: motherduck.com/blog/pushing-geo-boundaries-with-motherduck-geobase.md
    quote: they have a lookup table for pickups and lots of data we can use, and it
      is available via HTTPS.
    char_start: 0
    char_end: 96
- statement: The generated PNG visualizes NYC taxi trip volume by borough.
  type: definition
  entity: NYC Taxi Trip Volume
  keywords:
  - definition
  - generated
  - png
  - visualizes
  - nyc
  - taxi
  - trip
  - volume
  - borough
  source:
    doc: motherduck.com/blog/semantic-layer-duckdb-tutorial.md
    quote: 'The generated PNG looks like this: ![image](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_sem_71b5372e80.png&w=3840&q=75)'
    char_start: 0
    char_end: 192
- statement: Observable is a platform for real-time collaboration on data visualizations.
  type: feature
  entity: Observable
  keywords:
  - feature
  - observable
  - platform
  - real
  - time
  - collaboration
  - data
  - visualizations
  source:
    doc: motherduck.com/videos/taming-file-zoos-data-science-with-duckdb-database-files.md
    quote: Observable is a platform for real-time collaboration on data visualizations.
    char_start: 0
    char_end: 76
- statement: Octopus Deploy is an advanced deployment automation platform for complex
    multi-environment releases with approval workflows.
  type: definition
  entity: Octopus Deploy
  keywords:
  - definition
  - octopus
  - deploy
  - advanced
  - deployment
  - automation
  - platform
  - complex
  - multi
  - environment
  - releases
  - approval
  - workflows
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: Advanced deployment automation platform for complex multi-environment releases
      with approval workflows
    char_start: 0
    char_end: 102
- statement: Full 1:1 data copying is the least efficient but simplest approach.
  type: definition
  entity: ODBC
  keywords:
  - definition
  - full
  - data
  - copying
  - least
  - efficient
  - simplest
  - approach
  source:
    doc: motherduck.com/blog/git-for-data-part-1.md
    quote: The least efficient but simplest approach is full 1:1 data copying.
    char_start: 0
    char_end: 67
- statement: Okapi bm25 is used as a scoring function in Full Text Search.
  type: definition
  entity: Okapi BM25
  keywords:
  - definition
  - okapi
  - bm25
  - used
  - scoring
  - function
  - full
  - text
  - search
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md
    quote: Okapi bm25 is used as a scoring function in Full Text Search.
    char_start: 0
    char_end: 61
- statement: The Okapi BM25 scoring function is used to rank documents based on keyword
    relevance.
  type: definition
  entity: Okapi BM25
  keywords:
  - definition
  - okapi
  - bm25
  - scoring
  - function
  - used
  - rank
  - documents
  - based
  - keyword
  - relevance
  source:
    doc: motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md
    quote: The FTS extension implements the Okapi BM25 scoring function which scores
      a document based on the keyword terms appearing in each document.
    char_start: 0
    char_end: 139
- statement: Okta manages a security-focused data platform.
  type: definition
  entity: Okta
  keywords:
  - definition
  - okta
  - manages
  - security
  - focused
  - data
  - platform
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: Okta manages a security-focused data platform to efficiently manage high-volume
      secure data.
    char_start: 0
    char_end: 92
- statement: Okta processed 7.5 trillion records across 130 million files using DuckDB.
  type: definition
  entity: Okta
  keywords:
  - definition
  - okta
  - processed
  - '7.5'
  - trillion
  - records
  - across
  - '130'
  - million
  - files
  - using
  - duckdb
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: In six months, their defensive cyber operations team processed 7.5 trillion
      records across 130 million files using thousands of concurrent DuckDB instances.
    char_start: 0
    char_end: 156
- statement: Analytical queries are a completely different beast.
  type: definition
  entity: OLAP
  keywords:
  - definition
  - analytical
  - queries
  - completely
  - different
  - beast
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: Analytical queries are a completely different beast.
    char_start: 0
    char_end: 52
- statement: OLAP databases are designed for querying and analyzing large datasets.
  type: definition
  entity: OLAP
  keywords:
  - definition
  - olap
  - databases
  - designed
  - querying
  - analyzing
  - large
  - datasets
  source:
    doc: motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md
    quote: Analytical databases, or OLAP (Online Analytical Processing) databases,
      are designed for querying and analyzing large datasets.
    char_start: 0
    char_end: 127
- statement: OLAP enables analysts to gain insight into data through fast, consistent,
    interactive access.
  type: definition
  entity: OLAP
  keywords:
  - definition
  - olap
  - enables
  - analysts
  - gain
  - insight
  - data
  - fast
  - consistent
  - interactive
  - access
  source:
    doc: motherduck.com/blog/vibe-coding-sql-cursor.md
    quote: Online Analytical Processing - a category of software technology that enables
      analysts, managers, and executives to gain insight into data through fast, consistent,
      interactive access.
    char_start: 0
    char_end: 184
- statement: OLAP supports complex data analysis.
  type: definition
  entity: OLAP
  keywords:
  - definition
  - olap
  - supports
  - complex
  - data
  - analysis
  source:
    doc: motherduck.com/blog/why-web-developers-should-care-about-analytical-databases.md
    quote: Learn what OLAP (Online Analytical Processing) is and how it supports complex
      data analysis.
    char_start: 0
    char_end: 92
- statement: OLAP systems utilize multidimensional data structures, known as OLAP
    cubes, to organize and analyze data.
  type: definition
  entity: OLAP
  keywords:
  - definition
  - olap
  - systems
  - utilize
  - multidimensional
  - data
  - structures
  - known
  - cubes
  - organize
  - analyze
  source:
    doc: motherduck.com/videos/duckdb-run-dbt-build-with-sub-second-execution-times.md
    quote: OLAP systems utilize multidimensional data structures, known as OLAP cubes,
      to organize and analyze data.
    char_start: 0
    char_end: 105
- statement: Traditional OLAP databases once handled analytical data storage.
  type: definition
  entity: OLAP
  keywords:
  - definition
  - traditional
  - olap
  - databases
  - handled
  - analytical
  - data
  - storage
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: Traditional OLAP databases once handled analytical data storage.
    char_start: 0
    char_end: 64
- statement: Ollama is a simple API for creating, running, and managing models.
  type: definition
  entity: Ollama
  keywords:
  - definition
  - ollama
  - simple
  - api
  - creating
  - running
  - managing
  - models
  source:
    doc: motherduck.com/blog/log-processing-savings-bacalhau-motherduck.md
    quote: and Ollama, a simple API for creating, running, and managing models.
    char_start: 0
    char_end: 68
- statement: Ollama lets you run language models on your system.
  type: definition
  entity: Ollama
  keywords:
  - definition
  - ollama
  - lets
  - run
  - language
  - models
  - system
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2024.md
    quote: One benefit of Ollama is that it lets you run language models on your system.
    char_start: 0
    char_end: 77
- statement: Small AI models can run on consumer-grade laptops and even phones.
  type: definition
  entity: Ollama
  keywords:
  - definition
  - small
  - ai
  - models
  - run
  - consumer
  - grade
  - laptops
  - even
  - phones
  source:
    doc: motherduck.com/blog/duckdb-the-great-federator.md
    quote: These small models only have maybe 0.5 to 70 billion parameters. They are
      only a few gigabytes in size, which means they definitely fit on your laptop
      - heck, they even fit on a phone.
    char_start: 0
    char_end: 184
- statement: OLTP databases are brilliant for handling thousands of small, fast transactions.
  type: definition
  entity: OLTP
  keywords:
  - definition
  - oltp
  - databases
  - brilliant
  - handling
  - thousands
  - small
  - fast
  - transactions
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: OLTP databases are brilliant for handling thousands of small, fast transactions.
    char_start: 0
    char_end: 80
- statement: OLTP is a class of software applications capable of supporting transaction-oriented
    programs.
  type: definition
  entity: OLTP
  keywords:
  - definition
  - oltp
  - class
  - software
  - applications
  - capable
  - supporting
  - transaction
  - oriented
  - programs
  source:
    doc: motherduck.com/blog/vibe-coding-sql-cursor.md
    quote: Online Transaction Processing - a class of software applications capable
      of supporting transaction-oriented programs.
    char_start: 0
    char_end: 117
- statement: Row-oriented storage is inefficient for analytical queries.
  type: definition
  entity: OLTP
  keywords:
  - definition
  - row
  - oriented
  - storage
  - inefficient
  - analytical
  - queries
  source:
    doc: motherduck.com/learn-more/pandas-dataframes-guide.md
    quote: But for an analytical query that only needs to sum the sale_amount column
      across millions of rows, a row-store is forced to read every single column for
      every single row.
    char_start: 0
    char_end: 170
- statement: 'Oluwajuwon Ogunseye announced a challenge called #30DaysofDuckDBChallenge.'
  type: definition
  entity: Oluwajuwon Ogunseye
  keywords:
  - definition
  - oluwajuwon
  - ogunseye
  - announced
  - challenge
  - called
  - 30daysofduckdbchallenge
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md
    quote: 'he announced a challenge called #30DaysofDuckDBChallenge'
    char_start: 0
    char_end: 56
- statement: Omni is a business intelligence platform that helps companies explore
    data.
  type: definition
  entity: Omni (Company)
  keywords:
  - definition
  - omni
  - business
  - intelligence
  - platform
  - helps
  - companies
  - explore
  - data
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: 'Omni: Business intelligence platform that helps companies explore data.'
    char_start: 0
    char_end: 71
- statement: Open Charge Map aims to document the world's Electric Vehicle Charging
    Points.
  type: definition
  entity: Open Charge Map
  keywords:
  - definition
  - open
  - charge
  - map
  - aims
  - document
  - world
  - electric
  - vehicle
  - charging
  - points
  source:
    doc: motherduck.com/blog/simplifying-iot-analytics-motherduck.md
    quote: This website aims to document the world's Electric Vehicle (EV) Charging
      Points.
    char_start: 0
    char_end: 80
- statement: Open Charge Map has produced a dataset of over 200K+ charging point locations
    around the world.
  type: definition
  entity: Open Charge Map
  keywords:
  - definition
  - open
  - charge
  - map
  - produced
  - dataset
  - over
  - 200k
  - charging
  - point
  - locations
  - around
  - world
  source:
    doc: motherduck.com/blog/simplifying-iot-analytics-motherduck.md
    quote: They have produced a dataset of over 200K+ charging point locations around
      the world.
    char_start: 0
    char_end: 85
- statement: The data from Open Charge Map is loaded into the poi_france table.
  type: definition
  entity: Open Charge Map
  keywords:
  - definition
  - data
  - open
  - charge
  - map
  - loaded
  - poi
  - france
  - table
  source:
    doc: motherduck.com/blog/simplifying-iot-analytics-motherduck.md
    quote: Once our data is loaded in the poi_france table...
    char_start: 0
    char_end: 50
- statement: The compute engine is a critical component of the Open Data Platform.
  type: definition
  entity: Open Data Platform
  keywords:
  - definition
  - compute
  - engine
  - critical
  - component
  - open
  - data
  - platform
  source:
    doc: motherduck.com/blog/how-to-extract-analytics-from-bluesky.md
    quote: The compute engine is a critical component, as interchangeable engines
      (such as Spark, DuckDB, Snowflake, etc.) allow you to process and query data
      without being locked into any vendor's ecosystem.
    char_start: 0
    char_end: 197
- statement: Open Table Format bundles distributed files into manageable tables with
    database-like features.
  type: definition
  entity: Open Table Format
  keywords:
  - definition
  - open
  - table
  - format
  - bundles
  - distributed
  - files
  - manageable
  - tables
  - database
  - like
  - features
  source:
    doc: motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md
    quote: Open Table Format bundles distributed files into manageable tables with
      database-like features.
    char_start: 0
    char_end: 95
- statement: Open Table Format is a format for organizing and managing data in a table
    structure.
  type: definition
  entity: Open Table Format
  keywords:
  - definition
  - open
  - table
  - format
  - organizing
  - managing
  - data
  - structure
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: Open Table Format is a format for organizing and managing data in a table
      structure.
    char_start: 0
    char_end: 84
- statement: OpenAI is an AI research and deployment company.
  type: definition
  entity: OpenAI
  keywords:
  - definition
  - openai
  - ai
  - research
  - deployment
  - company
  source:
    doc: motherduck.com/blog/motherduck-union-orchestration.md
    quote: OpenAI is an AI research and deployment company.
    char_start: 0
    char_end: 48
- statement: GPT-4 provided noticeably lower-quality results than GPT-4.
  type: comparison
  entity: OpenAI GPT-4
  keywords:
  - comparison
  - gpt
  - provided
  - noticeably
  - lower
  - quality
  - results
  source:
    doc: motherduck.com/blog/introducing-fixit-ai-sql-error-fixer.md
    quote: While GPT-3.5 is the lowest-cost option, it also provided noticeably lower-quality
      results than GPT-4.
    char_start: 0
    char_end: 102
- statement: The Fix Success Rate for GPT-4 is 78%.
  type: definition
  entity: OpenAI GPT-4
  keywords:
  - definition
  - fix
  - success
  - rate
  - gpt
  - '78'
  source:
    doc: motherduck.com/blog/introducing-fixit-ai-sql-error-fixer.md
    quote: 'Fix Success Rate: Percentage of randomly corrupted queries that execute
      successfully after the suggested fix.'
    char_start: 0
    char_end: 109
- statement: OpenStreetMap is a data source for GIS applications.
  type: definition
  entity: OpenStreetMap
  keywords:
  - definition
  - openstreetmap
  - data
  - source
  - gis
  - applications
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: When you pull data from sources like OpenStreetMap or satellite imagery...
    char_start: 0
    char_end: 74
- statement: Oracle is proprietary compared to the open-source DuckDB.
  type: definition
  entity: Oracle
  keywords:
  - definition
  - oracle
  - proprietary
  - compared
  - open
  - source
  - duckdb
  source:
    doc: motherduck.com/blog/tableau-cloud-motherduck.md
    quote: Oracle is also proprietary compared to the open-source DuckDB.
    char_start: 0
    char_end: 62
- statement: Oracle offers a free developer option for their latest 23ai version.
  type: definition
  entity: Oracle
  keywords:
  - definition
  - oracle
  - offers
  - free
  - developer
  - option
  - latest
  - 23ai
  - version
  source:
    doc: motherduck.com/blog/streaming-oracle-to-motherduck.md
    quote: Oracle released a free developer option for their latest 23ai version.
    char_start: 0
    char_end: 70
- statement: To stream data from Oracle to MotherDuck, you will need an Oracle database
    and a MotherDuck account.
  type: requirement
  entity: Oracle
  keywords:
  - requirement
  - stream
  - data
  - oracle
  - motherduck
  - need
  - database
  - account
  source:
    doc: motherduck.com/blog/tableau-cloud-motherduck.md
    quote: 'To stream data from Oracle to MotherDuck, you will need: An Oracle database
      (version 11g or higher) and a MotherDuck account.'
    char_start: 0
    char_end: 125
- statement: Traditional analytics required expensive licenses and complex setups.
  type: definition
  entity: Oracle
  keywords:
  - definition
  - traditional
  - analytics
  - required
  - expensive
  - licenses
  - complex
  - setups
  source:
    doc: motherduck.com/blog/faster-ducks.md
    quote: Back in the 2000s, if you wanted to do analytics, you'd install Oracle
      or SQL Server. Expensive licenses, complex setup...
    char_start: 0
    char_end: 122
- statement: Once your Oracle database is properly configured, it’s a breeze to hook
    it up in Estuary.
  type: instruction
  entity: Oracle Database
  keywords:
  - instruction
  - oracle
  - database
  - properly
  - configured
  - breeze
  - hook
  - up
  - estuary
  source:
    doc: motherduck.com/blog/summer-data-engineering-roadmap.md
    quote: Once your Oracle database is properly configured, it’s a breeze to hook
      it up in Estuary.
    char_start: 0
    char_end: 89
- statement: Oracle Database is a mature, SQL-based relational database management
    system.
  type: definition
  entity: Oracle Database
  keywords:
  - definition
  - oracle
  - database
  - mature
  - sql
  - based
  - relational
  - management
  - system
  source:
    doc: motherduck.com/blog/streaming-oracle-to-motherduck.md
    quote: Oracle Database is a mature, SQL-based relational database management system
      (RDBMS).
    char_start: 0
    char_end: 85
- statement: The Oracle database must be in ARCHIVELOG mode.
  type: definition
  entity: Oracle Database
  keywords:
  - definition
  - oracle
  - database
  - archivelog
  - mode
  source:
    doc: motherduck.com/blog/summer-data-engineering-roadmap.md
    quote: ensure that your database is in ARCHIVELOG mode (as opposed to NOARCHIVELOG
      mode)
    char_start: 0
    char_end: 81
- statement: The retention policy should be set to at least 24 hours.
  type: definition
  entity: Oracle Database
  keywords:
  - definition
  - retention
  - policy
  - set
  - least
  - '24'
  - hours
  source:
    doc: motherduck.com/blog/summer-data-engineering-roadmap.md
    quote: you’ll need to set the retention policy to at least 24 hours
    char_start: 0
    char_end: 60
- statement: Estuary uses Oracle LogMiner for Oracle CDC.
  type: definition
  entity: Oracle LogMiner
  keywords:
  - definition
  - estuary
  - uses
  - oracle
  - logminer
  - cdc
  source:
    doc: motherduck.com/blog/streaming-oracle-to-motherduck.md
    quote: This is what Estuary uses for Oracle CDC.
    char_start: 0
    char_end: 41
- statement: Oracle’s redo log records all of the changes made on a database as they
    occur.
  type: definition
  entity: Oracle redo log
  keywords:
  - definition
  - oracle
  - redo
  - log
  - records
  - changes
  - made
  - database
  - occur
  source:
    doc: motherduck.com/blog/summer-data-engineering-roadmap.md
    quote: Intended for recovery purposes, Oracle’s redo log records all of the changes
      made on a database as they occur.
    char_start: 0
    char_end: 110
- statement: An orchestrator can help establish and automate data management processes.
  type: definition
  entity: orchestrator
  keywords:
  - definition
  - orchestrator
  - help
  - establish
  - automate
  - data
  - management
  - processes
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-three.md
    quote: 'An orchestrator can help here for a number of reasons: To establish a
      process... To automate that established process...'
    char_start: 0
    char_end: 120
- statement: The ORDER BY clause lets you sort your rows based on a specific column.
  type: definition
  entity: ORDER BY
  keywords:
  - definition
  - order
  - clause
  - lets
  - sort
  - rows
  - based
  - specific
  - column
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md
    quote: The ORDER BY clause lets you sort your rows based on a specific column.
    char_start: 0
    char_end: 71
- statement: The orders table can be written to Parquet files partitioned by year
    and month.
  type: definition
  entity: orders
  keywords:
  - definition
  - orders
  - table
  - written
  - parquet
  - files
  - partitioned
  - year
  - month
  source:
    doc: motherduck.com/videos.md
    quote: Let's start with a simple example, writing our table to Parquet files,
      partitioned by year and month.
    char_start: 0
    char_end: 101
- statement: Countries with populations over 10 million are aggregated by region.
  type: definition
  entity: over_10m_population
  keywords:
  - definition
  - countries
  - populations
  - over
  - '10'
  - million
  - aggregated
  - region
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: Find average population per region for these large countries
    char_start: 0
    char_end: 60
- statement: Copy-on-Write Optimization helps save memory and improves performance.
  type: definition
  entity: Pandas
  keywords:
  - definition
  - copy
  - write
  - optimization
  - helps
  - save
  - memory
  - improves
  - performance
  source:
    doc: motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md
    quote: Copy-on-write is a smart method for working with modifiable resources...
    char_start: 0
    char_end: 72
- statement: 'I expect to see the same trends on the data engineering side: Pandas
    & Polars wars, Arrow and Rust FTW.'
  type: definition
  entity: Pandas
  keywords:
  - definition
  - expect
  - see
  - trends
  - data
  - engineering
  - side
  - pandas
  - polars
  - wars
  - arrow
  - rust
  - ftw
  source:
    doc: motherduck.com/blog/data-engineer-highlights-PyConDE-2023.md
    quote: 'I expect however to see the same trends on the data engineering side:
      Pandas & Polars wars, Arrow and Rust FTW.'
    char_start: 0
    char_end: 111
- statement: Pandas 2.0 was released in 2023.
  type: definition
  entity: Pandas
  keywords:
  - definition
  - pandas
  - '2.0'
  - released
  - '2023'
  source:
    doc: motherduck.com/blog/duckdb-wasm-in-browser.md
    quote: It had a significant release in 2023, Pandas 2.0.
    char_start: 0
    char_end: 49
- statement: Pandas and Polars are dominating discussions at PyCon DE 2023.
  type: definition
  entity: Pandas
  keywords:
  - definition
  - pandas
  - polars
  - dominating
  - discussions
  - pycon
  - de
  - '2023'
  source:
    doc: motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md
    quote: There were a lot of talks, workshops dedicated to Pandas and Polars.
    char_start: 0
    char_end: 68
- statement: Pandas and Polars do not provide full ACID guarantees.
  type: definition
  entity: Pandas
  keywords:
  - definition
  - pandas
  - polars
  - provide
  - full
  - acid
  - guarantees
  source:
    doc: motherduck.com/blog/redshift-files-hunt-for-big-data.md
    quote: Unlike Pandas or Polars, which don’t provide full ACID guarantees.
    char_start: 0
    char_end: 66
- statement: Pandas can accidentally pull an entire dataset into local memory.
  type: definition
  entity: Pandas
  keywords:
  - definition
  - pandas
  - accidentally
  - pull
  - entire
  - dataset
  - local
  - memory
  source:
    doc: motherduck.com/blog/python-faker-duckdb-exploration.md
    quote: it is easy to accidentally pull an entire dataset into local memory when
      you only needed a small subset.
    char_start: 0
    char_end: 104
- statement: Pandas changed everything in data analytics.
  type: definition
  entity: Pandas
  keywords:
  - definition
  - pandas
  - changed
  - everything
  - data
  - analytics
  source:
    doc: motherduck.com/blog/faster-ducks.md
    quote: Then Python exploded in popularity. Pandas came along and changed everything.
    char_start: 0
    char_end: 77
- statement: Pandas DataFrames are versatile, two-dimensional labeled data structures
    in Python.
  type: definition
  entity: Pandas
  keywords:
  - definition
  - pandas
  - dataframes
  - versatile
  - two
  - dimensional
  - labeled
  - data
  - structures
  - python
  source:
    doc: motherduck.com/learn-more/bigquery-alternative-motherduck.md
    quote: Pandas DataFrames are versatile, two-dimensional labeled data structures
      in Python that can hold various types of data.
    char_start: 0
    char_end: 119
- statement: Pandas DataFrames can be used to create Parquet files.
  type: definition
  entity: Pandas
  keywords:
  - definition
  - pandas
  - dataframes
  - used
  - create
  - parquet
  - files
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: Pandas DataFrames are actually a great way to create parquet files.
    char_start: 0
    char_end: 67
- statement: Pandas doesn’t have a SQL interface, and it’s more Dataframe style.
  type: definition
  entity: Pandas
  keywords:
  - definition
  - pandas
  - doesn
  - sql
  - interface
  - dataframe
  - style
  source:
    doc: motherduck.com/blog/small-data-sf-recap.md
    quote: Pandas doesn’t have a SQL interface, and it’s more Dataframe style.
    char_start: 0
    char_end: 67
- statement: Pandas faced memory overload during processing.
  type: definition
  entity: Pandas
  keywords:
  - definition
  - pandas
  - faced
  - memory
  - overload
  - processing
  source:
    doc: motherduck.com/blog/motherduck-kestra-etl-pipelines.md
    quote: Pandas didn’t manage to get it through.
    char_start: 0
    char_end: 39
- statement: Pandas is a flexible data manipulation library.
  type: definition
  entity: Pandas
  keywords:
  - definition
  - pandas
  - flexible
  - data
  - manipulation
  - library
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: Pandas (flexible data manipulation)
    char_start: 0
    char_end: 35
- statement: Pandas is installed with pyarrow which is pretty large but also needed
    for read/writing to AWS S3.
  type: definition
  entity: Pandas
  keywords:
  - definition
  - pandas
  - installed
  - pyarrow
  - which
  - pretty
  - large
  - also
  - needed
  - read
  - writing
  - aws
  - s3
  source:
    doc: motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md
    quote: Pandas project is here is installed with pyarrow which is pretty large
      but also needed for read/writing to AWS S3.
    char_start: 0
    char_end: 114
- statement: Pandas is the de facto standard for Dataframe in Python.
  type: definition
  entity: Pandas
  keywords:
  - definition
  - pandas
  - de
  - facto
  - standard
  - dataframe
  - python
  source:
    doc: motherduck.com/blog/duckdb-versus-pandas-versus-polars.md
    quote: If you are a Python developer and working with data, chances are high that
      you came across the Pandas.
    char_start: 0
    char_end: 102
- statement: Pandas now supports Pyarrow backend for faster operations.
  type: definition
  entity: Pandas
  keywords:
  - definition
  - pandas
  - now
  - supports
  - pyarrow
  - backend
  - faster
  - operations
  source:
    doc: motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md
    quote: Support for Pyarrow backend, resulting in faster and more memory-efficient
      operations.
    char_start: 0
    char_end: 86
- statement: Pandas ran out of memory during the operation.
  type: definition
  entity: Pandas
  keywords:
  - definition
  - pandas
  - ran
  - out
  - memory
  - operation
  source:
    doc: motherduck.com/blog/small-data-sf-recap.md
    quote: Pandas X → memory overload.
    char_start: 0
    char_end: 27
- statement: Pandas uses highly optimized C code for many operations.
  type: definition
  entity: Pandas
  keywords:
  - definition
  - pandas
  - uses
  - highly
  - optimized
  - code
  - many
  - operations
  source:
    doc: motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse.md
    quote: Under the hood, libraries like Pandas use highly optimized C code (via
      NumPy) for many operations.
    char_start: 0
    char_end: 98
- statement: The pandas DataFrame is used to store and manage person records before
    saving them.
  type: definition
  entity: Pandas
  keywords:
  - definition
  - pandas
  - dataframe
  - used
  - store
  - manage
  - person
  - records
  - saving
  - them
  source:
    doc: motherduck.com/blog/redshift-files-hunt-for-big-data.md
    quote: The pandas DataFrame is used to store and manage person records before
      saving them.
    char_start: 0
    char_end: 83
- statement: Apache Parquet is an open-source columnar storage file format designed
    for efficient data processing.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - apache
  - parquet
  - open
  - source
  - columnar
  - storage
  - file
  - format
  - designed
  - efficient
  - data
  - processing
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Apache Parquet is an open-source columnar storage file format designed
      for efficient data processing.
    char_start: 0
    char_end: 101
- statement: Consolidation enables column pruning, predicate pushdown, and stats,
    often cutting execution time or credits 'by half or more'.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - consolidation
  - enables
  - column
  - pruning
  - predicate
  - pushdown
  - stats
  - often
  - cutting
  - execution
  - time
  - credits
  - half
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: Performance notes from the article are consolidation enables column pruning,
      predicate pushdown, and stats, often cutting execution time or credits 'by half
      or more'.
    char_start: 0
    char_end: 166
- statement: Imagine running complex SQL queries on a 20 GB Parquet file directly
    on your laptop, without a flicker of memory strain.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - imagine
  - running
  - complex
  - sql
  - queries
  - '20'
  - gb
  - parquet
  - file
  - directly
  - laptop
  - without
  - flicker
  - memory
  - strain
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: Imagine running complex SQL queries on a 20 GB Parquet file directly on
      your laptop, without a flicker of memory strain.
    char_start: 0
    char_end: 120
- statement: Parquet effectively supports techniques like predicate pushdown and column
    pruning, which are crucial for optimizing data queries.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - parquet
  - effectively
  - supports
  - techniques
  - like
  - predicate
  - pushdown
  - column
  - pruning
  - which
  - crucial
  - optimizing
  - data
  - queries
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Parquet effectively supports techniques like predicate pushdown and column
      pruning, which are crucial for optimizing data queries.
    char_start: 0
    char_end: 130
- statement: Parquet efficiently manages large datasets while ensuring high performance.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - parquet
  - efficiently
  - manages
  - large
  - datasets
  - ensuring
  - high
  - performance
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Parquet stands out in data processing environments for its ability to efficiently
      manage large datasets while ensuring high performance.
    char_start: 0
    char_end: 136
- statement: Parquet enhances query performance, making it ideal for data-intensive
    tasks.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - parquet
  - enhances
  - query
  - performance
  - making
  - ideal
  - data
  - intensive
  - tasks
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: By minimizing I/O operations, Parquet enhances query performance, making
      it ideal for data-intensive tasks.
    char_start: 0
    char_end: 107
- statement: Parquet excels at analytical queries that involve reading a subset of
    columns from a large dataset.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - parquet
  - excels
  - analytical
  - queries
  - involve
  - reading
  - subset
  - columns
  - large
  - dataset
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: By storing data in a columnar fashion, Parquet excels at analytical queries
      that involve reading a subset of columns from a large dataset.
    char_start: 0
    char_end: 138
- statement: Parquet files are immutable, requiring complete rewrites for updates.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - parquet
  - files
  - immutable
  - requiring
  - complete
  - rewrites
  - updates
  source:
    doc: motherduck.com/learn-more/partitioned-writes-parquet-ducklake.md
    quote: Parquet files are immutable, requiring complete rewrites for updates.
    char_start: 0
    char_end: 69
- statement: Parquet files can be imported into a database on MotherDuck.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - parquet
  - files
  - imported
  - database
  - motherduck
  source:
    doc: motherduck.com/blog/motherduck-dbt-pipelines.md
    quote: Today we want to move from our local environment to MotherDuck, where we
      want to look at importing these parquet files into a database.
    char_start: 0
    char_end: 135
- statement: Parquet has emerged as a popular choice for its columnar storage layout
    and impressive compression capabilities.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - parquet
  - emerged
  - popular
  - choice
  - columnar
  - storage
  - layout
  - impressive
  - compression
  - capabilities
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Parquet has emerged as a popular choice for its columnar storage layout
      and impressive compression capabilities.
    char_start: 0
    char_end: 112
- statement: Parquet has native support across various big data processing frameworks.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - parquet
  - native
  - support
  - across
  - various
  - big
  - data
  - processing
  - frameworks
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Major platforms like Apache Spark, Apache Hadoop, and Presto have native
      support for reading and writing Parquet files.
    char_start: 0
    char_end: 119
- statement: Parquet has superior compression and faster query performance.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - parquet
  - superior
  - compression
  - faster
  - query
  - performance
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: 'Core Benefits: Superior compression, faster query performance (via column
      pruning and predicate pushdown), and schema evolution support.'
    char_start: 0
    char_end: 136
- statement: Parquet is a general standard supported by all cloud data warehouses.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - parquet
  - general
  - standard
  - supported
  - cloud
  - data
  - warehouses
  source:
    doc: motherduck.com/blog/solving-advent-code-duckdb-dbt.md
    quote: Today, Parquet is a general standard supported by all cloud data warehouses.
    char_start: 0
    char_end: 76
- statement: Parquet is an open-source file format used for storing data in DuckLake.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - parquet
  - open
  - source
  - file
  - format
  - used
  - storing
  - data
  - ducklake
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2024.md
    quote: An open-source file format used for storing data in DuckLake.
    char_start: 0
    char_end: 61
- statement: Parquet is an open-source project governed by the Apache Software Foundation.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - parquet
  - open
  - source
  - project
  - governed
  - apache
  - software
  - foundation
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Parquet is an open-source project governed by the Apache Software Foundation.
    char_start: 0
    char_end: 77
- statement: Parquet is designed to handle evolving data structures with ease.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - parquet
  - designed
  - handle
  - evolving
  - data
  - structures
  - ease
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Parquet is designed to handle evolving data structures with ease.
    char_start: 0
    char_end: 65
- statement: Parquet is the most used file format, CSV second and JSON third.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - parquet
  - used
  - file
  - format
  - csv
  - second
  - json
  - third
  source:
    doc: motherduck.com/blog/motherduck-in-europe.md
    quote: Parquet is the most used file format, CSV second and JSON third.
    char_start: 0
    char_end: 64
- statement: Parquet leverages specialized encoding techniques such as dictionary,
    run-length, and delta encoding to optimize storage.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - parquet
  - leverages
  - specialized
  - encoding
  - techniques
  - dictionary
  - run
  - length
  - delta
  - optimize
  - storage
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Instead of treating data uniformly, Parquet leverages specialized encoding
      techniques such as dictionary, run-length, and delta encoding to optimize storage.
    char_start: 0
    char_end: 157
- statement: Parquet organizes data by columns rather than rows.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - parquet
  - organizes
  - data
  - columns
  - rather
  - rows
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Unlike traditional row-based formats, Parquet organizes data by columns
      rather than rows.
    char_start: 0
    char_end: 89
- statement: Parquet remains integral across diverse computing environments, valued
    for its performance and reliability.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - parquet
  - remains
  - integral
  - across
  - diverse
  - computing
  - environments
  - valued
  - performance
  - reliability
  source:
    doc: motherduck.com/videos/duckdb-motherduck-for-beginners-your-ultimate-guide.md
    quote: This adaptability ensures Parquet remains integral across diverse computing
      environments, valued for its performance and reliability.
    char_start: 0
    char_end: 133
- statement: Parquet was developed as part of the Apache Hadoop ecosystem.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - parquet
  - developed
  - part
  - apache
  - hadoop
  - ecosystem
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Developed as part of the Apache Hadoop ecosystem, Parquet has gained widespread
      adoption.
    char_start: 0
    char_end: 89
- statement: Parquet's main benefits include efficient data compression and encoding,
    schema evolution support, and performance optimization.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - parquet
  - main
  - benefits
  - include
  - efficient
  - data
  - compression
  - encoding
  - schema
  - evolution
  - support
  - performance
  - optimization
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Parquet's main benefits include efficient data compression and encoding,
      schema evolution support, and performance optimization.
    char_start: 0
    char_end: 128
- statement: Parquet's proficiency with complex data structures facilitates versatile
    data modeling.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - parquet
  - proficiency
  - complex
  - data
  - structures
  - facilitates
  - versatile
  - modeling
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Parquet's proficiency with complex data structures—like nested fields—facilitates
      versatile data modeling.
    char_start: 0
    char_end: 106
- statement: Parquet's role as a cornerstone of modern data strategies is highlighted.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - parquet
  - role
  - cornerstone
  - modern
  - data
  - strategies
  - highlighted
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Parquet's role as a cornerstone of modern data strategies.
    char_start: 0
    char_end: 58
- statement: Startups can adopt a lean stack using open formats like Parquet on S3
    combined with a serverless analytics engine.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - startups
  - adopt
  - lean
  - stack
  - using
  - open
  - formats
  - like
  - parquet
  - s3
  - combined
  - serverless
  - analytics
  - engine
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: Instead of complex, expensive platforms like Snowflake or BigQuery, startups
      can adopt a lean stack using open formats like Parquet on S3 combined with a
      serverless analytics engine.
    char_start: 0
    char_end: 182
- statement: The database can be exported as Parquet files.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - database
  - exported
  - parquet
  - files
  source:
    doc: motherduck.com/blog/duckdb-tutorial-for-beginners.md
    quote: You can also export your whole database as Parquet files `EXPORT DATABASE
      'target_directory' (FORMAT PARQUET);`
    char_start: 0
    char_end: 111
- statement: Use the Parquet file format for large datasets to benefit from its columnar
    storage and compression capabilities.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - use
  - parquet
  - file
  - format
  - large
  - datasets
  - benefit
  - columnar
  - storage
  - compression
  - capabilities
  source:
    doc: motherduck.com/videos/duckdb-tutorial-for-beginners.md
    quote: Use the Parquet file format for large datasets to benefit from its columnar
      storage and compression capabilities.
    char_start: 0
    char_end: 113
- statement: Users can create databases and tables from Parquet files using the MotherDuck
    UI.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - users
  - create
  - databases
  - tables
  - parquet
  - files
  - using
  - motherduck
  - ui
  source:
    doc: motherduck.com/blog/effortless-etl-unstructured-data-unstructuredio-motherduck.md
    quote: we can either create the database on the MotherDuck UI and import our tables
      from our Parquet files on S3.
    char_start: 0
    char_end: 106
- statement: Using parquet_metadata() avoids the need to download the entire Parquet
    file.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - using
  - parquet
  - metadata
  - avoids
  - need
  - download
  - entire
  - file
  source:
    doc: motherduck.com/blog/motherduck-kestra-etl-pipelines.md
    quote: The parquet_metadata() function is particularly useful here as it avoids
      the need to download the entire Parquet file
    char_start: 0
    char_end: 117
- statement: You can query the file’s internal metadata directly to see column names,
    types, and nullability.
  type: definition
  entity: Parquet
  keywords:
  - definition
  - query
  - file
  - internal
  - metadata
  - directly
  - see
  - column
  - names
  - types
  - nullability
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: For Parquet files, you can query the file’s internal metadata directly
      to see column names, types, and nullability.
    char_start: 0
    char_end: 115
- statement: Grouping and summarizing large datasets is now faster thanks to partition-aware
    aggregation.
  type: definition
  entity: partition-aware aggregation
  keywords:
  - definition
  - grouping
  - summarizing
  - large
  - datasets
  - now
  - faster
  - thanks
  - partition
  - aware
  - aggregation
  source:
    doc: motherduck.com/blog/announcing-motherduck-general-availability-data-warehousing-with-duckdb.md
    quote: Grouping and summarizing large datasets is now faster thanks to partition-aware
      aggregation.
    char_start: 0
    char_end: 92
- statement: Partitioning gives you flexibility to match your storage layout to your
    query patterns.
  type: definition
  entity: partitioning
  keywords:
  - definition
  - partitioning
  - gives
  - flexibility
  - match
  - storage
  - layout
  - query
  - patterns
  source:
    doc: motherduck.com/videos.md
    quote: Partitioning gives you flexibility to match your storage layout to your
      query patterns.
    char_start: 0
    char_end: 87
- statement: Building software for distributed systems is just harder than building
    on a single node.
  type: definition
  entity: Paxos
  keywords:
  - definition
  - building
  - software
  - distributed
  - systems
  - harder
  - single
  - node
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part2.md
    quote: Building software for distributed systems is just harder than building
      on a single node.
    char_start: 0
    char_end: 88
- statement: Pedram Navid is the owner of West Marin Data.
  type: definition
  entity: Pedram Navid
  keywords:
  - definition
  - pedram
  - navid
  - owner
  - west
  - marin
  - data
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md
    quote: Pedram Navid, Owner of West Marin Data.
    char_start: 0
    char_end: 39
- statement: Pedro Holanda discusses DuckDB in a technical talk.
  type: definition
  entity: Pedro Holanda
  keywords:
  - definition
  - pedro
  - holanda
  - discusses
  - duckdb
  - technical
  - talk
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md
    quote: 'Pedro Holanda - DuckDB: Bringing analytical SQL directly to your Python
      shell.'
    char_start: 0
    char_end: 78
- statement: Pedro Holanda is the Chief of Operations at DuckDB Labs.
  type: definition
  entity: Pedro Holanda
  keywords:
  - definition
  - pedro
  - holanda
  - chief
  - operations
  - duckdb
  - labs
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: currently as working as Chief of Operations at DuckDB Labs.
    char_start: 0
    char_end: 59
- statement: The percent_rank() Function is used for relative ranking.
  type: definition
  entity: percent_rank() Function
  keywords:
  - definition
  - percent
  - rank
  - function
  - used
  - relative
  - ranking
  source:
    doc: motherduck.com/blog/preswald-health-data-analysis.md
    quote: The percent_rank() Function for relative ranking
    char_start: 0
    char_end: 48
- statement: Performance is optimized for query speed and processing efficiency.
  type: definition
  entity: Performance
  keywords:
  - definition
  - performance
  - optimized
  - query
  - speed
  - processing
  - efficiency
  source:
    doc: motherduck.com/case-studies/atm-com-analytics-costs-sql-expressibility.md
    quote: Performance Optimize for query speed, processing efficiency, and low-latency
      data access across the entire architecture.
    char_start: 0
    char_end: 120
- statement: Balancing query performance with resource utilization is crucial, especially
    for applications dealing with large datasets or complex analyses.
  type: definition
  entity: Performance Optimization
  keywords:
  - definition
  - balancing
  - query
  - performance
  - resource
  - utilization
  - crucial
  - especially
  - applications
  - dealing
  - large
  - datasets
  - complex
  - analyses
  source:
    doc: motherduck.com/ecosystem.md
    quote: Performance Optimization Balancing query performance with resource utilization
      is crucial, especially for applications dealing with large datasets or complex
      analyses.
    char_start: 0
    char_end: 167
- statement: Maximizing performance improves cost efficiency.
  type: definition
  entity: Performance Tuning
  keywords:
  - definition
  - maximizing
  - performance
  - improves
  - cost
  - efficiency
  source:
    doc: motherduck.com/learn-more/bigquery-alternative-motherduck.md
    quote: Similarly, if you maximize performance, you also improve cost efficiency
      at the same time.
    char_start: 0
    char_end: 90
- statement: The PDS is open-source.
  type: definition
  entity: Personal Data Server (PDS)
  keywords:
  - definition
  - pds
  - open
  - source
  source:
    doc: motherduck.com/blog/duckdb-versus-pandas-versus-polars.md
    quote: the so-called Personal Data Server (PDS), which is also open-source.
    char_start: 0
    char_end: 68
- statement: The Personal Data Server allows users to host their own content.
  type: definition
  entity: Personal Data Server (PDS)
  keywords:
  - definition
  - personal
  - data
  - server
  - allows
  - users
  - host
  - content
  source:
    doc: motherduck.com/blog/duckdb-versus-pandas-versus-polars.md
    quote: everyone can host their content on their server.
    char_start: 0
    char_end: 48
- statement: Peter Boncz delivered a keynote on data systems research.
  type: definition
  entity: Peter Boncz
  keywords:
  - definition
  - peter
  - boncz
  - delivered
  - keynote
  - data
  - systems
  - research
  source:
    doc: motherduck.com/blog/log-processing-savings-bacalhau-motherduck.md
    quote: Peter Boncz from Centrum Wiskunde & Informatica (CWI) is currently on sabbatical
      at MotherDuck. He delivered an inspiring keynote...
    char_start: 0
    char_end: 132
- statement: Peter Boncz is a Visiting Researcher at MotherDuck.
  type: definition
  entity: Peter Boncz
  keywords:
  - definition
  - peter
  - boncz
  - visiting
  - researcher
  - motherduck
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2024.md
    quote: Peter Boncz, Visiting Researcher at MotherDuck and database luminary.
    char_start: 0
    char_end: 69
- statement: Peter Boncz will discuss the evolution of analytical database systems
    at the event.
  type: definition
  entity: Peter Boncz
  keywords:
  - definition
  - peter
  - boncz
  - discuss
  - evolution
  - analytical
  - database
  - systems
  - event
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: In this session, Peter Boncz will discuss the evolution of analytical database
      systems.
    char_start: 0
    char_end: 87
- statement: Choose PG DuckDB when you need high-performance analytics on PostgreSQL
    data.
  type: definition
  entity: PG DuckDB
  keywords:
  - definition
  - choose
  - pg
  - duckdb
  - need
  - high
  - performance
  - analytics
  - postgresql
  - data
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: 'Choose PG DuckDB when: You need high-performance analytics on PostgreSQL
      data.'
    char_start: 0
    char_end: 78
- statement: With pg_duckdb, you truly get the power of the duck in the elephant's
    hands.
  type: definition
  entity: pg_duckdb
  keywords:
  - definition
  - pg
  - duckdb
  - truly
  - get
  - power
  - duck
  - elephant
  - hands
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: With pg_duckdb, you truly get the power of the duck in the elephant's hands.
    char_start: 0
    char_end: 76
- statement: You can accelerate local analytics by orders of magnitude without changing
    your data storage.
  type: definition
  entity: pg_duckdb
  keywords:
  - definition
  - accelerate
  - local
  - analytics
  - orders
  - magnitude
  - without
  - changing
  - data
  - storage
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: You can accelerate local analytics by orders of magnitude without changing
      your data storage.
    char_start: 0
    char_end: 93
- statement: pg_mooncake can deliver up to 1,000x faster analytics over regular Postgres
    tables.
  type: performance
  entity: pg_mooncake
  keywords:
  - performance
  - pg
  - mooncake
  - deliver
  - up
  - 000x
  - faster
  - analytics
  - over
  - regular
  - postgres
  - tables
  source:
    doc: motherduck.com/blog/spark-ducklake-getting-started.md
    quote: The combination of a columnar storage format and DuckDB execution, means
      pg_mooncake can deliver up to 1,000x faster analytics over regular Postgres
      tables.
    char_start: 0
    char_end: 156
- statement: pg_mooncake is modular and will seamlessly integrate future updates to
    pg_duckdb.
  type: feature
  entity: pg_mooncake
  keywords:
  - feature
  - pg
  - mooncake
  - modular
  - seamlessly
  - integrate
  - future
  - updates
  - duckdb
  source:
    doc: motherduck.com/blog/pg-mooncake-columnstore.md
    quote: pg_mooncake is modular and will seamlessly integrate future updates to
      pg_duckdb.
    char_start: 0
    char_end: 81
- statement: pg_mooncake is officially in preview.
  type: definition
  entity: pg_mooncake
  keywords:
  - definition
  - pg
  - mooncake
  - officially
  - preview
  source:
    doc: motherduck.com/blog/python-duckdb-vs-dataframe-libraries.md
    quote: pg_mooncake is officially in preview.
    char_start: 0
    char_end: 37
- statement: pg_mooncake is open source under a permissive MIT license.
  type: definition
  entity: pg_mooncake
  keywords:
  - definition
  - pg
  - mooncake
  - open
  - source
  - permissive
  - mit
  - license
  source:
    doc: motherduck.com/blog/spark-ducklake-getting-started.md
    quote: pg_mooncake is open source under a permissive MIT license.
    char_start: 0
    char_end: 58
- statement: pg_mooncake provides columnstore tables in Postgres to enable faster
    analytics.
  type: definition
  entity: pg_mooncake
  keywords:
  - definition
  - pg
  - mooncake
  - provides
  - columnstore
  - tables
  - postgres
  - enable
  - faster
  - analytics
  source:
    doc: motherduck.com/blog/small-data-sf-recap.md
    quote: New pg_mooncake provides columnstore tables in Postgres to enable faster
      analytics.
    char_start: 0
    char_end: 83
- statement: pg_replicate captures changes from PostgreSQL's Write-Ahead Log (WAL)
    and streams them to another destination like MotherDuck.
  type: definition
  entity: pg_replicate
  keywords:
  - definition
  - pg
  - replicate
  - captures
  - changes
  - postgresql
  - write
  - ahead
  - log
  - wal
  - streams
  - them
  - another
  - destination
  - like
  - motherduck
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: pg_replicate captures changes from PostgreSQL's Write-Ahead Log (WAL) and
      streams them to another destination like MotherDuck.
    char_start: 0
    char_end: 126
- statement: Adobe's web version of Photoshop utilizes Wasm for computationally intensive
    image processing tasks.
  type: definition
  entity: Photoshop
  keywords:
  - definition
  - adobe
  - web
  - version
  - photoshop
  - utilizes
  - wasm
  - computationally
  - intensive
  - image
  - processing
  - tasks
  source:
    doc: motherduck.com/videos/is-bi-too-big-for-small-data.md
    quote: Adobe's web version of Photoshop utilizes Wasm for computationally intensive
      image processing tasks.
    char_start: 0
    char_end: 100
- statement: Photoshop utilizes WebAssembly for computationally intensive image processing
    tasks.
  type: definition
  entity: Photoshop
  keywords:
  - definition
  - photoshop
  - utilizes
  - webassembly
  - computationally
  - intensive
  - image
  - processing
  - tasks
  source:
    doc: motherduck.com/learn-more/pandas-dataframes-guide.md
    quote: Adobe's web version of Photoshop utilizes Wasm for computationally intensive
      image processing tasks.
    char_start: 0
    char_end: 100
- statement: Examples of vector databases include Pinecone, Weaviate, Qdrant, Chroma,
    Milvus, and Zilliz.
  type: definition
  entity: Pinecone
  keywords:
  - definition
  - examples
  - vector
  - databases
  - include
  - pinecone
  - weaviate
  - qdrant
  - chroma
  - milvus
  - zilliz
  source:
    doc: motherduck.com/learn-more/data-warehouse-tco.md
    quote: Examples include Pinecone, Weaviate, Qdrant, Chroma, Milvus, and Zilliz.
    char_start: 0
    char_end: 72
- statement: Plotly creates interactive visualizations, including maps with scattergeo,
    choropleth, and densitymapbox.
  type: definition
  entity: Plotly
  keywords:
  - definition
  - plotly
  - creates
  - interactive
  - visualizations
  - including
  - maps
  - scattergeo
  - choropleth
  - densitymapbox
  source:
    doc: motherduck.com/blog/motherduck-duckdb-dbt.md
    quote: 'Plotly: Creates interactive visualizations, including maps with scattergeo,
      choropleth, and densitymapbox.'
    char_start: 0
    char_end: 106
- statement: Plotly is a graphing library for Python that makes interactive, publication-quality
    graphs online.
  type: definition
  entity: Plotly
  keywords:
  - definition
  - plotly
  - graphing
  - library
  - python
  - makes
  - interactive
  - publication
  - quality
  - graphs
  - online
  source:
    doc: motherduck.com/blog/preswald-health-data-analysis.md
    quote: Plotly is a graphing library for Python that makes interactive, publication-quality
      graphs online.
    char_start: 0
    char_end: 98
- statement: Plotly is used to create interactive charts in Preswald.
  type: definition
  entity: Plotly
  keywords:
  - definition
  - plotly
  - used
  - create
  - interactive
  - charts
  - preswald
  source:
    doc: motherduck.com/blog/just-enough-sql-for-ai.md
    quote: We’ll build three Plotly charts and present them with Preswald.
    char_start: 0
    char_end: 63
- statement: ST_Point is used to transform longitude and latitude into a geometry
    type.
  type: definition
  entity: poi_france
  keywords:
  - definition
  - st
  - point
  - used
  - transform
  - longitude
  - latitude
  - geometry
  - type
  source:
    doc: motherduck.com/blog/simplifying-iot-analytics-motherduck.md
    quote: ST_Point is the spatial function to transform the longitude and latitude
      as geometry type.
    char_start: 0
    char_end: 90
- statement: The dataset includes geographical points represented as 'POINT' data
    types.
  type: definition
  entity: POINT
  keywords:
  - definition
  - dataset
  - includes
  - geographical
  - points
  - represented
  - point
  - data
  - types
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: The only thing left now is to display this. To create a map, we first create
      a `layer`, which is here a `HeatmapLayer`, and load data using the `from_duckdb`
      method.
    char_start: 0
    char_end: 165
- statement: AlibabaCloud showcased PolarDB-MP, their multi-primary cloud-native database
    that leverages disaggregated shared memory.
  type: definition
  entity: PolarDB-MP
  keywords:
  - definition
  - alibabacloud
  - showcased
  - polardb
  - mp
  - multi
  - primary
  - cloud
  - native
  - database
  - leverages
  - disaggregated
  - shared
  - memory
  source:
    doc: motherduck.com/blog/perf-is-not-enough.md
    quote: AlibabaCloud showcased PolarDB-MP, their multi-primary cloud-native database
      that leverages disaggregated shared memory.
    char_start: 0
    char_end: 120
- statement: Polaris is a catalog service that provides data management capabilities.
  type: definition
  entity: Polaris
  keywords:
  - definition
  - polaris
  - catalog
  - service
  - provides
  - data
  - management
  - capabilities
  source:
    doc: motherduck.com/blog/motherduck-dbt-pipelines.md
    quote: Which catalog should you use? Unity? Polaris? Glue? Iceberg Rest Catalog?
      AWS Iceberg Tables?
    char_start: 0
    char_end: 93
- statement: Polars employs lazy evaluation to optimize query execution.
  type: definition
  entity: Polars
  keywords:
  - definition
  - polars
  - employs
  - lazy
  - evaluation
  - optimize
  - query
  - execution
  source:
    doc: motherduck.com/blog/duckdb-the-great-federator.md
    quote: It employs lazy evaluation to optimize query execution, which can result
      in faster operations, particularly when working with large datasets.
    char_start: 0
    char_end: 141
- statement: Polars has just released a CLI written in Rust.
  type: definition
  entity: Polars
  keywords:
  - definition
  - polars
  - released
  - cli
  - written
  - rust
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: Polars outside Python and Rust has just released a CLI written in Rust.
    char_start: 0
    char_end: 71
- statement: Polars is a DataFrame library for Rust and Python that provides fast
    data manipulation capabilities.
  type: definition
  entity: Polars
  keywords:
  - definition
  - polars
  - dataframe
  - library
  - rust
  - python
  - provides
  - fast
  - data
  - manipulation
  - capabilities
  source:
    doc: motherduck.com/blog/announcing-small-data-sf-2025.md
    quote: Polars is a DataFrame library for Rust and Python that provides fast data
      manipulation capabilities.
    char_start: 0
    char_end: 100
- statement: Polars is fast due to its use of Rust and Apache Arrow.
  type: definition
  entity: Polars
  keywords:
  - definition
  - polars
  - fast
  - due
  - use
  - rust
  - apache
  - arrow
  source:
    doc: motherduck.com/blog/duckdb-the-great-federator.md
    quote: Polars is fast. For multiple reasons. It leverages Rust in the backend
      to multithread some parts of the process. It also uses Apache Arrow Columnar
      Format as the memory model.
    char_start: 0
    char_end: 175
- statement: Polars is making waves as the new go-to library for fast data manipulation
    and analysis in Python.
  type: definition
  entity: Polars
  keywords:
  - definition
  - polars
  - making
  - waves
  - new
  - go
  - library
  - fast
  - data
  - manipulation
  - analysis
  - python
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: Polars is making waves as the new go-to library for fast data manipulation
      and analysis in Python.
    char_start: 0
    char_end: 98
- statement: Polars requires understanding of lazy evaluation to avoid memory issues.
  type: definition
  entity: Polars
  keywords:
  - definition
  - polars
  - requires
  - understanding
  - lazy
  - evaluation
  - avoid
  - memory
  - issues
  source:
    doc: motherduck.com/blog/motherduck-kestra-etl-pipelines.md
    quote: For Polars, I had to use lazy-evaluation Dataframe otherwise it would blew
      up also my memory.
    char_start: 0
    char_end: 93
- statement: The lazy feature in Polars offers substantial performance and resource
    management benefits.
  type: definition
  entity: Polars
  keywords:
  - definition
  - lazy
  - feature
  - polars
  - offers
  - substantial
  - performance
  - resource
  - management
  - benefits
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: The lazy feature in Polars offers substantial performance and resource
      management benefits.
    char_start: 0
    char_end: 91
- statement: Polyglot Persistence uses multiple data storage technologies to meet
    diverse data model and query pattern requirements.
  type: definition
  entity: Polyglot Persistence
  keywords:
  - definition
  - polyglot
  - persistence
  - uses
  - multiple
  - data
  - storage
  - technologies
  - meet
  - diverse
  - model
  - query
  - pattern
  - requirements
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: Polyglot Persistence Using multiple data storage technologies to meet diverse
      data model and query pattern requirements.
    char_start: 0
    char_end: 120
- statement: Polytomic can sync data with MotherDuck in both directions.
  type: integration
  entity: Polytomic
  keywords:
  - integration
  - polytomic
  - sync
  - data
  - motherduck
  - both
  - directions
  source:
    doc: motherduck.com/learn-more/data-application.md
    quote: Polytomic can sync data with MotherDuck in both directions.
    char_start: 0
    char_end: 59
- statement: Polytomic is a single platform for moving data in both directions between
    various data sources.
  type: definition
  entity: Polytomic
  keywords:
  - definition
  - polytomic
  - single
  - platform
  - moving
  - data
  - both
  - directions
  - various
  - sources
  source:
    doc: motherduck.com/blog/vibe-coding-sql-cursor.md
    quote: Polytomic is a single platform for moving data in both directions between
      data warehouses, databases, SaaS applications like Salesforce, spreadsheets,
      cloud storage buckets like S3, and arbitrary HTTP
    char_start: 0
    char_end: 206
- statement: PostGIS is an extension for Postgres that adds geospatial capabilities.
  type: definition
  entity: PostGIS
  keywords:
  - definition
  - postgis
  - extension
  - postgres
  - adds
  - geospatial
  - capabilities
  source:
    doc: motherduck.com/blog/read-scaling-preview.md
    quote: Yes, there's an extension for Postgres, such as PostGIS.
    char_start: 0
    char_end: 56
- statement: Spatial operations are much faster than SQL joins due to the use of spatial
    indexes.
  type: definition
  entity: PostGIS
  keywords:
  - definition
  - spatial
  - operations
  - much
  - faster
  - sql
  - joins
  - due
  - use
  - indexes
  source:
    doc: motherduck.com/blog/pg_duckdb-postgresql-extension-for-duckdb-motherduck.md
    quote: These indexes organize data differently and optimize for geometric operations.
    char_start: 0
    char_end: 78
- statement: A relational database without a geospatial data type can't do it fast
    enough.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - relational
  - database
  - without
  - geospatial
  - data
  - type
  - fast
  - enough
  source:
    doc: motherduck.com/blog/read-scaling-preview.md
    quote: A relational database without a geospatial data type can't do it fast enough.
    char_start: 0
    char_end: 77
- statement: Data can be quickly moved from PostgreSQL to other formats like Parquet.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - data
  - quickly
  - moved
  - postgresql
  - formats
  - like
  - parquet
  source:
    doc: motherduck.com/blog/semantic-layer-duckdb-tutorial.md
    quote: Quickly move data from PostgreSQL to other formats like Parquet.
    char_start: 0
    char_end: 64
- statement: DuckDB supports Postgres and MySQL for secrets management.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - duckdb
  - supports
  - postgres
  - mysql
  - secrets
  - management
  source:
    doc: motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md
    quote: DuckDB supports through secrets manager.
    char_start: 0
    char_end: 40
- statement: DuckLake can be used with PostgreSQL, MySQL, or SQLite as a catalog database.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - ducklake
  - used
  - postgresql
  - mysql
  - sqlite
  - catalog
  - database
  source:
    doc: motherduck.com/blog/solving-advent-code-duckdb-dbt.md
    quote: 'That catalog database can be: PostgreSQL or MySQL (preferred, especially
      for multi-user read/write) - DuckDB (great for local use or playgrounds) - SQLite
      (for multi-client local use)'
    char_start: 0
    char_end: 183
- statement: Integrating PostgreSQL with DuckDB and MotherDuck offers practical ways
    to enhance your analytical capabilities.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - integrating
  - postgresql
  - duckdb
  - motherduck
  - offers
  - practical
  - ways
  - enhance
  - analytical
  - capabilities
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: Integrating PostgreSQL with DuckDB and MotherDuck offers practical ways
      to enhance your analytical capabilities without migrating all your data or building
      an entire data warehouse from scratch.
    char_start: 0
    char_end: 194
- statement: Modern databases come in various types, including relational databases
    like PostgreSQL and MySQL, and NoSQL databases like MongoDB and Cassandra.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - modern
  - databases
  - come
  - various
  - types
  - including
  - relational
  - like
  - postgresql
  - mysql
  - nosql
  - mongodb
  - cassandra
  source:
    doc: motherduck.com/learn-more/data-application.md
    quote: Modern databases come in various types, including relational databases
      like PostgreSQL and MySQL, and NoSQL databases like MongoDB and Cassandra.
    char_start: 0
    char_end: 145
- statement: Most organizations use dedicated transactional databases (PostgreSQL,
    MySQL) for operational systems.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - organizations
  - use
  - dedicated
  - transactional
  - databases
  - postgresql
  - mysql
  - operational
  - systems
  source:
    doc: motherduck.com/videos/what-if-sql-queries-returned-results-instantly.md
    quote: Most organizations use dedicated transactional databases (PostgreSQL, MySQL)
      for operational systems.
    char_start: 0
    char_end: 101
- statement: Our operational Postgres database contains tables that track essential
    metrics about our service.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - operational
  - postgres
  - database
  - contains
  - tables
  - track
  - essential
  - metrics
  - about
  - service
  source:
    doc: motherduck.com/blog/small-data-sf-workshops-agenda.md
    quote: Our operational Postgres database contains tables that track essential
      metrics about our service.
    char_start: 0
    char_end: 97
- statement: Popular relational database management systems include PostgreSQL, MySQL,
    and Oracle Database.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - popular
  - relational
  - database
  - management
  - systems
  - include
  - postgresql
  - mysql
  - oracle
  source:
    doc: motherduck.com/learn-more/data-warehouse-tco.md
    quote: 'Popular relational database management systems (RDBMS) include: PostgreSQL,
      MySQL, Oracle Database.'
    char_start: 0
    char_end: 99
- statement: Postgres integrates with pgvector to add vector capabilities.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - postgres
  - integrates
  - pgvector
  - add
  - vector
  - capabilities
  source:
    doc: motherduck.com/learn-more/data-warehouse-tco.md
    quote: Postgres integrates with pgvector to add vector capabilities.
    char_start: 0
    char_end: 61
- statement: Postgres is a transactional database commonly used for analytics.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - postgres
  - transactional
  - database
  - commonly
  - used
  - analytics
  source:
    doc: motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md
    quote: like Postgres.
    char_start: 0
    char_end: 14
- statement: Postgres is excellent at handling fast, small-scale operations.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - postgres
  - excellent
  - handling
  - fast
  - small
  - scale
  - operations
  source:
    doc: motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md
    quote: Unlike transactional databases like Postgres, which is excellent at handling
      fast, small-scale operations.
    char_start: 0
    char_end: 106
- statement: Postgres is used to keep track of metadata in the differential storage
    system.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - postgres
  - used
  - keep
  - track
  - metadata
  - differential
  - storage
  - system
  source:
    doc: motherduck.com/blog/local-duckdb-ui-visual-data-analysis.md
    quote: We built a transactional database (currently Postgres), to keep track of
      metadata.
    char_start: 0
    char_end: 82
- statement: PostgreSQL and MySQL are optimized for Online Transaction Processing
    (OLTP).
  type: definition
  entity: Postgres
  keywords:
  - definition
  - postgresql
  - mysql
  - optimized
  - online
  - transaction
  - processing
  - oltp
  source:
    doc: motherduck.com/learn-more/pandas-dataframes-guide.md
    quote: These databases are masterpieces of engineering for Online Transaction
      Processing (OLTP).
    char_start: 0
    char_end: 89
- statement: PostgreSQL can join local data with remote data lake files in a single
    query.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - postgresql
  - join
  - local
  - data
  - remote
  - lake
  - files
  - single
  - query
  source:
    doc: motherduck.com/blog/perf-is-not-enough.md
    quote: 'This architecture enables something particularly powerful: joining PostgreSQL
      data with remote data lake files in a single query.'
    char_start: 0
    char_end: 129
- statement: PostgreSQL is a transactional database, not an analytical one.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - postgresql
  - transactional
  - database
  - analytical
  - one
  source:
    doc: motherduck.com/blog/motherduck-open-for-all-with-series-b.md
    quote: PostgreSQL is a transactional database, not an analytical one.
    char_start: 0
    char_end: 62
- statement: PostgreSQL is known for its robustness and compliance with ACID properties.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - postgresql
  - known
  - robustness
  - compliance
  - acid
  - properties
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: the same data integrity guarantees found in larger server-based databases
      like PostgreSQL.
    char_start: 0
    char_end: 90
- statement: PostgreSQL is the most popular database among developers according to
    the 2024 Stack Overflow survey.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - postgresql
  - popular
  - database
  - among
  - developers
  - according
  - '2024'
  - stack
  - overflow
  - survey
  source:
    doc: motherduck.com/learn-more/product-analytics-motherduck-duckdb.md
    quote: PostgreSQL is on a roll. It was named DBMS of the Year in 2023 and continues
      to be the most popular database among developers.
    char_start: 0
    char_end: 126
- statement: PostgreSQL isn’t optimized for analytical workloads.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - postgresql
  - isn
  - optimized
  - analytical
  - workloads
  source:
    doc: motherduck.com/blog/read-scaling-preview.md
    quote: since PostgreSQL isn’t optimized for analytical workloads.
    char_start: 0
    char_end: 58
- statement: PostgreSQL requires that extensions on primary and replicas are identical.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - postgresql
  - requires
  - extensions
  - primary
  - replicas
  - identical
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: PostgreSQL requires that extensions on primary and replicas are identical
    char_start: 0
    char_end: 73
- statement: 'PostgreSQL version: 17.0'
  type: definition
  entity: Postgres
  keywords:
  - definition
  - postgresql
  - version
  - '17.0'
  source:
    doc: motherduck.com/blog/motherduck-duckdb-dbt.md
    quote: 'PostgreSQL version: 17.0 (from https://www.postgresql.org/download/linux/ubuntu/)'
    char_start: 0
    char_end: 81
- statement: PostgreSQL's dominance in database popularity.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - postgresql
  - dominance
  - database
  - popularity
  source:
    doc: motherduck.com/blog/duckdb-dbt-e2e-data-engineering-project-part-2.md
    quote: revealing PostgreSQL's dominance.
    char_start: 0
    char_end: 33
- statement: PostgreSQL's row-oriented storage and MVCC design make it perfect for
    transactional workloads.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - postgresql
  - row
  - oriented
  - storage
  - mvcc
  - design
  - make
  - perfect
  - transactional
  - workloads
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: PostgreSQL's row-oriented storage and MVCC design make it perfect for transactional
      workloads.
    char_start: 0
    char_end: 94
- statement: Postgres’ MySQL FDW encompasses all pushdown techniques.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - postgres
  - mysql
  - fdw
  - encompasses
  - pushdown
  - techniques
  source:
    doc: motherduck.com/blog/duckdb-the-great-federator.md
    quote: Postgres’ MySQL FDW already encompasses all these pushdown techniques.
    char_start: 0
    char_end: 70
- statement: Predicate pushdown is crucial for hybrid queries with large PostgreSQL
    tables.
  type: performance
  entity: Postgres
  keywords:
  - performance
  - predicate
  - pushdown
  - crucial
  - hybrid
  - queries
  - large
  - postgresql
  - tables
  source:
    doc: motherduck.com/blog/git-for-data-part-1.md
    quote: Predicate pushdown is crucial. For hybrid queries with large PostgreSQL
      tables...
    char_start: 0
    char_end: 81
- statement: Relational databases like PostgreSQL, MySQL, and SQLite can be extended
    to behave more like vector databases.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - relational
  - databases
  - like
  - postgresql
  - mysql
  - sqlite
  - extended
  - behave
  - vector
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: However, they come with extensions to make them behave more like vector
      databases.
    char_start: 0
    char_end: 82
- statement: Running the query on PostgreSQL took 1 minute and 29 seconds.
  type: performance
  entity: Postgres
  keywords:
  - performance
  - running
  - query
  - postgresql
  - took
  - minute
  - '29'
  - seconds
  source:
    doc: motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse.md
    quote: Running this query on our instance took **1 minute and 29 seconds**.
    char_start: 0
    char_end: 68
- statement: The built-in dlt Postgres to Postgres didn’t sufficiently load on the
    initial load.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - built
  - dlt
  - postgres
  - didn
  - sufficiently
  - load
  - initial
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: The built-in dlt Postgres to Postgres didn’t sufficiently load on the initial
      load.
    char_start: 0
    char_end: 83
- statement: The script allows for table replication from Postgres to MotherDuck.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - script
  - allows
  - table
  - replication
  - postgres
  - motherduck
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: Execute replication ctas_from_diff_db(duck_con)
    char_start: 0
    char_end: 47
- statement: Web applications often start with an OLTP database like Postgres.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - web
  - applications
  - often
  - start
  - oltp
  - database
  - like
  - postgres
  source:
    doc: motherduck.com/videos/how-to-efficiently-load-data-into-ducklake-with-estuary.md
    quote: You often start your web application with an OLTP database like Postgres.
    char_start: 0
    char_end: 73
- statement: You can start querying MotherDuck databases or shares within PostgreSQL.
  type: definition
  entity: Postgres
  keywords:
  - definition
  - start
  - querying
  - motherduck
  - databases
  - shares
  - within
  - postgresql
  source:
    doc: motherduck.com/blog/pgduckdb-beta-release-duckdb-postgres.md
    quote: Now within PostgreSQL, you can start querying MotherDuck databases or shares.
    char_start: 0
    char_end: 77
- statement: You need a PostgreSQL database with some data and settings setup.
  type: requirement
  entity: Postgres
  keywords:
  - requirement
  - need
  - postgresql
  - database
  - data
  - settings
  - setup
  source:
    doc: motherduck.com/blog/vibe-coding-sql-cursor.md
    quote: A PostgreSQL database with some data and settings setup (more on this below
      if you don't have an existing one)
    char_start: 0
    char_end: 110
- statement: Comments are associated with posts in the database.
  type: definition
  entity: Posts
  keywords:
  - definition
  - comments
  - associated
  - posts
  - database
  source:
    doc: motherduck.com/blog/duckdb-the-great-federator.md
    quote: A table in the database that contains comments associated with posts.
    char_start: 0
    char_end: 69
- statement: The Posts table contains 58329356 rows.
  type: definition
  entity: Posts
  keywords:
  - definition
  - posts
  - table
  - contains
  - '58329356'
  - rows
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: -- 58329356 rows
    char_start: 0
    char_end: 16
- statement: 5 million organizations worldwide use Microsoft Power BI for data visualization.
  type: definition
  entity: Power BI
  keywords:
  - definition
  - million
  - organizations
  - worldwide
  - use
  - microsoft
  - power
  - bi
  - data
  - visualization
  source:
    doc: motherduck.com/blog/announcing-motherduck-general-availability-data-warehousing-with-duckdb.md
    quote: 5 million organizations worldwide use Microsoft Power BI for data visualization,
      including 97% of Fortune 500.
    char_start: 0
    char_end: 110
- statement: Power BI and Visual Studio require using Windows or at least a VM with
    Windows.
  type: definition
  entity: Power BI
  keywords:
  - definition
  - power
  - bi
  - visual
  - studio
  - require
  - using
  - windows
  - least
  - vm
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-essential-tools.md
    quote: This requires using Windows or at least a VM with Windows.
    char_start: 0
    char_end: 58
- statement: PowerBI is Microsoft's business intelligence platform.
  type: definition
  entity: Power BI
  keywords:
  - definition
  - powerbi
  - microsoft
  - business
  - intelligence
  - platform
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: 'PowerBI: Microsoft''s business intelligence platform.'
    char_start: 0
    char_end: 52
- statement: Brian Bickell gave a talk about semantic layers.
  type: definition
  entity: Practical Data Community
  keywords:
  - definition
  - brian
  - bickell
  - gave
  - talk
  - about
  - semantic
  - layers
  source:
    doc: motherduck.com/blog/pushing-geo-boundaries-with-motherduck-geobase.md
    quote: Brian Bickell gave a great talk at the Practical Data Community about semantic
      layers and the problem they solve.
    char_start: 0
    char_end: 113
- statement: Predicate pushdown allows the engine to apply WHERE clause filters at
    the query level.
  type: definition
  entity: predicate pushdown
  keywords:
  - definition
  - predicate
  - pushdown
  - allows
  - engine
  - apply
  - clause
  - filters
  - query
  - level
  source:
    doc: motherduck.com/glossary/storage layer.md
    quote: Predicate pushdown allows the engine to apply WHERE clause filters at the
      query level.
    char_start: 0
    char_end: 86
- statement: Predictive Analytics applications use historical data to forecast future
    trends or outcomes.
  type: definition
  entity: Predictive Analytics Applications
  keywords:
  - definition
  - predictive
  - analytics
  - applications
  - use
  - historical
  - data
  - forecast
  - future
  - trends
  - outcomes
  source:
    doc: motherduck.com/ecosystem.md
    quote: Predictive Analytics Applications These applications use historical data
      to forecast future trends or outcomes.
    char_start: 0
    char_end: 111
- statement: Prefect integrates with Soda for data quality checks.
  type: integration
  entity: Prefect
  keywords:
  - integration
  - prefect
  - integrates
  - soda
  - data
  - quality
  - checks
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: Integration of Prefect and Soda for data quality checks.
    char_start: 0
    char_end: 56
- statement: Prefect is a workflow management system for data pipelines.
  type: definition
  entity: Prefect
  keywords:
  - definition
  - prefect
  - workflow
  - management
  - system
  - data
  - pipelines
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: A workflow management system for data pipelines.
    char_start: 0
    char_end: 48
- statement: Preset integrates with MotherDuck by connecting to it as a SQL-based
    data source.
  type: integration
  entity: Preset
  keywords:
  - integration
  - preset
  - integrates
  - motherduck
  - connecting
  - sql
  - based
  - data
  - source
  source:
    doc: motherduck.com/learn-more/data-application.md
    quote: Preset integrates with MotherDuck by connecting to it as a SQL-based data
      source.
    char_start: 0
    char_end: 81
- statement: Preswald allows users to build interactive data apps without extensive
    JavaScript knowledge.
  type: feature
  entity: Preswald
  keywords:
  - feature
  - preswald
  - allows
  - users
  - build
  - interactive
  - data
  - apps
  - without
  - extensive
  - javascript
  - knowledge
  source:
    doc: motherduck.com/blog/just-enough-sql-for-ai.md
    quote: Preswald gives you a near-instant route to interactive data apps, without
      forcing you to wade through a sea of JavaScript frameworks or pricey BI licenses.
    char_start: 0
    char_end: 155
- statement: Preswald helps you build live, Python-based data apps that go beyond
    static dashboards.
  type: definition
  entity: Preswald
  keywords:
  - definition
  - preswald
  - helps
  - build
  - live
  - python
  - based
  - data
  - apps
  - go
  - beyond
  - static
  - dashboards
  source:
    doc: motherduck.com/blog/motherduck-duckdb-dbt.md
    quote: Preswald helps you build live, Python-based data apps that go beyond static
      dashboards.
    char_start: 0
    char_end: 87
- statement: Preswald is the quick, straightforward way to turn your data queries
    into interactive dashboards.
  type: definition
  entity: Preswald
  keywords:
  - definition
  - preswald
  - quick
  - straightforward
  - way
  - turn
  - data
  - queries
  - interactive
  - dashboards
  source:
    doc: motherduck.com/blog/galileo-world-geospatial.md
    quote: Preswald is the quick, straightforward way to turn your data queries into
      interactive dashboards for broader consumption.
    char_start: 0
    char_end: 121
- statement: Product A has a moving average sales amount of 225 in the East region.
  type: definition
  entity: Product A
  keywords:
  - definition
  - product
  - moving
  - average
  - sales
  - amount
  - '225'
  - east
  - region
  source:
    doc: motherduck.com/blog/introducing-motherduck-for-business-analytics.md
    quote: 2023-01-01 | Product A | East  | 200          | 225
    char_start: 0
    char_end: 51
- statement: Product A has a sales rank of 1 in the East region.
  type: definition
  entity: Product A
  keywords:
  - definition
  - product
  - sales
  - rank
  - east
  - region
  source:
    doc: motherduck.com/blog/fabi-ai-llm-prompt-analysis.md
    quote: Product A | East | 300 | 1
    char_start: 0
    char_end: 26
- statement: The feature 'profile' is used by 373 distinct users.
  type: definition
  entity: profile
  keywords:
  - definition
  - feature
  - profile
  - used
  - '373'
  - distinct
  - users
  source:
    doc: motherduck.com/learn-more/pandas-dataframes-guide.md
    quote: '373'
    char_start: 0
    char_end: 3
- statement: Identical content always produces identical fingerprints.
  type: definition
  entity: Prolly Tree
  keywords:
  - definition
  - identical
  - content
  - always
  - produces
  - fingerprints
  source:
    doc: motherduck.com/blog/git-for-data-part-1.md
    quote: identical content always produces identical fingerprints.
    char_start: 0
    char_end: 57
- statement: Prolly Tree is used for efficient versioning in data management.
  type: definition
  entity: Prolly Tree
  keywords:
  - definition
  - prolly
  - tree
  - used
  - efficient
  - versioning
  - data
  - management
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: One technology used behind this is called Prolly Tree.
    char_start: 0
    char_end: 54
- statement: Prolly Trees are the technical foundation that makes Git-like versioning
    work for databases.
  type: definition
  entity: Prolly Tree
  keywords:
  - definition
  - prolly
  - trees
  - technical
  - foundation
  - makes
  - git
  - like
  - versioning
  - work
  - databases
  source:
    doc: motherduck.com/blog/git-for-data-part-1.md
    quote: Prolly Trees are the technical foundation that makes Git-like versioning
      work for databases.
    char_start: 0
    char_end: 92
- statement: Prometheus is an open-source systems monitoring and alerting toolkit.
  type: definition
  entity: Prometheus
  keywords:
  - definition
  - prometheus
  - open
  - source
  - systems
  - monitoring
  - alerting
  - toolkit
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: Prometheus is an open-source systems monitoring and alerting toolkit.
    char_start: 0
    char_end: 69
- statement: Prompt() lets you use language models directly in your MotherDuck queries.
  type: definition
  entity: prompt()
  keywords:
  - definition
  - prompt
  - lets
  - use
  - language
  - models
  - directly
  - motherduck
  - queries
  source:
    doc: motherduck.com/blog/motherduck-in-europe.md
    quote: Prompt() lets you use language models directly in your MotherDuck queries.
    char_start: 0
    char_end: 74
- statement: Prompt() leverages OpenAI's GPT-4o mini and GPT-4o models.
  type: definition
  entity: prompt()
  keywords:
  - definition
  - prompt
  - leverages
  - openai
  - gpt
  - 4o
  - mini
  - models
  source:
    doc: motherduck.com/blog/motherduck-in-europe.md
    quote: Prompt() leverages OpenAI's GPT-4o mini and GPT-4o models.
    char_start: 0
    char_end: 58
- statement: The prompt() function takes the review’s title and text along with the
    expected return struct format.
  type: definition
  entity: prompt()
  keywords:
  - definition
  - prompt
  - function
  - takes
  - review
  - title
  - text
  - along
  - expected
  - return
  - struct
  - format
  source:
    doc: motherduck.com/blog/introducing-instant-sql.md
    quote: The prompt() function takes the review’s title and text along with the
      expected return struct format.
    char_start: 0
    char_end: 101
- statement: htop is an interactive process viewer.
  type: definition
  entity: ps
  keywords:
  - definition
  - htop
  - interactive
  - process
  - viewer
  source:
    doc: motherduck.com/blog/data-warehouse-feature-roundup-oct-2024.md
    quote: 'htop: To check the current process.'
    char_start: 0
    char_end: 35
- statement: PULocationID represents taxi zones.
  type: definition
  entity: PULocationID
  keywords:
  - definition
  - pulocationid
  - represents
  - taxi
  - zones
  source:
    doc: motherduck.com/blog/pushing-geo-boundaries-with-motherduck-geobase.md
    quote: Pickup Location ID representing taxi zones.
    char_start: 0
    char_end: 43
- statement: Pulse is designed for lightweight, on-demand analytics.
  type: definition
  entity: Pulse
  keywords:
  - definition
  - pulse
  - designed
  - lightweight
  - demand
  - analytics
  source:
    doc: motherduck.com/blog/galileo-world-geospatial.md
    quote: 'Pulse: For lightweight, on-demand analytics'
    char_start: 0
    char_end: 43
- statement: Download the forever free PuppyGraph Developer Edition.
  type: definition
  entity: PuppyGraph
  keywords:
  - definition
  - download
  - forever
  - free
  - puppygraph
  - developer
  - edition
  source:
    doc: motherduck.com/blog/scaling-duckdb-with-ducklings.md
    quote: Ready to get started? Download the forever free PuppyGraph Developer Edition...
    char_start: 0
    char_end: 79
- statement: PuppyGraph Developer Edition allows users to create graph models in minutes.
  type: definition
  entity: PuppyGraph
  keywords:
  - definition
  - puppygraph
  - developer
  - edition
  - allows
  - users
  - create
  - graph
  - models
  - minutes
  source:
    doc: motherduck.com/blog/scaling-duckdb-with-ducklings.md
    quote: sign up for a free MotherDuck account to create your first graph model
      in minutes.
    char_start: 0
    char_end: 82
- statement: PuppyGraph enables graph querying without the need for a traditional
    graph database.
  type: definition
  entity: PuppyGraph
  keywords:
  - definition
  - puppygraph
  - enables
  - graph
  - querying
  - without
  - need
  - traditional
  - database
  source:
    doc: motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md
    quote: 'By integrating MotherDuck (and DuckDB), an in-process SQL OLAP data warehouse,
      with PuppyGraph, a graph query engine, SQL developers can seamlessly incorporate
      graph querying into their existing data '
    char_start: 0
    char_end: 207
- statement: PuppyGraph will be running at port 8081.
  type: definition
  entity: PuppyGraph
  keywords:
  - definition
  - puppygraph
  - running
  - port
  - '8081'
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: PuppyGraph will be running at port 8081.
    char_start: 0
    char_end: 40
- statement: You can even view the graph full-screen!
  type: definition
  entity: PuppyGraph
  keywords:
  - definition
  - even
  - view
  - graph
  - full
  - screen
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: You can even view the graph full-screen!
    char_start: 0
    char_end: 40
- statement: The Airbyte team released a public beta of PyAirbyte.
  type: definition
  entity: PyAirbyte
  keywords:
  - definition
  - airbyte
  - team
  - released
  - public
  - beta
  - pyairbyte
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: The Airbyte team released a public beta of PyAirbyte, or the packaging
      of Airbyte connectors to make them accessible in code.
    char_start: 0
    char_end: 125
- statement: PyArrow is a cross-language development platform for in-memory data.
  type: definition
  entity: PyArrow
  keywords:
  - definition
  - pyarrow
  - cross
  - language
  - development
  - platform
  - memory
  - data
  source:
    doc: motherduck.com/blog/data-engineers-answer-10-top-reddit-questions.md
    quote: A cross-language development platform for in-memory data.
    char_start: 0
    char_end: 57
- statement: PyCharm is used by 15.1% of developers.
  type: definition
  entity: PyCharm
  keywords:
  - definition
  - pycharm
  - used
  - '15.1'
  - developers
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: PyCharm (15.1%)
    char_start: 0
    char_end: 15
- statement: PyCon is a global phenomenon that brings together the brightest minds
    in the Python programming world.
  type: definition
  entity: PyCon DE 2023
  keywords:
  - definition
  - pycon
  - global
  - phenomenon
  - brings
  - together
  - brightest
  - minds
  - python
  - programming
  - world
  source:
    doc: motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md
    quote: As you may know, PyCon is a global phenomenon that brings together the
      brightest minds in the Python programming world.
    char_start: 0
    char_end: 119
- statement: Pydantic and Polars boost Python performance by rewriting core components
    in Rust.
  type: definition
  entity: Pydantic
  keywords:
  - definition
  - pydantic
  - polars
  - boost
  - python
  - performance
  - rewriting
  - core
  - components
  - rust
  source:
    doc: motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw.md
    quote: Pydantic and Polars work in a similar way, boosting Python performance
      by rewriting some core components in Rust.
    char_start: 0
    char_end: 113
- statement: Pydantic defines all the parameters expected to run our pipeline.
  type: definition
  entity: Pydantic
  keywords:
  - definition
  - pydantic
  - defines
  - parameters
  - expected
  - run
  - pipeline
  source:
    doc: motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md
    quote: In this `main()` function, we have all the main steps of our pipelines.
      The model definition of `PypiJobParameters` is available in the `models.py`.
    char_start: 0
    char_end: 148
- statement: Pydantic is used for data validation and settings management using Python
    type annotations.
  type: definition
  entity: Pydantic
  keywords:
  - definition
  - pydantic
  - used
  - data
  - validation
  - settings
  - management
  - using
  - python
  - type
  - annotations
  source:
    doc: motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md
    quote: Pydantic is used for data validation and settings management using Python
      type annotations.
    char_start: 0
    char_end: 91
- statement: Pydantic is used to handle schema.
  type: definition
  entity: Pydantic
  keywords:
  - definition
  - pydantic
  - used
  - handle
  - schema
  source:
    doc: motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md
    quote: We also saw interesting libraries like Pydantic to handle schema.
    char_start: 0
    char_end: 65
- statement: PyDeck is high-scale spatial rendering in Python, powered by deck.gl.
  type: definition
  entity: PyDeck
  keywords:
  - definition
  - pydeck
  - high
  - scale
  - spatial
  - rendering
  - python
  - powered
  - deck
  - gl
  source:
    doc: motherduck.com/blog/motherduck-duckdb-dbt.md
    quote: 'PyDeck: High-scale spatial rendering in Python, powered by deck.gl.'
    char_start: 0
    char_end: 67
- statement: Apache Iceberg facilitates complex data management with features like
    schema evolution and time travel.
  type: definition
  entity: PyIceberg
  keywords:
  - definition
  - apache
  - iceberg
  - facilitates
  - complex
  - data
  - management
  - features
  - like
  - schema
  - evolution
  - time
  - travel
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Apache Iceberg is crafted to optimize large-scale data lake operations,
      providing comprehensive support for multiple file formats, including Parquet.
    char_start: 0
    char_end: 149
- statement: Apache Iceberg often uses Parquet as its underlying file storage format.
  type: definition
  entity: PyIceberg
  keywords:
  - definition
  - apache
  - iceberg
  - often
  - uses
  - parquet
  - underlying
  - file
  - storage
  - format
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Newer table formats like Delta Lake and Apache Iceberg often use Parquet
      as their underlying file storage format while adding transactional guarantees.
    char_start: 0
    char_end: 151
- statement: dbt sources point to Iceberg tables.
  type: definition
  entity: PyIceberg
  keywords:
  - definition
  - dbt
  - sources
  - point
  - iceberg
  - tables
  source:
    doc: motherduck.com/learn-more/duckdb-struct-nested-data.md
    quote: Define dbt sources pointing to your Iceberg tables in S3.
    char_start: 0
    char_end: 57
- statement: Emerging table formats, including Delta Lake and Apache Iceberg, introduce
    enhancements that build on Parquet's capabilities.
  type: definition
  entity: PyIceberg
  keywords:
  - definition
  - emerging
  - table
  - formats
  - including
  - delta
  - lake
  - apache
  - iceberg
  - introduce
  - enhancements
  - build
  - parquet
  - capabilities
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: Emerging table formats, including Delta Lake and Apache Iceberg, introduce
      enhancements that build on Parquet's capabilities.
    char_start: 0
    char_end: 125
- statement: Iceberg allows you to store your data in a vendor-neutral format.
  type: definition
  entity: PyIceberg
  keywords:
  - definition
  - iceberg
  - allows
  - store
  - data
  - vendor
  - neutral
  - format
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: Iceberg allows you to store your data in a vendor-neutral format in your
      own object storage.
    char_start: 0
    char_end: 92
- statement: Iceberg's broad engine interoperability combined with DuckLake's simple,
    elegant user experience is a dream many data engineers share today.
  type: definition
  entity: PyIceberg
  keywords:
  - definition
  - iceberg
  - broad
  - engine
  - interoperability
  - combined
  - ducklake
  - simple
  - elegant
  - user
  - experience
  - dream
  - many
  - data
  - engineers
  - share
  - today
  source:
    doc: motherduck.com/learn-more/what-is-duckdb.md
    quote: Iceberg's broad engine interoperability combined with DuckLake's simple,
      elegant user experience.
    char_start: 0
    char_end: 97
- statement: Iceberg's catalog is a lightweight pointer to metadata files.
  type: definition
  entity: PyIceberg
  keywords:
  - definition
  - iceberg
  - catalog
  - lightweight
  - pointer
  - metadata
  - files
  source:
    doc: motherduck.com/learn-more/hybrid-analytics-guide.md
    quote: 'Iceberg''s Catalog: As we saw with `boring-catalog`, the catalog is a
      lightweight pointer to metadata files.'
    char_start: 0
    char_end: 107
- statement: PyIceberg is a Python library for working with Iceberg tables.
  type: definition
  entity: PyIceberg
  keywords:
  - definition
  - pyiceberg
  - python
  - library
  - working
  - iceberg
  - tables
  source:
    doc: motherduck.com/blog/data-app-generator.md
    quote: PyIceberg is a Python library for working with Iceberg tables.
    char_start: 0
    char_end: 62
- statement: The 'ice duck' command automatically creates a view for your table.
  type: definition
  entity: PyIceberg
  keywords:
  - definition
  - ice
  - duck
  - command
  - automatically
  - creates
  - view
  - table
  source:
    doc: motherduck.com/learn-more/ducklake-guide.md
    quote: The 'ice duck' command automatically creates a view for your table.
    char_start: 0
    char_end: 67
- statement: The ideal future would be a marriage of Iceberg's and DuckLake's strengths.
  type: definition
  entity: PyIceberg
  keywords:
  - definition
  - ideal
  - future
  - marriage
  - iceberg
  - ducklake
  - strengths
  source:
    doc: motherduck.com/learn-more/hybrid-analytics-guide.md
    quote: As Julien perfectly summarized, the ideal future would be a marriage of
      these two worlds.
    char_start: 0
    char_end: 89
- statement: You can create a new Iceberg table and commit your first snapshot.
  type: definition
  entity: PyIceberg
  keywords:
  - definition
  - create
  - new
  - iceberg
  - table
  - commit
  - first
  - snapshot
  source:
    doc: motherduck.com/learn-more/no-etl-query-raw-files.md
    quote: You've just created a new Iceberg table and committed your first snapshot.
    char_start: 0
    char_end: 74
- statement: You can go from zero to querying an Iceberg table with DuckDB in 5 minutes.
  type: definition
  entity: PyIceberg
  keywords:
  - definition
  - go
  - zero
  - querying
  - iceberg
  - table
  - duckdb
  - minutes
  source:
    doc: motherduck.com/learn-more/what-is-duckdb.md
    quote: 'Goal: Go from zero to querying an Iceberg table with DuckDB in 5 minutes.'
    char_start: 0
    char_end: 73
- statement: Pyodide provides a full Python environment in your browser.
  type: definition
  entity: Pyodide
  keywords:
  - definition
  - pyodide
  - provides
  - full
  - python
  - environment
  - browser
  source:
    doc: motherduck.com/blog/small-data-sf-recap.md
    quote: An exciting project in the Wasm ecosystem is pyodide, which ports CPython
      to WebAssembly, offering a full Python environment in your browser.
    char_start: 0
    char_end: 141
- statement: PyPI is a repository for Python packages.
  type: definition
  entity: PyPI
  keywords:
  - definition
  - pypi
  - repository
  - python
  - packages
  source:
    doc: motherduck.com/blog/dual-execution-dbt.md
    quote: The Python Package Index, a repository for Python packages.
    char_start: 0
    char_end: 59
- statement: The PyPI team has made the logs data available directly in Google BigQuery.
  type: definition
  entity: PyPI
  keywords:
  - definition
  - pypi
  - team
  - made
  - logs
  - data
  - available
  - directly
  - google
  - bigquery
  source:
    doc: motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md
    quote: The PyPI team has made the logs data available directly in Google BigQuery.
    char_start: 0
    char_end: 75
- statement: The Python Package Index is a repository of software for the Python programming
    language.
  type: definition
  entity: PyPI
  keywords:
  - definition
  - python
  - package
  - index
  - repository
  - software
  - programming
  - language
  source:
    doc: motherduck.com/blog/announcing-ducklake-support-motherduck-preview.md
    quote: The Python Package Index, a repository of software for the Python programming
      language.
    char_start: 0
    char_end: 87
- statement: The script allows switching between PySpark and DuckDB based on an environment
    variable.
  type: definition
  entity: PySpark
  keywords:
  - definition
  - script
  - allows
  - switching
  - pyspark
  - duckdb
  - based
  - environment
  - variable
  source:
    doc: motherduck.com/blog/local-duckdb-ui-visual-data-analysis.md
    quote: Our PySpark script contains a conditional import that look for an environment
      variable to be able to switch engine.
    char_start: 0
    char_end: 115
- statement: Python can generate parquet files.
  type: definition
  entity: Python
  keywords:
  - definition
  - python
  - generate
  - parquet
  - files
  source:
    doc: motherduck.com/blog/faster-data-pipelines-with-mcp-duckdb-ai.md
    quote: fastparquet.write('outfile_%s.parquet' % sys.argv[1], df)
    char_start: 0
    char_end: 57
- statement: Python is a high-level programming language used for general-purpose
    programming.
  type: definition
  entity: Python
  keywords:
  - definition
  - python
  - high
  - level
  - programming
  - language
  - used
  - general
  - purpose
  source:
    doc: motherduck.com/blog/analyze-x-data-nodejs-duckdb.md
    quote: Python is a high-level programming language used for general-purpose programming.
    char_start: 0
    char_end: 81
- statement: Python is a programming language commonly used in data engineering.
  type: definition
  entity: Python
  keywords:
  - definition
  - python
  - programming
  - language
  - commonly
  - used
  - data
  - engineering
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: let's look at a data engineer's programming language.
    char_start: 0
    char_end: 53
- statement: Python is considered the tooling language of a data engineer.
  type: definition
  entity: Python
  keywords:
  - definition
  - python
  - considered
  - tooling
  - language
  - data
  - engineer
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-essential-tools.md
    quote: Python is the tooling language of a data engineer...
    char_start: 0
    char_end: 52
- statement: Python is the glue language that ties everything together.
  type: definition
  entity: Python
  keywords:
  - definition
  - python
  - glue
  - language
  - ties
  - everything
  - together
  source:
    doc: motherduck.com/blog/announcing-motherduck-general-availability-data-warehousing-with-duckdb.md
    quote: Python is the glue language that ties everything together.
    char_start: 0
    char_end: 58
- statement: Python version 3.10 or higher is required to run marimo.
  type: definition
  entity: Python
  keywords:
  - definition
  - python
  - version
  - '3.10'
  - higher
  - required
  - run
  - marimo
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eight.md
    quote: Python >= 3.10
    char_start: 0
    char_end: 14
- statement: The AI modifies the Python script to render a heatmap instead of points.
  type: definition
  entity: Python
  keywords:
  - definition
  - ai
  - modifies
  - python
  - script
  - render
  - heatmap
  - instead
  - points
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: The AI modifies the Python script, importing the `HeatMap` plugin from
      Folium and regenerating the map.
    char_start: 0
    char_end: 103
- statement: The COPY command is used for data loading and exporting in DuckDB.
  type: definition
  entity: Python
  keywords:
  - definition
  - copy
  - command
  - used
  - data
  - loading
  - exporting
  - duckdb
  source:
    doc: motherduck.com/videos/a-new-paradigm-for-data-visualization-with-just-sql-markdown.md
    quote: A command in DuckDB used for data loading and exporting.
    char_start: 0
    char_end: 56
- statement: The webinar compares classic BI dashboards with custom-built data apps
    built in Python and JavaScript.
  type: definition
  entity: Python
  keywords:
  - definition
  - webinar
  - compares
  - classic
  - bi
  - dashboards
  - custom
  - built
  - data
  - apps
  - python
  - javascript
  source:
    doc: motherduck.com/videos/what-if-sql-queries-returned-results-instantly.md
    quote: In this webinar, we compare classic BI dashboards with custom-built data
      apps built in Python and JavaScript.
    char_start: 0
    char_end: 109
- statement: Python Faker is used to generate data for exploring DuckDB.
  type: definition
  entity: Python Faker
  keywords:
  - definition
  - python
  - faker
  - used
  - generate
  - data
  - exploring
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2024.md
    quote: Using the Python Faker library to generate data for exploring DuckDB
    char_start: 0
    char_end: 68
- statement: The Python Relational API allows interaction with DuckDB using Python.
  type: definition
  entity: Python Relational API
  keywords:
  - definition
  - python
  - relational
  - api
  - allows
  - interaction
  - duckdb
  - using
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: A feature of DuckDB that allows interaction with the database using Python.
    char_start: 0
    char_end: 75
- statement: Dr. Qiusheng Wu is an Associate Professor in the Department of Geography
    & Sustainability at the University of Tennessee.
  type: definition
  entity: Qiusheng Wu
  keywords:
  - definition
  - dr
  - qiusheng
  - wu
  - associate
  - professor
  - department
  - geography
  - sustainability
  - university
  - tennessee
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md
    quote: He is an Associate Professor in the Department of Geography & Sustainability
      at the University of Tennessee.
    char_start: 0
    char_end: 108
- statement: Dr. Qiusheng Wu is the creator of advanced open-source geospatial tools
    like geemap, leafmap, and segment-geospatial.
  type: definition
  entity: Qiusheng Wu
  keywords:
  - definition
  - dr
  - qiusheng
  - wu
  - creator
  - advanced
  - open
  - source
  - geospatial
  - tools
  - like
  - geemap
  - leafmap
  - segment
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md
    quote: Dr. Qiusheng Wu is the creator of advanced open-source geospatial tools
      like geemap, leafmap, and segment-geospatial.
    char_start: 0
    char_end: 117
- statement: Dr. Qiusheng Wu offers a free online course for further exploration of
    geospatial concepts.
  type: definition
  entity: Qiusheng Wu
  keywords:
  - definition
  - dr
  - qiusheng
  - wu
  - offers
  - free
  - online
  - course
  - exploration
  - geospatial
  - concepts
  source:
    doc: motherduck.com/blog/faster-data-pipelines-with-mcp-duckdb-ai.md
    quote: I recommend Dr. Qiusheng Wu's free online course.
    char_start: 0
    char_end: 49
- statement: Dr. Wu specializes in geospatial data science and open-source software
    development.
  type: definition
  entity: Qiusheng Wu
  keywords:
  - definition
  - dr
  - wu
  - specializes
  - geospatial
  - data
  - science
  - open
  - source
  - software
  - development
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md
    quote: Dr. Wu specializes in geospatial data science and open-source software
      development.
    char_start: 0
    char_end: 83
- statement: Quadratic is an exotic notebook with a spreadsheet style.
  type: definition
  entity: Quadratic
  keywords:
  - definition
  - quadratic
  - exotic
  - notebook
  - spreadsheet
  - style
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: 'Quadratic: Exotic notebook with a spreadsheet style.'
    char_start: 0
    char_end: 52
- statement: The QUALIFY Clause is used for advanced filtering.
  type: definition
  entity: QUALIFY Clause
  keywords:
  - definition
  - qualify
  - clause
  - used
  - advanced
  - filtering
  source:
    doc: motherduck.com/blog/preswald-health-data-analysis.md
    quote: The QUALIFY Clause for advanced filtering
    char_start: 0
    char_end: 41
- statement: Quentin Lhoest showed an entire LLM pipeline using pure SQL.
  type: definition
  entity: Quentin Lhoest
  keywords:
  - definition
  - quentin
  - lhoest
  - showed
  - entire
  - llm
  - pipeline
  - using
  - pure
  - sql
  source:
    doc: motherduck.com/blog/secoda-motherduck-integration-modern-duck-stack.md
    quote: Recently, he has been pushing the boundaries of the latest features of
      DuckDB by showing an entire LLM pipeline using pure SQL.
    char_start: 0
    char_end: 127
- statement: The lowest bucket would be queries that read less than 1 GB.
  type: definition
  entity: Query Size
  keywords:
  - definition
  - lowest
  - bucket
  - queries
  - read
  - less
  - gb
  source:
    doc: motherduck.com/blog/redshift-files-hunt-for-big-data.md
    quote: The lowest bucket would be queries that read less than 1 GB.
    char_start: 0
    char_end: 60
- statement: Questions are posts with a specific structure including title, body,
    and metadata.
  type: definition
  entity: Questions
  keywords:
  - definition
  - questions
  - posts
  - specific
  - structure
  - including
  - title
  - body
  - metadata
  source:
    doc: motherduck.com/blog/pg-duckdb-release.md
    quote: We have the Questions (Post with postTypeId=1) with a title, body, creationDate,
      ownerUserId, acceptedAnswerId, answerCount, tags, upvotes, downvotes, views,
      comments.
    char_start: 0
    char_end: 167
- statement: Quiver is a Go-powered hybrid vector database combining HNSW for fast
    vector search, DuckDB for SQL-based metadata filtering, and Apache Arrow for efficient
    data movement.
  type: definition
  entity: Quiver
  keywords:
  - definition
  - quiver
  - go
  - powered
  - hybrid
  - vector
  - database
  - combining
  - hnsw
  - fast
  - search
  - duckdb
  - sql
  - based
  - metadata
  - filtering
  - apache
  - arrow
  - efficient
  - data
  - movement
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: 'Thomas introduces Quiver, a Go-powered hybrid vector database combining
      HNSW (Hierarchical Navigable Small World) for fast vector search, DuckDB for
      SQL-based metadata filtering, and Apache Arrow for '
    char_start: 0
    char_end: 224
- statement: Quiver provides full SQL support and columnar storage optimized for analytical
    workloads powered by DuckDB.
  type: definition
  entity: Quiver
  keywords:
  - definition
  - quiver
  - provides
  - full
  - sql
  - support
  - columnar
  - storage
  - optimized
  - analytical
  - workloads
  - powered
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: Quiver is open-source and provides full SQL support and columnar storage
      optimized for analytical workloads powered by DuckDB.
    char_start: 0
    char_end: 126
- statement: Quokka is an open-source push-based vectorized query engine.
  type: definition
  entity: Quokka
  keywords:
  - definition
  - quokka
  - open
  - source
  - push
  - based
  - vectorized
  - query
  - engine
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: An open-source push-based vectorized query engine.
    char_start: 0
    char_end: 50
- statement: Amazon introduced RAIS, Redshift’s next-generation AI-powered Scaling.
  type: definition
  entity: RAIS
  keywords:
  - definition
  - amazon
  - introduced
  - rais
  - redshift
  - next
  - generation
  - ai
  - powered
  - scaling
  source:
    doc: motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md
    quote: Amazon also introduced RAIS, Redshift’s next-generation AI-powered Scaling.
    char_start: 0
    char_end: 75
- statement: The random module implements pseudo-random number generators.
  type: definition
  entity: random
  keywords:
  - definition
  - random
  - module
  - implements
  - pseudo
  - number
  - generators
  source:
    doc: motherduck.com/blog/faster-data-pipelines-with-mcp-duckdb-ai.md
    quote: A Python module that implements pseudo-random number generators.
    char_start: 0
    char_end: 64
- statement: The generator uses React components.
  type: definition
  entity: React
  keywords:
  - definition
  - generator
  - uses
  - react
  - components
  source:
    doc: motherduck.com/blog/data-app-generator.md
    quote: providing context on which React components to use
    char_start: 0
    char_end: 50
- statement: The ReAct framework was implemented for agent building.
  type: definition
  entity: ReAct framework
  keywords:
  - definition
  - react
  - framework
  - implemented
  - agent
  - building
  source:
    doc: motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md
    quote: implemented the ReAct framework for agent building
    char_start: 0
    char_end: 50
- statement: Read scaling enables customer-facing analytics.
  type: definition
  entity: Read Scaling
  keywords:
  - definition
  - read
  - scaling
  - enables
  - customer
  - facing
  - analytics
  source:
    doc: motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md
    quote: Customer-facing analytics use cases have different requirements than an
      analytics stack built to power your internal data teams.
    char_start: 0
    char_end: 128
- statement: Read Scaling improves data app performance by allowing multiple read
    operations.
  type: definition
  entity: Read Scaling
  keywords:
  - definition
  - read
  - scaling
  - improves
  - data
  - app
  - performance
  - allowing
  - multiple
  - operations
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-1.md
    quote: The other big use case for Read Scaling is for data apps...
    char_start: 0
    char_end: 59
- statement: Read Scaling improves DuckDB SQL query performance by scaling out to
    multiple DuckDB instances.
  type: definition
  entity: Read Scaling
  keywords:
  - definition
  - read
  - scaling
  - improves
  - duckdb
  - sql
  - query
  - performance
  - out
  - multiple
  - instances
  source:
    doc: motherduck.com/blog/MotherDuck-Visualize-Embeddings-Marimo.md
    quote: Read Scaling improves DuckDB SQL query performance by scaling out to multiple
      DuckDB instances.
    char_start: 0
    char_end: 95
- statement: Read Scaling is useful to speed up BI dashboards and data apps significantly.
  type: definition
  entity: Read Scaling
  keywords:
  - definition
  - read
  - scaling
  - useful
  - speed
  - up
  - bi
  - dashboards
  - data
  - apps
  - significantly
  source:
    doc: motherduck.com/blog/MotherDuck-Visualize-Embeddings-Marimo.md
    quote: It is useful to speed up BI dashboards and data apps significantly.
    char_start: 0
    char_end: 67
- statement: Read Scaling was introduced in December 2024 and has received overwhelmingly
    positive customer feedback.
  type: definition
  entity: Read Scaling
  keywords:
  - definition
  - read
  - scaling
  - introduced
  - december
  - '2024'
  - received
  - overwhelmingly
  - positive
  - customer
  - feedback
  source:
    doc: motherduck.com/blog/motherduck-open-for-all-with-series-b.md
    quote: We introduced [Read Scaling] in December 2024 and have received overwhelmingly
      positive customer feedback about its utility.
    char_start: 0
    char_end: 124
- statement: With Read Scaling, you don’t have to worry about whether MotherDuck can
    handle the number of users you throw at it.
  type: definition
  entity: Read Scaling
  keywords:
  - definition
  - read
  - scaling
  - don
  - worry
  - about
  - whether
  - motherduck
  - handle
  - number
  - users
  - throw
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-1.md
    quote: With Read Scaling, you don’t have to worry about whether MotherDuck can
      handle the number of users you throw at it.
    char_start: 0
    char_end: 115
- statement: Read Scaling replicas are read-only.
  type: definition
  entity: Read Scaling Tokens
  keywords:
  - definition
  - read
  - scaling
  - replicas
  source:
    doc: motherduck.com/blog/duckdb-tutorial-for-beginners.md
    quote: Since Read Scaling replicas are read-only...
    char_start: 0
    char_end: 44
- statement: Read Scaling Tokens provide read-only access to embedded analytics components.
  type: definition
  entity: Read Scaling Tokens
  keywords:
  - definition
  - read
  - scaling
  - tokens
  - provide
  - access
  - embedded
  - analytics
  - components
  source:
    doc: motherduck.com/blog/duckdb-cognee-sql-analytics-graph-rag.md
    quote: The API also enables new possibilities for app developers by allowing you
      to issue short-lived, Read Scaling Tokens to provide read-only access to embedded
      analytics components.
    char_start: 0
    char_end: 177
- statement: By leveraging tools like read_blob() for data ingestion, utilizing pre_hooks
    and variables to streamline logic with functions like array_agg(), and implementing
    incremental models with read_csv() for optimal performance, you can significantly
    enhance your data workflows.
  type: definition
  entity: read_blob
  keywords:
  - definition
  - leveraging
  - tools
  - like
  - read
  - blob
  - data
  - ingestion
  - utilizing
  - pre
  - hooks
  - variables
  - streamline
  - logic
  - functions
  - array
  - agg
  - implementing
  - incremental
  - models
  - csv
  source:
    doc: motherduck.com/blog/introducing-instant-sql.md
    quote: By leveraging tools like read_blob() for data ingestion, utilizing pre_hooks
      and variables to streamline logic with functions like array_agg() and implementing
      incremental models with read_csv() for o
    char_start: 0
    char_end: 270
- statement: The read_blob function returns a table with filenames, file size, schema,
    and last modified date.
  type: definition
  entity: read_blob
  keywords:
  - definition
  - read
  - blob
  - function
  - returns
  - table
  - filenames
  - file
  - size
  - schema
  - last
  - modified
  - date
  source:
    doc: motherduck.com/blog/motherduck-congratulates-duckdb-1.0-release.md
    quote: Read Blob is the first function required to make this pipeline work. It
      takes a path as a parameter and returns a table with filenames, file size, schema,
      and last modified date.
    char_start: 0
    char_end: 178
- statement: The read_blob() function is required to make this pipeline work.
  type: definition
  entity: read_blob
  keywords:
  - definition
  - read
  - blob
  - function
  - required
  - make
  - pipeline
  - work
  source:
    doc: motherduck.com/blog/motherduck-dbt-pipelines.md
    quote: Read Blob is the first function required to make this pipeline work.
    char_start: 0
    char_end: 68
- statement: Real-time Analytics applications are crucial for scenarios requiring
    immediate insights.
  type: definition
  entity: Real-time Analytics Applications
  keywords:
  - definition
  - real
  - time
  - analytics
  - applications
  - crucial
  - scenarios
  - requiring
  - immediate
  - insights
  source:
    doc: motherduck.com/ecosystem.md
    quote: Real-time Analytics Applications Designed to process and analyze data as
      it's generated, these applications are crucial for scenarios requiring immediate
      insights.
    char_start: 0
    char_end: 163
- statement: This integration supports various practical applications, such as real-time
    maritime activity analysis.
  type: definition
  entity: real-time maritime activity analysis
  keywords:
  - definition
  - integration
  - supports
  - various
  - practical
  - applications
  - real
  - time
  - maritime
  - activity
  - analysis
  source:
    doc: motherduck.com/blog/getting-started-ducklake-table-format.md
    quote: This integration supports various practical applications, such as real-time
      maritime activity analysis.
    char_start: 0
    char_end: 103
- statement: Redis is a key-value store used in data engineering.
  type: definition
  entity: Redis
  keywords:
  - definition
  - redis
  - key
  - value
  - store
  - used
  - data
  - engineering
  source:
    doc: motherduck.com/blog/getting-started-ducklake-table-format.md
    quote: the data might be stored on a data lake, maybe on a database, or a key-value
      store like Redis.
    char_start: 0
    char_end: 94
- statement: Redpanda streams operational data from PostgreSQL.
  type: definition
  entity: Redpanda
  keywords:
  - definition
  - redpanda
  - streams
  - operational
  - data
  - postgresql
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md
    quote: Redpanda that streams operational data from PostgreSQL.
    char_start: 0
    char_end: 55
- statement: The redset dataset is used for analysis in the document.
  type: definition
  entity: redset
  keywords:
  - definition
  - redset
  - dataset
  - used
  - analysis
  - document
  source:
    doc: motherduck.com/blog/redshift-files-hunt-for-big-data.md
    quote: You can get the redset dataset by attaching the share that I created.
    char_start: 0
    char_end: 69
- statement: A high Redshift bill can be due to its pricing models, even without massive
    data.
  type: definition
  entity: Redshift
  keywords:
  - definition
  - high
  - redshift
  - bill
  - due
  - pricing
  - models
  - even
  - without
  - massive
  - data
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part1.md
    quote: A high Redshift bill can be due to its pricing models, even without massive
      data.
    char_start: 0
    char_end: 81
- statement: Architectural differences can impact performance but are often marginal.
  type: definition
  entity: Redshift
  keywords:
  - definition
  - architectural
  - differences
  - impact
  - performance
  - often
  - marginal
  source:
    doc: motherduck.com/blog/separating-storage-compute-duckdb.md
    quote: The caveat to this rule, of course, is that architectural differences are
      hard to overcome.
    char_start: 0
    char_end: 91
- statement: High Redshift bills for smaller datasets often stem from its provisioned-cluster
    model.
  type: definition
  entity: Redshift
  keywords:
  - definition
  - high
  - redshift
  - bills
  - smaller
  - datasets
  - often
  - stem
  - provisioned
  - cluster
  - model
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: High Redshift bills for smaller datasets often stem from its provisioned-cluster
      model.
    char_start: 0
    char_end: 87
- statement: Interest in proprietary cloud databases like Redshift has declined.
  type: definition
  entity: Redshift
  keywords:
  - definition
  - interest
  - proprietary
  - cloud
  - databases
  - like
  - redshift
  - declined
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: proprietary cloud databases (DynamoDB, BigQuery, Redshift) showed declines.
    char_start: 0
    char_end: 75
- statement: Redshift required constant optimization and was not cost efficient.
  type: definition
  entity: Redshift
  keywords:
  - definition
  - redshift
  - required
  - constant
  - optimization
  - cost
  - efficient
  source:
    doc: motherduck.com/learn-more/bigquery-alternative-motherduck.md
    quote: It takes a lot of work to optimize Redshift.
    char_start: 0
    char_end: 44
- statement: The fastest Redshift cluster is the 4x ra3.16xlarge, which costs 29 times
    as much as MotherDuck Standard.
  type: definition
  entity: Redshift
  keywords:
  - definition
  - fastest
  - redshift
  - cluster
  - 4x
  - ra3.16
  - xlarge
  - which
  - costs
  - '29'
  - times
  - much
  - motherduck
  - standard
  source:
    doc: motherduck.com/blog/getting-started-gis-duckdb.md
    quote: The fastest Redshift cluster is the 4x ra3.16xlarge (that really rolls
      off the tongue), which costs 29 times as much, at $52/hour, and is just a little
      bit slower than the MotherDuck Standard.
    char_start: 0
    char_end: 192
- statement: Reflex built a culture of data-driven decision making.
  type: definition
  entity: Reflex
  keywords:
  - definition
  - reflex
  - built
  - culture
  - data
  - driven
  - decision
  - making
  source:
    doc: motherduck.com/learn-more/big-data.md
    quote: The team had built a culture of data-driven decision making.
    char_start: 0
    char_end: 60
- statement: Reflex connects major brands with on-demand retail associates across
    40+ cities.
  type: definition
  entity: Reflex
  keywords:
  - definition
  - reflex
  - connects
  - major
  - brands
  - demand
  - retail
  - associates
  - across
  - '40'
  - cities
  source:
    doc: motherduck.com/learn-more/big-data.md
    quote: Reflex is transforming how retail works. The Austin-based startup connects
      major brands like Ariat, Deckers, Everlane, Faherty with on-demand retail associates
      across 40+ cities.
    char_start: 0
    char_end: 178
- statement: Reflex's data infrastructure began showing cracks as they scaled nationally.
  type: definition
  entity: Reflex
  keywords:
  - definition
  - reflex
  - data
  - infrastructure
  - began
  - showing
  - cracks
  - scaled
  - nationally
  source:
    doc: motherduck.com/learn-more/big-data.md
    quote: As the company scaled nationally to over 100 brands, their data infrastructure
      began showing cracks.
    char_start: 0
    char_end: 100
- statement: Reflex's existing solution was beginning to show strain under the load
    of more complex business analytics queries.
  type: definition
  entity: Reflex
  keywords:
  - definition
  - reflex
  - existing
  - solution
  - beginning
  - show
  - strain
  - load
  - complex
  - business
  - analytics
  - queries
  source:
    doc: motherduck.com/case-studies/layers-multi-tenant-data-warehouse.md
    quote: the existing solution was beginning to show strain under the load of more
      complex business analytics queries.
    char_start: 0
    char_end: 109
- statement: The team solved a long-standing request to incorporate Excel data into
    their analytics.
  type: definition
  entity: Reflex
  keywords:
  - definition
  - team
  - solved
  - long
  - standing
  - request
  - incorporate
  - excel
  - data
  - analytics
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: The team also solved a long-standing request to incorporate Excel data
      into their analytics.
    char_start: 0
    char_end: 92
- statement: Matplotlib and Seaborn are libraries in Python for data visualization.
  type: definition
  entity: reject_errors
  keywords:
  - definition
  - matplotlib
  - seaborn
  - libraries
  - python
  - data
  - visualization
  source:
    doc: motherduck.com/glossary/Pandas DataFrames.md
    quote: libraries such as Matplotlib and Seaborn in Python or ggplot2 in R enable
      custom visualizations in code.
    char_start: 0
    char_end: 104
- statement: The reject_scans table logs details about rejected rows.
  type: definition
  entity: reject_errors
  keywords:
  - definition
  - reject
  - scans
  - table
  - logs
  - details
  - about
  - rejected
  - rows
  source:
    doc: motherduck.com/learn-more/data-warehouse-tco.md
    quote: FROM reject_scans; gives metadata about the `read_csv` operation itself.
    char_start: 0
    char_end: 72
- statement: Traditional database systems like PostgreSQL, Redis, Elasticsearch, and
    ClickHouse have added vector capabilities.
  type: definition
  entity: reject_errors
  keywords:
  - definition
  - traditional
  - database
  - systems
  - like
  - postgresql
  - redis
  - elasticsearch
  - clickhouse
  - added
  - vector
  - capabilities
  source:
    doc: motherduck.com/ecosystem/unstructured.md
    quote: Meanwhile, established database providers like PostgreSQL, Redis, Elasticsearch,
      and even ClickHouse have added vector search capabilities to their existing
      systems.
    char_start: 0
    char_end: 165
- statement: Columnar systems are poorly suited for workloads with frequent, single-row
    inserts, updates, or deletes.
  type: definition
  entity: reject_scans
  keywords:
  - definition
  - columnar
  - systems
  - poorly
  - suited
  - workloads
  - frequent
  - single
  - row
  - inserts
  - updates
  - deletes
  source:
    doc: motherduck.com/ecosystem/estuary.md
    quote: Columnar systems are poorly suited for workloads with frequent, single-row
      inserts, updates, or deletes.
    char_start: 0
    char_end: 104
- statement: Datasets serve as the foundation for data analysis, machine learning,
    and business intelligence tasks.
  type: definition
  entity: reject_scans
  keywords:
  - definition
  - datasets
  - serve
  - foundation
  - data
  - analysis
  - machine
  - learning
  - business
  - intelligence
  - tasks
  source:
    doc: motherduck.com/glossary/database.md
    quote: Datasets serve as the foundation for data analysis, machine learning, and
      business intelligence tasks.
    char_start: 0
    char_end: 102
- statement: reladiff is a tool to efficiently diff rows across databases.
  type: definition
  entity: reladiff
  keywords:
  - definition
  - reladiff
  - tool
  - efficiently
  - diff
  - rows
  - across
  - databases
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: Tool to efficiently diff rows across databases.
    char_start: 0
    char_end: 47
- statement: A relational database is a structured collection of data organized into
    tables with rows and columns.
  type: definition
  entity: Relational Databases
  keywords:
  - definition
  - relational
  - database
  - structured
  - collection
  - data
  - organized
  - tables
  - rows
  - columns
  source:
    doc: motherduck.com/learn-more/data-warehouse-tco.md
    quote: A relational database is a structured collection of data organized into
      tables with rows and columns.
    char_start: 0
    char_end: 101
- statement: Relational databases often fail to manage the volume of data and the
    speed at which it is generated.
  type: definition
  entity: Relational Databases
  keywords:
  - definition
  - relational
  - databases
  - often
  - fail
  - manage
  - volume
  - data
  - speed
  - which
  - generated
  source:
    doc: motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md
    quote: For instance, relational databases often fail to manage the volume of data
      and the speed at which it is generated.
    char_start: 0
    char_end: 114
- statement: Reliability involves implementing fault-tolerant designs.
  type: definition
  entity: Reliability
  keywords:
  - definition
  - reliability
  - involves
  - implementing
  - fault
  - tolerant
  - designs
  source:
    doc: motherduck.com/case-studies/atm-com-analytics-costs-sql-expressibility.md
    quote: Reliability Implement fault-tolerant designs with proper error handling,
      data replication, and recovery mechanisms.
    char_start: 0
    char_end: 115
- statement: Using remote columnar storage can provide even more speed.
  type: definition
  entity: remote columnar storage
  keywords:
  - definition
  - using
  - remote
  - columnar
  - storage
  - provide
  - even
  - speed
  source:
    doc: motherduck.com/videos.md
    quote: Learn practical tips and how to use remote columnar storage for even more
      speed.
    char_start: 0
    char_end: 80
- statement: The UDF 'remove_spaces_py' is correctly callable from SQL.
  type: definition
  entity: remove_spaces_py
  keywords:
  - definition
  - udf
  - remove
  - spaces
  - py
  - correctly
  - callable
  - sql
  source:
    doc: motherduck.com/learn-more.md
    quote: Success! Your Python UDF 'remove_spaces_py' is correctly callable from
      SQL and does its job.
    char_start: 0
    char_end: 92
- statement: Replit allows users to write and run code in the browser.
  type: definition
  entity: Replit
  keywords:
  - definition
  - replit
  - allows
  - users
  - write
  - run
  - code
  - browser
  source:
    doc: motherduck.com/blog/analyze-x-data-nodejs-duckdb.md
    quote: An online coding platform that allows users to write and run code in the
      browser.
    char_start: 0
    char_end: 81
- statement: Implement resource monitors as a critical safety net.
  type: definition
  entity: Resource Monitors
  keywords:
  - definition
  - implement
  - resource
  - monitors
  - critical
  - safety
  - net
  source:
    doc: motherduck.com/learn-more/product-analytics-motherduck-duckdb.md
    quote: Implement resource monitors as a critical safety net.
    char_start: 0
    char_end: 53
- statement: REST and JDBC are killing your data stack.
  type: definition
  entity: REST
  keywords:
  - definition
  - rest
  - jdbc
  - killing
  - data
  - stack
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: Why REST and JDBC Are Killing Your Data Stack
    char_start: 0
    char_end: 45
- statement: REST is duct tape. JDBC is legacy glue.
  type: definition
  entity: REST
  keywords:
  - definition
  - rest
  - duct
  - tape
  - jdbc
  - legacy
  - glue
  source:
    doc: motherduck.com/blog/flight-sql-vs-rest-vs-jdbc.md
    quote: The problem? REST is duct tape. JDBC is legacy glue.
    char_start: 0
    char_end: 52
- statement: Rest. Canoas La Ribera is one of the restaurants listed in the dataset.
  type: definition
  entity: Rest. Canoas La Ribera
  keywords:
  - definition
  - rest
  - canoas
  - la
  - ribera
  - one
  - restaurants
  - listed
  - dataset
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: │ 201363 │ POINT (-5.062485285379808 43.43078297825821)  │ Rest. Canoas
      La Ribera                        │
    char_start: 0
    char_end: 106
- statement: The 'result' keyword helps create powerful recursive queries for tasks
    like traversing hierarchical data structures or generating sequences.
  type: definition
  entity: result
  keywords:
  - definition
  - result
  - keyword
  - helps
  - create
  - powerful
  - recursive
  - queries
  - tasks
  - like
  - traversing
  - hierarchical
  - data
  - structures
  - generating
  - sequences
  source:
    doc: motherduck.com/learn-more/bigquery-alternative-motherduck.md
    quote: The 'result' keyword helps create powerful recursive queries for tasks
      like traversing hierarchical data structures or generating sequences.
    char_start: 0
    char_end: 140
- statement: Retrieval Augmented Generation (RAG) is a technique to feed LLMs relevant
    information for a question based on stored knowledge.
  type: definition
  entity: Retrieval Augmented Generation (RAG)
  keywords:
  - definition
  - retrieval
  - augmented
  - generation
  - rag
  - technique
  - feed
  - llms
  - relevant
  - information
  - question
  - based
  - stored
  - knowledge
  source:
    doc: motherduck.com/blog/six-reasons-duckdb-slaps.md
    quote: Retrieval Augmented Generation (RAG) is a technique to feed LLMs relevant
      information for a question based on stored knowledge.
    char_start: 0
    char_end: 127
- statement: Data management in a RAG pipeline often prevents coders from using RAGs
    effectively.
  type: definition
  entity: Retrieval-Augmented Generation
  keywords:
  - definition
  - data
  - management
  - rag
  - pipeline
  - often
  - prevents
  - coders
  - using
  - rags
  - effectively
  source:
    doc: motherduck.com/blog/why-web-developers-should-care-about-analytical-databases.md
    quote: Data management in a RAG pipeline often prevents coders from using RAGs
      effectively.
    char_start: 0
    char_end: 84
- statement: RAG enhances large language models by incorporating an external data
    store during the inference stage.
  type: definition
  entity: Retrieval-Augmented Generation
  keywords:
  - definition
  - rag
  - enhances
  - large
  - language
  - models
  - incorporating
  - external
  - data
  - store
  - inference
  - stage
  source:
    doc: motherduck.com/blog/why-web-developers-should-care-about-analytical-databases.md
    quote: RAG enhances large language models (LLMs) by incorporating an external
      data store during the inference stage.
    char_start: 0
    char_end: 109
- statement: RAG enhances LLMs by integrating them with a retrieval mechanism.
  type: definition
  entity: Retrieval-Augmented Generation
  keywords:
  - definition
  - rag
  - enhances
  - llms
  - integrating
  - them
  - retrieval
  - mechanism
  source:
    doc: motherduck.com/blog/the-future-of-bi-bi-as-code-duckdb-impact.md
    quote: RAG enhances LLMs by integrating them with a retrieval mechanism.
    char_start: 0
    char_end: 65
- statement: Retrieval-Augmented Generation combines retrieval of information with
    generative models.
  type: definition
  entity: Retrieval-Augmented Generation
  keywords:
  - definition
  - retrieval
  - augmented
  - generation
  - combines
  - information
  - generative
  - models
  source:
    doc: motherduck.com/blog/the-future-of-bi-bi-as-code-duckdb-impact.md
    quote: A method that combines retrieval of information with generative models
      to enhance AI capabilities.
    char_start: 0
    char_end: 98
- statement: The RAG framework boosts the precision and relevance of LLMs.
  type: definition
  entity: Retrieval-Augmented Generation
  keywords:
  - definition
  - rag
  - framework
  - boosts
  - precision
  - relevance
  - llms
  source:
    doc: motherduck.com/blog/the-future-of-bi-bi-as-code-duckdb-impact.md
    quote: The RAG framework boosts the precision and relevance of LLMs.
    char_start: 0
    char_end: 61
- statement: Rik Bauwens discussed DuckDB's implementation in Datacamp's notebook
    interface.
  type: definition
  entity: Rik Bauwens
  keywords:
  - definition
  - rik
  - bauwens
  - discussed
  - duckdb
  - implementation
  - datacamp
  - notebook
  - interface
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md
    quote: Rik Bauwens walked us through how they implemented neat features into Datacamp’s
      notebook interface using DuckDB.
    char_start: 0
    char_end: 113
- statement: Rill is an open-source and BI-as-Code platform.
  type: definition
  entity: Rill
  keywords:
  - definition
  - rill
  - open
  - source
  - bi
  - code
  - platform
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: 'Rill: Open-source and BI-as-Code platform.'
    char_start: 0
    char_end: 42
- statement: Rill Data provides real-time analytics and visualizations.
  type: definition
  entity: Rill Data
  keywords:
  - definition
  - rill
  - data
  - provides
  - real
  - time
  - analytics
  - visualizations
  source:
    doc: motherduck.com/blog/why-web-developers-should-care-about-analytical-databases.md
    quote: Rill Data provides real-time analytics and visualizations, enabling users
      to create interactive dashboards and monitor key metrics with minimal latency.
    char_start: 0
    char_end: 152
- statement: fzf is used to interactively search content.
  type: definition
  entity: Ripgrep
  keywords:
  - definition
  - fzf
  - used
  - interactively
  - search
  - content
  source:
    doc: motherduck.com/blog/data-warehouse-feature-roundup-oct-2024.md
    quote: fzf is a fuzzy finder.
    char_start: 0
    char_end: 22
- statement: Robin Moffatt is a technologist whose career spans from COBOL to Kafka.
  type: definition
  entity: Robin Moffatt
  keywords:
  - definition
  - robin
  - moffatt
  - technologist
  - whose
  - career
  - spans
  - cobol
  - kafka
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md
    quote: Robin is a technologist whose career spans from COBOL to Kafka!
    char_start: 0
    char_end: 63
- statement: Traditional files like `robots.txt` and `sitemap.xml` help search engines
    understand your site structure.
  type: definition
  entity: robots.txt
  keywords:
  - definition
  - traditional
  - files
  - like
  - robots
  - txt
  - sitemap
  - xml
  - help
  - search
  - engines
  - understand
  - site
  - structure
  source:
    doc: motherduck.com/blog/read-scaling-preview.md
    quote: Traditional files like `robots.txt` and `sitemap.xml` help search engines
      understand your site structure.
    char_start: 0
    char_end: 105
- statement: Row-Level Access Control (RLAC) is often overkill for startups.
  type: definition
  entity: Row-Level Access Control
  keywords:
  - definition
  - row
  - level
  - access
  - control
  - rlac
  - often
  - overkill
  - startups
  source:
    doc: motherduck.com/videos/4-lightning-talks-on-practical-ai-workflows-from-notion-1password-motherduck-evidence.md
    quote: RLAC, also known as Row-Level Security (RLS), restricts data access on
      a per-row basis according to user roles or attributes.
    char_start: 0
    char_end: 125
- statement: Row-Level Access Control introduces significant administrative complexity.
  type: definition
  entity: Row-Level Access Control
  keywords:
  - definition
  - row
  - level
  - access
  - control
  - introduces
  - significant
  - administrative
  - complexity
  source:
    doc: motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    quote: RLAC introduces significant administrative complexity.
    char_start: 0
    char_end: 54
- statement: rsync is used for synchronizing files.
  type: definition
  entity: rsync
  keywords:
  - definition
  - rsync
  - used
  - synchronizing
  - files
  source:
    doc: motherduck.com/blog/data-warehouse-feature-roundup-oct-2024.md
    quote: Rsync for a fast, versatile, synchronization tool to quickly back up or
      move data.
    char_start: 0
    char_end: 82
- statement: DuckDB can be directly queried as if they were tables.
  type: definition
  entity: Runji Wang
  keywords:
  - definition
  - duckdb
  - directly
  - queried
  - tables
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eight.md
    quote: DuckDB’s JSON extension so JSON files can be directly queried as if they
      were tables.
    char_start: 0
    char_end: 85
- statement: DuckDB can be used for spatial analysis with AWS Lambda.
  type: definition
  entity: Runji Wang
  keywords:
  - definition
  - duckdb
  - used
  - spatial
  - analysis
  - aws
  - lambda
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eight.md
    quote: Nabil Servais shared a very simple and straightforward way to make spatial
      analysis with AWS Lambda and DuckDB.
    char_start: 0
    char_end: 111
- statement: DuckDB can be used to build streaming applications with Streamlit.
  type: definition
  entity: Runji Wang
  keywords:
  - definition
  - duckdb
  - used
  - build
  - streaming
  - applications
  - streamlit
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eight.md
    quote: Octavian Zarzu showed us how to build a streaming application with the
      help of DuckDB and Streamlit.
    char_start: 0
    char_end: 100
- statement: DuckDB is used to explore TPC-DS benchmark queries.
  type: definition
  entity: Runji Wang
  keywords:
  - definition
  - duckdb
  - used
  - explore
  - tpc
  - ds
  - benchmark
  - queries
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eight.md
    quote: Carlin Eng just published a terrific blog post where he gave an overview
      of the TPC-DS dataset, with the queries translated to DuckDB.
    char_start: 0
    char_end: 134
- statement: Runji Wang develops low-level systems using Rust.
  type: definition
  entity: Runji Wang
  keywords:
  - definition
  - runji
  - wang
  - develops
  - low
  - level
  - systems
  - using
  - rust
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: Runji Wang from Beijing, China, enjoys developing low-level systems using
      Rust.
    char_start: 0
    char_end: 79
- statement: Rust is incredibly powerful when developing Python keybindings.
  type: definition
  entity: Rust
  keywords:
  - definition
  - rust
  - incredibly
  - powerful
  - developing
  - python
  - keybindings
  source:
    doc: motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw.md
    quote: Rust is incredibly powerful when developing Python keybindings.
    char_start: 0
    char_end: 63
- statement: Rusty Conover is a featured community member related to DuckDB.
  type: definition
  entity: Rusty Conover
  keywords:
  - definition
  - rusty
  - conover
  - featured
  - community
  - member
  - related
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eleven.md
    quote: Featured Community Member
    char_start: 0
    char_end: 25
- statement: Rusty Conover presented at DuckCon 2025 about connecting DuckDB to Apache
    Arrow.
  type: definition
  entity: Rusty Conover
  keywords:
  - definition
  - rusty
  - conover
  - presented
  - duckcon
  - '2025'
  - about
  - connecting
  - duckdb
  - apache
  - arrow
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: 'At DuckCon 2025, he presented ''Airport for DuckDB: Letting DuckDB Take
      Apache Arrow Flights.'''
    char_start: 0
    char_end: 93
- statement: Ryan Boyd will present on 'Data Analytics in the Post-Big-Data Era' at
    the OpenD/I Summit.
  type: definition
  entity: Ryan Boyd
  keywords:
  - definition
  - ryan
  - boyd
  - present
  - data
  - analytics
  - post
  - big
  - era
  - opend
  - summit
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: MotherDuck co-founder Ryan Boyd will present on 'Data Analytics in the
      Post-Big-Data Era.'
    char_start: 0
    char_end: 90
- statement: Ryan Boyd will speak at the Airbyte move(data) conference.
  type: definition
  entity: Ryan Boyd
  keywords:
  - definition
  - ryan
  - boyd
  - speak
  - airbyte
  - move
  - data
  - conference
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: MotherDuck co-founder Ryan Boyd will speak at the Airbyte move(data) conference
      on Fixing the data Engineering Lifecycle.
    char_start: 0
    char_end: 121
- statement: AWS Glue is a fully managed ETL service.
  type: definition
  entity: S3 Tables
  keywords:
  - definition
  - aws
  - glue
  - fully
  - managed
  - etl
  - service
  source:
    doc: motherduck.com/blog/pg-duckdb-release.md
    quote: AWS Glue is a fully managed extract, transform, and load (ETL) service.
    char_start: 0
    char_end: 71
- statement: The sales dataset is used to illustrate window functions.
  type: definition
  entity: sales
  keywords:
  - definition
  - sales
  - dataset
  - used
  - illustrate
  - window
  - functions
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-six.md
    quote: The sales dataset is used to illustrate window functions.
    char_start: 0
    char_end: 57
- statement: The sales_key_seq is used to auto-generate primary keys.
  type: definition
  entity: sales_key_seq
  keywords:
  - definition
  - sales
  - key
  - seq
  - used
  - auto
  - generate
  - primary
  - keys
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: CREATE SEQUENCE sales_key_seq START 1;
    char_start: 0
    char_end: 38
- statement: The query compares the average quantity of products sold historically
    and recently.
  type: definition
  entity: sales_trends_query
  keywords:
  - definition
  - query
  - compares
  - average
  - quantity
  - products
  - sold
  - historically
  - recently
  source:
    doc: motherduck.com/blog/semantic-layer-duckdb-tutorial.md
    quote: 'Let’s look at the actual query below which compares the average quantity
      of products sold:'
    char_start: 0
    char_end: 90
- statement: The sales_trends_query_task generates sales trends from recent e-commerce
    data.
  type: definition
  entity: sales_trends_query_task
  keywords:
  - definition
  - sales
  - trends
  - query
  - task
  - generates
  - recent
  - commerce
  - data
  source:
    doc: motherduck.com/blog/estuary-streaming-cdc-replication.md
    quote: A task that generates sales trends from recent e-commerce data.
    char_start: 0
    char_end: 63
- statement: The sales_trends_query_task runs a query to analyze sales trends using
    DuckDB.
  type: definition
  entity: sales_trends_query_task
  keywords:
  - definition
  - sales
  - trends
  - query
  - task
  - runs
  - analyze
  - using
  - duckdb
  source:
    doc: motherduck.com/blog/semantic-layer-duckdb-tutorial.md
    quote: sales_trends_query_task will have an input argument called mydf which is
      a pandas dataframe...
    char_start: 0
    char_end: 94
- statement: Salesforce can integrate with Stripe and HubSpot.
  type: definition
  entity: Salesforce
  keywords:
  - definition
  - salesforce
  - integrate
  - stripe
  - hubspot
  source:
    doc: motherduck.com/videos/duckfooding-at-motherduck.md
    quote: Salesforce can integrate with Stripe for payment processing.
    char_start: 0
    char_end: 60
- statement: Sam Ansmink has been a valuable member of the DuckDB Labs team for over
    a year.
  type: definition
  entity: Sam Ansmink
  keywords:
  - definition
  - sam
  - ansmink
  - valuable
  - member
  - duckdb
  - labs
  - team
  - over
  - year
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: Sam Ansmink has been a valuable member of the DuckDB Labs team for over
      a year.
    char_start: 0
    char_end: 79
- statement: As data volumes grow, applications must scale efficiently to handle increased
    load without compromising performance.
  type: definition
  entity: Scalability
  keywords:
  - definition
  - data
  - volumes
  - grow
  - applications
  - scale
  - efficiently
  - handle
  - increased
  - load
  - without
  - compromising
  - performance
  source:
    doc: motherduck.com/ecosystem.md
    quote: Scalability As data volumes grow, applications must scale efficiently to
      handle increased load without compromising performance.
    char_start: 0
    char_end: 128
- statement: Scalability is the ability to handle growing data volumes and user loads.
  type: definition
  entity: Scalability
  keywords:
  - definition
  - scalability
  - ability
  - handle
  - growing
  - data
  - volumes
  - user
  - loads
  source:
    doc: motherduck.com/case-studies/atm-com-analytics-costs-sql-expressibility.md
    quote: Scalability Design systems that can handle growing data volumes and user
      loads without significant architecture changes.
    char_start: 0
    char_end: 120
- statement: Seaborn can be combined with matplotlib for statistical visualizations
    on maps.
  type: definition
  entity: Seaborn
  keywords:
  - definition
  - seaborn
  - combined
  - matplotlib
  - statistical
  - visualizations
  - maps
  source:
    doc: motherduck.com/blog/motherduck-duckdb-dbt.md
    quote: 'Seaborn: While not geospatial-specific, it can be combined with matplotlib
      for statistical visualizations on maps.'
    char_start: 0
    char_end: 114
- statement: The feature 'search' is used by 369 distinct users.
  type: definition
  entity: search
  keywords:
  - definition
  - feature
  - search
  - used
  - '369'
  - distinct
  - users
  source:
    doc: motherduck.com/learn-more/pandas-dataframes-guide.md
    quote: '369'
    char_start: 0
    char_end: 3
- statement: SEC filings can be hundreds of pages long, but AI risks are typically
    only discussed in a few specific sections.
  type: definition
  entity: SEC filings
  keywords:
  - definition
  - sec
  - filings
  - hundreds
  - pages
  - long
  - ai
  - risks
  - typically
  - discussed
  - specific
  - sections
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: SEC filings can be hundreds of pages long, but AI risks are typically only
      discussed in a few specific sections.
    char_start: 0
    char_end: 112
- statement: SEC filings describe a company’s financial performance and operations,
    including key risk factors.
  type: definition
  entity: SEC filings
  keywords:
  - definition
  - sec
  - filings
  - describe
  - company
  - financial
  - performance
  - operations
  - including
  - key
  - risk
  - factors
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: The 10-K (annual) and 10-Q (quarterly) reports describe a company’s financial
      performance and operations, including key risk factors.
    char_start: 0
    char_end: 133
- statement: Secoda allows users to catalog all relevant data entities stored in MotherDuck.
  type: definition
  entity: Secoda
  keywords:
  - definition
  - secoda
  - allows
  - users
  - catalog
  - relevant
  - data
  - entities
  - stored
  - motherduck
  source:
    doc: motherduck.com/blog/secoda-motherduck-integration-modern-duck-stack.md
    quote: cataloging all relevant data entities such as views, columns, tables, and
      schemas stored in MotherDuck
    char_start: 0
    char_end: 102
- statement: Secoda and MotherDuck are collaborating for a masterclass.
  type: definition
  entity: Secoda
  keywords:
  - definition
  - secoda
  - motherduck
  - collaborating
  - masterclass
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md
    quote: Join Secoda and MotherDuck for a masterclass in using dbt, MotherDuck,
      and Secoda to enable data producers and consumers.
    char_start: 0
    char_end: 121
- statement: Secoda consolidates multiple tools into a single data management platform.
  type: definition
  entity: Secoda
  keywords:
  - definition
  - secoda
  - consolidates
  - multiple
  - tools
  - single
  - data
  - management
  - platform
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: Secoda consolidates multiple tools into a single data management platform
      to simplify your data catalog, lineage, governance, monitoring, and observability
      processes.
    char_start: 0
    char_end: 166
- statement: Secoda creates a single source of truth for an organization’s data.
  type: definition
  entity: Secoda
  keywords:
  - definition
  - secoda
  - creates
  - single
  - source
  - truth
  - organization
  - data
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: Secoda creates a single source of truth for an organization’s data by connecting
      to all data sources, models, pipelines, databases, warehouses, and visualization
      tools.
    char_start: 0
    char_end: 168
- statement: Secoda is a new member of the Modern Duck Stack.
  type: definition
  entity: Secoda
  keywords:
  - definition
  - secoda
  - new
  - member
  - modern
  - duck
  - stack
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: Secoda is a new member of the Modern Duck Stack.
    char_start: 0
    char_end: 48
- statement: Secoda provides an AI powered data catalog, observability, and governance
    platform.
  type: definition
  entity: Secoda
  keywords:
  - definition
  - secoda
  - provides
  - ai
  - powered
  - data
  - catalog
  - observability
  - governance
  - platform
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: Secoda is the command center for your data stack that provides an AI powered
      data catalog, observability, and governance platform to save you time and money.
    char_start: 0
    char_end: 157
- statement: Secoda sets monitors and thresholds to automatically detect data quality
    issues.
  type: definition
  entity: Secoda
  keywords:
  - definition
  - secoda
  - sets
  - monitors
  - thresholds
  - automatically
  - detect
  - data
  - quality
  - issues
  source:
    doc: motherduck.com/blog/secoda-motherduck-integration-modern-duck-stack.md
    quote: Set monitors and thresholds to automatically detect data quality issues.
    char_start: 0
    char_end: 72
- statement: Secoda simplifies how users find data using natural language search.
  type: definition
  entity: Secoda
  keywords:
  - definition
  - secoda
  - simplifies
  - users
  - find
  - data
  - using
  - natural
  - language
  - search
  source:
    doc: motherduck.com/blog/secoda-motherduck-integration-modern-duck-stack.md
    quote: Simplify how you find data using natural language search.
    char_start: 0
    char_end: 57
- statement: The MotherDuck x Secoda integration allows data producers and consumers
    to easily locate and access the data they need.
  type: definition
  entity: Secoda
  keywords:
  - definition
  - motherduck
  - secoda
  - integration
  - allows
  - data
  - producers
  - consumers
  - easily
  - locate
  - access
  - need
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-five.md
    quote: The MotherDuck x Secoda integration allows you to enable data producers
      and consumers, regardless of technical ability, to easily locate and access
      the data they need!
    char_start: 0
    char_end: 167
- statement: The integration simplifies data lineage tracking.
  type: definition
  entity: Secoda AI
  keywords:
  - definition
  - integration
  - simplifies
  - data
  - lineage
  - tracking
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: The integration simplifies data lineage tracking by providing clear and
      accessible visualizations of data lineage across MotherDuck and other data sources.
    char_start: 0
    char_end: 155
- statement: The integration streamlines the process of accessing new data.
  type: definition
  entity: Secoda AI
  keywords:
  - definition
  - integration
  - streamlines
  - process
  - accessing
  - new
  - data
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: The integration streamlines the process of accessing new data, allowing
      users to quickly find and use live, shared, and governed data sets.
    char_start: 0
    char_end: 139
- statement: Users can automatically generate documentation of new tables, columns,
    and schemas in MotherDuck.
  type: definition
  entity: Secoda AI
  keywords:
  - definition
  - users
  - automatically
  - generate
  - documentation
  - new
  - tables
  - columns
  - schemas
  - motherduck
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: With Secoda AI, users can automatically generate documentation of new tables,
      columns, and schemas in MotherDuck.
    char_start: 0
    char_end: 113
- statement: Security incorporates robust data protection measures.
  type: definition
  entity: Security
  keywords:
  - definition
  - security
  - incorporates
  - robust
  - data
  - protection
  - measures
  source:
    doc: motherduck.com/case-studies/atm-com-analytics-costs-sql-expressibility.md
    quote: Security Incorporate robust data protection measures, including encryption,
      access controls, and audit trails.
    char_start: 0
    char_end: 110
- statement: With growing concerns about data privacy, developers must implement robust
    security measures and comply with regulations like GDPR or CCPA.
  type: definition
  entity: Security and Privacy
  keywords:
  - definition
  - growing
  - concerns
  - about
  - data
  - privacy
  - developers
  - implement
  - robust
  - security
  - measures
  - comply
  - regulations
  - like
  - gdpr
  - ccpa
  source:
    doc: motherduck.com/ecosystem.md
    quote: Security and Privacy With growing concerns about data privacy, developers
      must implement robust security measures and comply with regulations like GDPR
      or CCPA.
    char_start: 0
    char_end: 160
- statement: 'The foundation of every single query you''ll ever write rests on two
    words: `SELECT` and `FROM`.'
  type: definition
  entity: SELECT
  keywords:
  - definition
  - foundation
  - every
  - single
  - query
  - ll
  - ever
  - write
  - rests
  - two
  - words
  - select
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md
    quote: 'The foundation of every single query you''ll ever write rests on two words:
      `SELECT` and `FROM`.'
    char_start: 0
    char_end: 95
- statement: Self-service analytics empowers teams to use collaborative tools and
    embed real-time dashboards affordably.
  type: definition
  entity: Self-Service Analytics
  keywords:
  - definition
  - self
  - service
  - analytics
  - empowers
  - teams
  - use
  - collaborative
  - tools
  - embed
  - real
  - time
  - dashboards
  - affordably
  source:
    doc: motherduck.com/blog/why-web-developers-should-care-about-analytical-databases.md
    quote: Unlock growth with our guide to self-service analytics for startups.
    char_start: 0
    char_end: 68
- statement: A semantic layer allows for dynamic data aggregation without the need
    for reprocessing ETL jobs.
  type: definition
  entity: semantic layer
  keywords:
  - definition
  - semantic
  - layer
  - allows
  - dynamic
  - data
  - aggregation
  - without
  - need
  - reprocessing
  - etl
  - jobs
  source:
    doc: motherduck.com/blog/getting-started-ducklake-table-format.md
    quote: A semantic layer, or ad hoc queries, does that on the fly.
    char_start: 0
    char_end: 58
- statement: A semantic layer allows users to compose queries in concepts they understand.
  type: definition
  entity: semantic layer
  keywords:
  - definition
  - semantic
  - layer
  - allows
  - users
  - compose
  - queries
  - concepts
  - understand
  source:
    doc: motherduck.com/blog/getting-started-ducklake-table-format.md
    quote: A semantic layer, also known as a metrics layer, lies between business
      users and the database, and lets those users compose queries in the concepts
      that they understand.
    char_start: 0
    char_end: 169
- statement: A semantic layer provides a single source of truth for business metrics.
  type: definition
  entity: semantic layer
  keywords:
  - definition
  - semantic
  - layer
  - provides
  - single
  - source
  - truth
  - business
  - metrics
  source:
    doc: motherduck.com/blog/pushing-geo-boundaries-with-motherduck-geobase.md
    quote: With a semantic layer, your revenue KPI or other complex company measures
      are defined once in a single source of truth.
    char_start: 0
    char_end: 119
- statement: Ad hoc queries must be flexible and change granularity based on added
    dimensions.
  type: definition
  entity: semantic layer
  keywords:
  - definition
  - ad
  - hoc
  - queries
  - flexible
  - change
  - granularity
  - based
  - added
  - dimensions
  source:
    doc: motherduck.com/blog/getting-started-ducklake-table-format.md
    quote: Ad hoc queries must be flexible and change granularity based on added dimensions.
    char_start: 0
    char_end: 81
- statement: Semantic layers bridge the gap between business needs and data source
    integration.
  type: definition
  entity: semantic layer
  keywords:
  - definition
  - semantic
  - layers
  - bridge
  - gap
  - business
  - needs
  - data
  - source
  - integration
  source:
    doc: motherduck.com/blog/pushing-geo-boundaries-with-motherduck-geobase.md
    quote: More broadly, semantic layers bridge the gap between business needs and
      data source integration in a very organized and governed way.
    char_start: 0
    char_end: 133
- statement: Semantic layers provide one definition that works across all platforms.
  type: definition
  entity: semantic layer
  keywords:
  - semantic
  - layers
  - provide
  - one
  - definition
  - works
  - across
  - platforms
  source:
    doc: motherduck.com/blog/getting-started-ducklake-table-format.md
    quote: Instead of maintaining separate calculated fields and business logic in
      each tool in a proprietary format, semantic layers provide one definition that
      works across all platforms.
    char_start: 0
    char_end: 178
- statement: The semantic layer acts as a translation layer between raw data and business
    concepts.
  type: definition
  entity: semantic layer
  keywords:
  - definition
  - semantic
  - layer
  - acts
  - translation
  - raw
  - data
  - business
  - concepts
  source:
    doc: motherduck.com/learn-more/hybrid-analytics-guide.md
    quote: A core component of this strategy is the semantic layer.
    char_start: 0
    char_end: 56
- statement: The semantic layer can directly query various data sources without moving
    them into a data lake.
  type: definition
  entity: semantic layer
  keywords:
  - definition
  - semantic
  - layer
  - directly
  - query
  - various
  - data
  - sources
  - without
  - moving
  - them
  - lake
  source:
    doc: motherduck.com/blog/getting-started-ducklake-table-format.md
    quote: For a non-production or high-load OLTP source, the semantic layer can directly
      query the various data sources instead of moving them into a data lake.
    char_start: 0
    char_end: 150
- statement: The semantic layer provides consistent metrics across any tool in your
    data stack.
  type: definition
  entity: semantic layer
  keywords:
  - definition
  - semantic
  - layer
  - provides
  - consistent
  - metrics
  - across
  - any
  - tool
  - data
  - stack
  source:
    doc: motherduck.com/blog/pushing-geo-boundaries-with-motherduck-geobase.md
    quote: The beauty of semantic layers lies in their empowering approach to working
      with metrics, complemented by advanced features, but also with a simple solution
      like we implemented here.
    char_start: 0
    char_end: 181
- statement: The SemanticModel defines dimensions and measures for data analysis.
  type: definition
  entity: SemanticModel
  keywords:
  - definition
  - semanticmodel
  - defines
  - dimensions
  - measures
  - data
  - analysis
  source:
    doc: motherduck.com/blog/estuary-streaming-cdc-replication.md
    quote: SemanticModel(table=tbl, dimensions={...})
    char_start: 0
    char_end: 42
- statement: Sentence Transformers are used for sentence embeddings.
  type: definition
  entity: Sentence Transformers
  keywords:
  - definition
  - sentence
  - transformers
  - used
  - embeddings
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2024.md
    quote: Embedding Model with HuggingFace and Sentence Transformers
    char_start: 0
    char_end: 58
- statement: Sentiment analysis is a technique in natural language processing.
  type: definition
  entity: Sentiment Analysis
  keywords:
  - definition
  - sentiment
  - analysis
  - technique
  - natural
  - language
  - processing
  source:
    doc: motherduck.com/blog/making-pyspark-code-faster-with-duckdb.md
    quote: Sentiment analysis is a technique in natural language processing that identifies
      sentiments in text.
    char_start: 0
    char_end: 100
- statement: Sentiment analysis is the process of determining the emotional tone behind
    a series of words.
  type: definition
  entity: Sentiment Analysis
  keywords:
  - definition
  - sentiment
  - analysis
  - process
  - determining
  - emotional
  - tone
  - behind
  - series
  - words
  source:
    doc: motherduck.com/blog/fabi-ai-llm-prompt-analysis.md
    quote: What is sentiment analysis, and what makes it challenging?
    char_start: 0
    char_end: 58
- statement: Traditional sentiment analysis methods struggle with context, sarcasm,
    and adapting to new domains.
  type: definition
  entity: Sentiment Analysis
  keywords:
  - definition
  - traditional
  - sentiment
  - analysis
  - methods
  - struggle
  - context
  - sarcasm
  - adapting
  - new
  - domains
  source:
    doc: motherduck.com/blog/motherduck-in-europe.md
    quote: Traditional sentiment analysis methods, like rule-based systems and ML
      models, often struggle with context, sarcasm, and adapting to new domains.
    char_start: 0
    char_end: 145
- statement: Serverless Computing leverages cloud provider-managed services for scalable,
    event-driven data processing without infrastructure management.
  type: definition
  entity: Serverless Computing
  keywords:
  - definition
  - serverless
  - computing
  - leverages
  - cloud
  - provider
  - managed
  - services
  - scalable
  - event
  - driven
  - data
  - processing
  - without
  - infrastructure
  - management
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: Serverless Computing Leveraging cloud provider-managed services for scalable,
      event-driven data processing without infrastructure management.
    char_start: 0
    char_end: 141
- statement: Serverless Data Processing improves scalability and reduces operational
    overhead.
  type: definition
  entity: Serverless Data Processing
  keywords:
  - definition
  - serverless
  - data
  - processing
  - improves
  - scalability
  - reduces
  - operational
  - overhead
  source:
    doc: motherduck.com/learn-more/data-application.md
    quote: Leveraging cloud-native, serverless architectures for data processing tasks,
      improving scalability and reducing operational overhead.
    char_start: 0
    char_end: 133
- statement: The average session duration is approximately 911406.71 milliseconds.
  type: definition
  entity: Session Duration
  keywords:
  - definition
  - average
  - session
  - duration
  - approximately
  - '911406.71'
  - milliseconds
  source:
    doc: motherduck.com/learn-more/no-etl-query-raw-files.md
    quote: │ average_session_duration_ms │ 911406.7083965256 │
    char_start: 0
    char_end: 51
- statement: Session windowing involves counting the number of users on a website
    over a brief period.
  type: definition
  entity: session windowing
  keywords:
  - definition
  - session
  - windowing
  - involves
  - counting
  - number
  - users
  - website
  - over
  - brief
  - period
  source:
    doc: motherduck.com/blog/galileo-world-geospatial.md
    quote: A user session spans their first page visit to 5 minutes after their last
      page visit.
    char_start: 0
    char_end: 85
- statement: The average number of sessions per user is approximately 14.51.
  type: definition
  entity: Sessions per User
  keywords:
  - definition
  - average
  - number
  - sessions
  - per
  - user
  - approximately
  - '14.51'
  source:
    doc: motherduck.com/learn-more/no-etl-query-raw-files.md
    quote: │ average_sessions_per_user │ 14.506 │
    char_start: 0
    char_end: 38
- statement: The feature 'settings' is used by 353 distinct users.
  type: definition
  entity: settings
  keywords:
  - definition
  - feature
  - settings
  - used
  - '353'
  - distinct
  - users
  source:
    doc: motherduck.com/learn-more/pandas-dataframes-guide.md
    quote: '353'
    char_start: 0
    char_end: 3
- statement: Shares allow users to access the same dataset as a zero-copy clone without
    duplicating data.
  type: definition
  entity: Shares
  keywords:
  - definition
  - shares
  - allow
  - users
  - access
  - dataset
  - zero
  - copy
  - clone
  - without
  - duplicating
  - data
  source:
    doc: motherduck.com/blog/duckdb-cognee-sql-analytics-graph-rag.md
    quote: Shares are read-only databases designed for collaboration and ad-hoc analytics.
      They allow users to access the same dataset as a zero-copy clone without duplicating
      data.
    char_start: 0
    char_end: 170
- statement: Shares are read-only databases that are purpose-built for data collaboration
    and ad-hoc analytics.
  type: feature
  entity: Shares
  keywords:
  - feature
  - shares
  - read
  - databases
  - purpose
  - built
  - data
  - collaboration
  - ad
  - hoc
  - analytics
  source:
    doc: motherduck.com/blog/duckdb-110-hidden-gems.md
    quote: Shares are read-only databases that are purpose-built for data collaboration
      and ad-hoc analytics.
    char_start: 0
    char_end: 98
- statement: SHARES provide read-only access to specific databases.
  type: definition
  entity: Shares
  keywords:
  - definition
  - shares
  - provide
  - read
  - access
  - specific
  - databases
  source:
    doc: motherduck.com/learn-more/hybrid-analytics-guide.md
    quote: Data can be stored once and shared securely using SHARES.
    char_start: 0
    char_end: 57
- statement: Shearwater is a specialized data consultancy focused on Self-Service
    Analytics founded by Looker alumni with 15+ years of experience in BI.
  type: definition
  entity: Shearwater
  keywords:
  - definition
  - shearwater
  - specialized
  - data
  - consultancy
  - focused
  - self
  - service
  - analytics
  - founded
  - looker
  - alumni
  - '15'
  - years
  - experience
  - bi
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: Shearwater is a specialized data consultancy focused on Self-Service Analytics
      founded by Looker alumni with 15+ years of experience in BI.
    char_start: 0
    char_end: 139
- statement: Experienced teams adopt Shift Left architectures because they mean fewer
    moving parts, fewer surprises downstream.
  type: definition
  entity: Shift Left
  keywords:
  - definition
  - experienced
  - teams
  - adopt
  - shift
  - left
  - architectures
  - mean
  - fewer
  - moving
  - parts
  - surprises
  - downstream
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part2.md
    quote: Experienced teams adopt Shift Left architectures because they mean fewer
      moving parts, fewer surprises downstream.
    char_start: 0
    char_end: 114
- statement: Implementing a Shift Left strategy is a practical imperative for organizations
    seeking to derive maximum value from their data.
  type: definition
  entity: Shift Left
  keywords:
  - definition
  - implementing
  - shift
  - left
  - strategy
  - practical
  - imperative
  - organizations
  - seeking
  - derive
  - maximum
  - value
  - data
  source:
    doc: motherduck.com/learn-more/columnar-storage-guide.md
    quote: Implementing a Shift Left strategy is a practical imperative for organizations
      seeking to derive maximum value from their data in today's dynamic environments.
    char_start: 0
    char_end: 159
- statement: Shift Left is how modern teams move fast without breaking things.
  type: definition
  entity: Shift Left
  keywords:
  - definition
  - shift
  - left
  - modern
  - teams
  - move
  - fast
  - without
  - breaking
  - things
  source:
    doc: motherduck.com/blog/streaming-data-to-motherduck.md
    quote: Shift Left is how modern teams move fast without breaking things.
    char_start: 0
    char_end: 65
- statement: The Shift Left concept originates from other domains, where testing is
    pushed earlier into the development cycle.
  type: definition
  entity: Shift Left
  keywords:
  - definition
  - shift
  - left
  - concept
  - originates
  - domains
  - testing
  - pushed
  - earlier
  - development
  - cycle
  source:
    doc: motherduck.com/learn-more/columnar-storage-guide.md
    quote: The Shift Left concept originates from other domains, where testing is
      pushed earlier into the development cycle.
    char_start: 0
    char_end: 113
- statement: The Ship Tracks site is now live so that you can discover more patterns
    and stories in the data.
  type: definition
  entity: Ship Tracks
  keywords:
  - definition
  - ship
  - tracks
  - site
  - now
  - live
  - discover
  - patterns
  - stories
  - data
  source:
    doc: motherduck.com/blog/semantic-layer-duckdb-tutorial.md
    quote: The Ship Tracks site is now live so that you can discover more patterns
      and stories in the data.
    char_start: 0
    char_end: 96
- statement: Shuffle Join is a type of join operation that involves redistributing
    data across nodes.
  type: definition
  entity: Shuffle Join
  keywords:
  - definition
  - shuffle
  - join
  - type
  - operation
  - involves
  - redistributing
  - data
  - across
  - nodes
  source:
    doc: motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md
    quote: A type of join operation that involves redistributing data across nodes.
    char_start: 0
    char_end: 72
- statement: Sigma Computing is a next-generation analytics and business intelligence
    platform.
  type: definition
  entity: Sigma Computing
  keywords:
  - definition
  - sigma
  - computing
  - next
  - generation
  - analytics
  - business
  - intelligence
  - platform
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: 'Sigma Computing: Next-generation analytics and business intelligence platform.'
    char_start: 0
    char_end: 78
- statement: The conference was held in Santiago, Chile.
  type: definition
  entity: SIGMOD PODS 2024
  keywords:
  - definition
  - conference
  - held
  - santiago
  - chile
  source:
    doc: motherduck.com/blog/motherduck-in-europe.md
    quote: It was a hub of intellectual exchange and collaboration, which made for
      an inspiring and productive week in Santiago, Chile for the MotherDuck team.
    char_start: 0
    char_end: 148
- statement: The SIGMOD/PODS 2024 conference highlighted ongoing advancements in database
    technologies.
  type: definition
  entity: SIGMOD/PODS 2024
  keywords:
  - definition
  - sigmod
  - pods
  - '2024'
  - conference
  - highlighted
  - ongoing
  - advancements
  - database
  - technologies
  source:
    doc: motherduck.com/blog/making-pyspark-code-faster-with-duckdb.md
    quote: The SIGMOD/PODS 2024 conference highlighted ongoing advancements in database
      technologies.
    char_start: 0
    char_end: 90
- statement: Simon Aubury and Ned Letcher are authors of 'Getting Started with DuckDB'.
  type: definition
  entity: Simon Aubury
  keywords:
  - definition
  - simon
  - aubury
  - ned
  - letcher
  - authors
  - getting
  - started
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-five.md
    quote: Simon Aubury and Ned Letcher, authors of Getting Started with DuckDB, bring
      a wealth of experience in data engineering and software development.
    char_start: 0
    char_end: 144
- statement: Simon is a Data Engineer and Technical Author with 20+ years of experience.
  type: definition
  entity: Simon Späti
  keywords:
  - definition
  - simon
  - data
  - engineer
  - technical
  - author
  - '20'
  - years
  - experience
  source:
    doc: motherduck.com/blog/MotherDuck-Visualize-Embeddings-Marimo.md
    quote: Simon is a Data Engineer and Technical Author with 20+ years of experience
      in the data field.
    char_start: 0
    char_end: 93
- statement: Simon Späti authored the blog posts featured in the document.
  type: definition
  entity: Simon Späti
  keywords:
  - definition
  - simon
  - sp
  - ti
  - authored
  - blog
  - posts
  - featured
  - document
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: 2025/10/30 - Simon Späti
    char_start: 0
    char_end: 24
- statement: Simon Späti has over 20 years of experience in the data field.
  type: definition
  entity: Simon Späti
  keywords:
  - definition
  - simon
  - sp
  - ti
  - over
  - '20'
  - years
  - experience
  - data
  - field
  source:
    doc: motherduck.com/blog/big-data-is-dead.md
    quote: Simon is a Data Engineer and Technical Author with 20+ years of experience
      in the data field.
    char_start: 0
    char_end: 93
- statement: The panel of experts provides practical wisdom for data engineers.
  type: definition
  entity: Simon Späti
  keywords:
  - definition
  - panel
  - experts
  - provides
  - practical
  - wisdom
  - data
  - engineers
  source:
    doc: motherduck.com/blog/big-data-is-dead.md
    quote: What emerged is genuinely exciting with practical wisdom from people who've
      faced these exact challenges.
    char_start: 0
    char_end: 105
- statement: Single database attach mode simplifies the connection process when you
    are only working with a single database.
  type: feature
  entity: single database attach mode
  keywords:
  - feature
  - single
  - database
  - attach
  - mode
  - simplifies
  - connection
  - process
  - working
  source:
    doc: motherduck.com/blog/duckdb-110-hidden-gems.md
    quote: Single database attach mode simplifies the connection process when you
      are only working with a single database.
    char_start: 0
    char_end: 111
- statement: Ritschel found switching back to SingleStore's syntax increasingly painful.
  type: definition
  entity: SingleStore
  keywords:
  - definition
  - ritschel
  - found
  - switching
  - back
  - singlestore
  - syntax
  - increasingly
  - painful
  source:
    doc: motherduck.com/blog/the-future-of-bi-bi-as-code-duckdb-impact.md
    quote: found switching back to SingleStore's syntax increasingly painful.
    char_start: 0
    char_end: 66
- statement: SingleStore can scan more than 3B rows per second per core.
  type: performance
  entity: SingleStore
  keywords:
  - performance
  - singlestore
  - scan
  - 3b
  - rows
  - per
  - second
  - core
  source:
    doc: motherduck.com/ecosystem.md
    quote: SingleStore has an old blog post and demo showing that they can scan more
      than 3B rows per second per core.
    char_start: 0
    char_end: 107
- statement: 'SingleStore''s pricing model meant costs could only go in one direction:
    up.'
  type: definition
  entity: SingleStore
  keywords:
  - definition
  - singlestore
  - pricing
  - model
  - meant
  - costs
  - go
  - one
  - direction
  - up
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: I saw costs balloon with SingleStore with no sign of remediation in sight.
    char_start: 0
    char_end: 74
- statement: The technical limitations of SingleStore created an unexpected problem.
  type: definition
  entity: SingleStore
  keywords:
  - definition
  - technical
  - limitations
  - singlestore
  - created
  - unexpected
  - problem
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: SingleStore's ingest functionality... created an unexpected problem.
    char_start: 0
    char_end: 68
- statement: SingleStoreDB Cloud is real-time transactional analytics (HTAP).
  type: definition
  entity: SingleStoreDB Cloud
  keywords:
  - definition
  - singlestoredb
  - cloud
  - real
  - time
  - transactional
  - analytics
  - htap
  source:
    doc: motherduck.com/learn-more/secure-startup-data-warehouse.md
    quote: Real-time transactional analytics (HTAP).
    char_start: 0
    char_end: 41
- statement: Sling Data integrates with MotherDuck by leveraging its comprehensive
    connector library.
  type: integration
  entity: Sling Data
  keywords:
  - integration
  - sling
  - data
  - integrates
  - motherduck
  - leveraging
  - comprehensive
  - connector
  - library
  source:
    doc: motherduck.com/ecosystem.md
    quote: Sling Data integrates with MotherDuck by leveraging its comprehensive connector
      library to facilitate seamless data transfer.
    char_start: 0
    char_end: 125
- statement: Sling Data is a modern data integration platform that enables seamless
    data movement across various sources and destinations.
  type: definition
  entity: Sling Data
  keywords:
  - definition
  - sling
  - data
  - modern
  - integration
  - platform
  - enables
  - seamless
  - movement
  - across
  - various
  - sources
  - destinations
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: Sling Data is a modern data integration platform that enables seamless
      data movement across various sources and destinations.
    char_start: 0
    char_end: 125
- statement: Most data warehouses use Type 2 for critical business dimensions where
    historical accuracy matters.
  type: definition
  entity: Slowly Changing Dimensions
  keywords:
  - definition
  - data
  - warehouses
  - use
  - type
  - critical
  - business
  - dimensions
  - historical
  - accuracy
  - matters
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: Most data warehouses use Type 2 for critical business dimensions where
      historical accuracy matters.
    char_start: 0
    char_end: 99
- statement: Small AI models run locally for fast, private, and cost-efficient development.
  type: definition
  entity: Small AI
  keywords:
  - definition
  - small
  - ai
  - models
  - run
  - locally
  - fast
  - private
  - cost
  - efficient
  - development
  source:
    doc: motherduck.com/videos.md
    quote: Discover how small AI models run locally for fast, private, and cost-efficient
      development.
    char_start: 0
    char_end: 91
- statement: Small models excel when combined with existing data through techniques
    like Retrieval Augmented Generation (RAG).
  type: definition
  entity: Small AI
  keywords:
  - definition
  - small
  - models
  - excel
  - combined
  - existing
  - data
  - techniques
  - like
  - retrieval
  - augmented
  - generation
  - rag
  source:
    doc: motherduck.com/blog/dosomething-motherduck-data-warehouse-ROI.md
    quote: Small models excel when combined with existing data through techniques
      like Retrieval Augmented Generation (RAG).
    char_start: 0
    char_end: 113
- statement: Small models offer flexibility in deployment.
  type: definition
  entity: Small AI
  keywords:
  - definition
  - small
  - models
  - offer
  - flexibility
  - deployment
  source:
    doc: motherduck.com/blog/dosomething-motherduck-data-warehouse-ROI.md
    quote: Small models offer flexibility in deployment - whether local, cloud, or
      hybrid without being locked into specific cloud providers or infrastructure
      requirements.
    char_start: 0
    char_end: 161
- statement: Small models run significantly faster than large models due to fewer
    parameters.
  type: definition
  entity: Small AI
  keywords:
  - definition
  - small
  - models
  - run
  - significantly
  - faster
  - large
  - due
  - fewer
  - parameters
  source:
    doc: motherduck.com/blog/dosomething-motherduck-data-warehouse-ROI.md
    quote: Small models run significantly faster than large models due to fewer parameters
      (computational time is quadratic with parameter count).
    char_start: 0
    char_end: 135
- statement: The same philosophy around Small Data also applies to Small AI.
  type: definition
  entity: Small AI
  keywords:
  - definition
  - philosophy
  - around
  - small
  - data
  - also
  - applies
  - ai
  source:
    doc: motherduck.com/blog/MotherDuck-Visualize-Embeddings-Marimo.md
    quote: This same philosophy around Small Data also applies to Small AI.
    char_start: 0
    char_end: 64
- statement: A new small-data playbook can help you find real meaning in your metrics.
  type: definition
  entity: Small Data
  keywords:
  - definition
  - new
  - small
  - data
  - playbook
  - help
  - find
  - real
  - meaning
  - metrics
  source:
    doc: motherduck.com/videos.md
    quote: a new small-data playbook can help you find real meaning in your metrics.
    char_start: 0
    char_end: 73
- statement: Data and AI that was once 'Big' can now be handled by a single machine.
  type: definition
  entity: Small Data
  keywords:
  - definition
  - data
  - ai
  - big
  - now
  - handled
  - single
  - machine
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: Data and AI that was once 'Big' can now be handled by a single machine.
    char_start: 0
    char_end: 71
- statement: Small data and AI is more powerful than you think.
  type: definition
  entity: Small Data
  keywords:
  - definition
  - small
  - data
  - ai
  - powerful
  - think
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: Small data and AI is more powerful than you think.
    char_start: 0
    char_end: 50
- statement: Small Data is a philosophy that embraces efficiency in making big data
    feel small.
  type: definition
  entity: Small Data
  keywords:
  - definition
  - small
  - data
  - philosophy
  - embraces
  - efficiency
  - making
  - big
  - feel
  source:
    doc: motherduck.com/blog/MotherDuck-Visualize-Embeddings-Marimo.md
    quote: 'Small Data isn''t just about data that fits on a single machine—it''s
      a philosophy that embraces: Efficiency in making big data feel small.'
    char_start: 0
    char_end: 137
- statement: Small Data is a very important trend.
  type: definition
  entity: Small Data
  keywords:
  - definition
  - small
  - data
  - important
  - trend
  source:
    doc: motherduck.com/blog/motherduck-data-warehouse.md
    quote: “I think Small Data is a very important trend…maybe the most important
      trend right now.” – George Fraser, Fivetran Founder and CEO
    char_start: 0
    char_end: 130
- statement: Small Data is bigger (and hotter) than ever.
  type: definition
  entity: Small Data
  keywords:
  - definition
  - small
  - data
  - bigger
  - hotter
  - ever
  source:
    doc: motherduck.com/blog/announcing-ducklake-support-motherduck-preview.md
    quote: Small Data is bigger (and hotter 🔥) than ever
    char_start: 0
    char_end: 45
- statement: The industry's shift toward more efficient solutions is captured in the
    blog post.
  type: definition
  entity: Small Data Manifesto
  keywords:
  - definition
  - industry
  - shift
  - toward
  - efficient
  - solutions
  - captured
  - blog
  - post
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part2.md
    quote: The industry's shift toward these more efficient solutions is captured
      in our blog post, The Simple Joys of Scaling Up.
    char_start: 0
    char_end: 119
- statement: Developing locally is effective and efficient.
  type: definition
  entity: Small Data SF
  keywords:
  - definition
  - developing
  - locally
  - effective
  - efficient
  source:
    doc: motherduck.com/blog/small-data-sf-recap-2025.md
    quote: Developing locally Just Works
    char_start: 0
    char_end: 29
- statement: More data does not necessarily lead to better results.
  type: definition
  entity: Small Data SF
  keywords:
  - definition
  - data
  - necessarily
  - lead
  - better
  - results
  source:
    doc: motherduck.com/blog/small-data-sf-recap-2025.md
    quote: More data ≠ better results
    char_start: 0
    char_end: 26
- statement: Small Data SF has added an additional day of hands-on workshops.
  type: definition
  entity: Small Data SF
  keywords:
  - definition
  - small
  - data
  - sf
  - added
  - additional
  - day
  - hands
  - workshops
  source:
    doc: motherduck.com/blog/motherduck-window-functions-in-sql.md
    quote: We decided to add an additional day of hands-on workshops!
    char_start: 0
    char_end: 58
- statement: Small Data SF includes workshops on September 23rd.
  type: definition
  entity: Small Data SF
  keywords:
  - definition
  - small
  - data
  - sf
  - includes
  - workshops
  - september
  - 23rd
  source:
    doc: motherduck.com/blog/just-enough-sql-for-ai.md
    quote: we have now added a half-day of Workshops to Small Data SF on **Monday,
      September 23rd**.
    char_start: 0
    char_end: 89
- statement: Small Data SF is a hands-on conference for builders creating faster,
    simpler, more cost-effective systems.
  type: definition
  entity: Small Data SF
  keywords:
  - definition
  - small
  - data
  - sf
  - hands
  - conference
  - builders
  - creating
  - faster
  - simpler
  - cost
  - effective
  - systems
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: For the second year in a row, data practitioners from around the globe
      joined us for Small Data SF, the hands-on conference for builders creating faster,
      simpler, more cost-effective systems.
    char_start: 0
    char_end: 191
- statement: Small Data SF is returning to San Francisco on November 4-5, 2025.
  type: definition
  entity: Small Data SF
  keywords:
  - definition
  - small
  - data
  - sf
  - returning
  - san
  - francisco
  - november
  - '2025'
  source:
    doc: motherduck.com/blog/MotherDuck-Visualize-Embeddings-Marimo.md
    quote: we're thrilled to announce that Small Data SF is returning to San Francisco
      on November 4-5, 2025!
    char_start: 0
    char_end: 98
- statement: Small Data SF is shifting focus from big data to small data.
  type: definition
  entity: Small Data SF
  keywords:
  - definition
  - small
  - data
  - sf
  - shifting
  - focus
  - big
  source:
    doc: motherduck.com/blog/big-data-is-dead.md
    quote: It's fascinating how we're seeing this shift from 'big' to 'small' — not
      in terms of scale but in terms of focus and efficiency.
    char_start: 0
    char_end: 128
- statement: Small Data SF sets a new standard for data conferences.
  type: definition
  entity: Small Data SF
  keywords:
  - definition
  - small
  - data
  - sf
  - sets
  - new
  - standard
  - conferences
  source:
    doc: motherduck.com/blog/MotherDuck-Visualize-Embeddings-Marimo.md
    quote: '"Small Data SF sets a new standard for data conferences!" - Celina Wong,
      Data Culture'
    char_start: 0
    char_end: 85
- statement: Small Data SF would not have been possible without our friends at Turso
    and Ollama.
  type: definition
  entity: Small Data SF
  keywords:
  - definition
  - small
  - data
  - sf
  - possible
  - without
  - friends
  - turso
  - ollama
  source:
    doc: motherduck.com/blog/motherduck-kestra-etl-pipelines.md
    quote: Small Data SF would not have been possible without our friends at Turso
      and Ollama.
    char_start: 0
    char_end: 83
- statement: The concept of Small Data and its ‘less is more’ approach are poised
    to have transformative impact.
  type: definition
  entity: Small Data SF
  keywords:
  - definition
  - concept
  - small
  - data
  - less
  - approach
  - poised
  - transformative
  - impact
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: It’s clear that the concept of Small Data and its ‘less is more’ approach
      are poised to have transformative impact.
    char_start: 0
    char_end: 115
- statement: The conference featured eight hands-on, technical workshops.
  type: definition
  entity: Small Data SF
  keywords:
  - definition
  - conference
  - featured
  - eight
  - hands
  - technical
  - workshops
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: where we welcomed our intrepid presenters for eight hands-on, technical
      workshops.
    char_start: 0
    char_end: 82
- statement: The conference includes hands-on workshops and talks from industry leaders.
  type: definition
  entity: Small Data SF
  keywords:
  - definition
  - conference
  - includes
  - hands
  - workshops
  - talks
  - industry
  - leaders
  source:
    doc: motherduck.com/blog/big-data-is-dead.md
    quote: 'Day 1 (November 4): Hands-on workshops... Day 2 (November 5): A full day
      of talks from industry leaders.'
    char_start: 0
    char_end: 104
- statement: The event featured 14 keynote and technical sessions.
  type: definition
  entity: Small Data SF
  keywords:
  - definition
  - event
  - featured
  - '14'
  - keynote
  - technical
  - sessions
  source:
    doc: motherduck.com/blog/duckdb-wasm-in-browser.md
    quote: '- 14 keynote and technical sessions'
    char_start: 0
    char_end: 35
- statement: The inaugural event brought together over 260 attendees.
  type: definition
  entity: Small Data SF
  keywords:
  - definition
  - inaugural
  - event
  - brought
  - together
  - over
  - '260'
  - attendees
  source:
    doc: motherduck.com/blog/MotherDuck-Visualize-Embeddings-Marimo.md
    quote: After an incredible inaugural event that brought together over 260 attendees.
    char_start: 0
    char_end: 77
- statement: 'The most exciting part of Small Data SF wasn’t just the talks: It was
    the group of people who came together to build this movement.'
  type: definition
  entity: Small Data SF
  keywords:
  - definition
  - exciting
  - part
  - small
  - data
  - sf
  - wasn
  - talks
  - group
  - people
  - who
  - came
  - together
  - build
  - movement
  source:
    doc: motherduck.com/blog/small-data-sf-recap.md
    quote: 'The most exciting part of Small Data SF wasn’t just the talks: It was
      the group of people who came together to build this movement.'
    char_start: 0
    char_end: 131
- statement: The people want more opportunities to come together around Small Data.
  type: definition
  entity: Small Data SF
  keywords:
  - definition
  - people
  - want
  - opportunities
  - come
  - together
  - around
  - small
  - data
  source:
    doc: motherduck.com/blog/motherduck-kestra-etl-pipelines.md
    quote: 'The overwhelming feedback we have received points to one key theme: The
      people want more opportunities to come together around Small Data!'
    char_start: 0
    char_end: 138
- statement: Workshops are included in the Small Data SF ticket.
  type: definition
  entity: Small Data SF
  keywords:
  - definition
  - workshops
  - included
  - small
  - data
  - sf
  - ticket
  source:
    doc: motherduck.com/blog/just-enough-sql-for-ai.md
    quote: The best part? Workshops are already included in your Small Data SF ticket!
    char_start: 0
    char_end: 75
- statement: Small Data SF 2025 is a data conference focused on efficiency in data
    management.
  type: definition
  entity: Small Data SF 2025
  keywords:
  - definition
  - small
  - data
  - sf
  - '2025'
  - conference
  - focused
  - efficiency
  - management
  source:
    doc: motherduck.com/blog/building-data-applications-with-motherduck.md
    quote: Dive into a recap of the world's hottest efficiency-themed data conference,
      Small Data SF!
    char_start: 0
    char_end: 90
- statement: Users can create a shareable report using Smartbook.
  type: definition
  entity: Smartbook
  keywords:
  - definition
  - users
  - create
  - shareable
  - report
  - using
  - smartbook
  source:
    doc: motherduck.com/blog/making-pyspark-code-faster-with-duckdb.md
    quote: Now we need to convert this to a shareable report for your teammates.
    char_start: 0
    char_end: 69
- statement: Snapshots enable time-travel capabilities in databases.
  type: definition
  entity: Snapshot
  keywords:
  - definition
  - snapshots
  - enable
  - time
  - travel
  - capabilities
  - databases
  source:
    doc: motherduck.com/blog/announcing-motherduck-general-availability-data-warehousing-with-duckdb.md
    quote: the state of the database file two snapshots ago by loading a snapshot
      composed of layers 3 -> 1.
    char_start: 0
    char_end: 97
- statement: Running sniff_csv first can save you significant guesswork when an import
    fails.
  type: definition
  entity: sniff_csv
  keywords:
  - definition
  - running
  - sniff
  - csv
  - first
  - save
  - significant
  - guesswork
  - import
  - fails
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: Running sniff_csv first can save you significant guesswork when an import
      fails.
    char_start: 0
    char_end: 80
- statement: 79% Snowflake cost savings.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - '79'
  - snowflake
  - cost
  - savings
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: 79% Snowflake cost savings
    char_start: 0
    char_end: 26
- statement: Big data problems are real, and they require big data tools like Snowflake
    or BigQuery.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - big
  - data
  - problems
  - real
  - require
  - tools
  - like
  - snowflake
  - bigquery
  source:
    doc: motherduck.com/videos/a-new-paradigm-for-data-visualization-with-just-sql-markdown.md
    quote: Don't use a 'big data' sledgehammer for a 'small data' nail.
    char_start: 0
    char_end: 60
- statement: High bills are driven by compute patterns rather than data at rest.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - high
  - bills
  - driven
  - compute
  - patterns
  - rather
  - data
  - rest
  source:
    doc: motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse.md
    quote: The cost isn't driven by data at rest, it's driven by data in motion, specifically
      by compute patterns.
    char_start: 0
    char_end: 103
- statement: High bills on platforms like Snowflake often stem from an idle compute
    tax.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - high
  - bills
  - platforms
  - like
  - snowflake
  - often
  - stem
  - idle
  - compute
  - tax
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: High bills on platforms like Snowflake often stem from an idle compute
      tax, where you're charged for a minimum of 60 seconds of compute even for a
      query that runs in two seconds.
    char_start: 0
    char_end: 178
- statement: LLMs automate the categorization of company names into predefined industry
    sectors.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - llms
  - automate
  - categorization
  - company
  - names
  - predefined
  - industry
  - sectors
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-four.md
    quote: Nate addresses common challenges in maintaining accurate industry classifications
      and leverages LLMs, specifically within Snowflake's database environment, to
      automate the categorization of company na
    char_start: 0
    char_end: 237
- statement: One team slashed their Snowflake BI spend by 79% using DuckDB.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - one
  - team
  - slashed
  - snowflake
  - bi
  - spend
  - '79'
  - using
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: Plus, real-world cost savings stories, including one team that slashed
      their Snowflake BI spend by 79% using DuckDB as a smart caching layer.
    char_start: 0
    char_end: 141
- statement: Setting the AUTO_SUSPEND parameter to exactly 60 seconds ensures the
    warehouse suspends after one minute of inactivity, stopping credit consumption.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - setting
  - auto
  - suspend
  - parameter
  - exactly
  - '60'
  - seconds
  - ensures
  - warehouse
  - suspends
  - one
  - minute
  - inactivity
  - stopping
  - credit
  - consumption
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-use-cases.md
    quote: Set aggressive yet intelligent warehouse timeouts. For most workloads,
      set the AUTO_SUSPEND parameter to exactly 60 seconds.
    char_start: 0
    char_end: 124
- statement: Snowflake and Amazon Redshift Serverless employ a 60-second minimum billing
    window for compute activation.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - snowflake
  - amazon
  - redshift
  - serverless
  - employ
  - '60'
  - second
  - minimum
  - billing
  - window
  - compute
  - activation
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: Both Snowflake and Amazon Redshift Serverless employ a 60-second minimum
      billing window for compute activation.
    char_start: 0
    char_end: 111
- statement: Snowflake and BigQuery were far behind.
  type: performance
  entity: Snowflake
  keywords:
  - performance
  - snowflake
  - bigquery
  - far
  - behind
  source:
    doc: motherduck.com/blog/duckdb-enterprise-5-key-categories.md
    quote: The results? Azure Data Warehouse was the fastest by far, followed by Redshift.
      Snowflake and BigQuery were far behind.
    char_start: 0
    char_end: 119
- statement: Snowflake can spin up additional warehouses for high concurrency.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - snowflake
  - spin
  - up
  - additional
  - warehouses
  - high
  - concurrency
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-1.md
    quote: Other data warehouse vendors have something similar; you can configure
      Snowflake to spin up additional warehouses when you have high concurrency.
    char_start: 0
    char_end: 145
- statement: Snowflake had a complete separation of compute and storage.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - snowflake
  - complete
  - separation
  - compute
  - storage
  source:
    doc: motherduck.com/videos/whats-new-in-data-small-data-big-impact.md
    quote: This design, implemented effectively by Snowflake (launched in 2014), had...
    char_start: 0
    char_end: 76
- statement: Snowflake is a cloud-based data warehousing service that can be compared
    to DuckDB.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - snowflake
  - cloud
  - based
  - data
  - warehousing
  - service
  - compared
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: A cloud-based data warehousing service.
    char_start: 0
    char_end: 39
- statement: Snowflake is used for massive, ad-hoc interactive queries.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - snowflake
  - used
  - massive
  - ad
  - hoc
  - interactive
  - queries
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: Use Snowflake or BigQuery for massive, ad-hoc interactive queries when
      you need the horsepower.
    char_start: 0
    char_end: 95
- statement: Snowflake makes it easier to write queries compared to other SQL dialects.
  type: performance
  entity: Snowflake
  keywords:
  - performance
  - snowflake
  - makes
  - easier
  - write
  - queries
  - compared
  - sql
  - dialects
  source:
    doc: motherduck.com/blog/making-pyspark-code-faster-with-duckdb.md
    quote: Snowflake did a great job of making it easier to write queries.
    char_start: 0
    char_end: 63
- statement: Snowflake offers a cloud-native architecture that separates compute and
    storage resources.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - snowflake
  - offers
  - cloud
  - native
  - architecture
  - separates
  - compute
  - storage
  - resources
  source:
    doc: motherduck.com/videos/using-sql-in-your-data-lake-with-duckdb-iceberg-dbt-and-motherduck.md
    quote: By creating an architecture designed specifically for the cloud, it offered
      separate compute and storage resources.
    char_start: 0
    char_end: 115
- statement: Snowflake provides predictable performance and mature features for heavy
    jobs.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - snowflake
  - provides
  - predictable
  - performance
  - mature
  - features
  - heavy
  - jobs
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: Large Batch ETL (>10TB) | Snowflake | Predictable performance and mature
      features for heavy jobs.
    char_start: 0
    char_end: 97
- statement: Snowflake shifts the focus from physical tuning to logical governance.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - snowflake
  - shifts
  - focus
  - physical
  - tuning
  - logical
  - governance
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part1.md
    quote: Snowflake shifts the focus from physical tuning to logical governance.
    char_start: 0
    char_end: 70
- statement: Snowflake uses S3 for data and Foundation DB for metadata.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - snowflake
  - uses
  - s3
  - data
  - foundation
  - db
  - metadata
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-2.md
    quote: Snowflake uses S3 for the data and Foundation DB for metadata.
    char_start: 0
    char_end: 62
- statement: Snowflake's architecture is optimized for massive, petabyte-scale enterprises.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - snowflake
  - architecture
  - optimized
  - massive
  - petabyte
  - scale
  - enterprises
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: Your Snowflake bill is likely high because its architecture is optimized
      for massive, petabyte-scale enterprises.
    char_start: 0
    char_end: 113
- statement: Snowflake's compute billing model enforces a 60-second minimum charge
    each time a warehouse resumes.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - snowflake
  - compute
  - billing
  - model
  - enforces
  - '60'
  - second
  - minimum
  - charge
  - time
  - warehouse
  - resumes
  source:
    doc: motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse.md
    quote: the compute billing model, which enforces a 60-second minimum charge each
      time a warehouse resumes.
    char_start: 0
    char_end: 99
- statement: Snowflake's costs can be unpredictable due to its credit-based model
    combined with a 60-second minimum charge.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - snowflake
  - costs
  - unpredictable
  - due
  - credit
  - based
  - model
  - combined
  - '60'
  - second
  - minimum
  - charge
  source:
    doc: motherduck.com/glossary/relational database.md
    quote: Snowflake's costs can be unpredictable due to its credit-based model combined
      with a [**60-second minimum charge**].
    char_start: 0
    char_end: 116
- statement: Snowflake's estimated monthly cost for continuous operation is $2,160.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - snowflake
  - estimated
  - monthly
  - cost
  - continuous
  - operation
  - '160'
  source:
    doc: motherduck.com/learn-more/hybrid-analytics-guide.md
    quote: A more common scenario where the warehouse runs 24/7 would cost $2,160.
    char_start: 0
    char_end: 71
- statement: Snowflake's provisioned compute model provides predictable power and
    performance.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - snowflake
  - provisioned
  - compute
  - model
  - provides
  - predictable
  - power
  - performance
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-use-cases.md
    quote: Snowflake's provisioned compute model provides predictable power and performance.
    char_start: 0
    char_end: 81
- statement: Snowflake's TCO is driven by its credit-based model, where you pay for
    compute time consumed by virtual warehouses.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - snowflake
  - tco
  - driven
  - credit
  - based
  - model
  - pay
  - compute
  - time
  - consumed
  - virtual
  - warehouses
  source:
    doc: motherduck.com/blog/why-everybody-hates-databases.md
    quote: Snowflake's TCO is driven by its credit-based model, where you pay for
      compute time consumed by virtual warehouses.
    char_start: 0
    char_end: 115
- statement: Startups can consider simpler alternatives instead of complex, expensive
    platforms like Snowflake or BigQuery.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - startups
  - consider
  - simpler
  - alternatives
  - instead
  - complex
  - expensive
  - platforms
  - like
  - snowflake
  - bigquery
  source:
    doc: motherduck.com/videos/using-sql-in-your-data-lake-with-duckdb-iceberg-dbt-and-motherduck.md
    quote: Instead of complex, expensive platforms like Snowflake or BigQuery, startups
      can ad...
    char_start: 0
    char_end: 86
- statement: Startups often overspend on massive data warehouses like Snowflake.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - startups
  - often
  - overspend
  - massive
  - data
  - warehouses
  - like
  - snowflake
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: Startups often overspend on massive data warehouses like Snowflake.
    char_start: 0
    char_end: 67
- statement: The 60-second minimum charge is unavoidable for each activation.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - '60'
  - second
  - minimum
  - charge
  - unavoidable
  - activation
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: the initial 60-second charge is unavoidable for each activation.
    char_start: 0
    char_end: 64
- statement: The primary driver of inflated Snowflake bills for bursty, interactive
    workloads is the platform's billing model for compute.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - primary
  - driver
  - inflated
  - snowflake
  - bills
  - bursty
  - interactive
  - workloads
  - platform
  - billing
  - model
  - compute
  source:
    doc: motherduck.com/learn-more/product-analytics-motherduck-duckdb.md
    quote: The primary driver of inflated Snowflake bills for bursty, interactive
      workloads is the platform's billing model for compute.
    char_start: 0
    char_end: 125
- statement: The solution achieved over 90% accuracy in returning single-word industry
    classifications.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - solution
  - achieved
  - over
  - '90'
  - accuracy
  - returning
  - single
  - word
  - industry
  - classifications
  source:
    doc: motherduck.com/learn-more/partitioned-writes-parquet-ducklake.md
    quote: The solution achieved over 90% accuracy in returning single-word industry
      classifications.
    char_start: 0
    char_end: 90
- statement: Using a hybrid approach can lead to a 79% reduction in Snowflake BI spend.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - using
  - hybrid
  - approach
  - lead
  - '79'
  - reduction
  - snowflake
  - bi
  - spend
  source:
    doc: motherduck.com/learn-more/what-is-duckdb.md
    quote: 79% immediate reduction in their Snowflake BI spend, and average query
      times sped up by 7x.
    char_start: 0
    char_end: 91
- statement: Using Snowflake's LLM integration, Nate developed an automated approach
    to classify companies by industry.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - using
  - snowflake
  - llm
  - integration
  - nate
  - developed
  - automated
  - approach
  - classify
  - companies
  - industry
  source:
    doc: motherduck.com/learn-more/duckdb-vs-sqlite-databases.md
    quote: Using Snowflake's LLM integration, Nate developed an automated approach
      to classify companies by industry.
    char_start: 0
    char_end: 106
- statement: We helped one analytics team save approximately $38,000 annually by moving
    its BI queries from a Medium to a Small warehouse.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - helped
  - one
  - analytics
  - team
  - save
  - approximately
  - '38'
  - '000'
  - annually
  - moving
  - bi
  - queries
  - medium
  - small
  - warehouse
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-use-cases.md
    quote: We helped one analytics team save approximately $38,000 annually by moving
      its BI queries from a Medium to a Small warehouse.
    char_start: 0
    char_end: 125
- statement: Your Snowflake bill is likely high because its architecture is optimized
    for massive, petabyte-scale enterprises.
  type: definition
  entity: Snowflake
  keywords:
  - definition
  - snowflake
  - bill
  - likely
  - high
  - architecture
  - optimized
  - massive
  - petabyte
  - scale
  - enterprises
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: Your Snowflake bill is likely high because its architecture is optimized
      for massive, petabyte-scale enterprises.
    char_start: 0
    char_end: 113
- statement: Opt for a Snowflake Schema when you need to reduce data redundancy significantly.
  type: definition
  entity: Snowflake Schema
  keywords:
  - definition
  - opt
  - snowflake
  - schema
  - need
  - reduce
  - data
  - redundancy
  - significantly
  source:
    doc: motherduck.com/videos/duckdb-motherduck-for-beginners-your-ultimate-guide.md
    quote: Opt for a Snowflake Schema when you need to reduce data redundancy significantly.
    char_start: 0
    char_end: 81
- statement: Snowflake schemas reduce redundancy but require more joins.
  type: definition
  entity: Snowflake Schema
  keywords:
  - definition
  - snowflake
  - schemas
  - reduce
  - redundancy
  - require
  - joins
  source:
    doc: motherduck.com/videos/how-to-efficiently-load-data-into-ducklake-with-estuary.md
    quote: The biggest pro of this schema is that it reduces redundancy, potentially
      making maintenance easier for some attributes.
    char_start: 0
    char_end: 120
- statement: Soda is a tool for monitoring and ensuring data quality.
  type: definition
  entity: Soda
  keywords:
  - definition
  - soda
  - tool
  - monitoring
  - ensuring
  - data
  - quality
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: A tool for monitoring and ensuring data quality.
    char_start: 0
    char_end: 48
- statement: SOPS is an encrypted secrets management tool that works with PGP/age
    keys to secure sensitive configuration data in Git repositories.
  type: definition
  entity: SOPS
  keywords:
  - definition
  - sops
  - encrypted
  - secrets
  - management
  - tool
  - works
  - pgp
  - age
  - keys
  - secure
  - sensitive
  - configuration
  - data
  - git
  - repositories
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: Encrypted secrets management tool that works with PGP/age keys to secure
      sensitive configuration data in Git repositories
    char_start: 0
    char_end: 121
- statement: SourceTree is a Git GUI client for managing repositories.
  type: definition
  entity: SourceTree
  keywords:
  - definition
  - sourcetree
  - git
  - gui
  - client
  - managing
  - repositories
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: Some popular options include SourceTree.
    char_start: 0
    char_end: 40
- statement: The government of South Australia uses DuckDB for its climate change
    dashboard.
  type: definition
  entity: South Australia Government
  keywords:
  - definition
  - government
  - south
  - australia
  - uses
  - duckdb
  - climate
  - change
  - dashboard
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: Another exciting is the government of South Australia use of duckdb-wasm
      for its climate change dashboard.
    char_start: 0
    char_end: 106
- statement: Spare Cores built a cloud infrastructure price comparison service using
    DuckDB.
  type: definition
  entity: Spare Cores
  keywords:
  - definition
  - spare
  - cores
  - built
  - cloud
  - infrastructure
  - price
  - comparison
  - service
  - using
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: For example, Spare Cores, a three-person startup, built a cloud infrastructure
      price comparison service.
    char_start: 0
    char_end: 104
- statement: Spark can read data with custom partitioning using DuckLake's metadata.
  type: definition
  entity: Spark
  keywords:
  - definition
  - spark
  - read
  - data
  - custom
  - partitioning
  - using
  - ducklake
  - metadata
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-three.md
    quote: 'I''m essentially telling Spark: ''Here''s exactly how this data is organized,
      and here''s the most efficient way to read it.'''
    char_start: 0
    char_end: 121
- statement: Spark infers schema automatically when loading data.
  type: definition
  entity: Spark
  keywords:
  - definition
  - spark
  - infers
  - schema
  - automatically
  - loading
  - data
  source:
    doc: motherduck.com/blog/python-faker-duckdb-exploration.md
    quote: I've included automatic schema inference to make the process as smooth
      as possible.
    char_start: 0
    char_end: 83
- statement: Spark is an open-source unified analytics engine for big data processing.
  type: definition
  entity: Spark
  keywords:
  - definition
  - spark
  - open
  - source
  - unified
  - analytics
  - engine
  - big
  - data
  - processing
  source:
    doc: motherduck.com/blog/python-duckdb-vs-dataframe-libraries.md
    quote: Then I use this intelligence to configure Spark's partitioning.
    char_start: 0
    char_end: 63
- statement: Spark utilizes the DataFrame API for structured data operations.
  type: definition
  entity: Spark
  keywords:
  - definition
  - spark
  - utilizes
  - dataframe
  - api
  - structured
  - data
  - operations
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-three.md
    quote: Spark utilizes the DataFrame API for structured data operations.
    char_start: 0
    char_end: 64
- statement: SQL Tables require zero retraining for analysts familiar with SQL.
  type: definition
  entity: Spark
  keywords:
  - definition
  - sql
  - tables
  - require
  - zero
  - retraining
  - analysts
  - familiar
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-three.md
    quote: If your analysts are already comfortable with Spark SQL, this approach
      requires zero retraining.
    char_start: 0
    char_end: 96
- statement: The DataFrame API provides significant performance gains.
  type: performance
  entity: Spark
  keywords:
  - dataframe
  - api
  - provides
  - significant
  - performance
  - gains
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-three.md
    quote: The explicit partitioning control can provide significant performance gains.
    char_start: 0
    char_end: 76
- statement: The script supports append operations for continuous data addition.
  type: definition
  entity: Spark
  keywords:
  - definition
  - script
  - supports
  - append
  - operations
  - continuous
  - data
  - addition
  source:
    doc: motherduck.com/blog/python-faker-duckdb-exploration.md
    quote: The script also demonstrates append operations, which is crucial for real-world
      scenarios where you're continuously adding new data.
    char_start: 0
    char_end: 132
- statement: The SQL-native approach allows for creating persistent tables in Spark's
    catalog.
  type: definition
  entity: Spark
  keywords:
  - definition
  - sql
  - native
  - approach
  - allows
  - creating
  - persistent
  - tables
  - spark
  - catalog
  source:
    doc: motherduck.com/blog/python-duckdb-vs-dataframe-libraries.md
    quote: If your team lives and breathes SQL, this second approach will feel much
      more natural. Instead of working with DataFrames and explicit partitioning,
      I'm creating persistent tables in Spark's catalog a
    char_start: 0
    char_end: 235
- statement: The write script automatically generates sample data if none exists.
  type: definition
  entity: Spark
  keywords:
  - definition
  - write
  - script
  - automatically
  - generates
  - sample
  - data
  - none
  - exists
  source:
    doc: motherduck.com/blog/python-faker-duckdb-exploration.md
    quote: The write script demonstrates something I find quite practical—it automatically
      generates sample data if none exists.
    char_start: 0
    char_end: 117
- statement: AI can assist in writing SQL queries effectively.
  type: definition
  entity: SQL
  keywords:
  - definition
  - ai
  - assist
  - writing
  - sql
  - queries
  - effectively
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: 'We can do something like this: CALL prompt_sql(''what are the top managers
      of my call center?'');'
    char_start: 0
    char_end: 95
- statement: AI generates queries that technically work but are incredibly slow on
    large datasets.
  type: definition
  entity: SQL
  keywords:
  - definition
  - ai
  - generates
  - queries
  - technically
  - work
  - incredibly
  - slow
  - large
  - datasets
  source:
    doc: motherduck.com/blog/small-data-sf-workshops-agenda.md
    quote: 'The Problem: AI generates queries that technically work but are incredibly
      slow on large datasets.'
    char_start: 0
    char_end: 98
- statement: AI-generated queries can be slow on large datasets if not optimized.
  type: definition
  entity: SQL
  keywords:
  - definition
  - ai
  - generated
  - queries
  - slow
  - large
  - datasets
  - optimized
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md
    quote: AI generates queries that technically work but are incredibly slow on large
      datasets.
    char_start: 0
    char_end: 85
- statement: AI-generated queries can create a Cartesian product if join conditions
    are not specified.
  type: definition
  entity: SQL
  keywords:
  - definition
  - ai
  - generated
  - queries
  - create
  - cartesian
  - product
  - join
  - conditions
  - specified
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md
    quote: AI forgets to specify how tables should be joined, creating a 'Cartesian
      product' where every row is matched with every other row.
    char_start: 0
    char_end: 130
- statement: Comparing numbers to strings can lead to unexpected results in SQL queries.
  type: definition
  entity: SQL
  keywords:
  - definition
  - comparing
  - numbers
  - strings
  - lead
  - unexpected
  - results
  - sql
  - queries
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md
    quote: AI might compare numbers to strings or dates to text, leading to unexpected
      results.
    char_start: 0
    char_end: 84
- statement: It’s a marketable skill that practically every organization needs.
  type: definition
  entity: SQL
  keywords:
  - definition
  - marketable
  - skill
  - practically
  - every
  - organization
  - needs
  source:
    doc: motherduck.com/blog/faster-ducks.md
    quote: It’s a marketable skill that practically every organization needs.
    char_start: 0
    char_end: 66
- statement: Master 9 essential SQL keyboard shortcuts to achieve a true flow state.
  type: definition
  entity: SQL
  keywords:
  - definition
  - master
  - essential
  - sql
  - keyboard
  - shortcuts
  - achieve
  - 'true'
  - flow
  - state
  source:
    doc: motherduck.com/blog.md
    quote: Master 9 essential SQL keyboard shortcuts to achieve a true flow state
      and make your data analysis faster and more joyful.
    char_start: 0
    char_end: 122
- statement: SQL allows for query optimization techniques to enhance performance.
  type: definition
  entity: SQL
  keywords:
  - definition
  - sql
  - allows
  - query
  - optimization
  - techniques
  - enhance
  - performance
  source:
    doc: motherduck.com/blog/duckdb-the-great-federator.md
    quote: Techniques used to improve the performance of SQL queries.
    char_start: 0
    char_end: 58
- statement: SQL databases and Python are foundational tools for data engineers.
  type: definition
  entity: SQL
  keywords:
  - definition
  - sql
  - databases
  - python
  - foundational
  - tools
  - data
  - engineers
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: SQL databases and Python as your foundational toolkit.
    char_start: 0
    char_end: 54
- statement: SQL is a fundamental skill for doing any data work.
  type: definition
  entity: SQL
  keywords:
  - definition
  - sql
  - fundamental
  - skill
  - doing
  - any
  - data
  - work
  source:
    doc: motherduck.com/blog/announcing-motherduck-general-availability-data-warehousing-with-duckdb.md
    quote: SQL is a **fundamental skill** for doing any data work.
    char_start: 0
    char_end: 55
- statement: SQL is an accessible, ubiquitous, and valuable language you can learn
    in 2024.
  type: definition
  entity: SQL
  keywords:
  - definition
  - sql
  - accessible
  - ubiquitous
  - valuable
  - language
  - learn
  - '2024'
  source:
    doc: motherduck.com/blog/faster-ducks.md
    quote: SQL is an accessible, ubiquitous, and valuable language you can learn in
      2024.
    char_start: 0
    char_end: 78
- statement: SQL is sometimes better for precise communication with AI.
  type: definition
  entity: SQL
  keywords:
  - definition
  - sql
  - sometimes
  - better
  - precise
  - communication
  - ai
  source:
    doc: motherduck.com/blog/how-to-extract-analytics-from-bluesky.md
    quote: That's why SQL is sometimes better to use or to explain to an LLM, so we
      communicate exactly what we want.
    char_start: 0
    char_end: 106
- statement: SQL is the language of data.
  type: definition
  entity: SQL
  keywords:
  - definition
  - sql
  - language
  - data
  source:
    doc: motherduck.com/blog/announcing-motherduck-general-availability-data-warehousing-with-duckdb.md
    quote: SQL is the **language of data**.
    char_start: 0
    char_end: 32
- statement: SQL is the most prominent language for data engineers.
  type: definition
  entity: SQL
  keywords:
  - definition
  - sql
  - prominent
  - language
  - data
  - engineers
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-essential-tools.md
    quote: The most prominent language you will use is still SQL...
    char_start: 0
    char_end: 56
- statement: SQL is universal.
  type: definition
  entity: SQL
  keywords:
  - definition
  - sql
  - universal
  source:
    doc: motherduck.com/blog/spark-ducklake-getting-started.md
    quote: But SQL is universal.
    char_start: 0
    char_end: 21
- statement: SQL is used to unnest and aggregate product attributes.
  type: definition
  entity: SQL
  keywords:
  - definition
  - sql
  - used
  - unnest
  - aggregate
  - product
  - attributes
  source:
    doc: motherduck.com/blog/introducing-instant-sql.md
    quote: Using DuckDB’s `unnest`, `array_agg`, and `array_distinct` functions...
    char_start: 0
    char_end: 71
- statement: SQL is used to view some of the fields in MotherDuck’s web UI.
  type: definition
  entity: SQL
  keywords:
  - definition
  - sql
  - used
  - view
  - fields
  - motherduck
  - web
  - ui
  source:
    doc: motherduck.com/blog/motherduck-congratulates-duckdb-1.0-release.md
    quote: 'Here’s an example SQL query we used to view some of the fields:'
    char_start: 0
    char_end: 63
- statement: SQL lets you add new, 'calculated' columns to your results on the fly.
  type: definition
  entity: SQL
  keywords:
  - definition
  - sql
  - lets
  - add
  - new
  - calculated
  - columns
  - results
  - fly
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md
    quote: SQL lets you add new, 'calculated' columns to your results on the fly.
    char_start: 0
    char_end: 70
- statement: The AI generated SQL can be verified by the user.
  type: definition
  entity: SQL
  keywords:
  - definition
  - ai
  - generated
  - sql
  - verified
  - user
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md
    quote: Because you learned the fundamentals, you can now verify the AI's logic
      and trust its answer.
    char_start: 0
    char_end: 93
- statement: The implementation uses SQL wrapped in Python.
  type: definition
  entity: SQL
  keywords:
  - definition
  - implementation
  - uses
  - sql
  - wrapped
  - python
  source:
    doc: motherduck.com/blog/small-data-sf-workshops-agenda.md
    quote: It should be noted that this is simply SQL, wrapped in python.
    char_start: 0
    char_end: 62
- statement: Understanding SQL transforms you from a passive user into an active analyst.
  type: definition
  entity: SQL
  keywords:
  - definition
  - understanding
  - sql
  - transforms
  - passive
  - user
  - active
  - analyst
  source:
    doc: motherduck.com/blog/small-data-sf-recap-2025.md
    quote: You don't need to be a SQL expert to leverage AI, but a foundational understanding
      is your superpower.
    char_start: 0
    char_end: 102
- statement: Using keyboard shortcuts can enhance the efficiency of running SQL queries.
  type: definition
  entity: SQL
  keywords:
  - definition
  - using
  - keyboard
  - shortcuts
  - enhance
  - efficiency
  - running
  - sql
  - queries
  source:
    doc: motherduck.com/blog/scaling-duckdb-with-ducklings.md
    quote: This lets you debug and build complex queries piece by piece, giving you
      an incredible level of control, all from the keyboard.
    char_start: 0
    char_end: 127
- statement: SQL analytics refers to using SQL queries to analyze data and derive
    insights.
  type: definition
  entity: SQL analytics
  keywords:
  - definition
  - sql
  - analytics
  - refers
  - using
  - queries
  - analyze
  - data
  - derive
  - insights
  source:
    doc: motherduck.com/learn-more/data-warehouse-tco.md
    quote: SQL analytics refers to using SQL queries to analyze data and derive insights,
      typically working with large datasets stored in databases or data warehouses.
    char_start: 0
    char_end: 156
- statement: The SQL Notebook is your primary workspace with cells for writing and
    executing SQL queries.
  type: definition
  entity: SQL Notebook
  keywords:
  - definition
  - sql
  - notebook
  - primary
  - workspace
  - cells
  - writing
  - executing
  - queries
  source:
    doc: motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md
    quote: 'The SQL Notebook (Center Panel): Your primary workspace with cells for
      writing and executing SQL queries.'
    char_start: 0
    char_end: 105
- statement: SQL Prophet shows time-series forecasting with DuckDB.
  type: definition
  entity: SQL Prophet
  keywords:
  - definition
  - sql
  - prophet
  - shows
  - time
  - series
  - forecasting
  - duckdb
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part2.md
    quote: The Evidence team has also published SQL Prophet showing time-series forecasting
      with DuckDB and evidence.
    char_start: 0
    char_end: 106
- statement: SQL can be used to extract risk category distribution across all companies.
  type: definition
  entity: SQL Server
  keywords:
  - definition
  - sql
  - used
  - extract
  - risk
  - category
  - distribution
  - across
  - companies
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part2.md
    quote: 'you can extract risk category distribution across all companies with a
      single query:'
    char_start: 0
    char_end: 84
- statement: SQL has been a cornerstone of data management since its creation in 1974.
  type: definition
  entity: SQL Server
  keywords:
  - definition
  - sql
  - cornerstone
  - data
  - management
  - since
  - creation
  - '1974'
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: SQL has been a cornerstone of data management since its creation in 1974.
    char_start: 0
    char_end: 73
- statement: SQL is used to query JSON data.
  type: definition
  entity: SQL Server
  keywords:
  - definition
  - sql
  - used
  - query
  - json
  - data
  source:
    doc: motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse.md
    quote: SQL is used to query JSON data.
    char_start: 0
    char_end: 31
- statement: SQL Server is known for its ACID compliance.
  type: definition
  entity: SQL Server
  keywords:
  - definition
  - sql
  - server
  - known
  - acid
  - compliance
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: the same data integrity guarantees found in larger server-based databases
      like SQL Server.
    char_start: 0
    char_end: 90
- statement: SQL stands for Structured Query Language, not Standard Query Language.
  type: definition
  entity: SQL Server
  keywords:
  - definition
  - sql
  - stands
  - structured
  - query
  - language
  - standard
  source:
    doc: motherduck.com/videos.md
    quote: “(SQL) stands for Structured Query Language, not Standard Query Language”
    char_start: 0
    char_end: 73
- statement: Ted Conner discusses SQL workflows and SQL IDEs.
  type: definition
  entity: SQL Server
  keywords:
  - definition
  - ted
  - conner
  - discusses
  - sql
  - workflows
  - ides
  source:
    doc: motherduck.com/learn-more/self-service-analytics-startups.md
    quote: Join Mehdi and Ted Conner to discuss SQL workflows and SQL IDEs!
    char_start: 0
    char_end: 64
- statement: The AI switches from SQL to Python to visualize the data.
  type: definition
  entity: SQL Server
  keywords:
  - definition
  - ai
  - switches
  - sql
  - python
  - visualize
  - data
  source:
    doc: motherduck.com/blog/vibe-coding-sql-cursor.md
    quote: the AI switches from SQL to Python.
    char_start: 0
    char_end: 35
- statement: The SQL query calculates the total revenue generated by each user from
    completed subscriptions.
  type: definition
  entity: SQL Server
  keywords:
  - definition
  - sql
  - query
  - calculates
  - total
  - revenue
  - generated
  - user
  - completed
  - subscriptions
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-use-cases.md
    quote: This query calculates the total revenue generated by each user from completed
      subscriptions.
    char_start: 0
    char_end: 92
- statement: 'The traditional SQL workflow has long been plagued by a familiar frustration:
    the waiting game.'
  type: definition
  entity: SQL Server
  keywords:
  - definition
  - traditional
  - sql
  - workflow
  - long
  - plagued
  - familiar
  - frustration
  - waiting
  - game
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: 'The traditional SQL workflow has long been plagued by a familiar frustration:
      the waiting game.'
    char_start: 0
    char_end: 95
- statement: With SQL as the common denominator, analysts, data engineers, and software
    developers can finally speak the same language.
  type: definition
  entity: SQL Server
  keywords:
  - definition
  - sql
  - common
  - denominator
  - analysts
  - data
  - engineers
  - software
  - developers
  - finally
  - speak
  - language
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: With SQL as the common denominator, analysts, data engineers, and software
      developers can finally speak the same language.
    char_start: 0
    char_end: 122
- statement: With this approach, SQL queries can swim with precision.
  type: definition
  entity: SQL Server
  keywords:
  - definition
  - approach
  - sql
  - queries
  - swim
  - precision
  source:
    doc: motherduck.com/case-studies/trunkrs-same-day-delivery-motherduck-from-redshift.md
    quote: With this approach, they can swim with precision.
    char_start: 0
    char_end: 49
- statement: You can use SQL to query local Excel and CSV files as if they were database
    tables.
  type: definition
  entity: SQL Server
  keywords:
  - definition
  - use
  - sql
  - query
  - local
  - excel
  - csv
  - files
  - database
  - tables
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: You can use SQL to query local Excel and CSV files as if they were database
      tables.
    char_start: 0
    char_end: 83
- statement: You learned how to write SQL to query the data you want.
  type: definition
  entity: SQL Server
  keywords:
  - definition
  - learned
  - write
  - sql
  - query
  - data
  - want
  source:
    doc: motherduck.com/blog/summer-data-engineering-roadmap.md
    quote: You learned how to write SQL to query the data you want.
    char_start: 0
    char_end: 56
- statement: SQL Workbench uses DuckDB for running queries on local or remote data.
  type: definition
  entity: SQL Workbench
  keywords:
  - definition
  - sql
  - workbench
  - uses
  - duckdb
  - running
  - queries
  - local
  - remote
  - data
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: SQL Workbench uses DuckDB for running queries on local or remote data.
    char_start: 0
    char_end: 70
- statement: The approach cuts hours off your SQL workflow.
  type: definition
  entity: SQL workflow
  keywords:
  - definition
  - approach
  - cuts
  - hours
  - 'off'
  - sql
  - workflow
  source:
    doc: motherduck.com/blog/motherduck-kestra-etl-pipelines.md
    quote: This approach cuts hours off your SQL workflow, transforming the tedious
      cycle of write-run-wait into a fluid process of exploration and discovery.
    char_start: 0
    char_end: 147
- statement: sql-workbench.com is an in-browser IDE that extends the experience of
    DuckDB.
  type: definition
  entity: sql-workbench.com
  keywords:
  - definition
  - sql
  - workbench
  - com
  - browser
  - ide
  - extends
  - experience
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-nine.md
    quote: an in-browser IDE with some really nice capabilities that extend the experience
      of DuckDB.
    char_start: 0
    char_end: 90
- statement: SQLFlow allows DuckDB users to leverage SQL for defining real-time data
    pipelines.
  type: definition
  entity: SQLFlow
  keywords:
  - definition
  - sqlflow
  - allows
  - duckdb
  - users
  - leverage
  - sql
  - defining
  - real
  - time
  - data
  - pipelines
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: 'Takeaway: SQLFlow allows DuckDB users to leverage SQL for defining real-time
      data pipelines, offering a lightweight alternative to traditional stream processing
      engines.'
    char_start: 0
    char_end: 169
- statement: SQLFlow executes SQL against streaming data, such as Kafka or webhooks.
  type: definition
  entity: SQLFlow
  keywords:
  - definition
  - sqlflow
  - executes
  - sql
  - against
  - streaming
  - data
  - kafka
  - webhooks
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-two.md
    quote: SQLFlow executes SQL against streaming data, such as Kafka or webhooks.
    char_start: 0
    char_end: 71
- statement: SQLFlow is a new stream processing engine powered by DuckDB.
  type: definition
  entity: SQLFlow
  keywords:
  - definition
  - sqlflow
  - new
  - stream
  - processing
  - engine
  - powered
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-two.md
    quote: SQLFlow is a new stream processing engine powered by DuckDB.
    char_start: 0
    char_end: 60
- statement: SQLFlow supports rolling window aggregations.
  type: definition
  entity: SQLFlow
  keywords:
  - definition
  - sqlflow
  - supports
  - rolling
  - window
  - aggregations
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-two.md
    quote: A key feature, SQLFlow, supports rolling window aggregations.
    char_start: 0
    char_end: 61
- statement: In 2021, he created sqlfmt, an autoformatter for dbt SQL, which has been
    downloaded over 1,500,000 times.
  type: definition
  entity: sqlfmt
  keywords:
  - definition
  - '2021'
  - created
  - sqlfmt
  - autoformatter
  - dbt
  - sql
  - which
  - downloaded
  - over
  - '500'
  - '000'
  - times
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2024.md
    quote: In 2021, he created sqlfmt, an autoformatter for dbt SQL, which has been
      downloaded over 1,500,000 times.
    char_start: 0
    char_end: 105
- statement: SQLFrame supports BigQuery, Postgres, and Snowflake.
  type: definition
  entity: SQLFrame
  keywords:
  - definition
  - sqlframe
  - supports
  - bigquery
  - postgres
  - snowflake
  source:
    doc: motherduck.com/blog/pg-duckdb-release.md
    quote: SQLFrame also supports BigQuery, Postgres, and Snowflake.
    char_start: 0
    char_end: 57
- statement: SQLite excels in transactional (OLTP) workloads with fast reads and writes
    of individual records.
  type: definition
  entity: SQLite
  keywords:
  - definition
  - sqlite
  - excels
  - transactional
  - oltp
  - workloads
  - fast
  - reads
  - writes
  - individual
  - records
  source:
    doc: motherduck.com/learn-more/partitioned-writes-parquet-ducklake.md
    quote: SQLite excels in transactional (OLTP) workloads with fast reads and writes
      of individual records.
    char_start: 0
    char_end: 97
- statement: SQLite has been improved for analytics workloads.
  type: definition
  entity: SQLite
  keywords:
  - definition
  - sqlite
  - improved
  - analytics
  - workloads
  source:
    doc: motherduck.com/blog/analyze-sqlite-databases-duckdb.md
    quote: there has been some work being done to make SQLite better for analytics
      workloads.
    char_start: 0
    char_end: 82
- statement: SQLite integrates with sqlite-vss to add vector capabilities.
  type: definition
  entity: SQLite
  keywords:
  - definition
  - sqlite
  - integrates
  - vss
  - add
  - vector
  - capabilities
  source:
    doc: motherduck.com/learn-more/data-warehouse-tco.md
    quote: SQLite integrates with sqlite-vss to add vector capabilities.
    char_start: 0
    char_end: 61
- statement: SQLite is a lightweight transactional database that is widely used for
    embedded database applications.
  type: definition
  entity: SQLite
  keywords:
  - definition
  - sqlite
  - lightweight
  - transactional
  - database
  - widely
  - used
  - embedded
  - applications
  source:
    doc: motherduck.com/learn-more/partitioned-writes-parquet-ducklake.md
    quote: SQLite is a lightweight transactional database that is widely used for
      embedded database applications.
    char_start: 0
    char_end: 102
- statement: SQLite is the world’s most widely deployed database with many copies
    running on nearly every laptop and mobile phone.
  type: definition
  entity: SQLite
  keywords:
  - definition
  - sqlite
  - world
  - widely
  - deployed
  - database
  - many
  - copies
  - running
  - nearly
  - every
  - laptop
  - mobile
  - phone
  source:
    doc: motherduck.com/learn-more/partitioned-writes-parquet-ducklake.md
    quote: SQLite is the world’s most widely deployed database with many copies running
      on nearly every laptop and mobile phone.
    char_start: 0
    char_end: 117
- statement: SQLite is used for storing user data in the PDS.
  type: definition
  entity: SQLite
  keywords:
  - definition
  - sqlite
  - used
  - storing
  - user
  - data
  - pds
  source:
    doc: motherduck.com/blog/duckdb-versus-pandas-versus-polars.md
    quote: each user's data is implemented and stored with a single SQLite database.
    char_start: 0
    char_end: 73
- statement: SQLite is weakly typed, allowing for flexible data types.
  type: definition
  entity: SQLite
  keywords:
  - definition
  - sqlite
  - weakly
  - typed
  - allowing
  - flexible
  - data
  - types
  source:
    doc: motherduck.com/blog/duckdb-cognee-sql-analytics-graph-rag.md
    quote: SQLite doesn't strictly enforce types in the data -- this is known as being
      weakly typed.
    char_start: 0
    char_end: 89
- statement: SQLite relies on SQL statements or APIs to load data from external sources.
  type: definition
  entity: SQLite
  keywords:
  - definition
  - sqlite
  - relies
  - sql
  - statements
  - apis
  - load
  - data
  - external
  - sources
  source:
    doc: motherduck.com/learn-more/partitioned-writes-parquet-ducklake.md
    quote: SQLite relies on SQL statements or APIs to load data from external sources.
    char_start: 0
    char_end: 75
- statement: SQLite stores data row-by-row while DuckDB stores data by columns.
  type: definition
  entity: SQLite
  keywords:
  - definition
  - sqlite
  - stores
  - data
  - row
  - duckdb
  - columns
  source:
    doc: motherduck.com/blog/duckdb-cognee-sql-analytics-graph-rag.md
    quote: SQLite, as a data store focused on transactions, stores data row-by-row
      while DuckDB, as a database engine for analytics, stores data by columns.
    char_start: 0
    char_end: 145
- statement: SQLite supports concurrent reads but limits concurrent writes.
  type: definition
  entity: SQLite
  keywords:
  - definition
  - sqlite
  - supports
  - concurrent
  - reads
  - limits
  - writes
  source:
    doc: motherduck.com/videos/understanding-ducklake-a-table-format-with-a-modern-architecture.md
    quote: SQLite supports concurrent reads but limits concurrent writes to ensure
      data integrity.
    char_start: 0
    char_end: 87
- statement: SQLite's performance advantage lies in simple queries that can be efficiently
    served from indices.
  type: definition
  entity: SQLite
  keywords:
  - definition
  - sqlite
  - performance
  - advantage
  - lies
  - simple
  - queries
  - efficiently
  - served
  - indices
  source:
    doc: motherduck.com/videos/understanding-ducklake-a-table-format-with-a-modern-architecture.md
    quote: SQLite's performance advantage lies in simple queries that can be efficiently
      served from indices.
    char_start: 0
    char_end: 98
- statement: SQLite's performance is optimized for point queries and transactional
    workloads.
  type: definition
  entity: SQLite
  keywords:
  - definition
  - sqlite
  - performance
  - optimized
  - point
  - queries
  - transactional
  - workloads
  source:
    doc: motherduck.com/learn-more/duckdb-vs-sqlite-databases.md
    quote: SQLite's performance is optimized for point queries and transactional workloads.
    char_start: 0
    char_end: 80
- statement: SQLite, Postgres, MySQL are all growing strongly.
  type: definition
  entity: SQLite
  keywords:
  - definition
  - sqlite
  - postgres
  - mysql
  - growing
  - strongly
  source:
    doc: motherduck.com/blog/announcing-small-data-sf-2025.md
    quote: SQLite, Postgres, MySQL are all growing strongly.
    char_start: 0
    char_end: 49
- statement: SQLite Cloud is a cloud-based solution for SQLite.
  type: definition
  entity: SQLite Cloud
  keywords:
  - definition
  - sqlite
  - cloud
  - based
  - solution
  source:
    doc: motherduck.com/learn-more/partitioned-writes-parquet-ducklake.md
    quote: SQLite Cloud is a cloud-based solution for SQLite.
    char_start: 0
    char_end: 50
- statement: The SQLite Sakila Sample Database represents a fictitious DVD rental
    store.
  type: definition
  entity: SQLite Sakila Sample Database
  keywords:
  - definition
  - sqlite
  - sakila
  - sample
  - database
  - represents
  - fictitious
  - dvd
  - rental
  - store
  source:
    doc: motherduck.com/blog/data-engineer-highlights-PyConDE-2023.md
    quote: This database is a SQLite port of the original MySQL sample database representing
      a ficticious DVD rental store.
    char_start: 0
    char_end: 112
- statement: SQLMesh is a data transformation framework designed to simplify the development
    and management of data pipelines.
  type: definition
  entity: sqlmesh
  keywords:
  - definition
  - sqlmesh
  - data
  - transformation
  - framework
  - designed
  - simplify
  - development
  - management
  - pipelines
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: SQLMesh is a data transformation framework designed to simplify the development
      and management of data pipelines.
    char_start: 0
    char_end: 113
- statement: SQLMesh manages complex financial modeling for strategic planning.
  type: definition
  entity: sqlmesh
  keywords:
  - definition
  - sqlmesh
  - manages
  - complex
  - financial
  - modeling
  - strategic
  - planning
  source:
    doc: motherduck.com/case-studies/reflex-careers-gig-economy-retail.md
    quote: managing everything from nightly de-duplication processes on tables approaching
      10 billion rows to complex financial modeling for strategic planning.
    char_start: 0
    char_end: 149
- statement: Foursquare has released SQLRooms, an open-source React framework for
    building single-node data applications powered by DuckDB.
  type: definition
  entity: SQLRooms
  keywords:
  - definition
  - foursquare
  - released
  - sqlrooms
  - open
  - source
  - react
  - framework
  - building
  - single
  - node
  - data
  - applications
  - powered
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2024.md
    quote: Foursquare has released SQLRooms, an open-source React framework for building
      single-node data applications powered by DuckDB.
    char_start: 0
    char_end: 126
- statement: SQLRooms automatically handles DuckDB operations, including format recognition
    and schema inference.
  type: definition
  entity: SQLRooms
  keywords:
  - definition
  - sqlrooms
  - automatically
  - handles
  - duckdb
  - operations
  - including
  - format
  - recognition
  - schema
  - inference
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: The framework automatically handles DuckDB operations, including format
      recognition (CSV, Parquet, JSON, Arrow), schema inference, and table registration
      for immediate querying.
    char_start: 0
    char_end: 177
- statement: 'SQLRooms combines five core components: RoomShell, RoomStore, an embedded
    DuckDB instance, an AI-powered analytics assistant, and a reusable component library.'
  type: definition
  entity: SQLRooms
  keywords:
  - definition
  - sqlrooms
  - combines
  - five
  - core
  - components
  - roomshell
  - roomstore
  - embedded
  - duckdb
  - instance
  - ai
  - powered
  - analytics
  - assistant
  - reusable
  - component
  - library
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2024.md
    quote: 'SQLRooms combines five core components: RoomShell (UI container), RoomStore
      (state management), an embedded DuckDB instance, an AI-powered analytics assistant,
      and a reusable component library.'
    char_start: 0
    char_end: 193
- statement: The framework automatically handles DuckDB operations, including format
    recognition, schema inference, and table registration for immediate querying.
  type: definition
  entity: SQLRooms
  keywords:
  - definition
  - framework
  - automatically
  - handles
  - duckdb
  - operations
  - including
  - format
  - recognition
  - schema
  - inference
  - table
  - registration
  - immediate
  - querying
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2024.md
    quote: The framework automatically handles DuckDB operations, including format
      recognition (CSV, Parquet, JSON, Arrow), schema inference, and table registration
      for immediate querying.
    char_start: 0
    char_end: 177
- statement: ssh is used to connect to another machine.
  type: definition
  entity: SSH
  keywords:
  - definition
  - ssh
  - used
  - connect
  - another
  - machine
  source:
    doc: motherduck.com/blog/data-warehouse-feature-roundup-oct-2024.md
    quote: ssh to connect to another machine.
    char_start: 0
    char_end: 34
- statement: ST_Point is used to create point geometries in DuckDB.
  type: definition
  entity: ST_Point
  keywords:
  - definition
  - st
  - point
  - used
  - create
  - geometries
  - duckdb
  source:
    doc: motherduck.com/blog/getting-started-gis-duckdb.md
    quote: you would convert it with DuckDB by just using the ST_Point from the spatial
      extension.
    char_start: 0
    char_end: 87
- statement: Stackblitz allows developers to create web applications in the browser.
  type: definition
  entity: Stackblitz
  keywords:
  - definition
  - stackblitz
  - allows
  - developers
  - create
  - web
  - applications
  - browser
  source:
    doc: motherduck.com/blog/analyze-x-data-nodejs-duckdb.md
    quote: An online IDE that allows developers to create web applications in the
      browser.
    char_start: 0
    char_end: 79
- statement: It takes a long time to download the StackOverflow data dumps.
  type: definition
  entity: StackOverflow
  keywords:
  - definition
  - takes
  - long
  - time
  - download
  - stackoverflow
  - data
  - dumps
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: It takes a long time (for me two days in total) to download, especially
      the posts file.
    char_start: 0
    char_end: 87
- statement: StackOverflow data is available on S3.
  type: definition
  entity: StackOverflow
  keywords:
  - definition
  - stackoverflow
  - data
  - available
  - s3
  source:
    doc: motherduck.com/blog/duckdb-tutorial-for-beginners.md
    quote: 'I uploaded them to S3 you can find them here: `s3://us-prd-motherduck-open-datasets/stackoverflow/parquet/2023-05`'
    char_start: 0
    char_end: 114
- statement: StackOverflow is a question and answer site for professional and enthusiast
    programmers.
  type: definition
  entity: StackOverflow
  keywords:
  - definition
  - stackoverflow
  - question
  - answer
  - site
  - professional
  - enthusiast
  - programmers
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: StackOverflow is a question and answer site for professional and enthusiast
      programmers.
    char_start: 0
    char_end: 88
- statement: StackOverflow publishes all their data publicly on the internet archive
    every month.
  type: definition
  entity: StackOverflow
  keywords:
  - definition
  - stackoverflow
  - publishes
  - data
  - publicly
  - internet
  - archive
  - every
  - month
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: StackOverflow publishes all their data publicly on the internet archive
      every month.
    char_start: 0
    char_end: 84
- statement: The data has only 65,000 tags and 20 million users (600MB compressed
    CSV), but 58 million posts (3GB).
  type: definition
  entity: StackOverflow
  keywords:
  - definition
  - data
  - '65'
  - '000'
  - tags
  - '20'
  - million
  - users
  - 600mb
  - compressed
  - csv
  - '58'
  - posts
  - 3gb
  source:
    doc: motherduck.com/blog/duckdb-tutorial-for-beginners.md
    quote: The data has only 65,000 tags and 20 million users (600MB compressed CSV),
      but 58 million posts (3GB).
    char_start: 0
    char_end: 102
- statement: The upload of the StackOverflow database took around 1 hour for 15GB
    of data.
  type: definition
  entity: StackOverflow
  keywords:
  - definition
  - upload
  - stackoverflow
  - database
  - took
  - around
  - hour
  - 15gb
  - data
  source:
    doc: motherduck.com/blog/effortless-etl-unstructured-data-unstructuredio-motherduck.md
    quote: it took quite some time to finish the upload, around 1 hour, sending 15GB
      of data for our 11GB database.
    char_start: 0
    char_end: 104
- statement: Standard is designed for common data warehouse workloads.
  type: definition
  entity: Standard Feature
  keywords:
  - definition
  - standard
  - designed
  - common
  - data
  - warehouse
  - workloads
  source:
    doc: motherduck.com/blog/galileo-world-geospatial.md
    quote: 'Standard: Designed for common data warehouse workloads, including loads
      and transforms'
    char_start: 0
    char_end: 86
- statement: A Star Schema organizes data into fact and dimension tables.
  type: definition
  entity: Star Schema
  keywords:
  - definition
  - star
  - schema
  - organizes
  - data
  - fact
  - dimension
  - tables
  source:
    doc: motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md
    quote: At its core, a Star Schema is a dimensional data modeling technique that
      organizes data into two main types of tables.
    char_start: 0
    char_end: 118
- statement: Choose a Star Schema when query performance and simplicity are your primary
    concerns.
  type: definition
  entity: Star Schema
  keywords:
  - definition
  - choose
  - star
  - schema
  - query
  - performance
  - simplicity
  - primary
  - concerns
  source:
    doc: motherduck.com/videos/duckdb-motherduck-for-beginners-your-ultimate-guide.md
    quote: Choose a Star Schema when query performance and simplicity are your primary
      concerns.
    char_start: 0
    char_end: 85
- statement: Its focus on query performance, user comprehension, and analytical insights
    makes it a powerful foundation.
  type: definition
  entity: Star Schema
  keywords:
  - definition
  - focus
  - query
  - performance
  - user
  - comprehension
  - analytical
  - insights
  - makes
  - powerful
  - foundation
  source:
    doc: motherduck.com/videos/duckdb-motherduck-for-beginners-your-ultimate-guide.md
    quote: Its focus on query performance, user comprehension, and analytical insights
      makes it a powerful foundation.
    char_start: 0
    char_end: 107
- statement: Star schemas are optimized for read-heavy analytical workloads (OLAP).
  type: definition
  entity: Star Schema
  keywords:
  - definition
  - star
  - schemas
  - optimized
  - read
  - heavy
  - analytical
  - workloads
  - olap
  source:
    doc: motherduck.com/learn-more/star-schema-data-warehouse-guide.md
    quote: Star schemas are optimized for read-heavy analytical workloads (OLAP),
      not for high-frequency transactional writes (OLTP).
    char_start: 0
    char_end: 122
- statement: Star schemas come with trade-offs such as data redundancy and maintenance
    challenges.
  type: definition
  entity: Star Schema
  keywords:
  - definition
  - star
  - schemas
  - come
  - trade
  - offs
  - data
  - redundancy
  - maintenance
  - challenges
  source:
    doc: motherduck.com/learn-more/star-schema-data-warehouse-guide.md
    quote: 'Like any modeling technique, star schemas come with trade-offs: Data Redundancy...'
    char_start: 0
    char_end: 82
- statement: Star schemas intentionally denormalize dimension data into fewer tables
    to optimize for analytical queries.
  type: definition
  entity: Star Schema
  keywords:
  - definition
  - star
  - schemas
  - intentionally
  - denormalize
  - dimension
  - data
  - fewer
  - tables
  - optimize
  - analytical
  - queries
  source:
    doc: motherduck.com/videos/duckdb-motherduck-for-beginners-your-ultimate-guide.md
    quote: Star schemas intentionally denormalize dimension data into fewer tables
      to optimize for analytical queries.
    char_start: 0
    char_end: 107
- statement: The primary difference lies in structure and purpose.
  type: definition
  entity: Star Schema
  keywords:
  - definition
  - primary
  - difference
  - lies
  - structure
  - purpose
  source:
    doc: motherduck.com/videos/duckdb-motherduck-for-beginners-your-ultimate-guide.md
    quote: The primary difference lies in structure and purpose.
    char_start: 0
    char_end: 53
- statement: The Star Schema is a dimensional data modeling technique that organizes
    data into a structure resembling a star.
  type: definition
  entity: Star Schema
  keywords:
  - definition
  - star
  - schema
  - dimensional
  - data
  - modeling
  - technique
  - organizes
  - structure
  - resembling
  source:
    doc: motherduck.com/learn-more/star-schema-data-warehouse-guide.md
    quote: At its core, a Star Schema is a dimensional data modeling technique that
      organizes data into two main typ...
    char_start: 0
    char_end: 108
- statement: The Star Schema isn't flashy or trendy, but it's a workhorse in data
    warehousing for good reason.
  type: definition
  entity: Star Schema
  keywords:
  - definition
  - star
  - schema
  - isn
  - flashy
  - trendy
  - workhorse
  - data
  - warehousing
  - good
  - reason
  source:
    doc: motherduck.com/videos/duckdb-motherduck-for-beginners-your-ultimate-guide.md
    quote: The Star Schema isn't flashy or trendy, but it's a workhorse in data warehousing
      for good reason.
    char_start: 0
    char_end: 97
- statement: Using a star schema is a proven technique for accelerating analytical
    queries.
  type: definition
  entity: Star Schema
  keywords:
  - definition
  - using
  - star
  - schema
  - proven
  - technique
  - accelerating
  - analytical
  - queries
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: Using a star schema, which organizes data into a central 'fact' table and
      surrounding 'dimension' tables, is a proven technique for accelerating analytical
      queries in columnar databases.
    char_start: 0
    char_end: 186
- statement: Starburst Galaxy supports federated queries across data lakes.
  type: definition
  entity: Starburst Galaxy
  keywords:
  - definition
  - starburst
  - galaxy
  - supports
  - federated
  - queries
  - across
  - data
  - lakes
  source:
    doc: motherduck.com/learn-more/secure-startup-data-warehouse.md
    quote: Federated queries across data lakes (data mesh).
    char_start: 0
    char_end: 48
- statement: Stemming simplifies words by removing common endings.
  type: definition
  entity: stemmer
  keywords:
  - definition
  - stemming
  - simplifies
  - words
  - removing
  - common
  - endings
  source:
    doc: motherduck.com/blog/search-using-duckdb-part-3.md
    quote: Stemming is a process of simplifying words by removing common word endings.
    char_start: 0
    char_end: 75
- statement: Stephanie Wang and Till Döhmen collaborated on a sponsor talk.
  type: definition
  entity: Stephanie Wang
  keywords:
  - definition
  - stephanie
  - wang
  - till
  - hmen
  - collaborated
  - sponsor
  - talk
  source:
    doc: motherduck.com/blog/log-processing-savings-bacalhau-motherduck.md
    quote: Stephanie Wang, Founding Engineer, and Till Döhmen collaborated on a sponsor
      talk...
    char_start: 0
    char_end: 84
- statement: Stopwords are commonly used words that are often removed from search
    queries.
  type: definition
  entity: stopwords
  keywords:
  - definition
  - stopwords
  - commonly
  - used
  - words
  - often
  - removed
  - search
  - queries
  source:
    doc: motherduck.com/blog/search-using-duckdb-part-3.md
    quote: Stopwords are commonly used words in a language, and are often removed
      from the search context.
    char_start: 0
    char_end: 95
- statement: Separating storage allowed us to build a dedicated storage system that
    allows sharing.
  type: definition
  entity: storage layer
  keywords:
  - definition
  - separating
  - storage
  - allowed
  - us
  - build
  - dedicated
  - system
  - allows
  - sharing
  source:
    doc: motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md
    quote: Separating storage allowed us to build a dedicated storage system that
      allows sharing.
    char_start: 0
    char_end: 86
- statement: The reject_errors table logs errors encountered during CSV import.
  type: definition
  entity: store_rejects
  keywords:
  - definition
  - reject
  - errors
  - table
  - logs
  - encountered
  - csv
  - import
  source:
    doc: motherduck.com/learn-more/data-warehouse-tco.md
    quote: FROM reject_errors; shows details about the failed rows.
    char_start: 0
    char_end: 56
- statement: Streaming Ingestion offers the lowest latency for real-time needs.
  type: definition
  entity: Streaming Ingestion
  keywords:
  - definition
  - streaming
  - ingestion
  - offers
  - lowest
  - latency
  - real
  - time
  - needs
  source:
    doc: motherduck.com/learn-more/what-is-duckdb.md
    quote: Streaming Ingestion offers the lowest latency.
    char_start: 0
    char_end: 46
- statement: Streamkap is streaming ETL and change data capture built on Apache Kafka
    and Flink.
  type: definition
  entity: Streamkap
  keywords:
  - definition
  - streamkap
  - streaming
  - etl
  - change
  - data
  - capture
  - built
  - apache
  - kafka
  - flink
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: Streamkap is streaming ETL and change data capture built on Apache Kafka
      and Flink.
    char_start: 0
    char_end: 83
- statement: Streamkap makes it easy to move operational data into analytics systems
    with low latency and high reliability.
  type: definition
  entity: Streamkap
  keywords:
  - definition
  - streamkap
  - makes
  - easy
  - move
  - operational
  - data
  - analytics
  - systems
  - low
  - latency
  - high
  - reliability
  source:
    doc: motherduck.com/learn-more/columnar-storage-guide.md
    quote: Streamkap is a real-time data pipeline platform that makes it easy to move
      operational data into analytics systems with low latency and high reliability.
    char_start: 0
    char_end: 153
- statement: Using Streamkap removes the need for batch ETL jobs.
  type: definition
  entity: Streamkap
  keywords:
  - definition
  - using
  - streamkap
  - removes
  - need
  - batch
  - etl
  - jobs
  source:
    doc: motherduck.com/learn-more/columnar-storage-guide.md
    quote: This early transformation layer removes the need for batch ETL jobs.
    char_start: 0
    char_end: 68
- statement: Streamlit is an open-source app framework for Machine Learning and Data
    Science projects.
  type: definition
  entity: Streamlit
  keywords:
  - definition
  - streamlit
  - open
  - source
  - app
  - framework
  - machine
  - learning
  - data
  - science
  - projects
  source:
    doc: motherduck.com/videos.md
    quote: Streamlit is an open-source app framework for Machine Learning and Data
      Science projects.
    char_start: 0
    char_end: 89
- statement: Streamlit powers our data app that combines interactive visualizations,
    filtering capabilities, a natural language interface, and anomaly highlighting.
  type: definition
  entity: Streamlit
  keywords:
  - definition
  - streamlit
  - powers
  - data
  - app
  - combines
  - interactive
  - visualizations
  - filtering
  - capabilities
  - natural
  - language
  - interface
  - anomaly
  - highlighting
  source:
    doc: motherduck.com/blog/python-faker-duckdb-exploration.md
    quote: 'Streamlit powers our data app that combines: - Interactive Visualizations:
      Including 3D plots (because why not?) showing relationships between temperature,
      vibration, and RPM. - Filtering Capabilities'
    char_start: 0
    char_end: 443
- statement: Streamlit serves as the dashboarding tool, directly querying MotherDuck
    for real-time analytics.
  type: definition
  entity: Streamlit
  keywords:
  - definition
  - streamlit
  - serves
  - dashboarding
  - tool
  - directly
  - querying
  - motherduck
  - real
  - time
  - analytics
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: Streamlit serves as the dashboarding tool, directly querying MotherDuck
      for real-time analytics.
    char_start: 0
    char_end: 96
- statement: Apache Hadoop emerged as the open-source implementation of MapReduce.
  type: definition
  entity: strict_mode
  keywords:
  - definition
  - apache
  - hadoop
  - emerged
  - open
  - source
  - implementation
  - mapreduce
  source:
    doc: motherduck.com/glossary/CLI.md
    quote: Apache Hadoop emerged as the open-source implementation of MapReduce.
    char_start: 0
    char_end: 69
- statement: Artie is a fully managed CDC streaming platform that keeps production
    data continuously in sync with your warehouse.
  type: definition
  entity: strict_mode
  keywords:
  - definition
  - artie
  - fully
  - managed
  - cdc
  - streaming
  - platform
  - keeps
  - production
  - data
  - continuously
  - sync
  - warehouse
  source:
    doc: motherduck.com/glossary/CSV.md
    quote: Artie is the modern data infrastructure layer for the AI era — a fully
      managed CDC streaming platform that keeps production data continuously in sync
      with your warehouse.
    char_start: 0
    char_end: 170
- statement: Codecentric is a leading German IT consultancy with deep expertise in
    Data & AI.
  type: definition
  entity: strict_mode
  keywords:
  - definition
  - codecentric
  - leading
  - german
  - consultancy
  - deep
  - expertise
  - data
  - ai
  source:
    doc: motherduck.com/glossary/Apache Arrow.md
    quote: codecentric AG is a leading German IT consultancy with deep expertise in
      Data & AI.
    char_start: 0
    char_end: 83
- statement: DuckLake has no cost for idle compute.
  type: definition
  entity: strict_mode
  keywords:
  - definition
  - ducklake
  - cost
  - idle
  - compute
  source:
    doc: motherduck.com/ecosystem/dbt.md
    quote: There is no cost for idle compute.
    char_start: 0
    char_end: 34
- statement: DuckLake offers serverless, consumption-based queries.
  type: definition
  entity: strict_mode
  keywords:
  - definition
  - ducklake
  - offers
  - serverless
  - consumption
  - based
  - queries
  source:
    doc: motherduck.com/ecosystem/dbt.md
    quote: You pay for cheap object storage... and for serverless, consumption-based
      queries.
    char_start: 0
    char_end: 82
- statement: Estuary allows for efficient data migration from proprietary systems.
  type: definition
  entity: strict_mode
  keywords:
  - definition
  - estuary
  - allows
  - efficient
  - data
  - migration
  - proprietary
  - systems
  source:
    doc: motherduck.com/ecosystem/dagster.md
    quote: Free your data with Estuary. Migrate from proprietary enterprise systems
      to a streamlined, modern destination like MotherDuck.
    char_start: 0
    char_end: 126
- statement: Estuary connects with PostgreSQL for data management.
  type: definition
  entity: strict_mode
  keywords:
  - definition
  - estuary
  - connects
  - postgresql
  - data
  - management
  source:
    doc: motherduck.com/ecosystem/polytomic.md
    quote: The connection string contains the hostname, user, and password that would
      be used in the Estuary connector.
    char_start: 0
    char_end: 108
- statement: For that, a traditional OLTP database like PostgreSQL or MySQL remains
    the best choice.
  type: definition
  entity: strict_mode
  keywords:
  - definition
  - traditional
  - oltp
  - database
  - like
  - postgresql
  - mysql
  - remains
  - best
  - choice
  source:
    doc: motherduck.com/glossary/Amazon S3.md
    quote: For that, a traditional OLTP database like PostgreSQL or MySQL remains
      the best choice.
    char_start: 0
    char_end: 87
- statement: GitHub Actions is used for orchestration with dbt core.
  type: definition
  entity: strict_mode
  keywords:
  - definition
  - github
  - actions
  - used
  - orchestration
  - dbt
  - core
  source:
    doc: motherduck.com/glossary/AI.md
    quote: 'Orchestration: GitHub Actions (with dbt core)'
    char_start: 0
    char_end: 45
- statement: Moving data from an operational OLTP database is a necessary step in
    any analytics journey.
  type: definition
  entity: strict_mode
  keywords:
  - definition
  - moving
  - data
  - operational
  - oltp
  - database
  - necessary
  - step
  - any
  - analytics
  - journey
  source:
    doc: motherduck.com/ecosystem/gooddata.md
    quote: Moving data from an operational OLTP database is a necessary step in any
      analytics journey.
    char_start: 0
    char_end: 91
- statement: null_padding fills missing columns with NULL instead of throwing an error.
  type: definition
  entity: strict_mode
  keywords:
  - definition
  - 'null'
  - padding
  - fills
  - missing
  - columns
  - instead
  - throwing
  - error
  source:
    doc: motherduck.com/glossary/7-Zip.md
    quote: Instead of throwing an error, DuckDB just fills in the blanks with NULL.
    char_start: 0
    char_end: 72
- statement: Providing the schema as an XML file is effective for getting good results.
  type: definition
  entity: strict_mode
  keywords:
  - definition
  - providing
  - schema
  - xml
  - file
  - effective
  - getting
  - good
  - results
  source:
    doc: motherduck.com/glossary/ETL.md
    quote: providing the schema as an XML file within the prompt's context is particularly
      effective for getting good results.
    char_start: 0
    char_end: 115
- statement: Setting strict_mode to false allows DuckDB to make its best guess on
    data.
  type: definition
  entity: strict_mode
  keywords:
  - definition
  - setting
  - strict
  - mode
  - 'false'
  - allows
  - duckdb
  - make
  - best
  - guess
  - data
  source:
    doc: motherduck.com/glossary/7-Zip.md
    quote: When you set strict_mode=false, you’re trusting DuckDB to make its best
      guess.
    char_start: 0
    char_end: 78
- statement: Streamlit allows you to stay within your Python data workflow.
  type: definition
  entity: strict_mode
  keywords:
  - definition
  - streamlit
  - allows
  - stay
  - within
  - python
  - data
  - workflow
  source:
    doc: motherduck.com/ecosystem/rill-data.md
    quote: The primary advantage (and possibly disadvantage) of Streamlit is that
      it allows you to stay within your Python data workflow.
    char_start: 0
    char_end: 126
- statement: Tools like Tableau, Power BI, and Looker are popular for creating interactive
    dashboards.
  type: definition
  entity: strict_mode
  keywords:
  - definition
  - tools
  - like
  - tableau
  - power
  - bi
  - looker
  - popular
  - creating
  - interactive
  - dashboards
  source:
    doc: motherduck.com/glossary/Pandas DataFrames.md
    quote: Tools like Tableau, Power BI, and Looker are popular for creating interactive
      dashboards and reports.
    char_start: 0
    char_end: 101
- statement: Zenlytic offers self-serve analytics capabilities, allowing users to
    gain insights from their data without needing technical expertise.
  type: definition
  entity: strict_mode
  keywords:
  - definition
  - zenlytic
  - offers
  - self
  - serve
  - analytics
  - capabilities
  - allowing
  - users
  - gain
  - insights
  - data
  - without
  - needing
  - technical
  - expertise
  source:
    doc: motherduck.com/ecosystem/bruin.md
    quote: Zenlytic is a business intelligence tool designed for e-commerce and direct-to-consumer
      brands. It offers self-serve analytics capabilities, allowing users to gain
      insights from their data without nee
    char_start: 0
    char_end: 225
- statement: Striim implemented a similar solution with DuckDB as an OLAP Cache with
    PostgreSQL Extension.
  type: definition
  entity: Striim
  keywords:
  - definition
  - striim
  - implemented
  - similar
  - solution
  - duckdb
  - olap
  - cache
  - postgresql
  - extension
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: Striim implemented a similar solution with DuckDB as an OLAP Cache with
      PostgreSQL Extension as part of their streaming solution.
    char_start: 0
    char_end: 129
- statement: Striim is an enterprise-grade CDC platform for streaming data pipelines.
  type: definition
  entity: Striim
  keywords:
  - definition
  - striim
  - enterprise
  - grade
  - cdc
  - platform
  - streaming
  - data
  - pipelines
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md
    quote: Striim (an enterprise-grade CDC platform) and DuckDB.
    char_start: 0
    char_end: 53
- statement: Comparisons work by comparing the fields positionally from left to right
    based on the defined schema order.
  type: definition
  entity: STRUCT
  keywords:
  - definition
  - comparisons
  - work
  - comparing
  - fields
  - positionally
  - left
  - right
  - based
  - defined
  - schema
  - order
  source:
    doc: motherduck.com/videos/using-sql-in-your-data-lake-with-duckdb-iceberg-dbt-and-motherduck.md
    quote: Comparisons work by comparing the fields positionally from left to right
      based on the defined schema order of the keys.
    char_start: 0
    char_end: 119
- statement: Every row in a STRUCT column must have the exact same keys with the same
    names and data types.
  type: definition
  entity: STRUCT
  keywords:
  - definition
  - every
  - row
  - struct
  - column
  - exact
  - keys
  - names
  - data
  - types
  source:
    doc: motherduck.com/videos/using-sql-in-your-data-lake-with-duckdb-iceberg-dbt-and-motherduck.md
    quote: every row in a STRUCT column must have the exact same keys with the same
      names and data types.
    char_start: 0
    char_end: 94
- statement: You can flatten STRUCTs in DuckDB to analyze nested data more easily.
  type: definition
  entity: STRUCT
  keywords:
  - definition
  - flatten
  - structs
  - duckdb
  - analyze
  - nested
  - data
  - easily
  source:
    doc: motherduck.com/videos/duckfooding-at-motherduck.md
    quote: One of the most powerful things you can do with STRUCTs... is to 'flatten'
      them.
    char_start: 0
    char_end: 80
- statement: SUBGROUP_ID is an identifier for demographic or age groups in the dataset.
  type: definition
  entity: SUBGROUP_ID
  keywords:
  - definition
  - subgroup
  - id
  - identifier
  - demographic
  - age
  - groups
  - dataset
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md
    quote: An identifier for demographic or age groups in the dataset.
    char_start: 0
    char_end: 59
- statement: Sublime Text is used by 10.9% of developers.
  type: definition
  entity: Sublime Text
  keywords:
  - definition
  - sublime
  - text
  - used
  - '10.9'
  - developers
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: Sublime Text (10.9%)
    char_start: 0
    char_end: 20
- statement: The summary_wf function summarizes recent e-commerce data.
  type: definition
  entity: summary_wf
  keywords:
  - definition
  - summary
  - wf
  - function
  - summarizes
  - recent
  - commerce
  - data
  source:
    doc: motherduck.com/blog/estuary-streaming-cdc-replication.md
    quote: A workflow function that summarizes recent e-commerce data.
    char_start: 0
    char_end: 59
- statement: Supabase is a great option for PostgreSQL databases.
  type: definition
  entity: Supabase
  keywords:
  - definition
  - supabase
  - great
  - option
  - postgresql
  - databases
  source:
    doc: motherduck.com/blog/semantic-layer-duckdb-tutorial.md
    quote: For the PostgreSQL database, Supabase is a great option.
    char_start: 0
    char_end: 56
- statement: Supabase provides a backend as a service, including a PostgreSQL database.
  type: definition
  entity: Supabase
  keywords:
  - definition
  - supabase
  - provides
  - backend
  - service
  - including
  - postgresql
  - database
  source:
    doc: motherduck.com/blog/spark-ducklake-getting-started.md
    quote: An open-source Firebase alternative that provides a backend as a service,
      including a PostgreSQL database.
    char_start: 0
    char_end: 106
- statement: Supabase provides tools for data replication from PostgreSQL.
  type: definition
  entity: Supabase
  keywords:
  - definition
  - supabase
  - provides
  - tools
  - data
  - replication
  - postgresql
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: This is a Change Data Capture approach that creates a continuous data pipeline,
      replicating changes from PostgreSQL to another system.
    char_start: 0
    char_end: 134
- statement: Choose Supabase ETL when you need near real-time data synchronization.
  type: definition
  entity: Supabase ETL
  keywords:
  - definition
  - choose
  - supabase
  - etl
  - need
  - near
  - real
  - time
  - data
  - synchronization
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: 'Choose Supabase ETL (CDC) when: You need near real-time data synchronization.'
    char_start: 0
    char_end: 77
- statement: Supabase ETL addresses the need for low-latency, continuous data movement.
  type: definition
  entity: Supabase ETL
  keywords:
  - definition
  - supabase
  - etl
  - addresses
  - need
  - low
  - latency
  - continuous
  - data
  - movement
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: Supabase ETL addresses the need for low-latency, continuous data movement.
    char_start: 0
    char_end: 74
- statement: Supabase ETL is a tool for change data capture and real-time analytics.
  type: definition
  entity: Supabase ETL
  keywords:
  - definition
  - supabase
  - etl
  - tool
  - change
  - data
  - capture
  - real
  - time
  - analytics
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: Supabase ETL is a tool for change data capture and real-time analytics.
    char_start: 0
    char_end: 71
- statement: Superdope is a fictional company that sells fashion apparel.
  type: definition
  entity: Superdope
  keywords:
  - definition
  - superdope
  - fictional
  - company
  - sells
  - fashion
  - apparel
  source:
    doc: motherduck.com/blog/making-pyspark-code-faster-with-duckdb.md
    quote: A fictional company that sells fashion apparel.
    char_start: 0
    char_end: 47
- statement: System Logs monitor infrastructure health.
  type: definition
  entity: System Logs
  keywords:
  - definition
  - system
  - logs
  - monitor
  - infrastructure
  - health
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: 'System Logs: Monitor infrastructure health when run in Kubernetes or similar
      platforms for data workloads.'
    char_start: 0
    char_end: 106
- statement: Local-first architecture allows applications to run offline and sync
    later.
  type: definition
  entity: Søren Brammer Schmidt
  keywords:
  - definition
  - local
  - first
  - architecture
  - allows
  - applications
  - run
  - offline
  - sync
  - later
  source:
    doc: motherduck.com/blog/introducing-fixit-ai-sql-error-fixer.md
    quote: If you have an application built in this local first way, you can run it
      without the cloud.
    char_start: 0
    char_end: 91
- statement: The Table Summary allows users to move faster from raw data to insights.
  type: definition
  entity: Table Summary
  keywords:
  - definition
  - table
  - summary
  - allows
  - users
  - move
  - faster
  - raw
  - data
  - insights
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: Our new Table Summary in the MotherDuck UI allows you to move faster from
      raw data to insights before writing a SELECT * query to explore your data.
    char_start: 0
    char_end: 148
- statement: The Table Summary supports ad-hoc analysis by providing an overview of
    the shape of your underlying data table and fields.
  type: definition
  entity: Table Summary
  keywords:
  - definition
  - table
  - summary
  - supports
  - ad
  - hoc
  - analysis
  - providing
  - overview
  - shape
  - underlying
  - data
  - fields
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: The Table Summary supports ad-hoc analysis by providing an overview of
      the shape of your underlying data table and fields.
    char_start: 0
    char_end: 122
- statement: 60,000 companies globally rely on Tableau for data visualization.
  type: definition
  entity: Tableau
  keywords:
  - definition
  - '60'
  - '000'
  - companies
  - globally
  - rely
  - tableau
  - data
  - visualization
  source:
    doc: motherduck.com/blog/announcing-motherduck-general-availability-data-warehousing-with-duckdb.md
    quote: 60,000 companies globally rely on Tableau (part of Salesforce) for data
      visualization.
    char_start: 0
    char_end: 86
- statement: Tableau Desktop is a data visualization tool.
  type: definition
  entity: Tableau
  keywords:
  - definition
  - tableau
  - desktop
  - data
  - visualization
  - tool
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: A data visualization tool.
    char_start: 0
    char_end: 26
- statement: Tableau is an Enterprise BI tool with powerful ETL features.
  type: definition
  entity: Tableau
  keywords:
  - definition
  - tableau
  - enterprise
  - bi
  - tool
  - powerful
  - etl
  - features
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: 'Tableau: An Enterprise BI tool that has existed for a long time, with
      powerful ETL and other features.'
    char_start: 0
    char_end: 102
- statement: Experienced Tableau users typically complete the setup in less than 15
    minutes.
  type: definition
  entity: Tableau Cloud
  keywords:
  - definition
  - experienced
  - tableau
  - users
  - typically
  - complete
  - setup
  - less
  - '15'
  - minutes
  source:
    doc: motherduck.com/learn-more/bigquery-alternative-motherduck.md
    quote: Experienced Tableau users typically complete the setup in less than 15
      minutes.
    char_start: 0
    char_end: 79
- statement: Tableau dashboard runs 10 separate, highly optimized queries to render
    its visuals.
  type: definition
  entity: Tableau Cloud
  keywords:
  - definition
  - tableau
  - dashboard
  - runs
  - '10'
  - separate
  - highly
  - optimized
  - queries
  - render
  - visuals
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: Your Head of Sales loads a Tableau dashboard that runs 10 separate, highly
      optimized queries to render its visuals.
    char_start: 0
    char_end: 115
- statement: The slow performance of Tableau dashboards meant most insights were locked
    behind the data team.
  type: definition
  entity: Tableau Cloud
  keywords:
  - definition
  - slow
  - performance
  - tableau
  - dashboards
  - meant
  - insights
  - locked
  - behind
  - data
  - team
  source:
    doc: motherduck.com/learn-more/secure-startup-data-warehouse.md
    quote: The slow performance of Tableau dashboards connected to Postgres meant
      most insights were locked behind the data team.
    char_start: 0
    char_end: 118
- statement: DataFrames organize data in rows and columns, similar to a spreadsheet
    or database table.
  type: definition
  entity: tabular data
  keywords:
  - definition
  - dataframes
  - organize
  - data
  - rows
  - columns
  - similar
  - spreadsheet
  - database
  - table
  source:
    doc: motherduck.com/videos/pg_duckdb-postgres-analytics-just-got-faster-with-duckdb.md
    quote: DataFrames organize data in rows and columns, similar to a spreadsheet
      or database table.
    char_start: 0
    char_end: 89
- statement: The most popular tag is javascript with 2479947 counts.
  type: definition
  entity: Tags
  keywords:
  - definition
  - popular
  - tag
  - javascript
  - '2479947'
  - counts
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: │ javascript │ 2479947 │
    char_start: 0
    char_end: 24
- statement: The Tags file contains 64465 entries.
  type: definition
  entity: Tags
  keywords:
  - definition
  - tags
  - file
  - contains
  - '64465'
  - entries
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: SELECT count(*) FROM read_csv_auto('Tags.csv.gz');
    char_start: 0
    char_end: 50
- statement: Tanatorio Cangas de Onís is one of the funeral homes listed in the dataset.
  type: definition
  entity: Tanatorio Cangas de Onís
  keywords:
  - definition
  - tanatorio
  - cangas
  - de
  - one
  - funeral
  - homes
  - listed
  - dataset
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: │ 271112 │ POINT (-5.1120723 43.350132)                  │ Tanatorio Cangas
      de Onís                      │
    char_start: 0
    char_end: 106
- statement: Tangled and Gitea are alternatives to Git for data versioning.
  type: definition
  entity: Tangled
  keywords:
  - definition
  - tangled
  - gitea
  - alternatives
  - git
  - data
  - versioning
  source:
    doc: motherduck.com/blog/semantic-layer-duckdb-tutorial.md
    quote: alternatives are Tangled and Gitea
    char_start: 0
    char_end: 34
- statement: The belief that data contains inherent value is flawed for most organizations.
  type: definition
  entity: Target
  keywords:
  - definition
  - belief
  - data
  - contains
  - inherent
  - value
  - flawed
  - organizations
  source:
    doc: motherduck.com/learn-more/product-analytics-motherduck-duckdb.md
    quote: A lot of people came to very much believe that data just contains value...
      And all it takes is us to have the right tools to get that insight out.
    char_start: 0
    char_end: 146
- statement: TARGIT is an enterprise BI solution specializing in industry-specific
    implementations.
  type: definition
  entity: TARGIT
  keywords:
  - definition
  - targit
  - enterprise
  - bi
  - solution
  - specializing
  - industry
  - specific
  - implementations
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: 'TARGIT: Enterprise BI solution specializing in industry-specific implementations
      in the Nordics.'
    char_start: 0
    char_end: 96
- statement: Tasman is an analytics agency that turns data into meaningful business
    value.
  type: definition
  entity: Tasman
  keywords:
  - definition
  - tasman
  - analytics
  - agency
  - turns
  - data
  - meaningful
  - business
  - value
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: Tasman is an analytics agency that turns data into meaningful business
      value.
    char_start: 0
    char_end: 77
- statement: Ted Conbeer is a mechanical engineer turned management consultant, who
    eventually became an analytics engineer and startup executive and advisor.
  type: definition
  entity: Ted Conbeer
  keywords:
  - definition
  - ted
  - conbeer
  - mechanical
  - engineer
  - turned
  - management
  - consultant
  - who
  - eventually
  - became
  - analytics
  - startup
  - executive
  - advisor
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2024.md
    quote: Ted Conbeer is a mechanical engineer turned management consultant, who
      eventually became an analytics engineer and startup executive and advisor.
    char_start: 0
    char_end: 145
- statement: Temporal is an open-source platform for running microservices and workflows.
  type: definition
  entity: Temporal
  keywords:
  - definition
  - temporal
  - open
  - source
  - platform
  - running
  - microservices
  - workflows
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: An open-source platform for running microservices and workflows.
    char_start: 0
    char_end: 64
- statement: AI-related risk is fundamentally reshaping global economic outlooks.
  type: definition
  entity: Tensorlake
  keywords:
  - definition
  - ai
  - related
  - risk
  - fundamentally
  - reshaping
  - global
  - economic
  - outlooks
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: AI-related risk is fundamentally reshaping global economic outlooks.
    char_start: 0
    char_end: 68
- statement: Tensorlake allows querying unstructured documents with SQL.
  type: definition
  entity: Tensorlake
  keywords:
  - definition
  - tensorlake
  - allows
  - querying
  - unstructured
  - documents
  - sql
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2024.md
    quote: Learn how to query unstructured documents with friendly SQL!
    char_start: 0
    char_end: 60
- statement: Tensorlake's Document Ingestion API can turn risk disclosures into queryable
    JSON.
  type: definition
  entity: Tensorlake
  keywords:
  - definition
  - tensorlake
  - document
  - ingestion
  - api
  - turn
  - risk
  - disclosures
  - queryable
  - json
  source:
    doc: motherduck.com/learn-more/diagnose-fix-slow-queries.md
    quote: With the right pages identified, it's time to extract structured data.
    char_start: 0
    char_end: 70
- statement: Together, Tensorlake and MotherDuck turn unstructured documents into
    analytics-ready datasets.
  type: definition
  entity: Tensorlake
  keywords:
  - definition
  - together
  - tensorlake
  - motherduck
  - turn
  - unstructured
  - documents
  - analytics
  - ready
  - datasets
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part2.md
    quote: Together, Tensorlake and MotherDuck turn unstructured documents into analytics-ready
      datasets.
    char_start: 0
    char_end: 94
- statement: Companies like Teradata introduced Massively Parallel Processing (MPP)
    machines, including the DBC/1012 in 1984.
  type: definition
  entity: Teradata
  keywords:
  - definition
  - companies
  - like
  - teradata
  - introduced
  - massively
  - parallel
  - processing
  - mpp
  - machines
  - including
  - dbc
  - '1012'
  - '1984'
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: Companies like Teradata introduced Massively Parallel Processing (MPP)
      machines, including the DBC/1012 in 1984.
    char_start: 0
    char_end: 112
- statement: Terraform is an open-source infrastructure as code tool.
  type: definition
  entity: Terraform
  keywords:
  - definition
  - terraform
  - open
  - source
  - infrastructure
  - code
  - tool
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: Popular frameworks, such as Terraform, Helm, and Ansible, as well as other
      scripts, can be deployed on any cloud.
    char_start: 0
    char_end: 113
- statement: Text embedding is a representation of text in a high-dimensional space,
    often used in natural language processing.
  type: definition
  entity: text embedding
  keywords:
  - definition
  - text
  - embedding
  - representation
  - high
  - dimensional
  - space
  - often
  - used
  - natural
  - language
  - processing
  source:
    doc: motherduck.com/blog/announcing-small-data-sf-2025.md
    quote: Text embedding is a representation of text in a high-dimensional space,
      often used in natural language processing.
    char_start: 0
    char_end: 114
- statement: Text embeddings are dense vectors that represent the meaning of text.
  type: definition
  entity: text embeddings
  keywords:
  - definition
  - text
  - embeddings
  - dense
  - vectors
  - represent
  - meaning
  source:
    doc: motherduck.com/blog/announcing-small-data-sf-2025.md
    quote: Text embeddings are dense vectors that represent the meaning of text.
    char_start: 0
    char_end: 69
- statement: The text-embedding-3-large model is used for generating text representations.
  type: definition
  entity: text-embedding-3-large
  keywords:
  - definition
  - text
  - embedding
  - large
  - model
  - used
  - generating
  - representations
  source:
    doc: motherduck.com/blog/announcing-small-data-sf-2025.md
    quote: An embedding model used for generating text representations.
    char_start: 0
    char_end: 60
- statement: Text2SQL solutions are primarily used today as co-pilots for SQL analysts
    and data scientists.
  type: definition
  entity: Text2SQL
  keywords:
  - definition
  - text2sql
  - solutions
  - primarily
  - used
  - today
  - co
  - pilots
  - sql
  - analysts
  - data
  - scientists
  source:
    doc: motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md
    quote: Text2SQL solutions are primarily used today as co-pilots for SQL analysts
      and data scientists to yield significant productivity gains.
    char_start: 0
    char_end: 134
- statement: Text2SQL was a topic of many discussions.
  type: definition
  entity: Text2SQL
  keywords:
  - definition
  - text2sql
  - topic
  - many
  - discussions
  source:
    doc: motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md
    quote: Text2SQL was a topic.
    char_start: 0
    char_end: 21
- statement: Textplot enables terminal-based visualizations with functions for progress
    indicators.
  type: definition
  entity: Textplot
  keywords:
  - definition
  - textplot
  - enables
  - terminal
  - based
  - visualizations
  - functions
  - progress
  - indicators
  source:
    doc: motherduck.com/blog/estuary-streaming-cdc-replication.md
    quote: Meanwhile, their Textplot extension enables terminal-based visualizations
      with functions for progress indicators...
    char_start: 0
    char_end: 115
- statement: The Data Engineering Cookbook is a widely used reference for data platform
    architecture fundamentals.
  type: definition
  entity: The Data Engineering Cookbook
  keywords:
  - definition
  - data
  - engineering
  - cookbook
  - widely
  - used
  - reference
  - platform
  - architecture
  - fundamentals
  source:
    doc: motherduck.com/blog/motherduck-union-orchestration.md
    quote: The Data Engineering Cookbook, an open-source GitHub resource that has
      become a widely used reference for data platform architecture fundamentals.
    char_start: 0
    char_end: 146
- statement: The top watched movies during the COVID lockdown included 'The Mitchells
    vs. The Machines', 'How the Grinch Stole Christmas', 'Vivo', '365 Days', and 'Despicable
    Me 2'.
  type: definition
  entity: The Mitchells vs. The Machines
  keywords:
  - definition
  - top
  - watched
  - movies
  - covid
  - lockdown
  - included
  - mitchells
  - vs
  - machines
  - grinch
  - stole
  - christmas
  - vivo
  - '365'
  - days
  - despicable
  - me
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-1.md
    quote: the top 5 mostly include kids show.
    char_start: 0
    char_end: 35
- statement: Tigris allows for the creation of isolated copies of data for experimentation.
  type: definition
  entity: Tigris
  keywords:
  - definition
  - tigris
  - allows
  - creation
  - isolated
  - copies
  - data
  - experimentation
  source:
    doc: motherduck.com/blog/postgres-duckdb-options.md
    quote: You can instantly create an isolated copy of your data for development,
      testing, or experimentation.
    char_start: 0
    char_end: 100
- statement: Till Döhmen presented research on SchemaPile.
  type: definition
  entity: Till Döhmen
  keywords:
  - definition
  - till
  - hmen
  - presented
  - research
  - schemapile
  source:
    doc: motherduck.com/blog/log-processing-savings-bacalhau-motherduck.md
    quote: 'Till Döhmen, AI/ML Lead, presented his research on ''SchemaPile: A Large
      Collection of Relational Database Schemas''.'
    char_start: 0
    char_end: 115
- statement: Time to Value (TTV) is the time for a customer to realize product value.
  type: definition
  entity: Time to Value (TTV)
  keywords:
  - definition
  - time
  - value
  - ttv
  - customer
  - realize
  - product
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: Time to Value (TTV)
    char_start: 0
    char_end: 19
- statement: Shelby’s team is building small language models.
  type: definition
  entity: TinyGiant
  keywords:
  - definition
  - shelby
  - team
  - building
  - small
  - language
  - models
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: Yes! Yes it does, and Shelby’s team is building them.
    char_start: 0
    char_end: 53
- statement: Tobias created the sql-workbench-embedded extension for embedding DuckDB
    queries.
  type: definition
  entity: Tobias
  keywords:
  - definition
  - tobias
  - created
  - sql
  - workbench
  - embedded
  - extension
  - embedding
  - duckdb
  - queries
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: Tobias, a very active community member, also created another extension
      called sql-workbench-embedded for embedding DuckDB queries.
    char_start: 0
    char_end: 130
- statement: Tobias Müller is a notable builder of DuckDB things.
  type: definition
  entity: Tobias Müller
  keywords:
  - definition
  - tobias
  - ller
  - notable
  - builder
  - duckdb
  - things
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-nine.md
    quote: Tobias Muller is a notable builder of DuckDB things.
    char_start: 0
    char_end: 52
- statement: Tobias Müller writes about DuckDB on his blog tobilg.com.
  type: definition
  entity: Tobias Müller
  keywords:
  - definition
  - tobias
  - ller
  - writes
  - about
  - duckdb
  - blog
  - tobilg
  - com
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-nine.md
    quote: Tobias Müller and writing about them on his blog, tobilg.com.
    char_start: 0
    char_end: 61
- statement: Victoriano is visualizing the post in a network graph with Graphext.
  type: definition
  entity: Tobias Müller
  keywords:
  - definition
  - victoriano
  - visualizing
  - post
  - network
  - graph
  - graphext
  source:
    doc: motherduck.com/blog/duckdb-wasm-in-browser.md
    quote: Victoriano is visualizing the post in a network graph with [Graphext](https://github.com/victoriano/bluesky-social-graph).
    char_start: 0
    char_end: 122
- statement: Tomasz Tunguz and Lauren DeMeuse discuss the evolution of enterprise
    data needs.
  type: definition
  entity: Tomasz Tunguz
  keywords:
  - definition
  - tomasz
  - tunguz
  - lauren
  - demeuse
  - discuss
  - evolution
  - enterprise
  - data
  - needs
  source:
    doc: motherduck.com/videos/duckdb-run-dbt-build-with-sub-second-execution-times.md
    quote: In this discussion, we cover the evolution of enterprise data needs.
    char_start: 0
    char_end: 68
- statement: TortoiseSVN was a popular version control system before Git.
  type: definition
  entity: TortoiseSVN
  keywords:
  - definition
  - tortoisesvn
  - popular
  - version
  - control
  - system
  - git
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: There was a time of TortoiseSVN and others.
    char_start: 0
    char_end: 43
- statement: TPC-DS is a benchmark for evaluating the performance of data processing
    systems.
  type: definition
  entity: TPC-DS
  keywords:
  - definition
  - tpc
  - ds
  - benchmark
  - evaluating
  - performance
  - data
  - processing
  - systems
  source:
    doc: motherduck.com/blog/dual-execution-dbt.md
    quote: TPC-DS is a benchmark for evaluating the performance of data processing
      systems.
    char_start: 0
    char_end: 80
- statement: Transaction Logs track database operations.
  type: definition
  entity: Transaction Logs
  keywords:
  - definition
  - transaction
  - logs
  - track
  - database
  - operations
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: 'Transaction Logs: Track database operations and changes to ensure data
      integrity.'
    char_start: 0
    char_end: 81
- statement: Many analytical projects begin on transactional databases, especially
    for smaller datasets.
  type: definition
  entity: Transactional Database
  keywords:
  - definition
  - many
  - analytical
  - projects
  - begin
  - transactional
  - databases
  - especially
  - smaller
  - datasets
  source:
    doc: motherduck.com/blog/why-web-developers-should-care-about-analytical-databases.md
    quote: Many analytical projects begin like that, especially for smaller datasets
      or simple reporting.
    char_start: 0
    char_end: 94
- statement: Tributary enables real-time SQL access to Kafka streams.
  type: definition
  entity: Tributary
  keywords:
  - definition
  - tributary
  - enables
  - real
  - time
  - sql
  - access
  - kafka
  - streams
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: a DuckDB community extension built at Query.Farm that enables real-time
      SQL access to Kafka streams.
    char_start: 0
    char_end: 100
- statement: TRN1 instances have 8 100-gigabit network adapters.
  type: definition
  entity: TRN1 instances
  keywords:
  - definition
  - trn1
  - instances
  - '100'
  - gigabit
  - network
  - adapters
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: the TRN1 instances have 8 100-gigabit network adapters
    char_start: 0
    char_end: 54
- statement: Slow queries had a cascading effect on Trunkrs' operational efficiency.
  type: definition
  entity: Trunkrs
  keywords:
  - definition
  - slow
  - queries
  - cascading
  - effect
  - trunkrs
  - operational
  - efficiency
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: The slow queries had a cascading effect.
    char_start: 0
    char_end: 40
- statement: The migration proved surprisingly straightforward.
  type: definition
  entity: Trunkrs
  keywords:
  - definition
  - migration
  - proved
  - surprisingly
  - straightforward
  source:
    doc: motherduck.com/case-studies/trunkrs-same-day-delivery-motherduck-from-redshift.md
    quote: The migration proved surprisingly straightforward.
    char_start: 0
    char_end: 50
- statement: The move to MotherDuck lowered Trunkrs' data platform's complexity and
    cost.
  type: definition
  entity: Trunkrs
  keywords:
  - definition
  - move
  - motherduck
  - lowered
  - trunkrs
  - data
  - platform
  - complexity
  - cost
  source:
    doc: motherduck.com/learn-more/data-application-architecture.md
    quote: The move not only lowered their data platform's complexity and cost.
    char_start: 0
    char_end: 68
- statement: The quicker you can go through this and drill down in that data, the
    more insights you will get.
  type: definition
  entity: Trunkrs
  keywords:
  - definition
  - quicker
  - go
  - drill
  - down
  - data
  - insights
  - get
  source:
    doc: motherduck.com/blog/why-web-developers-should-care-about-analytical-databases.md
    quote: The quicker you can go through this and drill down in that data, the more
      insights you will get and easier it becomes to make sure that we're not making
      the same mistake today that we made yesterday.
    char_start: 0
    char_end: 199
- statement: Trunkrs continues to revolutionize same-day delivery in the Netherlands.
  type: definition
  entity: Trunkrs
  keywords:
  - definition
  - trunkrs
  - continues
  - revolutionize
  - day
  - delivery
  - netherlands
  source:
    doc: motherduck.com/blog/streaming-data-to-motherduck.md
    quote: As Trunkrs continues to revolutionize same-day delivery in the Netherlands,
      they now have the analytical horsepower to match their operational ambitions.
    char_start: 0
    char_end: 153
- statement: Trunkrs experienced faster, 'snappier' responses after migrating to MotherDuck.
  type: definition
  entity: Trunkrs
  keywords:
  - definition
  - trunkrs
  - experienced
  - faster
  - snappier
  - responses
  - migrating
  - motherduck
  source:
    doc: motherduck.com/learn-more/data-application-architecture.md
    quote: After migrating to MotherDuck, they experienced immediately faster, 'snappier'
      responses.
    char_start: 0
    char_end: 89
- statement: Trunkrs has become the market leader in frozen meat delivery by leveraging
    their quick network.
  type: definition
  entity: Trunkrs
  keywords:
  - definition
  - trunkrs
  - become
  - market
  - leader
  - frozen
  - meat
  - delivery
  - leveraging
  - quick
  - network
  source:
    doc: motherduck.com/blog/streaming-oracle-to-motherduck.md
    quote: The company has become the market leader in frozen meat delivery by leveraging
      their quick network to eliminate the need for expensive cold chain logistics.
    char_start: 0
    char_end: 156
- statement: Trunkrs is a perfect example of how MotherDuck shines.
  type: definition
  entity: Trunkrs
  keywords:
  - definition
  - trunkrs
  - perfect
  - example
  - motherduck
  - shines
  source:
    doc: motherduck.com/blog/local-duckdb-ui-visual-data-analysis.md
    quote: Trunkrs is a perfect example of how MotherDuck shines.
    char_start: 0
    char_end: 54
- statement: Trunkrs is expanding how they use analytics by embedding analytics directly
    in their shipping portal.
  type: definition
  entity: Trunkrs
  keywords:
  - definition
  - trunkrs
  - expanding
  - use
  - analytics
  - embedding
  - directly
  - shipping
  - portal
  source:
    doc: motherduck.com/blog/vibe-coding-sql-cursor.md
    quote: With approximately 700GB already migrated (about 30-40% of their total
      data), Trunkrs is expanding how they use analytics.
    char_start: 0
    char_end: 122
- statement: Trunkrs migrated from Redshift to MotherDuck to power their real-time
    operational decisions.
  type: definition
  entity: Trunkrs
  keywords:
  - definition
  - trunkrs
  - migrated
  - redshift
  - motherduck
  - power
  - real
  - time
  - operational
  - decisions
  source:
    doc: motherduck.com/blog/separating-storage-compute-duckdb.md
    quote: Trunkrs migrated from Redshift to MotherDuck to power their real-time operational
      decisions.
    char_start: 0
    char_end: 92
- statement: Trunkrs orchestrates a network of existing assets to create an efficient
    same-day delivery network.
  type: definition
  entity: Trunkrs
  keywords:
  - definition
  - trunkrs
  - orchestrates
  - network
  - existing
  - assets
  - create
  - efficient
  - day
  - delivery
  source:
    doc: motherduck.com/blog/streaming-oracle-to-motherduck.md
    quote: Trunkrs orchestrates a network of existing assets—vehicles that would otherwise
      sit idle in the evenings—to create an efficient same-day delivery network specializing
      in perishable goods.
    char_start: 0
    char_end: 187
- statement: Trunkrs runs a day-start meeting where teams dive into the previous day's
    performance.
  type: definition
  entity: Trunkrs
  keywords:
  - definition
  - trunkrs
  - runs
  - day
  - start
  - meeting
  - teams
  - dive
  - previous
  - performance
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: Every morning, Trunkrs runs a day-start meeting where teams dive into the
      previous day's performance.
    char_start: 0
    char_end: 101
- statement: Trunkrs transitioned from Redshift to a more efficient serverless solution.
  type: definition
  entity: Trunkrs
  keywords:
  - definition
  - trunkrs
  - transitioned
  - redshift
  - efficient
  - serverless
  - solution
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: From Redshift frustration to serverless simplicity
    char_start: 0
    char_end: 50
- statement: Trunkrs uses dbt and Looker for their data processes.
  type: definition
  entity: Trunkrs
  keywords:
  - definition
  - trunkrs
  - uses
  - dbt
  - looker
  - data
  - processes
  source:
    doc: motherduck.com/blog/vibe-coding-sql-cursor.md
    quote: The team has also split their MotherDuck usage between transformation workloads
      (dbt and ELT processes) and query workloads (Looker and direct SQL access).
    char_start: 0
    char_end: 155
- statement: Trunkrs utilizes hybrid columnar platforms for same-day delivery.
  type: definition
  entity: Trunkrs
  keywords:
  - definition
  - trunkrs
  - utilizes
  - hybrid
  - columnar
  - platforms
  - day
  - delivery
  source:
    doc: motherduck.com/learn-more/data-application-architecture.md
    quote: A compelling example of the hybrid model's success is the logistics company
      Trunkrs.
    char_start: 0
    char_end: 84
- statement: With MotherDuck, we're seeing that response is just a lot snappier.
  type: definition
  entity: Trunkrs
  keywords:
  - definition
  - motherduck
  - re
  - seeing
  - response
  - lot
  - snappier
  source:
    doc: motherduck.com/blog/separating-storage-compute-duckdb.md
    quote: '"With MotherDuck, we''re seeing that response is just a lot snappier,"
      explains Hidde Stokvis, COO and data leader at Trunkrs.'
    char_start: 0
    char_end: 125
- statement: Turso offers a cloud solution for SQLite databases.
  type: definition
  entity: Turso
  keywords:
  - definition
  - turso
  - offers
  - cloud
  - solution
  - sqlite
  - databases
  source:
    doc: motherduck.com/learn-more/partitioned-writes-parquet-ducklake.md
    quote: Turso offers a cloud solution for SQLite databases.
    char_start: 0
    char_end: 51
- statement: Twitch is a live streaming platform for gamers.
  type: definition
  entity: Twitch
  keywords:
  - definition
  - twitch
  - live
  - streaming
  - platform
  - gamers
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: Twitch is a live streaming platform for gamers.
    char_start: 0
    char_end: 47
- statement: The dataset contains sampled twitch gamer accounts as well as the mutual
    follower relationships between them.
  type: definition
  entity: Twitch Gamers
  keywords:
  - definition
  - dataset
  - contains
  - sampled
  - twitch
  - gamer
  - accounts
  - well
  - mutual
  - follower
  - relationships
  - them
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: The dataset contains sampled twitch gamer accounts as well as the mutual
      follower relationships between them.
    char_start: 0
    char_end: 109
- statement: The dataset contains 168,114 features.
  type: definition
  entity: twitch_gamers
  keywords:
  - definition
  - dataset
  - contains
  - '168'
  - '114'
  - features
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: D select count(*) from features; ┌──────────────┐ │ count_star() │ │ int64
      │ ├──────────────┤ │ 168114 │ └──────────────┘
    char_start: 0
    char_end: 121
- statement: The dataset contains 6,797,557 edges.
  type: definition
  entity: twitch_gamers
  keywords:
  - definition
  - dataset
  - contains
  - '797'
  - '557'
  - edges
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: D select count(*) from edges; ┌──────────────┐ │ count_star() │ │ int64
      │ ├──────────────┤ │ 6797557 │ └──────────────┘
    char_start: 0
    char_end: 119
- statement: There are 5,159 dead accounts in the dataset.
  type: definition
  entity: twitch_gamers
  keywords:
  - definition
  - '159'
  - dead
  - accounts
  - dataset
  source:
    doc: motherduck.com/blog/json-log-analysis-duckdb-motherduck.md
    quote: D select count(*) from features where dead_account; ┌──────────────┐ │
      count_star() │ │ int64 │ ├──────────────┤ │ 5159 │ └──────────────┘
    char_start: 0
    char_end: 138
- statement: TypeQL offers an expressive type system that promises to revolutionize
    database interaction.
  type: definition
  entity: TypeDB
  keywords:
  - definition
  - typeql
  - offers
  - expressive
  - type
  - system
  - promises
  - revolutionize
  - database
  - interaction
  source:
    doc: motherduck.com/blog/duckdb-enterprise-5-key-categories.md
    quote: TypeDB showcased TypeQL, a new query language inspired by natural language.
    char_start: 0
    char_end: 75
- statement: UDisc reduced typical queries from 6 hours to 30 minutes.
  type: definition
  entity: uDisc
  keywords:
  - definition
  - udisc
  - reduced
  - typical
  - queries
  - hours
  - '30'
  - minutes
  source:
    doc: motherduck.com/learn-more/no-etl-query-raw-files.md
    quote: '[dbt job time reduced from](https://motherduck.com/case-studies/udisc-motherduck-sports-management/)
      and typical queries dropped from minutes to 5 seconds.'
    char_start: 0
    char_end: 155
- statement: UMAP is a dimensionality reduction technique used for visualizing high-dimensional
    data.
  type: definition
  entity: UMAP
  keywords:
  - definition
  - umap
  - dimensionality
  - reduction
  - technique
  - used
  - visualizing
  - high
  - dimensional
  - data
  source:
    doc: motherduck.com/blog/announcing-small-data-sf-2025.md
    quote: A dimensionality reduction technique used for visualizing high-dimensional
      data.
    char_start: 0
    char_end: 80
- statement: Unity Catalog supports Delta Lake and implements the Iceberg REST Catalog
    API interface.
  type: definition
  entity: UnityCatalog
  keywords:
  - definition
  - unity
  - catalog
  - supports
  - delta
  - lake
  - implements
  - iceberg
  - rest
  - api
  - interface
  source:
    doc: motherduck.com/blog/duckdb-versus-pandas-versus-polars.md
    quote: Unity Catalog supports Delta Lake and also implements the Iceberg REST
      Catalog API interface.
    char_start: 0
    char_end: 93
- statement: Scalable, interactive data visualizations are needed for better data
    interaction.
  type: definition
  entity: University of Washington
  keywords:
  - definition
  - scalable
  - interactive
  - data
  - visualizations
  - needed
  - better
  - interaction
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-2.md
    quote: discussions of scalable, interactive data visualizations by University
      of Washington PhD student Junran Yang also highlighted the need for better ways
      to interact with data.
    char_start: 0
    char_end: 173
- statement: A distributed system will almost always display higher latency than a
    single node system.
  type: definition
  entity: unknown
  keywords:
  - definition
  - distributed
  - system
  - almost
  - always
  - display
  - higher
  - latency
  - single
  - node
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: A distributed system will almost always display higher latency, especially
      tail latency, than a single node system.
    char_start: 0
    char_end: 115
- statement: Accessing Databricks UnityCatalog data using DuckDB improves efficiency
    by bypassing Spark for direct delta file reads.
  type: definition
  entity: unknown
  keywords:
  - definition
  - accessing
  - databricks
  - unitycatalog
  - data
  - using
  - duckdb
  - improves
  - efficiency
  - bypassing
  - spark
  - direct
  - delta
  - file
  - reads
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: Accessing Databricks UnityCatalog data using DuckDB improves efficiency
      by bypassing Spark for direct delta file reads.
    char_start: 0
    char_end: 119
- statement: ACID stands for Atomicity, Consistency, Isolation, and Durability.
  type: definition
  entity: unknown
  keywords:
  - definition
  - acid
  - stands
  - atomicity
  - consistency
  - isolation
  - durability
  source:
    doc: motherduck.com/blog/streaming-oracle-to-motherduck.md
    quote: At its core, ACID stands for Atomicity, Consistency, Isolation, and Durability.
    char_start: 0
    char_end: 79
- statement: ACID transactions are the foundation of data integrity in relational
    databases.
  type: definition
  entity: unknown
  keywords:
  - definition
  - acid
  - transactions
  - foundation
  - data
  - integrity
  - relational
  - databases
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: ACID transactions are the foundation of data integrity in relational databases.
    char_start: 0
    char_end: 79
- statement: AI can boost productivity in data app development through Cursor configurations.
  type: definition
  entity: unknown
  keywords:
  - definition
  - ai
  - boost
  - productivity
  - data
  - app
  - development
  - cursor
  - configurations
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: Archie's Cursor configurations that boost productivity in data app development
    char_start: 0
    char_end: 78
- statement: AI can empower users to write accurate SQL using MotherDuck and DuckDB.
  type: definition
  entity: unknown
  keywords:
  - definition
  - ai
  - empower
  - users
  - write
  - accurate
  - sql
  - using
  - motherduck
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: AI can empower you to 'vibe code'—using AI to write accurate SQL, enabled
      only by the magic of MotherDuck & DuckDB
    char_start: 0
    char_end: 114
- statement: AI can shorten data engineering test-deploy cycles using MCP feedback
    loops.
  type: definition
  entity: unknown
  keywords:
  - definition
  - ai
  - shorten
  - data
  - engineering
  - test
  - deploy
  - cycles
  - using
  - mcp
  - feedback
  - loops
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: How Mehdi shortens his data engineering test-deploy cycles using MCP feedback
      loops
    char_start: 0
    char_end: 83
- statement: Attendees will enjoy a fun-filled atmosphere where they can network with
    fellow AWS enthusiasts.
  type: definition
  entity: unknown
  keywords:
  - definition
  - attendees
  - enjoy
  - fun
  - filled
  - atmosphere
  - network
  - fellow
  - aws
  - enthusiasts
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: Attendees will enjoy a fun-filled atmosphere where they can network with
      fellow AWS enthusiasts.
    char_start: 0
    char_end: 96
- statement: Bayu anticipates a performance boost from MinIO compared to traditional
    local storage.
  type: definition
  entity: unknown
  keywords:
  - definition
  - bayu
  - anticipates
  - performance
  - boost
  - minio
  - compared
  - traditional
  - local
  - storage
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Bayu anticipates a performance boost from MinIO compared to traditional
      local storage, enabling faster and more reliable data delivery.
    char_start: 0
    char_end: 135
- statement: BGE-M3 can produce dense and multi-vector term embeddings.
  type: definition
  entity: unknown
  keywords:
  - definition
  - bge
  - m3
  - produce
  - dense
  - multi
  - vector
  - term
  - embeddings
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: BGE-M3 due to its multi-lingual capabilities and the fact that it can produce
      dense and multi-vector term embeddings.
    char_start: 0
    char_end: 117
- statement: Big data has become integral to industries like finance, retail, healthcare,
    and technology.
  type: definition
  entity: unknown
  keywords:
  - definition
  - big
  - data
  - become
  - integral
  - industries
  - like
  - finance
  - retail
  - healthcare
  - technology
  source:
    doc: motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md
    quote: Big data has become integral to industries like finance, retail, healthcare,
      and technology.
    char_start: 0
    char_end: 92
- statement: boringcatalog provides a simple, file-based Iceberg catalog implementation.
  type: definition
  entity: unknown
  keywords:
  - definition
  - boringcatalog
  - provides
  - simple
  - file
  - based
  - iceberg
  - catalog
  - implementation
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Julien Hurault introduces boringcatalog, a Python package that provides
      a simple, file-based Iceberg catalog implementation.
    char_start: 0
    char_end: 124
- statement: Cloud storage offers scalability, redundancy, and cost-effectiveness.
  type: definition
  entity: unknown
  keywords:
  - definition
  - cloud
  - storage
  - offers
  - scalability
  - redundancy
  - cost
  - effectiveness
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: Cloud storage offers scalability, redundancy, and cost-effectiveness.
    char_start: 0
    char_end: 69
- statement: Cloud storage refers to a model of data storage where digital information
    is saved on remote servers accessed through the internet.
  type: definition
  entity: unknown
  keywords:
  - definition
  - cloud
  - storage
  - refers
  - model
  - data
  - digital
  - information
  - saved
  - remote
  - servers
  - accessed
  - internet
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: Cloud storage refers to a model of data storage where digital information
      is saved on remote servers accessed through the internet.
    char_start: 0
    char_end: 131
- statement: Cloudflare offers a cost-effective alternative to enterprise solutions
    for data lakes.
  type: definition
  entity: unknown
  keywords:
  - definition
  - cloudflare
  - offers
  - cost
  - effective
  - alternative
  - enterprise
  - solutions
  - data
  - lakes
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: This article explores building a cost-effective data lake using Cloudflare's
      services.
    char_start: 0
    char_end: 86
- statement: Columnar formats achieve high compression ratios, reducing storage costs
    and speeding up queries.
  type: definition
  entity: unknown
  keywords:
  - definition
  - columnar
  - formats
  - achieve
  - high
  - compression
  - ratios
  - reducing
  - storage
  - costs
  - speeding
  - up
  - queries
  source:
    doc: motherduck.com/case-studies/reflex-careers-gig-economy-retail.md
    quote: It's common for columnar formats to achieve high compression ratios, which
      not only reduces storage costs but also speeds up queries by minimizing the
      amount of data that needs to be read from disk.
    char_start: 0
    char_end: 198
- statement: Columnar systems have evolved beyond monolithic data warehouses.
  type: definition
  entity: unknown
  keywords:
  - definition
  - columnar
  - systems
  - evolved
  - beyond
  - monolithic
  - data
  - warehouses
  source:
    doc: motherduck.com/learn-more.md
    quote: Columnar systems have evolved beyond monolithic data warehouses into flexible
      architectures that serve different needs.
    char_start: 0
    char_end: 119
- statement: Concurrency scaling ensures consistent performance during high query
    demand.
  type: definition
  entity: unknown
  keywords:
  - definition
  - concurrency
  - scaling
  - ensures
  - consistent
  - performance
  - high
  - query
  - demand
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: This feature allows a warehouse to automatically add more compute resources
      to handle periods of high query demand.
    char_start: 0
    char_end: 115
- statement: Data apps are applications that are designed to handle and analyze data.
  type: definition
  entity: unknown
  keywords:
  - definition
  - data
  - apps
  - applications
  - designed
  - handle
  - analyze
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: Data apps are applications that are designed to handle and analyze data.
    char_start: 0
    char_end: 72
- statement: Data engineers manage and optimize data pipelines and infrastructure.
  type: definition
  entity: unknown
  keywords:
  - definition
  - data
  - engineers
  - manage
  - optimize
  - pipelines
  - infrastructure
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: Data engineers manage and optimize data pipelines and infrastructure.
    char_start: 0
    char_end: 69
- statement: Data Governance ensures data quality and compliance.
  type: definition
  entity: unknown
  keywords:
  - definition
  - data
  - governance
  - ensures
  - quality
  - compliance
  source:
    doc: motherduck.com/case-studies/atm-com-analytics-costs-sql-expressibility.md
    quote: Data Governance Ensure data quality, lineage tracking, and compliance with
      regulatory requirements throughout the architecture.
    char_start: 0
    char_end: 127
- statement: Databases typically achieve durability using techniques like write-ahead
    logging.
  type: definition
  entity: unknown
  keywords:
  - definition
  - databases
  - typically
  - achieve
  - durability
  - using
  - techniques
  - like
  - write
  - ahead
  - logging
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: Databases typically achieve durability using techniques like write-ahead
      logging (WAL).
    char_start: 0
    char_end: 87
- statement: dbt Core can be set up with MotherDuck using DuckDB.
  type: definition
  entity: unknown
  keywords:
  - definition
  - dbt
  - core
  - set
  - up
  - motherduck
  - using
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Jacob provides a step-by-step guide to setting up dbt Core with MotherDuck
      using DuckDB.
    char_start: 0
    char_end: 88
- statement: dbt testing can be automated with a CI pipeline.
  type: definition
  entity: unknown
  keywords:
  - definition
  - dbt
  - testing
  - automated
  - ci
  - pipeline
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: automating testing with pre-commit hooks, and creating a streamlined continuous
      integration (CI) pipeline.
    char_start: 0
    char_end: 106
- statement: Demetrios Brinkmann brings on Hannes Mühleisen and Jordan Tigani to talk
    about developer experience.
  type: definition
  entity: unknown
  keywords:
  - definition
  - demetrios
  - brinkmann
  - brings
  - hannes
  - hleisen
  - jordan
  - tigani
  - talk
  - about
  - developer
  - experience
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2024.md
    quote: Demetrios Brinkmann brings on Hannes Mühleisen and Jordan Tigani to talk
      about this question, building an empathetic developer experience.
    char_start: 0
    char_end: 138
- statement: Different companies frame execution challenges of operational AI risks
    differently.
  type: definition
  entity: unknown
  keywords:
  - definition
  - different
  - companies
  - frame
  - execution
  - challenges
  - operational
  - ai
  - risks
  - differently
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part2.md
    quote: 'how different companies frame execution challenges:'
    char_start: 0
    char_end: 51
- statement: Duckberg leverages the power of PyIceberg and DuckDB to facilitate efficient
    querying of large Iceberg datasets.
  type: definition
  entity: unknown
  keywords:
  - definition
  - duckberg
  - leverages
  - power
  - pyiceberg
  - duckdb
  - facilitate
  - efficient
  - querying
  - large
  - iceberg
  - datasets
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: Duckberg leverages the power of PyIceberg and DuckDB to facilitate efficient
      querying of large Iceberg datasets using a Python package.
    char_start: 0
    char_end: 135
- statement: Duckberg supports various Iceberg catalog types like REST, SQL, Hive,
    Glue, and DynamoDB.
  type: definition
  entity: unknown
  keywords:
  - definition
  - duckberg
  - supports
  - various
  - iceberg
  - catalog
  - types
  - like
  - rest
  - sql
  - hive
  - glue
  - dynamodb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: The package supports various Iceberg catalog types like REST, SQL, Hive,
      Glue, and DynamoDB.
    char_start: 0
    char_end: 92
- statement: 'DuckCon #5 took place in Seattle in August 2024.'
  type: definition
  entity: unknown
  keywords:
  - definition
  - duckcon
  - took
  - place
  - seattle
  - august
  - '2024'
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: The fifth DuckCon took place in Seattle in August; the videos are online
      now.
    char_start: 0
    char_end: 77
- statement: DuckDB Labs allows querying Hugging Face datasets directly from DuckDB.
  type: definition
  entity: unknown
  keywords:
  - definition
  - duckdb
  - labs
  - allows
  - querying
  - hugging
  - face
  - datasets
  - directly
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: with the help of DuckDB Labs, you can now query Hugging Face datasets directly
      from DuckDB using `hf://`.
    char_start: 0
    char_end: 105
- statement: duckdb.yazi is a Yazi plugin leveraging DuckDB for rapid data file preview
    and summarization.
  type: definition
  entity: unknown
  keywords:
  - definition
  - duckdb
  - yazi
  - plugin
  - leveraging
  - rapid
  - data
  - file
  - preview
  - summarization
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eleven.md
    quote: duckdb.yazi is a Yazi plugin leveraging DuckDB for rapid data file preview
      and summarization.
    char_start: 0
    char_end: 93
- statement: duckdb_featureserv provides an OGC API - Features compliant REST layer
    over DuckDB.
  type: definition
  entity: unknown
  keywords:
  - definition
  - duckdb
  - featureserv
  - provides
  - ogc
  - api
  - features
  - compliant
  - rest
  - layer
  - over
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: duckdb_featureserv provides an OGC API - Features compliant REST layer
      over DuckDB.
    char_start: 0
    char_end: 83
- statement: DuckLakes is now in preview and can scale to petabytes.
  type: definition
  entity: unknown
  keywords:
  - definition
  - ducklakes
  - now
  - preview
  - scale
  - petabytes
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: 'MotherDuck Managed DuckLakes Now in Preview: Scale to Petabytes'
    char_start: 0
    char_end: 63
- statement: DuckRAG creates per-user DuckDB database files stored on S3 containing
    embeddings of all content a user has access to.
  type: definition
  entity: unknown
  keywords:
  - definition
  - duckrag
  - creates
  - per
  - user
  - duckdb
  - database
  - files
  - stored
  - s3
  - containing
  - embeddings
  - content
  - access
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: DuckRAG creates per-user DuckDB database files (4-6MB each) stored on S3
      containing embeddings of all content a user has access to.
    char_start: 0
    char_end: 131
- statement: ElementTree is used to create XML elements in the script.
  type: definition
  entity: unknown
  keywords:
  - definition
  - elementtree
  - used
  - create
  - xml
  - elements
  - script
  source:
    doc: motherduck.com/blog/streaming-data-to-motherduck.md
    quote: import xml.etree.ElementTree as ET
    char_start: 0
    char_end: 34
- statement: Estuary Flow is recommended for managing data transfer with CDC.
  type: definition
  entity: unknown
  keywords:
  - definition
  - estuary
  - flow
  - recommended
  - managing
  - data
  - transfer
  - cdc
  source:
    doc: motherduck.com/blog/summer-data-engineering-roadmap.md
    quote: When using Estuary Flow, we recommend a minimum retention policy of seven
      days.
    char_start: 0
    char_end: 79
- statement: Fenjin Wang is the creator and maintainer of duckdb-rs.
  type: definition
  entity: unknown
  keywords:
  - definition
  - fenjin
  - wang
  - creator
  - maintainer
  - duckdb
  - rs
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: He’s the creator and maintainer of duckdb-rs
    char_start: 0
    char_end: 44
- statement: Fintech Company X enhanced their existing Airflow-orchestrated data pipeline
    by integrating vector embeddings.
  type: definition
  entity: unknown
  keywords:
  - definition
  - fintech
  - company
  - enhanced
  - existing
  - airflow
  - orchestrated
  - data
  - pipeline
  - integrating
  - vector
  - embeddings
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: Fintech Company X enhanced their existing Airflow-orchestrated data pipeline
      by integrating vector embeddings without duplicating infrastructure.
    char_start: 0
    char_end: 145
- statement: FSST provides good compression with fast decompression speeds.
  type: definition
  entity: unknown
  keywords:
  - definition
  - fsst
  - provides
  - good
  - compression
  - fast
  - decompression
  - speeds
  source:
    doc: motherduck.com/learn-more.md
    quote: FSST (Fast Static Symbol Table) tokenizes strings and builds a dictionary
      of common substrings, providing good compression with very fast decompression
      speeds.
    char_start: 0
    char_end: 159
- statement: Google Sheets can be used with SQL to extract analytical insights.
  type: definition
  entity: unknown
  keywords:
  - definition
  - google
  - sheets
  - used
  - sql
  - extract
  - analytical
  - insights
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: combining multiple Excel sheets, or in this case, Google Sheets, and using
      SQL to join and extract analytical insights.
    char_start: 0
    char_end: 119
- statement: Healthcare Provider Y integrated RAG capabilities into their existing
    document processing pipeline using MotherDuck.
  type: definition
  entity: unknown
  keywords:
  - definition
  - healthcare
  - provider
  - integrated
  - rag
  - capabilities
  - existing
  - document
  - processing
  - pipeline
  - using
  - motherduck
  source:
    doc: motherduck.com/blog/vector-technologies-ai-data-stack.md
    quote: Healthcare Provider Y integrated RAG capabilities into their existing document
      processing pipeline using MotherDuck as their cloud data warehouse.
    char_start: 0
    char_end: 146
- statement: Hoyt Emerson created The Full Data Stack Substack and YouTube channel.
  type: definition
  entity: unknown
  keywords:
  - definition
  - hoyt
  - emerson
  - created
  - full
  - data
  - stack
  - substack
  - youtube
  - channel
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: He is the creator of The Full Data Stack Substack and YouTube channel.
    char_start: 0
    char_end: 70
- statement: Hoyt Emerson is a Senior Product Manager focused on Data and AI.
  type: definition
  entity: unknown
  keywords:
  - definition
  - hoyt
  - emerson
  - senior
  - product
  - manager
  - focused
  - data
  - ai
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: Hoyt Emerson is a Senior Product Manager focused on Data and AI, with over
      a decade of experience across Fortune 25 companies and Silicon Valley startups.
    char_start: 0
    char_end: 154
- statement: I could speed up reading 25 million rows over a mobile phone without
    cache from 49.366 seconds to 3.304 seconds after the first cache.
  type: definition
  entity: unknown
  keywords:
  - definition
  - speed
  - up
  - reading
  - '25'
  - million
  - rows
  - over
  - mobile
  - phone
  - without
  - cache
  - '49.366'
  - seconds
  - '3.304'
  - first
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: I could speed up reading 25 million rows over a mobile phone without cache
      from 49.366 seconds to 3.304 seconds after the first cache.
    char_start: 0
    char_end: 134
- statement: In benchmarks using NYC bike trip data with 58 million rows, the new
    point-in-polygon join now finishes in just 28.7 seconds.
  type: definition
  entity: unknown
  keywords:
  - definition
  - benchmarks
  - using
  - nyc
  - bike
  - trip
  - data
  - '58'
  - million
  - rows
  - new
  - point
  - polygon
  - join
  - now
  - finishes
  - '28.7'
  - seconds
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: In benchmarks using NYC bike trip data with 58 million rows, the new point-in-polygon
      join now finishes in just 28.7 seconds.
    char_start: 0
    char_end: 125
- statement: Layers faced performance isolation concerns with their multi-tenant analytical
    service.
  type: definition
  entity: unknown
  keywords:
  - definition
  - layers
  - faced
  - performance
  - isolation
  - concerns
  - multi
  - tenant
  - analytical
  - service
  source:
    doc: motherduck.com/learn-more/columnar-storage-guide.md
    quote: A multi-tenant analytical service raised concerns about performance isolation.
    char_start: 0
    char_end: 78
- statement: Layers must surface fresh usage metrics in customer-facing dashboards.
  type: definition
  entity: unknown
  keywords:
  - definition
  - layers
  - surface
  - fresh
  - usage
  - metrics
  - customer
  - facing
  - dashboards
  source:
    doc: motherduck.com/learn-more/columnar-storage-guide.md
    quote: Layers must surface fresh usage metrics in customer-facing dashboards.
    char_start: 0
    char_end: 70
- statement: Layers paused roadmap work to find a new pattern after a pricing model
    change.
  type: definition
  entity: unknown
  keywords:
  - definition
  - layers
  - paused
  - roadmap
  - work
  - find
  - new
  - pattern
  - pricing
  - model
  - change
  source:
    doc: motherduck.com/learn-more/columnar-storage-guide.md
    quote: Layers paused roadmap work to find a new pattern.
    char_start: 0
    char_end: 49
- statement: Layers powers on-site product search, recommendations, and usage analytics
    for retail brands.
  type: definition
  entity: unknown
  keywords:
  - definition
  - layers
  - powers
  - site
  - product
  - search
  - recommendations
  - usage
  - analytics
  - retail
  - brands
  source:
    doc: motherduck.com/learn-more/columnar-storage-guide.md
    quote: Layers powers on-site product search, recommendations, and usage analytics
      for retail brands.
    char_start: 0
    char_end: 93
- statement: LLMs can be applied to SQL for smarter CRM data cleaning.
  type: definition
  entity: unknown
  keywords:
  - definition
  - llms
  - applied
  - sql
  - smarter
  - crm
  - data
  - cleaning
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: How Nate applies LLMs to SQL for smarter CRM data cleaning in analytics
    char_start: 0
    char_end: 71
- statement: Lorenzo Mangani is CEO and Co-Founder at QXIP BV.
  type: definition
  entity: unknown
  keywords:
  - definition
  - lorenzo
  - mangani
  - ceo
  - co
  - founder
  - qxip
  - bv
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: Lorenzo is CEO and Co-Founder at QXIP BV, Leaders in Open-Source Telecom
      Observability.
    char_start: 0
    char_end: 87
- statement: Matt Forrest serves as a Field CTO at Carto.
  type: definition
  entity: unknown
  keywords:
  - definition
  - matt
  - forrest
  - serves
  - field
  - cto
  - carto
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: Based in New York, Matt serves as a Field CTO at Carto.
    char_start: 0
    char_end: 55
- statement: Matt Martin contributes to DuckDB.
  type: definition
  entity: unknown
  keywords:
  - definition
  - matt
  - martin
  - contributes
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: He recently made his first contribution to DuckDB.
    char_start: 0
    char_end: 50
- statement: Matt Martin is a Staff Engineer at State Farm.
  type: definition
  entity: unknown
  keywords:
  - definition
  - matt
  - martin
  - staff
  - engineer
  - state
  - farm
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: Matt Martin is a Staff Engineer at State Farm.
    char_start: 0
    char_end: 46
- statement: Matt Martin writes a newsletter about data engineering topics.
  type: definition
  entity: unknown
  keywords:
  - definition
  - matt
  - martin
  - writes
  - newsletter
  - about
  - data
  - engineering
  - topics
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: Matt also shares his knowledge through his newsletter, High Performance
      DE Newsletter.
    char_start: 0
    char_end: 86
- statement: MinIO offers a performance boost compared to traditional local storage.
  type: definition
  entity: unknown
  keywords:
  - definition
  - minio
  - offers
  - performance
  - boost
  - compared
  - traditional
  - local
  - storage
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Bayu anticipates a performance boost from MinIO compared to traditional
      local storage.
    char_start: 0
    char_end: 86
- statement: Modern data warehouses allow for the separation of storage and compute
    resources.
  type: definition
  entity: unknown
  keywords:
  - definition
  - modern
  - data
  - warehouses
  - allow
  - separation
  - storage
  - compute
  - resources
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: This is the foundational concept of the cloud data warehouse. It allows
      you to scale your storage resources (how much data you have) independently from
      your compute resources (the processing power use
    char_start: 0
    char_end: 222
- statement: Modern data warehouses support semi-structured data formats like JSON
    and Avro.
  type: definition
  entity: unknown
  keywords:
  - definition
  - modern
  - data
  - warehouses
  - support
  - semi
  - structured
  - formats
  - like
  - json
  - avro
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: Warehouses now offer native support for ingesting and querying semi-structured
      data formats like JSON, Avro, and Parquet.
    char_start: 0
    char_end: 121
- statement: Modern single-node systems are huge and can handle almost any workload.
  type: definition
  entity: unknown
  keywords:
  - definition
  - modern
  - single
  - node
  - systems
  - huge
  - handle
  - almost
  - any
  - workload
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: Modern single-node systems are huge and can handle almost any workload.
    char_start: 0
    char_end: 71
- statement: Naty discussed leveraging DuckDB in their talk.
  type: definition
  entity: unknown
  keywords:
  - definition
  - naty
  - discussed
  - leveraging
  - duckdb
  - talk
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: Naty Clementi from Voltron Data explains how you can leverage Ibis and
      DuckDB for geospatial work.
    char_start: 0
    char_end: 98
- statement: Neil provides a Model Context Protocol (MCP) server that enables querying
    Apple Health data with natural language and SQL.
  type: definition
  entity: unknown
  keywords:
  - definition
  - neil
  - provides
  - model
  - context
  - protocol
  - mcp
  - server
  - enables
  - querying
  - apple
  - health
  - data
  - natural
  - language
  - sql
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: Neil provides a Model Context Protocol (MCP) server that enables querying
      Apple Health data with natural language and SQL.
    char_start: 0
    char_end: 122
- statement: Network latency added close to 100 milliseconds to dashboard serving.
  type: definition
  entity: unknown
  keywords:
  - definition
  - network
  - latency
  - added
  - close
  - '100'
  - milliseconds
  - dashboard
  - serving
  source:
    doc: motherduck.com/learn-more/columnar-storage-guide.md
    quote: Serving dashboards over a stateless serverless API added 'close to 100
      milliseconds' on its own.
    char_start: 0
    char_end: 96
- statement: Niels Claeys is a lead data engineer at Data Minded.
  type: definition
  entity: unknown
  keywords:
  - definition
  - niels
  - claeys
  - lead
  - data
  - engineer
  - minded
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: Niels Claeys is a lead data engineer at Data Minded.
    char_start: 0
    char_end: 52
- statement: Niels contributed to the dbt adapter for DuckDB.
  type: definition
  entity: unknown
  keywords:
  - definition
  - niels
  - contributed
  - dbt
  - adapter
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: He recently contributed to the dbt adapter for DuckDB.
    char_start: 0
    char_end: 54
- statement: Paradime, Hex, and MotherDuck are organizing a dbt data modeling challenge.
  type: definition
  entity: unknown
  keywords:
  - definition
  - paradime
  - hex
  - motherduck
  - organizing
  - dbt
  - data
  - modeling
  - challenge
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: Paradime, Hex, and MotherDuck have joined forces to bring data professionals
      worldwide a one-of-a-kind competition.
    char_start: 0
    char_end: 115
- statement: Parameterized queries help prevent SQL injection and can improve performance
    for repeated queries.
  type: definition
  entity: unknown
  keywords:
  - definition
  - parameterized
  - queries
  - help
  - prevent
  - sql
  - injection
  - improve
  - performance
  - repeated
  source:
    doc: motherduck.com/blog/streaming-oracle-to-motherduck.md
    quote: Parameterized query using '$param_name' syntax and a dictionary helps prevent
      SQL injection.
    char_start: 0
    char_end: 92
- statement: Patrick demonstrates how to download and process 3.5TB of GitHub event
    data using Modal's serverless infrastructure and DuckDB in just 15 minutes.
  type: definition
  entity: unknown
  keywords:
  - definition
  - patrick
  - demonstrates
  - download
  - process
  - '3.5'
  - tb
  - github
  - event
  - data
  - using
  - modal
  - serverless
  - infrastructure
  - duckdb
  - '15'
  - minutes
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md
    quote: Patrick demonstrates how to download and process 3.5TB of GitHub event
      data using Modal's serverless infrastructure and DuckDB in just 15 minutes.
    char_start: 0
    char_end: 146
- statement: PostgreSQL is a powerful, open-source object-relational database system.
  type: definition
  entity: unknown
  keywords:
  - definition
  - postgresql
  - powerful
  - open
  - source
  - object
  - relational
  - database
  - system
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: PostgreSQL is a powerful, open-source object-relational database system
      with a strong reputation for reliability, feature robustness, and performance.
    char_start: 0
    char_end: 150
- statement: Quack to SQL is an AI model that understands duck sounds and translates
    them into queries.
  type: definition
  entity: unknown
  keywords:
  - definition
  - quack
  - sql
  - ai
  - model
  - understands
  - duck
  - sounds
  - translates
  - them
  - queries
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-four.md
    quote: Quack to SQL — our first AI model that understands duck sounds and translates
      them into queries.
    char_start: 0
    char_end: 96
- statement: Quentin Lhoest is an Open Source ML Engineer at Hugging Face.
  type: definition
  entity: unknown
  keywords:
  - definition
  - quentin
  - lhoest
  - open
  - source
  - ml
  - engineer
  - hugging
  - face
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Quentin Lhoest is an Open Source ML Engineer at Hugging Face and a maintainer
      of Datasets.
    char_start: 0
    char_end: 90
- statement: Quentin Lhoest presented at a DuckDB meetup in Paris how Hugging Face
    uses DuckDB behind the scenes.
  type: definition
  entity: unknown
  keywords:
  - definition
  - quentin
  - lhoest
  - presented
  - duckdb
  - meetup
  - paris
  - hugging
  - face
  - uses
  - behind
  - scenes
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Back in March, he presented at a DuckDB meetup in Paris how Hugging Face
      uses DuckDB behind the scenes to provide direct insights into over 200,000 datasets.
    char_start: 0
    char_end: 157
- statement: Query.Farm released two community extensions—Marisa for space-efficient
    trie-based string operations and Textplot for ASCII/Unicode data visualization
    directly in SQL queries.
  type: definition
  entity: unknown
  keywords:
  - definition
  - query
  - farm
  - released
  - two
  - community
  - extensions
  - marisa
  - space
  - efficient
  - trie
  - based
  - string
  - operations
  - textplot
  - ascii
  - unicode
  - data
  - visualization
  - directly
  - sql
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: Query.Farm released two community extensions—Marisa for space-efficient
      trie-based string operations and Textplot for ASCII/Unicode data visualization
      directly in SQL queries.
    char_start: 0
    char_end: 175
- statement: Ryan Boyd is a co-founder at MotherDuck.
  type: definition
  entity: unknown
  keywords:
  - definition
  - ryan
  - boyd
  - co
  - founder
  - motherduck
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: Ryan Boyd, co-founder at MotherDuck.
    char_start: 0
    char_end: 36
- statement: Ryan will keep the newsletter going monthly with help from the community.
  type: definition
  entity: unknown
  keywords:
  - definition
  - ryan
  - keep
  - newsletter
  - going
  - monthly
  - help
  - community
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md
    quote: Don't worry, we'll keep this newsletter going monthly with help from the
      community!
    char_start: 0
    char_end: 83
- statement: SaaSCo's true cost can be more than double their initial budget.
  type: definition
  entity: unknown
  keywords:
  - definition
  - saasco
  - 'true'
  - cost
  - double
  - initial
  - budget
  source:
    doc: motherduck.com/learn-more/data-warehouse-tco.md
    quote: SaaSCo's true cost can be more than double their initial budget, and the
      primary driver of that overage depends entirely on the platform's architecture.
    char_start: 0
    char_end: 152
- statement: Scale-up architecture offers joyful advantages over scale-out architecture.
  type: definition
  entity: unknown
  keywords:
  - definition
  - scale
  - up
  - architecture
  - offers
  - joyful
  - advantages
  - over
  - out
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md
    quote: Explores why scale-out became so dominant, whether those rationales still
      hold, and some joyful advantages of scale-up architecture.
    char_start: 0
    char_end: 132
- statement: Scaling out doesn’t necessarily lead to more robust systems.
  type: definition
  entity: unknown
  keywords:
  - definition
  - scaling
  - out
  - doesn
  - necessarily
  - lead
  - robust
  - systems
  source:
    doc: motherduck.com/blog/the-simple-joys-of-scaling-up.md
    quote: Scaling out doesn’t necessarily lead to more robust systems.
    char_start: 0
    char_end: 60
- statement: Serverless architecture simplifies operations by automatically managing
    compute resources.
  type: definition
  entity: unknown
  keywords:
  - definition
  - serverless
  - architecture
  - simplifies
  - operations
  - automatically
  - managing
  - compute
  - resources
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: In a truly serverless model, you don't need to provision, manage, or size
      clusters of servers.
    char_start: 0
    char_end: 94
- statement: Simon Späti authored blog posts related to DuckDB and data engineering.
  type: definition
  entity: unknown
  keywords:
  - definition
  - simon
  - sp
  - ti
  - authored
  - blog
  - posts
  - related
  - duckdb
  - data
  - engineering
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: Author of the blog posts related to DuckDB and data engineering.
    char_start: 0
    char_end: 64
- statement: Small Data SF is organized by MotherDuck.
  type: definition
  entity: unknown
  keywords:
  - definition
  - small
  - data
  - sf
  - organized
  - motherduck
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: we’re just a month away from Small Data SF, organized by MotherDuck
    char_start: 0
    char_end: 67
- statement: Sqlfluff is used for setting up a SQL linter in dbt.
  type: definition
  entity: unknown
  keywords:
  - definition
  - sqlfluff
  - used
  - setting
  - up
  - sql
  - linter
  - dbt
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md
    quote: It covers setting up a SQL linter with Sqlfluff.
    char_start: 0
    char_end: 48
- statement: SQLFrame supports DuckDB as a backend for SQL operations.
  type: definition
  entity: unknown
  keywords:
  - definition
  - sqlframe
  - supports
  - duckdb
  - backend
  - sql
  - operations
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: SQLFrame also supports BigQuery, Postgres, and Snowflake.
    char_start: 0
    char_end: 57
- statement: Stack Overflow publishes the results of their developer survey annually.
  type: definition
  entity: unknown
  keywords:
  - definition
  - stack
  - overflow
  - publishes
  - results
  - developer
  - survey
  - annually
  source:
    doc: motherduck.com/blog/csv-files-persist-duckdb-solution.md
    quote: Each year, Stack Overflow publishes the results of their developer survey,
      including raw data in—you guessed it—CSV format.
    char_start: 0
    char_end: 123
- statement: Superset is an open-source data visualization and exploration platform.
  type: definition
  entity: unknown
  keywords:
  - definition
  - superset
  - open
  - source
  - data
  - visualization
  - exploration
  - platform
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: An open-source data visualization and exploration platform.
    char_start: 0
    char_end: 59
- statement: The AI identified three promising locations for restaurants without African
    cuisine.
  type: definition
  entity: unknown
  keywords:
  - definition
  - ai
  - identified
  - three
  - promising
  - locations
  - restaurants
  - without
  - african
  - cuisine
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: After a few self-corrections, it produces a new query that works, identifying
      three promising locations.
    char_start: 0
    char_end: 104
- statement: The architecture is cost-effective (approximately $0.001/month for their
    team's usage).
  type: definition
  entity: unknown
  keywords:
  - definition
  - architecture
  - cost
  - effective
  - approximately
  - '0.001'
  - month
  - team
  - usage
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: Despite data duplication, the architecture is cost-effective (approximately
      $0.001/month for their team's usage) while eliminating load on production systems.
    char_start: 0
    char_end: 158
- statement: The cache_httpfs DuckDB extension accelerates data reads from object
    storage by leveraging local caching.
  type: definition
  entity: unknown
  keywords:
  - definition
  - cache
  - httpfs
  - duckdb
  - extension
  - accelerates
  - data
  - reads
  - object
  - storage
  - leveraging
  - local
  - caching
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: The cache_httpfs DuckDB extension accelerates data reads from object storage
      by leveraging local caching, offering significant performance improvements.
    char_start: 0
    char_end: 152
- statement: The columnar layout is highly compatible with modern CPU architecture.
  type: definition
  entity: unknown
  keywords:
  - definition
  - columnar
  - layout
  - highly
  - compatible
  - modern
  - cpu
  - architecture
  source:
    doc: motherduck.com/case-studies/reflex-careers-gig-economy-retail.md
    quote: The columnar layout is highly compatible with modern CPU architecture.
    char_start: 0
    char_end: 70
- statement: The Data Stack Show discusses modern data stacks and related topics.
  type: definition
  entity: unknown
  keywords:
  - definition
  - data
  - stack
  - show
  - discusses
  - modern
  - stacks
  - related
  - topics
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md
    quote: The Data Stack Show, Eric and Kostas chat with Pedram Navid.
    char_start: 0
    char_end: 60
- statement: The entire infrastructure is defined as code with Terraform.
  type: definition
  entity: unknown
  keywords:
  - definition
  - entire
  - infrastructure
  - defined
  - code
  - terraform
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: The entire infrastructure is defined as code with Terraform.
    char_start: 0
    char_end: 60
- statement: The error message indicates a conversion issue with the 'Hobbyist' column.
  type: definition
  entity: unknown
  keywords:
  - definition
  - error
  - message
  - indicates
  - conversion
  - issue
  - hobbyist
  - column
  source:
    doc: motherduck.com/blog/csv-files-persist-duckdb-solution.md
    quote: Could not convert string "NA" to 'BOOLEAN'
    char_start: 0
    char_end: 42
- statement: The extension introduces a radio object managing multiple event source
    subscriptions.
  type: definition
  entity: unknown
  keywords:
  - definition
  - extension
  - introduces
  - radio
  - object
  - managing
  - multiple
  - event
  - source
  - subscriptions
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: The extension introduces a radio object managing multiple event source
      subscriptions with independent connections and queues for incoming and outgoing
      messages.
    char_start: 0
    char_end: 160
- statement: The extension leverages in-browser OAuth for authentication.
  type: definition
  entity: unknown
  keywords:
  - definition
  - extension
  - leverages
  - browser
  - oauth
  - authentication
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: The extension leverages in-browser OAuth for authentication, simplifying
      the process to just logging into Google.
    char_start: 0
    char_end: 113
- statement: The framework uses a Directed Acyclic Graph (DAG) execution model.
  type: definition
  entity: unknown
  keywords:
  - definition
  - framework
  - uses
  - directed
  - acyclic
  - graph
  - dag
  - execution
  - model
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md
    quote: The framework uses a Directed Acyclic Graph (DAG) execution model.
    char_start: 0
    char_end: 66
- statement: The full movie 'Charade' resulted in a table of 47 billion rows, stored
    in approximately 200 GB.
  type: definition
  entity: unknown
  keywords:
  - definition
  - full
  - movie
  - charade
  - resulted
  - table
  - '47'
  - billion
  - rows
  - stored
  - approximately
  - '200'
  - gb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md
    quote: The full movie, at 720x392 resolution, resulted in a table of 47 billion
      rows, stored in approximately 200 GB.
    char_start: 0
    char_end: 110
- statement: The Geospatial extension statically bundles standard FOSS GIS packages,
    including the PROJ database.
  type: definition
  entity: unknown
  keywords:
  - definition
  - geospatial
  - extension
  - statically
  - bundles
  - standard
  - foss
  - gis
  - packages
  - including
  - proj
  - database
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: The Geospatial extension statically bundles standard FOSS GIS packages,
      including the PROJ database.
    char_start: 0
    char_end: 100
- statement: The map shows restaurant density across Oakland.
  type: definition
  entity: unknown
  keywords:
  - definition
  - map
  - shows
  - restaurant
  - density
  - across
  - oakland
  source:
    doc: motherduck.com/learn-more/acid-transactions-sql.md
    quote: Now we have a much clearer view of restaurant density across Oakland.
    char_start: 0
    char_end: 69
- statement: The Marisa extension enables efficient prefix searches and string lookups.
  type: definition
  entity: unknown
  keywords:
  - definition
  - marisa
  - extension
  - enables
  - efficient
  - prefix
  - searches
  - string
  - lookups
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: The extension brings MARISA (Matching Algorithm with Recursively Implemented
      StorAge) trie functionality to DuckDB, enabling efficient prefix searches and
      string lookups.
    char_start: 0
    char_end: 170
- statement: The MCP server enables natural language and SQL querying of Apple Health
    data.
  type: definition
  entity: unknown
  keywords:
  - definition
  - mcp
  - server
  - enables
  - natural
  - language
  - sql
  - querying
  - apple
  - health
  - data
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: Neil provides a Model Context Protocol (MCP) server that enables natural
      language and SQL querying of Apple Health data using DuckDB as the underlying
      engine.
    char_start: 0
    char_end: 158
- statement: The MCP server processes various health metrics from CSV files exported
    from the Simple Health Export app.
  type: definition
  entity: unknown
  keywords:
  - definition
  - mcp
  - server
  - processes
  - various
  - health
  - metrics
  - csv
  - files
  - exported
  - simple
  - export
  - app
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: The server expects CSV files exported from the Simple Health Export CSV
      iOS app and processes various health metrics.
    char_start: 0
    char_end: 117
- statement: The MCP server uses DuckDB for efficient data analysis.
  type: definition
  entity: unknown
  keywords:
  - definition
  - mcp
  - server
  - uses
  - duckdb
  - efficient
  - data
  - analysis
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md
    quote: The project uses DuckDB for efficient data analysis.
    char_start: 0
    char_end: 52
- statement: The New South Wales Department of Education uses GitHub Codespace for
    their data stack.
  type: definition
  entity: unknown
  keywords:
  - definition
  - new
  - south
  - wales
  - department
  - education
  - uses
  - github
  - codespace
  - data
  - stack
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: you can play with your own data stack in a box with just a click on GitHub
      Codespace.
    char_start: 0
    char_end: 85
- statement: The new SPATIAL_JOIN operator builds an R-tree index on-the-fly for the
    smaller (right) table during join execution.
  type: definition
  entity: unknown
  keywords:
  - definition
  - new
  - spatial
  - join
  - operator
  - builds
  - tree
  - index
  - fly
  - smaller
  - right
  - table
  - execution
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: The new SPATIAL_JOIN operator builds an R-tree index on-the-fly for the
      smaller (right) table during join execution.
    char_start: 0
    char_end: 116
- statement: The No-ETL method allows startups to query multiple raw CSV, JSON, &
    Parquet files directly with SQL.
  type: definition
  entity: unknown
  keywords:
  - definition
  - etl
  - method
  - allows
  - startups
  - query
  - multiple
  - raw
  - csv
  - json
  - parquet
  - files
  - directly
  - sql
  source:
    doc: motherduck.com/blog/why-web-developers-should-care-about-analytical-databases.md
    quote: Skip complex ETL. Learn the No-ETL method for startups to query multiple
      raw CSV, JSON, & Parquet files directly with SQL.
    char_start: 0
    char_end: 122
- statement: The OpenAI API is used alongside DuckDB for chatbot development.
  type: definition
  entity: unknown
  keywords:
  - definition
  - openai
  - api
  - used
  - alongside
  - duckdb
  - chatbot
  - development
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: OpenAI API is used alongside DuckDB.
    char_start: 0
    char_end: 36
- statement: The project is live at duckdbstats.com.
  type: definition
  entity: unknown
  keywords:
  - definition
  - project
  - live
  - duckdbstats
  - com
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md
    quote: The project is live at duckdbstats.com.
    char_start: 0
    char_end: 39
- statement: The QuackStore DuckDB extension introduces block-based caching for remote
    files, enhancing performance for recurring data queries.
  type: definition
  entity: unknown
  keywords:
  - definition
  - quackstore
  - duckdb
  - extension
  - introduces
  - block
  - based
  - caching
  - remote
  - files
  - enhancing
  - performance
  - recurring
  - data
  - queries
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: The QuackStore DuckDB extension introduces block-based caching for remote
      files, enhancing performance for recurring data queries by localizing frequently
      accessed data.
    char_start: 0
    char_end: 169
- statement: The spatial extension allows management of raster data in DuckDB.
  type: definition
  entity: unknown
  keywords:
  - definition
  - spatial
  - extension
  - allows
  - management
  - raster
  - data
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2024.md
    quote: The spatial extension allows management of raster data in DuckDB.
    char_start: 0
    char_end: 65
- statement: The stack integrates Go for data extraction and loading.
  type: definition
  entity: unknown
  keywords:
  - definition
  - stack
  - integrates
  - go
  - data
  - extraction
  - loading
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: The stack integrates Go for data extraction and loading.
    char_start: 0
    char_end: 56
- statement: The survey results and schemas are stored in DuckDB tables.
  type: definition
  entity: unknown
  keywords:
  - definition
  - survey
  - results
  - schemas
  - stored
  - duckdb
  - tables
  source:
    doc: motherduck.com/blog/csv-files-persist-duckdb-solution.md
    quote: CREATE OR REPLACE TABLE stackoverflow_survey.{config['table']}
    char_start: 0
    char_end: 62
- statement: The tarfs extension allows reading files within uncompressed tar archives.
  type: feature
  entity: unknown
  keywords:
  - feature
  - tarfs
  - extension
  - allows
  - reading
  - files
  - within
  - uncompressed
  - tar
  - archives
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: This new community extension lets you read and globalize files within uncompressed
      tar archives.
    char_start: 0
    char_end: 96
- statement: The VS Code extension allows you to connect to DuckDB instances.
  type: definition
  entity: unknown
  keywords:
  - definition
  - vs
  - code
  - extension
  - allows
  - connect
  - duckdb
  - instances
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: He has recently built a great VS Code extension for DuckDB.
    char_start: 0
    char_end: 59
- statement: This allows users to convert between geospatial formats using GDAL and
    perform transformations via SQL.
  type: definition
  entity: unknown
  keywords:
  - definition
  - allows
  - users
  - convert
  - geospatial
  - formats
  - using
  - gdal
  - perform
  - transformations
  - via
  - sql
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md
    quote: This allows users to convert between geospatial formats using GDAL and
      perform transformations via SQL.
    char_start: 0
    char_end: 103
- statement: Thomas McGeehan is a cloud data architect and consultant based in the
    US.
  type: definition
  entity: unknown
  keywords:
  - definition
  - thomas
  - mcgeehan
  - cloud
  - data
  - architect
  - consultant
  - based
  - us
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: Thomas McGeehan is a cloud data architect and consultant based in the US.
    char_start: 0
    char_end: 73
- statement: Traditional row-based databases often struggle with massive datasets
    for analytics.
  type: definition
  entity: unknown
  keywords:
  - definition
  - traditional
  - row
  - based
  - databases
  - often
  - struggle
  - massive
  - datasets
  - analytics
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: While traditional row-based databases have served us well for transactional
      workloads, they often struggle when you need to crunch through massive datasets
      for analytics.
    char_start: 0
    char_end: 170
- statement: Transistor density has increased by 1000x in two decades.
  type: definition
  entity: unknown
  keywords:
  - definition
  - transistor
  - density
  - increased
  - 1000x
  - two
  - decades
  source:
    doc: motherduck.com/learn-more/columnar-storage-guide.md
    quote: In two decades, transistor density has increased by 1000x.
    char_start: 0
    char_end: 58
- statement: UNION ALL BY NAME enhances vertical stacking by matching columns by name.
  type: definition
  entity: unknown
  keywords:
  - definition
  - union
  - name
  - enhances
  - vertical
  - stacking
  - matching
  - columns
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: UNION ALL BY NAME enhances vertical stacking by matching columns by name,
      supporting evolving schemas, and improving performance.
    char_start: 0
    char_end: 129
- statement: Unstructured automatically transforms complex, unstructured data into
    clean, structured data for GenAI applications.
  type: definition
  entity: unknown
  keywords:
  - definition
  - unstructured
  - automatically
  - transforms
  - complex
  - data
  - clean
  - structured
  - genai
  - applications
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part1.md
    quote: Unstructured automatically transforms complex, unstructured data into clean,
      structured data for GenAI applications.
    char_start: 0
    char_end: 116
- statement: User Defined Functions (UDFs) are a feature in DuckDB for custom operations.
  type: definition
  entity: unknown
  keywords:
  - definition
  - user
  - defined
  - functions
  - udfs
  - feature
  - duckdb
  - custom
  - operations
  source:
    doc: motherduck.com/learn-more/columnar-storage-guide.md
    quote: User Defined Functions (UDFs) are a feature in DuckDB for custom operations.
    char_start: 0
    char_end: 76
- statement: Using cache_httpfs allows users to reduce S3 costs and accelerate their
    DuckDB queries.
  type: definition
  entity: unknown
  keywords:
  - definition
  - using
  - cache
  - httpfs
  - allows
  - users
  - reduce
  - s3
  - costs
  - accelerate
  - duckdb
  - queries
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md
    quote: Using cache_httpfs allows users to reduce S3 costs and accelerate their
      DuckDB queries with minimal configuration changes.
    char_start: 0
    char_end: 122
- statement: With 3FS and Smallpond, 50 compute nodes sorted 110.5 TiB of data in
    just over 30 minutes.
  type: definition
  entity: unknown
  keywords:
  - definition
  - 3fs
  - smallpond
  - '50'
  - compute
  - nodes
  - sorted
  - '110.5'
  - tib
  - data
  - over
  - '30'
  - minutes
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md
    quote: DeepSeek reported that with 3FS and Smallpond, 50 compute nodes sorted
      110.5 TiB of data in just over 30 minutes (3.66 TiB/minute throughput).
    char_start: 0
    char_end: 142
- statement: YAML is a human-readable data serialization standard that is often used
    for configuration files.
  type: definition
  entity: unknown
  keywords:
  - definition
  - yaml
  - human
  - readable
  - data
  - serialization
  - standard
  - often
  - used
  - configuration
  - files
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md
    quote: YAML, a human-readable data serialization standard that is often used for
      configuration files.
    char_start: 0
    char_end: 94
- statement: You can download the book for free, courtesy of MotherDuck.
  type: definition
  entity: unknown
  keywords:
  - definition
  - download
  - book
  - free
  - courtesy
  - motherduck
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md
    quote: You can download the book for free, courtesy of MotherDuck.
    char_start: 0
    char_end: 59
- statement: You can use this official Docker image by pulling it with docker pull
    duckdb/duckdb:latest.
  type: definition
  entity: unknown
  keywords:
  - definition
  - use
  - official
  - docker
  - image
  - pulling
  - pull
  - duckdb
  - latest
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md
    quote: You can use this official Docker image by pulling it with docker pull duckdb/duckdb:latest.
    char_start: 0
    char_end: 91
- statement: advanced techniques like unnest() combined with arg_max() allow for more
    sophisticated data manipulation.
  type: definition
  entity: unnest()
  keywords:
  - definition
  - advanced
  - techniques
  - like
  - unnest
  - combined
  - arg
  - max
  - allow
  - sophisticated
  - data
  - manipulation
  source:
    doc: motherduck.com/blog/introducing-instant-sql.md
    quote: Additionally, advanced techniques like unnest() combined with arg_max()
      allow for more sophisticated data manipulation.
    char_start: 0
    char_end: 119
- statement: The Unstructured.io connector does not automatically create a database,
    schema, or table for data ingestion into MotherDuck.
  type: definition
  entity: Unstructured.io
  keywords:
  - definition
  - unstructured
  - io
  - connector
  - automatically
  - create
  - database
  - schema
  - table
  - data
  - ingestion
  - motherduck
  source:
    doc: motherduck.com/blog/motherduck-congratulates-duckdb-1.0-release.md
    quote: The Unstructured.io connector does not automatically create a database,
      schema, or table for data ingestion into MotherDuck.
    char_start: 0
    char_end: 124
- statement: Unstructured.io enhances scalability and efficiency in AI application
    development.
  type: definition
  entity: Unstructured.io
  keywords:
  - definition
  - unstructured
  - io
  - enhances
  - scalability
  - efficiency
  - ai
  - application
  - development
  source:
    doc: motherduck.com/blog/ducklake-motherduck.md
    quote: Streamlining data pipelines from ingestion to retrieval enhances scalability
      and efficiency in AI application development.
    char_start: 0
    char_end: 122
- statement: Unstructured.io helps in processing unstructured data.
  type: definition
  entity: Unstructured.io
  keywords:
  - definition
  - unstructured
  - io
  - helps
  - processing
  - data
  source:
    doc: motherduck.com/blog/just-enough-sql-for-ai.md
    quote: load unstructured data into MotherDuck with Unstructured.io...
    char_start: 0
    char_end: 62
- statement: Unstructured.io provides a Python framework to orchestrate your ETL pipeline.
  type: definition
  entity: Unstructured.io
  keywords:
  - definition
  - unstructured
  - io
  - provides
  - python
  - framework
  - orchestrate
  - etl
  - pipeline
  source:
    doc: motherduck.com/blog/motherduck-dbt-pipelines.md
    quote: Unstructured.io provides a Python framework to orchestrate your ETL pipeline.
    char_start: 0
    char_end: 77
- statement: Unstructured.io simplifies the Extract, Transform, and Load (ETL) process
    for unstructured data.
  type: definition
  entity: Unstructured.io
  keywords:
  - definition
  - unstructured
  - io
  - simplifies
  - extract
  - transform
  - load
  - etl
  - process
  - data
  source:
    doc: motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-2.md
    quote: Unstructured.io addresses these issues by simplifying the Extract, Transform,
      and Load (ETL) process for unstructured data.
    char_start: 0
    char_end: 123
- statement: Using Unstructured.io and MotherDuck together provides a powerful solution
    for maximizing the value of unstructured data.
  type: definition
  entity: Unstructured.io
  keywords:
  - definition
  - using
  - unstructured
  - io
  - motherduck
  - together
  - provides
  - powerful
  - solution
  - maximizing
  - value
  - data
  source:
    doc: motherduck.com/blog/motherduck-dbt-pipelines.md
    quote: using Unstructured.io and MotherDuck together provides a powerful solution
      for maximizing the value of unstructured data.
    char_start: 0
    char_end: 121
- statement: Users can automate updates by setting the UPDATE AUTOMATIC option during
    share creation.
  type: definition
  entity: UPDATE AUTOMATIC
  keywords:
  - definition
  - users
  - automate
  - updates
  - setting
  - update
  - automatic
  - option
  - share
  - creation
  source:
    doc: motherduck.com/blog/data-warehouse-feature-roundup-oct-2024.md
    quote: Now, users can automate updates by setting the UPDATE AUTOMATIC option
      during share creation.
    char_start: 0
    char_end: 93
- statement: We automatically receive information about your interactions with our
    Website.
  type: definition
  entity: Usage Information
  keywords:
  - definition
  - automatically
  - receive
  - information
  - about
  - interactions
  - website
  source:
    doc: motherduck.com/videos/duckdb-run-dbt-build-with-sub-second-execution-times.md
    quote: 'To help us understand how you use our Website and to help us improve it,
      we automatically receive information about your interactions with our Website
      like the pages or other content you view and the '
    char_start: 0
    char_end: 231
- statement: Creating intuitive interfaces and promoting data literacy within organizations
    can be challenging but is essential for the success of data applications.
  type: definition
  entity: User Adoption
  keywords:
  - definition
  - creating
  - intuitive
  - interfaces
  - promoting
  - data
  - literacy
  - within
  - organizations
  - challenging
  - essential
  - success
  - applications
  source:
    doc: motherduck.com/ecosystem.md
    quote: User Adoption Creating intuitive interfaces and promoting data literacy
      within organizations can be challenging but is essential for the success of
      data applications.
    char_start: 0
    char_end: 166
- statement: User Engagement includes metrics like DAU, WAU, MAU, session duration,
    and sessions per user.
  type: definition
  entity: User Engagement
  keywords:
  - definition
  - user
  - engagement
  - includes
  - metrics
  - like
  - dau
  - wau
  - mau
  - session
  - duration
  - sessions
  - per
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: User Engagement (DAU, WAU, MAU, Session Duration, Sessions per User)
    char_start: 0
    char_end: 68
- statement: User Funnel Analysis is a method of analyzing user steps to complete
    actions.
  type: definition
  entity: User Funnel Analysis
  keywords:
  - definition
  - user
  - funnel
  - analysis
  - method
  - analyzing
  - steps
  - complete
  - actions
  source:
    doc: motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md
    quote: User Funnel Analysis
    char_start: 0
    char_end: 20
- statement: Many include a user interface for interacting with the data.
  type: definition
  entity: User Interface
  keywords:
  - definition
  - many
  - include
  - user
  - interface
  - interacting
  - data
  source:
    doc: motherduck.com/ecosystem.md
    quote: While not always present in backend-focused data applications, many include
      a user interface for interacting with the data.
    char_start: 0
    char_end: 123
- statement: The User Management API simplifies user management for organizations
    with complex workflows.
  type: definition
  entity: User Management API
  keywords:
  - definition
  - user
  - management
  - api
  - simplifies
  - organizations
  - complex
  - workflows
  source:
    doc: motherduck.com/blog/duckdb-cognee-sql-analytics-graph-rag.md
    quote: We’re delighted to introduce the User Management API, which simplifies
      user management for organizations with complex workflows.
    char_start: 0
    char_end: 128
- statement: December’s feature roundup includes a User Management REST API.
  type: definition
  entity: User Management REST API
  keywords:
  - definition
  - december
  - feature
  - roundup
  - includes
  - user
  - management
  - rest
  - api
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md
    quote: Introducing the User Management REST API, the Table Summary, and a read-only
      MD_INFORMATION_SCHEMA for metadata.
    char_start: 0
    char_end: 112
- statement: Introducing the User Management REST API, the Table Summary, and a read-only
    MD_INFORMATION_SCHEMA for metadata.
  type: definition
  entity: User Management REST API
  keywords:
  - definition
  - introducing
  - user
  - management
  - rest
  - api
  - table
  - summary
  - read
  - md
  - information
  - schema
  - metadata
  source:
    doc: motherduck.com/blog/duckdb-dashboard-e2e-data-engineering-project-part-3.md
    quote: Introducing the User Management REST API, the Table Summary, and a read-only
      MD_INFORMATION_SCHEMA for metadata.
    char_start: 0
    char_end: 112
- statement: User retention measures the percentage of users who continue using the
    product over time.
  type: definition
  entity: User Retention
  keywords:
  - definition
  - user
  - retention
  - measures
  - percentage
  - users
  - who
  - continue
  - using
  - product
  - over
  - time
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-use-cases.md
    quote: Measures the percentage of users who continue using the product over time.
    char_start: 0
    char_end: 74
- statement: The user_prompt_wf function processes user prompts and recent data.
  type: definition
  entity: user_prompt_wf
  keywords:
  - definition
  - user
  - prompt
  - wf
  - function
  - processes
  - prompts
  - recent
  - data
  source:
    doc: motherduck.com/blog/estuary-streaming-cdc-replication.md
    quote: The user_prompt_wf function that processes user prompts and recent data.
    char_start: 0
    char_end: 72
- statement: The Users table contains 19942787 rows.
  type: definition
  entity: Users
  keywords:
  - definition
  - users
  - table
  - contains
  - '19942787'
  - rows
  source:
    doc: motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md
    quote: -- 19942787 rows
    char_start: 0
    char_end: 16
- statement: The users table represents user data in the DuckDB database example.
  type: definition
  entity: Users
  keywords:
  - definition
  - users
  - table
  - represents
  - user
  - data
  - duckdb
  - database
  - example
  source:
    doc: motherduck.com/learn-more/web-assembly.md
    quote: A table in the DuckDB database example representing user data.
    char_start: 0
    char_end: 62
- statement: The uv package manager is used to manage Python environments.
  type: definition
  entity: uv
  keywords:
  - definition
  - uv
  - package
  - manager
  - used
  - manage
  - python
  - environments
  source:
    doc: motherduck.com/blog/vibe-coding-sql-cursor.md
    quote: By leveraging the uv package manager, we can simply ignore our python environment.
    char_start: 0
    char_end: 82
- statement: uv is a Python package manager that focuses on fast dependency resolution.
  type: definition
  entity: uv
  keywords:
  - definition
  - uv
  - python
  - package
  - manager
  - focuses
  - fast
  - dependency
  - resolution
  source:
    doc: motherduck.com/blog/spark-ducklake-getting-started.md
    quote: A Python package manager that focuses on fast dependency resolution.
    char_start: 0
    char_end: 68
- statement: Vaex is a high-performance library for lazy out-of-core DataFrames.
  type: definition
  entity: Vaex
  keywords:
  - definition
  - vaex
  - high
  - performance
  - library
  - lazy
  - out
  - core
  - dataframes
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: High-performance library for lazy out-of-core DataFrames, to visualize
      and explore big tabular datasets.
    char_start: 0
    char_end: 104
- statement: Variables allow us to insert arbitrary values into them with the set
    variable command.
  type: definition
  entity: variables
  keywords:
  - definition
  - variables
  - allow
  - us
  - insert
  - arbitrary
  - values
  - them
  - set
  - variable
  - command
  source:
    doc: motherduck.com/blog/motherduck-kestra-etl-pipelines.md
    quote: Variables allow us to insert arbitrary values into them with the set variable
      command.
    char_start: 0
    char_end: 86
- statement: The new VARIANT type provides fast processing of JSON and other semi-structured
    data.
  type: definition
  entity: VARIANT Type
  keywords:
  - definition
  - new
  - variant
  - type
  - provides
  - fast
  - processing
  - json
  - semi
  - structured
  - data
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eight.md
    quote: The new VARIANT type provides fast processing of JSON and other semi-structured
      data.
    char_start: 0
    char_end: 85
- statement: DuckDB has introduced a VARINT data type for variable-length integers.
  type: feature
  entity: VARINT
  keywords:
  - feature
  - duckdb
  - introduced
  - varint
  - data
  - type
  - variable
  - length
  - integers
  source:
    doc: motherduck.com/blog/data-engineer-highlights-PyConDE-2023.md
    quote: VARINT type refers to a variable-length integer data type.
    char_start: 0
    char_end: 58
- statement: VARINT optimizes the storage by using fewer bytes for smaller numbers
    and more bytes for larger numbers.
  type: definition
  entity: VARINT
  keywords:
  - definition
  - varint
  - optimizes
  - storage
  - using
  - fewer
  - bytes
  - smaller
  - numbers
  - larger
  source:
    doc: motherduck.com/blog/duckdb-cognee-sql-analytics-graph-rag.md
    quote: Unlike fixed-size integers (like INT or BIGINT), which allocate a fixed
      number of bytes regardless of the size of the value stored, VARINT optimizes
      the storage by using fewer bytes for smaller number
    char_start: 0
    char_end: 236
- statement: Vector databases are optimized for storing and querying vector data.
  type: definition
  entity: Vector Database
  keywords:
  - definition
  - vector
  - databases
  - optimized
  - storing
  - querying
  - data
  source:
    doc: motherduck.com/blog/simplifying-iot-analytics-motherduck.md
    quote: Understand when to use a vector database and how it differs from vector
      search engines.
    char_start: 0
    char_end: 87
- statement: Vectorized execution engines for analytical processing and specialized
    vector databases for AI embeddings together represent the future of fast data
    processing.
  type: definition
  entity: Vector Database
  keywords:
  - definition
  - vectorized
  - execution
  - engines
  - analytical
  - processing
  - specialized
  - vector
  - databases
  - ai
  - embeddings
  - together
  - represent
  - future
  - fast
  - data
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: recent developments indicate that vectorized execution engines for analytical
      processing and specialized vector databases for AI embeddings together represent
      the future of fast data processing.
    char_start: 0
    char_end: 194
- statement: Vector embeddings are used for Large Language Models (LLMs) and AI workloads.
  type: definition
  entity: vector embeddings
  keywords:
  - definition
  - vector
  - embeddings
  - used
  - large
  - language
  - models
  - llms
  - ai
  - workloads
  source:
    doc: motherduck.com/learn-more/data-warehouse-tco.md
    quote: Vector embeddings are used for Large Language Models (LLMs) and AI workloads.
    char_start: 0
    char_end: 77
- statement: Vector embeddings are used in various machine learning applications.
  type: definition
  entity: vector embeddings
  keywords:
  - definition
  - vector
  - embeddings
  - used
  - various
  - machine
  - learning
  - applications
  source:
    doc: motherduck.com/blog/sql-keyboard-shortcuts-for-joyful-querying.md
    quote: Vector embeddings are used in various machine learning applications.
    char_start: 0
    char_end: 68
- statement: Vector engines and vector databases serve different purposes.
  type: definition
  entity: Vector Engine
  keywords:
  - definition
  - vector
  - engines
  - databases
  - serve
  - different
  - purposes
  source:
    doc: motherduck.com/learn-more/duckdb-python-quickstart-part1.md
    quote: 'Key Differences: When to Use Each'
    char_start: 0
    char_end: 33
- statement: The Vector Tiles API processes data into vector tiles.
  type: definition
  entity: Vector Tiles API
  keywords:
  - definition
  - vector
  - tiles
  - api
  - processes
  - data
  source:
    doc: motherduck.com/blog/semantic-layer-duckdb-tutorial.md
    quote: 'Vector Tiles API: Processes data into vector tiles.'
    char_start: 0
    char_end: 51
- statement: Vectorized engines process data in batches of thousands of values.
  type: definition
  entity: vectorized engines
  keywords:
  - definition
  - vectorized
  - engines
  - process
  - data
  - batches
  - thousands
  - values
  source:
    doc: motherduck.com/glossary/storage layer.md
    quote: Instead of processing data one row at a time, vectorized engines process
      data in batches of thousands of values.
    char_start: 0
    char_end: 112
- statement: Version Control applies software engineering practices to data models
    and transformation logic.
  type: definition
  entity: Version Control
  keywords:
  - definition
  - version
  - control
  - applies
  - software
  - engineering
  - practices
  - data
  - models
  - transformation
  - logic
  source:
    doc: motherduck.com/learn-more/data-application-architecture.md
    quote: Adopt Version Control for Data and Code Apply software engineering practices
      to data models, schemas, and transformation logic.
    char_start: 0
    char_end: 127
- statement: Vertex AI can be integrated with MotherDuck for AI solutions.
  type: integration
  entity: Vertex AI
  keywords:
  - integration
  - vertex
  - ai
  - integrated
  - motherduck
  - solutions
  source:
    doc: motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md
    quote: Vertex AI can be integrated with MotherDuck for AI solutions.
    char_start: 0
    char_end: 61
- statement: Tobias Muller built skyfirehose.
  type: definition
  entity: Victoriano
  keywords:
  - definition
  - tobias
  - muller
  - built
  - skyfirehose
  source:
    doc: motherduck.com/blog/duckdb-wasm-in-browser.md
    quote: Tobias Muller built [skyfirehose](https://skyfirehose.com/) to also offers
      to query the Bluesky Jetstream with DuckDB.
    char_start: 0
    char_end: 118
- statement: The feature 'video_player' is used by 367 distinct users.
  type: definition
  entity: video_player
  keywords:
  - definition
  - feature
  - video
  - player
  - used
  - '367'
  - distinct
  - users
  source:
    doc: motherduck.com/learn-more/pandas-dataframes-guide.md
    quote: '367'
    char_start: 0
    char_end: 3
- statement: Vim can be intimidating at first, but it's a worthwhile investment.
  type: definition
  entity: Vim
  keywords:
  - definition
  - vim
  - intimidating
  - first
  - worthwhile
  - investment
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: Vim can be intimidating at first, but it's a worthwhile investment.
    char_start: 0
    char_end: 67
- statement: Vim is used by 21.6% of developers.
  type: definition
  entity: Vim
  keywords:
  - definition
  - vim
  - used
  - '21.6'
  - developers
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: Vim (21.6%)
    char_start: 0
    char_end: 11
- statement: Operational overhead directly reduces the ability of small data teams
    to deliver value.
  type: definition
  entity: Virtual Warehouses
  keywords:
  - definition
  - operational
  - overhead
  - directly
  - reduces
  - ability
  - small
  - data
  - teams
  - deliver
  - value
  source:
    doc: motherduck.com/learn-more/modern-data-warehouse-playbook.md
    quote: For a small data team, operational overhead directly reduces their ability
      to deliver value.
    char_start: 0
    char_end: 92
- statement: Visual Studio Code is a source-code editor developed by Microsoft.
  type: definition
  entity: Visual Studio Code
  keywords:
  - definition
  - visual
  - studio
  - code
  - source
  - editor
  - developed
  - microsoft
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md
    quote: If you don't have a good code editor, download and install Visual Studio
      Code.
    char_start: 0
    char_end: 78
- statement: Visual Studio Code is used by 73.6% of developers.
  type: definition
  entity: Visual Studio Code
  keywords:
  - definition
  - visual
  - studio
  - code
  - used
  - '73.6'
  - developers
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: 'Popular IDEs are with their used based on the StackOverflow Survey 2024:
      Visual Studio Code (73.6%)'
    char_start: 0
    char_end: 99
- statement: Data applications often include a visualization layer.
  type: definition
  entity: Visualization Layer
  keywords:
  - definition
  - data
  - applications
  - often
  - include
  - visualization
  - layer
  source:
    doc: motherduck.com/ecosystem.md
    quote: Data applications often include a visualization layer.
    char_start: 0
    char_end: 54
- statement: Evidence can be developed using VSCode.
  type: definition
  entity: VSCode
  keywords:
  - definition
  - evidence
  - developed
  - using
  - vscode
  source:
    doc: motherduck.com/blog/unstructured-analysis-tensorlake-motherduck.md
    quote: using the devcontainer feature from VSCode.
    char_start: 0
    char_end: 43
- statement: Wasm allows for fast, lightweight applications that are easy to deploy.
  type: definition
  entity: Wasm
  keywords:
  - definition
  - wasm
  - allows
  - fast
  - lightweight
  - applications
  - easy
  - deploy
  source:
    doc: motherduck.com/blog/small-data-sf-recap.md
    quote: Wasm is a powerful tool that is gaining traction in web development...
      fast, lightweight applications that are easy to deploy.
    char_start: 0
    char_end: 126
- statement: WebAssembly enables the execution of binary code in the browser.
  type: definition
  entity: Wasm
  keywords:
  - definition
  - webassembly
  - enables
  - execution
  - binary
  - code
  - browser
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md
    quote: This is where WebAssembly, an open standard that enables the execution
      of binary code, comes into play.
    char_start: 0
    char_end: 103
- statement: WebAssembly excels in scenarios such as data analytics, computation-intensive
    tasks, gaming, and real-time applications.
  type: definition
  entity: Wasm
  keywords:
  - definition
  - webassembly
  - excels
  - scenarios
  - data
  - analytics
  - computation
  - intensive
  - tasks
  - gaming
  - real
  - time
  - applications
  source:
    doc: motherduck.com/learn-more/no-etl-query-raw-files.md
    quote: 'WebAssembly excels in several scenarios: Data Analytics and Processing,
      Computation-Intensive Tasks, Gaming and Graphics, Porting Existing Applications,
      Real-time Applications.'
    char_start: 0
    char_end: 176
- statement: WebAssembly offers predictable, near-native performance.
  type: performance
  entity: Wasm
  keywords:
  - webassembly
  - offers
  - predictable
  - near
  - native
  - performance
  source:
    doc: motherduck.com/videos/is-bi-too-big-for-small-data.md
    quote: WebAssembly offers predictable, near-native performance, while JavaScript
      performance depends heavily on the runtime's optimization capabilities.
    char_start: 0
    char_end: 145
- statement: WebAssembly represents a significant advancement in web platform capabilities.
  type: definition
  entity: Wasm
  keywords:
  - definition
  - webassembly
  - represents
  - significant
  - advancement
  - web
  - platform
  - capabilities
  source:
    doc: motherduck.com/videos/ai-powered-bi-can-llms-really-generate-your-dashboards-ft-michael-driscoll.md
    quote: WebAssembly represents a significant advancement in web platform capabilities,
      enabling high-performance code execution directly in the browser.
    char_start: 0
    char_end: 144
- statement: WebAssembly will play an increasingly important role in the future of
    web development.
  type: definition
  entity: Wasm
  keywords:
  - definition
  - webassembly
  - play
  - increasingly
  - important
  - role
  - future
  - web
  - development
  source:
    doc: motherduck.com/videos/ai-powered-bi-can-llms-really-generate-your-dashboards-ft-michael-driscoll.md
    quote: As the ecosystem matures and browser support continues to improve, WebAssembly
      will play an increasingly important role in the future of web development.
    char_start: 0
    char_end: 153
- statement: The Wasm SDK is a software development kit for building applications
    using WebAssembly.
  type: definition
  entity: WASM SDK
  keywords:
  - definition
  - wasm
  - sdk
  - software
  - development
  - kit
  - building
  - applications
  - using
  - webassembly
  source:
    doc: motherduck.com/blog/announcing-series-seed-and-a.md
    quote: Introducing the MotherDuck Wasm SDK
    char_start: 0
    char_end: 35
- statement: The Wasm SDK reduces cloud computing costs.
  type: definition
  entity: WASM SDK
  keywords:
  - definition
  - wasm
  - sdk
  - reduces
  - cloud
  - computing
  - costs
  source:
    doc: motherduck.com/videos.md
    quote: Unlock high-speed data apps with the MotherDuck Wasm SDK, reducing your
      cloud computing cost...
    char_start: 0
    char_end: 95
- statement: The `CREATE TABLE weather AS` command tells DuckDB to create a new table
    named weather.
  type: definition
  entity: weather
  keywords:
  - definition
  - create
  - table
  - weather
  - command
  - tells
  - duckdb
  - new
  - named
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md
    quote: The `CREATE TABLE weather AS` command tells DuckDB to create a new table
      named weather.
    char_start: 0
    char_end: 87
- statement: With a single line of SQL, we can create a new table called weather from
    a CSV file.
  type: definition
  entity: weather
  keywords:
  - definition
  - single
  - line
  - sql
  - create
  - new
  - table
  - called
  - weather
  - csv
  - file
  source:
    doc: motherduck.com/blog/pg to motherduck at motherduck.md
    quote: With a single line of SQL, we can create a new table called weather from
      a CSV file containing weather data from Washington.
    char_start: 0
    char_end: 124
- statement: The website collects personal information from users.
  type: definition
  entity: Website
  keywords:
  - definition
  - website
  - collects
  - personal
  - information
  - users
  source:
    doc: motherduck.com/videos/duckdb-run-dbt-build-with-sub-second-execution-times.md
    quote: We may collect a variety of personal information from or about you or your
      devices from various sources.
    char_start: 0
    char_end: 104
- statement: Users may not be able to use our Website or Events if personal information
    is not provided.
  type: definition
  entity: Website
  keywords:
  - definition
  - users
  - able
  - use
  - website
  - events
  - personal
  - information
  - provided
  source:
    doc: motherduck.com/videos/duckdb-run-dbt-build-with-sub-second-execution-times.md
    quote: If you do not provide your personal information when requested, you may
      not be able to use our Website or Events.
    char_start: 0
    char_end: 113
- statement: The future will be a multi-engine data stack.
  type: definition
  entity: Wes McKinney
  keywords:
  - definition
  - future
  - multi
  - engine
  - data
  - stack
  source:
    doc: motherduck.com/blog/duckdb-the-great-federator.md
    quote: I do believe that the future will be a multi-engine data stack where we
      will choose different tools...
    char_start: 0
    char_end: 102
- statement: The `WHERE` clause is your tool for filtering rows based on specific
    conditions.
  type: definition
  entity: WHERE
  keywords:
  - definition
  - clause
  - tool
  - filtering
  - rows
  - based
  - specific
  - conditions
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md
    quote: The `WHERE` clause is your tool for filtering rows based on...
    char_start: 0
    char_end: 62
- statement: It would be ideal to enrich with data from Wikipedia.
  type: definition
  entity: Wikipedia
  keywords:
  - definition
  - ideal
  - enrich
  - data
  - wikipedia
  source:
    doc: motherduck.com/learn-more/big-data.md
    quote: So it would be ideal to enrich with data from Wikipedia.
    char_start: 0
    char_end: 56
- statement: Window functions allow performing calculations across a set of table
    rows that are somehow related to the current row.
  type: definition
  entity: Window Functions
  keywords:
  - definition
  - window
  - functions
  - allow
  - performing
  - calculations
  - across
  - set
  - table
  - rows
  - somehow
  - related
  - current
  - row
  source:
    doc: motherduck.com/blog/fabi-ai-llm-prompt-analysis.md
    quote: A feature in SQL that allows performing calculations across a set of table
      rows that are somehow related to the current row.
    char_start: 0
    char_end: 124
- statement: Window functions enable data professionals to perform sophisticated analytical
    queries.
  type: definition
  entity: Window Functions
  keywords:
  - definition
  - window
  - functions
  - enable
  - data
  - professionals
  - perform
  - sophisticated
  - analytical
  - queries
  source:
    doc: motherduck.com/blog/fabi-ai-llm-prompt-analysis.md
    quote: By offering these flexible, easy-to-use analytics capabilities, MotherDuck
      supports seamless and fast insight generation for even the most complex queries.
    char_start: 0
    char_end: 155
- statement: Window functions in SQL require the OVER clause for their operation.
  type: definition
  entity: Window Functions
  keywords:
  - definition
  - window
  - functions
  - sql
  - require
  - over
  - clause
  - operation
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-six.md
    quote: Window functions in SQL require the OVER clause for their operation.
    char_start: 0
    char_end: 68
- statement: Workload-Fit Architecture matches the tool to the job's specific concurrency,
    latency, and cost requirements.
  type: definition
  entity: Workload-Fit Architecture
  keywords:
  - definition
  - workload
  - fit
  - architecture
  - matches
  - tool
  - job
  - specific
  - concurrency
  - latency
  - cost
  - requirements
  source:
    doc: motherduck.com/blog/vibe-coding-sql-cursor.md
    quote: 'This leads to a more modern approach: Workload-Fit Architecture, which
      is the principle of matching the tool to the job''s specific concurrency, latency,
      and cost requirements.'
    char_start: 0
    char_end: 175
- statement: To access multiple databases as part of cross-database workflows, use
    attach_mode=workspace instead.
  type: feature
  entity: workspace attach mode
  keywords:
  - feature
  - access
  - multiple
  - databases
  - part
  - cross
  - database
  - workflows
  - use
  - attach
  - mode
  - workspace
  - instead
  source:
    doc: motherduck.com/blog/duckdb-110-hidden-gems.md
    quote: To access multiple databases as part of cross-database workflows, use attach_mode=workspace
      instead.
    char_start: 0
    char_end: 100
- statement: WSL allows users to work with Linux commands on Windows.
  type: definition
  entity: WSL
  keywords:
  - definition
  - wsl
  - allows
  - users
  - work
  - linux
  - commands
  - windows
  source:
    doc: motherduck.com/blog/15-companies-duckdb-in-prod.md
    quote: if you are challenged to work mainly in Linux and the command line, Linux
      or MacOS are still the better option.
    char_start: 0
    char_end: 111
- statement: X started offering a way for its users to download an archive of their
    data.
  type: definition
  entity: X
  keywords:
  - definition
  - started
  - offering
  - way
  - users
  - download
  - archive
  - data
  source:
    doc: motherduck.com/blog/data-app-generator.md
    quote: Not very long ago, X started offering a way for its users to download an
      archive of their data.
    char_start: 0
    char_end: 95
- statement: Xcode is used by 9.3% of developers.
  type: definition
  entity: Xcode
  keywords:
  - definition
  - xcode
  - used
  - '9.3'
  - developers
  source:
    doc: motherduck.com/blog/analyze-json-data-using-sql.md
    quote: Xcode (9.3%)
    char_start: 0
    char_end: 12
- statement: Xebia is a pioneering Software Engineering and IT consultancy company.
  type: definition
  entity: Xebia
  keywords:
  - definition
  - xebia
  - pioneering
  - software
  - engineering
  - consultancy
  - company
  source:
    doc: motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md
    quote: Xebia is a pioneering Software Engineering and IT consultancy company.
    char_start: 0
    char_end: 70
- statement: XGBoost models are primarily used for user behavior prediction and financial
    risk assessment.
  type: definition
  entity: XGBoost
  keywords:
  - definition
  - xgboost
  - models
  - primarily
  - used
  - user
  - behavior
  - prediction
  - financial
  - risk
  - assessment
  source:
    doc: motherduck.com/case-studies/reflex-careers-gig-economy-retail.md
    quote: We're mostly working with XGBoost models for various business functions,
      from user behavior prediction to financial risk assessment.
    char_start: 0
    char_end: 132
- statement: Xorq is a declarative framework for building multi-engine computations.
  type: definition
  entity: Xorq
  keywords:
  - definition
  - xorq
  - declarative
  - framework
  - building
  - multi
  - engine
  - computations
  source:
    doc: motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md
    quote: A declarative framework for building multi-engine computations.
    char_start: 0
    char_end: 63
- statement: Xorq is a library for creating persistent data cubes.
  type: definition
  entity: Xorq
  keywords:
  - definition
  - xorq
  - library
  - creating
  - persistent
  - data
  - cubes
  source:
    doc: motherduck.com/blog/estuary-streaming-cdc-replication.md
    quote: the option is there with the help of [Xorq]...
    char_start: 0
    char_end: 46
- statement: YAML configuration can be used to add retries and alerts on failure.
  type: definition
  entity: YAML
  keywords:
  - definition
  - yaml
  - configuration
  - used
  - add
  - retries
  - alerts
  - failure
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-three.md
    quote: adding retries and alerts on failure is a matter of adding a couple of
      lines of YAML configuration...
    char_start: 0
    char_end: 101
- statement: YAML is used for defining metrics in a semantic layer.
  type: definition
  entity: YAML
  keywords:
  - definition
  - yaml
  - used
  - defining
  - metrics
  - semantic
  - layer
  source:
    doc: motherduck.com/blog/pushing-geo-boundaries-with-motherduck-geobase.md
    quote: so we use YAML for this.
    char_start: 0
    char_end: 24
- statement: YamlQL is a new tool that transforms YAML files into queryable relational
    databases using DuckDB.
  type: definition
  entity: YamlQL
  keywords:
  - definition
  - yamlql
  - new
  - tool
  - transforms
  - yaml
  - files
  - queryable
  - relational
  - databases
  - using
  - duckdb
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2024.md
    quote: YamlQL is a new tool that transforms YAML files into queryable relational
      databases using DuckDB.
    char_start: 0
    char_end: 97
- statement: YamlQL works well with complex configuration files such as Kubernetes
    manifests.
  type: definition
  entity: YamlQL
  keywords:
  - definition
  - yamlql
  - works
  - well
  - complex
  - configuration
  - files
  - kubernetes
  - manifests
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-march-2024.md
    quote: 'Practically: Works well with complex configuration files such as Kubernetes
      manifests applications.'
    char_start: 0
    char_end: 99
- statement: Yazi allows us to show images and now also data set files that we can
    explore immediately.
  type: definition
  entity: Yazi
  keywords:
  - definition
  - yazi
  - allows
  - us
  - show
  - images
  - now
  - also
  - data
  - set
  - files
  - explore
  - immediately
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eleven.md
    quote: It allows us to show images and now also data set files that we can explore
      immediately.
    char_start: 0
    char_end: 88
- statement: Yazi is a fast terminal file manager written in Rust based on async I/O.
  type: definition
  entity: Yazi
  keywords:
  - definition
  - yazi
  - fast
  - terminal
  - file
  - manager
  - written
  - rust
  - based
  - async
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-eleven.md
    quote: Yazi, in case you haven't heard, is a Ranger alternative, a fast terminal
      file manager written in Rust based on async I/O.
    char_start: 0
    char_end: 122
- statement: YData Profiling provides exploratory analysis and Soda performs accurate
    checks.
  type: definition
  entity: YData Profiling
  keywords:
  - definition
  - ydata
  - profiling
  - provides
  - exploratory
  - analysis
  - soda
  - performs
  - accurate
  - checks
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-nine.md
    quote: With YData Profiling providing exploratory analysis and Soda performing
      accurate checks, you can get back to having a peaceful night's sleep.
    char_start: 0
    char_end: 141
- statement: The series is available on YouTube.
  type: definition
  entity: YouTube
  keywords:
  - definition
  - series
  - available
  - youtube
  source:
    doc: motherduck.com/blog/from-data-lake-to-lakehouse-duckdb-portable-catalog.md
    quote: And if you prefer video content, the series is also available on our YouTube
      channel.
    char_start: 0
    char_end: 85
- statement: There's a video tutorial you can watch on YouTube.
  type: definition
  entity: YouTube
  keywords:
  - definition
  - video
  - tutorial
  - watch
  - youtube
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md
    quote: There's also a video tutorial you can watch here.
    char_start: 0
    char_end: 49
- statement: Zain Hasan conducted a session on open-source.
  type: definition
  entity: Zain Hasan
  keywords:
  - definition
  - zain
  - hasan
  - conducted
  - session
  - open
  - source
  source:
    doc: motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md
    quote: Zain Hasan of Together.ai jumped straight into a hands-on session
    char_start: 0
    char_end: 65
- statement: Zain Hasan conducted a workshop on building AI data science agents.
  type: definition
  entity: Zain Hasan
  keywords:
  - definition
  - zain
  - hasan
  - conducted
  - workshop
  - building
  - ai
  - data
  - science
  - agents
  source:
    doc: motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md
    quote: After lunch, Zain Hasan of Together.ai jumped straight into a hands-on
      session for the data science-inclined.
    char_start: 0
    char_end: 109
- statement: Zed is a high-performance, multiplayer code editor with AI capabilities
    created by former Atom developers.
  type: definition
  entity: Zed
  keywords:
  - definition
  - zed
  - high
  - performance
  - multiplayer
  - code
  - editor
  - ai
  - capabilities
  - created
  - former
  - atom
  - developers
  source:
    doc: motherduck.com/blog/analyze-x-data-nodejs-duckdb.md
    quote: A high-performance, multiplayer code editor with AI capabilities created
      by former Atom developers.
    char_start: 0
    char_end: 99
- statement: Zeppelin is an open-source notebook for data analysis.
  type: definition
  entity: Zeppelin
  keywords:
  - definition
  - zeppelin
  - open
  - source
  - notebook
  - data
  - analysis
  source:
    doc: motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md
    quote: 'Zeppelin: Open-source notebook for data analysis.'
    char_start: 0
    char_end: 49
- statement: The zero-copy clone capability was rolled out last week.
  type: definition
  entity: zero copy cloning
  keywords:
  - definition
  - zero
  - copy
  - clone
  - capability
  - rolled
  - out
  - last
  - week
  source:
    doc: motherduck.com/blog/announcing-duckdb-13-on-motherduck-cdw.md
    quote: We just rolled out this feature last week on MotherDuck - so we encourage
      you to try out our new zero-copy clone capability!
    char_start: 0
    char_end: 124
- statement: Zero copy cloning allows for isolated test environments.
  type: definition
  entity: zero copy cloning
  keywords:
  - definition
  - zero
  - copy
  - cloning
  - allows
  - isolated
  - test
  - environments
  source:
    doc: motherduck.com/blog/announcing-mega-giga-instance-sizes-huge-scale.md
    quote: Learn how concepts like zero copy cloning and metadata pointers can finally
      give you isolated test environments.
    char_start: 0
    char_end: 112
- statement: Zero-shot learning addresses some of the limitations of current learned
    DBMS approaches.
  type: definition
  entity: zero-shot learning
  keywords:
  - definition
  - zero
  - shot
  - learning
  - addresses
  - limitations
  - current
  - learned
  - dbms
  - approaches
  source:
    doc: motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw.md
    quote: However, it has its limitations, which led the speaker to introduce zero-shot
      learning.
    char_start: 0
    char_end: 87
- statement: Zürich has the highest number of chocolate stores.
  type: definition
  entity: Zurich
  keywords:
  - definition
  - rich
  - highest
  - number
  - chocolate
  - stores
  source:
    doc: motherduck.com/blog/new-collaboration-sharing-motherduck-data-warehouse-organization-auto-join.md
    quote: Zürich has the highest number of chocolate stores.
    char_start: 0
    char_end: 50
