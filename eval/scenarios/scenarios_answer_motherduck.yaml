---
# Kurt Evaluation Scenarios - MotherDuck Question Answering
#
# Simple scenario for testing the answer command with MotherDuck documentation

scenarios:
  - name: answer_motherduck
    description: Answer question about MotherDuck file formats using knowledge graph
    project: motherduck

    notes: |
      Tests the answer command with MotherDuck documentation:
      - Load pre-built knowledge graph from motherduck dump (874 docs, 371 entities)
      - Run kurt answer command and save output to file
      - Verify the answer contains relevant content

      This is a command-based scenario that runs kurt answer directly via setup_commands
      rather than using a conversational agent.

    setup_commands:
      # Run the answer command and save output to a file
      - KURT_TELEMETRY_DISABLED=1 uv run kurt answer "What file formats are most efficient for loading data into MotherDuck?" > answer_output.txt 2>&1 || true

    # No conversational prompt needed - this is pure command execution
    initial_prompt: |
      The kurt answer command has been executed. Please confirm the test completed successfully.

    assertions:
      # Verify knowledge graph is populated
      - type: SQLQueryAssertion
        query: SELECT COUNT(*) >= 100 FROM entities

      - type: SQLQueryAssertion
        query: SELECT COUNT(*) >= 500 FROM documents

      # Verify answer output file exists and contains expected content
      - type: FileExists
        path: answer_output.txt

      - type: FileContains
        path: answer_output.txt
        content: "(?i)Parquet"
        is_regex: true

      - type: FileContains
        path: answer_output.txt
        content: "(?i)file format"
        is_regex: true
