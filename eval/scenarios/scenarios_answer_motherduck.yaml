---
# Kurt Evaluation Scenarios - MotherDuck Question Answering
#
# Simple scenario for testing the answer command with MotherDuck documentation

scenarios:
  - name: answer_motherduck
    description: Answer question about MotherDuck file formats using knowledge graph
    project: motherduck

    notes: |
      Tests the answer command with MotherDuck documentation:
      - Load pre-built knowledge graph from motherduck dump (874 docs, 371 entities)
      - Answer a technical question about file formats
      - Verify the answer contains relevant content

    initial_prompt: |
      Run the kurt answer command to find out what file formats are most efficient for loading data into MotherDuck.

      Use this exact command:
      KURT_TELEMETRY_DISABLED=1 uv run kurt answer "What file formats are most efficient for loading data into MotherDuck?"

    assertions:
      # Verify knowledge graph is populated
      - type: SQLQueryAssertion
        query: SELECT COUNT(*) >= 100 FROM entities

      - type: SQLQueryAssertion
        query: SELECT COUNT(*) >= 500 FROM documents

      # Verify answer contains expected content
      - type: ConversationContains
        text: "Parquet"
        case_sensitive: false

      - type: ConversationContains
        text: "file format"
        case_sensitive: false

      # Verify conversation completed
      - type: MetricEquals
        metric_path: conversation.completed
        expected_value: true
