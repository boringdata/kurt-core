# Answer

**Parquet is the most efficient file format for loading data into MotherDuck**, especially for analytical workloads.

Key advantages of Parquet:
- **Columnar storage layout** - excels at analytical queries reading subsets of columns
- **Impressive compression** - uses dictionary, run-length, and delta encoding to optimize storage
- **Predicate pushdown and column pruning** - optimizes data queries
- **Native support** - widely supported across big data frameworks

MotherDuck can also natively ingest from **CSV, JSON, Iceberg, and Delta** file formats, but Parquet is preferred for efficiency due to its columnar nature and compression capabilities.

For CSV files, DuckDB (which powers MotherDuck) includes a CSV sniffer that auto-detects structure. Use `ignore_errors = true` to handle malformed rows gracefully.

---
Sources:
- Parquet claims [4aa515a5]: columnar storage, compression, predicate pushdown, schema evolution
- MotherDuck cross-entity claim: native ingestion of CSV, Parquet, JSON, Iceberg, Delta
- CSV sniffer claims: error handling options
