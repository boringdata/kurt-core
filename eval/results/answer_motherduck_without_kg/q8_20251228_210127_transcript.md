# Scenario: answer_motherduck_without_kg

**Status**: âœ… PASSED
**Timestamp**: 20251228_210127

**Duration**: 135.44 seconds
**Tokens Used**: 0

---

## Conversation


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ SCENARIO: answer_motherduck_without_kg
   Answer MotherDuck questions by searching sources directly (no KG)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”


ğŸ” Verifying .claude installation...
   âœ“ .claude folder exists at /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_33e1e0xk/.claude
   âœ“ Skills: 0 found
   âœ“ Commands: 0 found

ğŸ” Filtering to questions: [8]

ğŸ§ª Running 1 of 10 question(s) defined in questions_motherduck.yaml


======================================================================
â“ Question 8/10
...What's the difference between a MotherDuck database and a share?
======================================================================


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ’¬ QUESTION 8
â”‚ Answer this question by searching through the .kurt/sources/ directory:

...What's the difference between a MotherDuck database and a share?

Required Steps:
1. Search for relevant markdown files in .kurt/sources/ using glob and grep
2. Read the most relevant files (aim for 3-5 most relevant sources)
3. As you read each file, keep track of:
   - The file path
   - The file title/name
   - Key information extracted from that file
4. Synthesize a comprehensive answer based on the information found
5. Write your answer to: /tmp/answer_without_kg_8.md

IMPORTANT - Your answer MUST have this structure:
```markdown
# Answer

[Your comprehensive answer here, drawing from the sources you read]

## Sources

List each source file you actually read and used, showing the EXACT LOCAL FILE PATH:
- .kurt/sources/motherduck.com/[path/to/file.md] - Brief description of key information used from this file
- .kurt/sources/motherduck.com/[path/to/file.md] - Brief description of key information used from this file
[etc.]

DO NOT use URLs or document titles as links. Show the actual file path you read with the Read tool.
```

The Sources section is MANDATORY - you must list every file you read to answer the question.

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ§¹ Clearing Claude Code context for clean scenario start...
   âœ“ Context cleared


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ ğŸ”„ TURN 1
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  [96mğŸ”§ TOOL:[0m Grep â†’ database.*share|share.*database

  [96mğŸ”§ TOOL:[0m Grep â†’ MotherDuck.*share|share.*MotherDuck

  [96mğŸ”§ TOOL:[0m Grep â†’ what is a share
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "mode": "files_with_matches",
  [2m  â”‚[0m   "filenames": [],
  [2m  â”‚[0m   "numFiles": 0
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "mode": "files_with_matches",
  [2m  â”‚[0m   "filenames": [
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/why-web-developers-should-care-about-analytical-databases.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/working-with-sql-with-your-favorite-editor-check-this.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/using-sql-in-your-data-lake-with-duckdb-iceberg-dbt-and-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/whats-new-in-data-small-data-big-impact.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/whats-new-in-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/spatial-data-management-with-duckdb-ft-mattforrest.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/sql-ide-safari-harlequin-in-your-terminal.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/motherduck-in-100-seconds-by-a-duck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/no-sql-standard-for-7-years.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/pg_duckdb-postgres-analytics-just-got-faster-with-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/simple-way-to-convert-csv-and-parquet-files.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/leveraging-duckdb-and-delta-lake-together.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/more-than-a-vibe-ai-driven-sql-that-actually-works.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/motherduck-ga-produck-tour.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/fixing-sql-spaghetti-effective-refactoring-techniques.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/friendly-sql-with-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/how-to-bootstrap-a-data-warehouse-with-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/instant-sql-mode-real-time-feedback-to-make-sql-data-exploration-fly.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-run-dbt-build-with-sub-second-execution-times.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-dbt-accelerating-the-developer-experience-with-local-power.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/bringing-duckdb-to-the-cloud-dual-execution-explained.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/building-data-apps-with-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/4-lightning-talks-on-practical-ai-workflows-from-notion-1password-motherduck-evidence.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/a-new-paradigm-for-data-visualization-with-just-sql-markdown.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/startups.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/terms-of-service.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/terms-of-use.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/trust-and-security.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/data-teams.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/duckdb-users.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/pricing.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/quacking-around-the-web.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/app-developers.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/secure-startup-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/self-service-analytics-startups.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/hybrid-analytics-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/modern-data-warehouse-playbook.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/duckdb-python-quickstart-part1.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/hack-night.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/index.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/columnar-storage-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/ecosystem/evidence.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/customer-support.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/ecosystem.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/kultura-capital.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/udisc-motherduck-sports-management.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/careers.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/dexibit.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/dominik-moritz.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/vibe-coding-sql-cursor.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/sql-embeddings-for-semantic-meaning-in-text-and-rag.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/sql-keyboard-shortcuts-for-joyful-querying.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/sql-llm-prompt-function-gpt-models.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/search-using-duckdb-part-3.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/secoda-motherduck-integration-modern-duck-stack.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/semantic-layer-duckdb-tutorial.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/separating-storage-compute-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/read-scaling-preview.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/redshift-files-hunt-for-big-data.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pg_duckdb-postgresql-extension-for-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pgduckdb-beta-release-duckdb-postgres.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/preswald-health-data-analysis.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-vercel-marketplace-native-integration.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/new-collaboration-sharing-motherduck-data-warehouse-organization-auto-join.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-open-for-all-with-series-b.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-congratulates-duckdb-1.0-release.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-headquarters-seattle-opening.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/just-enough-sql-for-ai.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/llm-data-pipelines-prompt-motherduck-dbt.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/introducing-instant-sql.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/introducing-motherduck-for-business-analytics.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/json-log-analysis-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/google-sheets-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/how-to-extract-analytics-from-bluesky.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/galileo-world-geospatial.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/getting-started-gis-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/effortless-etl-unstructured-data-unstructuredio-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/estuary-streaming-cdc-replication.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-1.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/fabi-ai-llm-prompt-analysis.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-tutorial-for-beginners.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-three.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-two.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-enterprise-5-key-categories.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-one.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-seven.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-six.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-nine.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-march-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-eight.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-eleven.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-five.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-four.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-december-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/dual-execution-dbt.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-dashboard-e2e-data-engineering-project-part-3.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-engineering-toolkit-essential-tools.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-engineers-answer-10-top-reddit-questions.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-warehouse-feature-roundup-dec-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-warehouse-feature-roundup-nov-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-warehouse-feature-roundup-oct-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/building-data-applications-with-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/building-motherduck-partner-ecosystem.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/csv-files-persist-duckdb-solution.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-app-generator.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-duckdb-snippet-sets-with-motherduck-sharing-databases.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-ducklake-support-motherduck-preview.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-mega-giga-instance-sizes-huge-scale.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-motherduck-general-availability-data-warehousing-with-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-series-seed-and-a.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-duckdb-13-on-motherduck-cdw.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-duckdb-141-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/15-companies-duckdb-in-prod.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/authors/ryan-boyd.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/authors/marc-d.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/authors/doug-raymond.md"
  [2m  â”‚[0m   ],
  [2m  â”‚[0m   "numFiles": 135
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "mode": "files_with_matches",
  [2m  â”‚[0m   "filenames": [
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/pg_duckdb-postgres-analytics-just-got-faster-with-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-motherduck-for-beginners-your-ultimate-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/duckdb-users.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/app-developers.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/secure-startup-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/self-service-analytics-startups.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/hybrid-analytics-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/duckdb-python-quickstart-part1.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/hack-night.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/columnar-storage-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/API.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/dexibit.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/the-simple-joys-of-scaling-up.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/search-using-duckdb-part-3.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/separating-storage-compute-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/read-scaling-preview.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/redshift-files-hunt-for-big-data.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/scaling-duckdb-with-ducklings.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pg-duckdb-release.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pgduckdb-beta-release-duckdb-postgres.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/new-collaboration-sharing-motherduck-data-warehouse-organization-auto-join.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/perf-is-not-enough.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-congratulates-duckdb-1.0-release.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/json-log-analysis-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/google-sheets-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/how-to-extract-analytics-from-bluesky.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/getting-started-gis-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/from-data-lake-to-lakehouse-duckdb-portable-catalog.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-1.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-the-great-federator.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-two.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-june-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-dashboard-e2e-data-engineering-project-part-3.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-engineering-toolkit-essential-tools.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-warehouse-feature-roundup-dec-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-warehouse-feature-roundup-nov-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-warehouse-feature-roundup-oct-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/building-motherduck-partner-ecosystem.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/csv-files-persist-duckdb-solution.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-app-generator.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/big-data-is-dead.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-duckdb-snippet-sets-with-motherduck-sharing-databases.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-mega-giga-instance-sizes-huge-scale.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud.md"
  [2m  â”‚[0m   ],
  [2m  â”‚[0m   "numFiles": 53
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [96mğŸ”§ TOOL:[0m Grep â†’ share|sharing

  [96mğŸ”§ TOOL:[0m Grep â†’ CREATE SHARE|DROP SHARE|SHOW SHARES
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "mode": "files_with_matches",
  [2m  â”‚[0m   "filenames": [
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-motherduck-for-beginners-your-ultimate-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/hack-night.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/getting-started-gis-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/from-data-lake-to-lakehouse-duckdb-portable-catalog.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/csv-files-persist-duckdb-solution.md"
  [2m  â”‚[0m   ],
  [2m  â”‚[0m   "numFiles": 7
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "mode": "files_with_matches",
  [2m  â”‚[0m   "filenames": [
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/new-collaboration-sharing-motherduck-data-warehouse-organization-auto-join.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-duckdb-snippet-sets-with-motherduck-sharing-databases.md"
  [2m  â”‚[0m   ],
  [2m  â”‚[0m   "numFiles": 2
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [96mğŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_33e1e0xk/.kurt/sources/motherduck.com/blog/announcing-duckdb-snippet-sets-with-motherduck-sharing-databases.md

  [96mğŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_33e1e0xk/.kurt/sources/motherduck.com/blog/new-collaboration-sharing-motherduck-data-warehouse-organization-auto-join.md
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_33e1e0xk/.kurt/sources/motherduck.com/blog/announcing-duckdb-snippet-sets-with-motherduck-sharing-databases.md",
  [2m  â”‚[0m     "content": "---\ntitle: announcing-duckdb-snippet-sets-with-motherduck-sharing-databases\ncontent_type: blog\nsource_url: https://motherduck.com/blog/announcing-duckdb-snippet-sets-with-motherduck-sharing-databases\nindexed_at: '2025-11-25T19:57:31.492927'\ncontent_hash: 91d0e93ee1158937\nhas_code_examples: true\nhas_narrative: true\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n[GO BACK TO BLOG](https://motherduck.com/blog/)\n\n# Announcing: DuckDB code snippet sets with MotherDuck Sharing\n\n2023/11/28 - 3 min read\n\nBY\n\n[Ryan Boyd](https://motherduck.com/authors/ryan-boyd/)\n\nThe [DuckDB Snippets site](https://duckdbsnippets.com/?orderBy=snippet.createdAt%3DDESC) has been a source of inspiration for me as I\u2019ve explored all the powerful analytic capabilities and SQL simplification in DuckDB. The site brings together code snippets from the community for DuckDB in SQL, Python, Bash and R to do things like [Quickly Convert a CSV to Parquet](https://duckdbsnippets.com/snippets/6/quickly-convert-a-csv-to-parquet-bash-function), [Query the Output of Another Process](https://duckdbsnippets.com/snippets/10/query-the-output-of-another-process), [Filter Column Names Using a Pattern](https://duckdbsnippets.com/snippets/20/filter-column-names-using-a-pattern) and [more](https://duckdbsnippets.com/),\n\nToday, we\u2019ve released a couple features that will make the site even more powerful: the ability to bundle multiple themed snippets together, and the ability to include a [MotherDuck Share](https://motherduck.com/docs/key-tasks/managing-shared-motherduck-database/) of public data with your snippet(s).\n\n## Sharing DuckDB Data with MotherDuck\n\n[MotherDuck Shares](https://motherduck.com/docs/key-tasks/managing-shared-motherduck-database/) give you the power to share an updatable snapshot of an entire DuckDB database with other users by providing them with a secret URL. We\u2019ve seen them be used inside companies to give colleagues access to data and publicly like the authors of the [DuckDB in Action book](https://motherduck.com/duckdb-book-brief/) have chosen to do \\[see page 26 in the free book\\].\n\nHere\u2019s a snippet showing [how to use DuckDB-specific SQL extensions](https://duckdbsnippets.com/snippets/145/duckdb-in-action-some-neat-duckdb-specific-sql-extension) from [Michael Simons](https://twitter.com/rotnroll666), one of the authors of the DuckDB book:\n\n[![screenshot of duckdbsnippets.com code snippet of using DuckDB-specific SQL extensions](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimage2_310f0661ee.png&w=3840&q=75)](https://duckdbsnippets.com/snippets/145/duckdb-in-action-some-neat-duckdb-specific-sql-extension)\n\nTo see this code snippet quack into action \\[ha!\\], you can visit [app.motherduck.com](https://app.motherduck.com/) and sign up for a free MotherDuck account. Then you can copy the `ATTACH`, `USE`, and desired `SELECT` statements into your MotherDuck notebook to see the SQL in action. Note that you can also do this all in the DuckDB CLI if you prefer.\n\nWe encourage you to check these out, vote on the snippets you find most helpful and submit your own snippets with public data.\n\n## Bundle Multiple Snippets Together\n\nIf you\u2019re a current DuckDB Snippets user, you probably already caught that the snippet I shared above bundled multiple code snippets together into a single set. You can now do that whether or not you have a MotherDuck Share link referenced.\n\nHere\u2019s an example from [Simon Aubury](https://twitter.com/SimonAubury), who is also writing an upcoming [DuckDB book](https://www.barnesandnoble.com/w/getting-started-with-duckdb-simon-aubury/1143504699), on how to [load remote parquet files into DuckDB](https://duckdbsnippets.com/snippets/167/loading-remote-parquet-files):\n\n[![screenshot of duckdbsnippets.com code snippets on loading remote parquet files into DuckDB](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimage1_fda11804a7.png&w=3840&q=75)](https://duckdbsnippets.com/snippets/167/loading-remote-parquet-files)\n\nYou can try out this snippet in [MotherDuck](https://app.motherduck.com/) or in the DuckDB CLI running on your laptop.\n\nSimon also has other great snippets on [Working with public REST APIs using DuckDB](https://duckdbsnippets.com/snippets/169/working-with-public-rest-apis) and [Working with spatial data in DuckDB](https://duckdbsnippets.com/snippets/162/working-with-spatial-data).\n\n## Thanks to the DuckDB Community\n\nThanks to the community for writing such great code snippets for the [DuckDB Snippets site](https://duckdbsnippets.com/?orderBy=snippet.createdAt%3DDESC) and voting on the snippets you like the most. Special thanks to [Michael Simons](https://duckdbsnippets.com/users/121), [Michael Hunger](https://duckdbsnippets.com/users/129), [Simon Aubury](https://duckdbsnippets.com/users/53) and the MotherDuck DevRel team ( [Mehdi Ouazza](https://duckdbsnippets.com/users/11), [David Neal](https://duckdbsnippets.com/users/181)) for seeding these new-style snippets on the site. Looking forward to seeing what **_you_** submit!\n\n### TABLE OF CONTENTS\n\n[Sharing DuckDB Data with MotherDuck](https://motherduck.com/blog/announcing-duckdb-snippet-sets-with-motherduck-sharing-databases/#sharing-duckdb-data-with-motherduck)\n\n[Bundle Multiple Snippets Together](https://motherduck.com/blog/announcing-duckdb-snippet-sets-with-motherduck-sharing-databases/#bundle-multiple-snippets-together)\n\n[Thanks to the DuckDB Community](https://motherduck.com/blog/announcing-duckdb-snippet-sets-with-motherduck-sharing-databases/#thanks-to-the-duckdb-community)\n\nStart using MotherDuck now!\n\n[Try 21 Days Free](https://motherduck.com/get-started/)\n\nGet Started\n\n![blog subscription icon](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fblog-subscription-icon.67ccd5ae.png&w=828&q=75)\n\n### Subscribe to motherduck blog\n\nE-mail\n\nSubscribe to other MotherDuck Updates\n\nSubmit\n\n## PREVIOUS POSTS\n\n[![This Month in the DuckDB Ecosystem: November 2023](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fthumbnail_duckdb_newsletter_november_40fdfbd23c.png&w=3840&q=75)](https://motherduck.com/blog/duckdb-ecosystem-newsletter-november-2023/)\n\n[2023/11/22 - Marcos Ortiz](https://motherduck.com/blog/duckdb-ecosystem-newsletter-november-2023/)\n\n### [This Month in the DuckDB Ecosystem: November 2023](https://motherduck.com/blog/duckdb-ecosystem-newsletter-november-2023)\n\nDuckDB Monthly November: Featuring David Gasquez, top content, and upcoming events!\n\n[![DuckDB Tutorial For Beginners](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fgetting_started_duckdb_thumbnail_70b197b1ab.png&w=3840&q=75)](https://motherduck.com/blog/duckdb-tutorial-for-beginners/)\n\n[2024/10/31 - Mehdi Ouazza, Ryan Boyd](https://motherduck.com/blog/duckdb-tutorial-for-beginners/)\n\n### [DuckDB Tutorial For Beginners](https://motherduck.com/blog/duckdb-tutorial-for-beginners)\n\nGet up to speed quickly with DuckDB, including installation, VSCode workflow integration and your first SQL analytics project.\n\n[View all](https://motherduck.com/blog/)\n\nAuthorization Response",
  [2m  â”‚[0m     "numLines": 103,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 103
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_33e1e0xk/.kurt/sources/motherduck.com/blog/new-collaboration-sharing-motherduck-data-warehouse-organization-auto-join.md",
  [2m  â”‚[0m     "content": "---\ntitle: new-collaboration-sharing-motherduck-data-warehouse-organization-auto-join\ncontent_type: blog\nsource_url: https://motherduck.com/blog/new-collaboration-sharing-motherduck-data-warehouse-organization-auto-join\nindexed_at: '2025-11-25T19:57:50.590556'\ncontent_hash: 3dd755825ac241f8\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n[GO BACK TO BLOG](https://motherduck.com/blog/)\n\n# New Collaboration Features: Org-level sharing and Auto-Join\n\n2024/07/16 - 2 min read\n\nBY\n\n[Ryan Boyd](https://motherduck.com/authors/ryan-boyd/)\n\nAs the Ducking Simple Data Warehouse, MotherDuck aims to make it very easy for small teams to get their jobs done quickly and smoothly. We\u2019ve designed our initial collaboration capabilities with that in mind. In our latest release, we\u2019ve launched the ability to auto-join a MotherDuck Organization in the same email domain, and you can now easily share data with everyone in the organization. Combining these two capabilities makes building your collaborative [data warehouse](https://motherduck.com/product/data-teams/) a joyful experience.\n\n## Auto-Join\n\nTo enable users with an email address on your domain to automatically join your organization, you\u2019ll find an option for \u201cAnyone with a @xyz.com email can join\u201d under \u201cSettings\u201d \\[top left menu\\], \u201cOrganization.\u201d\n\nHere\u2019s an example for the motherduck.com Organization:\n\n![alt_text](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fallow_anyone_join_06885b7f25.gif&w=3840&q=75)\n\n## Org-level Sharing and Discoverability\n\nMotherDuck has URL-based sharing, where a user can get a share URL and pass it onto another user for them to query. Now, we\u2019re excited that org-level sharing and discoverability have been added to MotherDuck to make sharing even easier. You simply click the ellipses after hovering over a database in the UI and choosing \u201cShare.\u201d\n\n![alt_text](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fcreate_share_menu_b4f20ed2ec.jpg&w=3840&q=75)\n\nNext you can choose what level of Access to the data you want to enable \u2013 whether anyone with the share link (including folks outside your Organization), or restricted to folks inside the organization with the share link.\n\n![alt_text](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fcreate_share_dialog_c94c5309ae.jpg&w=3840&q=75)\n\nLastly, you can select whether the shared data is discoverable by other users in the organization and will exist under the \u201cShared with me\u201d section in the MotherDuck UI left navigation \\[see screenshot above\\].\n\nNow all the users in your MotherDuck organization can analyze data, build machine learning models and more with the same shared dataset.\n\n## What Collaboration Features are Important to You?\n\nPlease let us know what collaboration features are important to you. You can either add suggestions to our [Canny feature tracker](https://motherduck.canny.io/), or start a conversation with the team on our [Community Slack](https://slack.motherduck.com/). We look forward to hearing from you!\n\n### TABLE OF CONTENTS\n\n[Auto-Join](https://motherduck.com/blog/new-collaboration-sharing-motherduck-data-warehouse-organization-auto-join/#auto-join)\n\n[Org-level Sharing and Discoverability](https://motherduck.com/blog/new-collaboration-sharing-motherduck-data-warehouse-organization-auto-join/#org-level-sharing-and-discoverability)\n\n[What Collaboration Features are Important to You?](https://motherduck.com/blog/new-collaboration-sharing-motherduck-data-warehouse-organization-auto-join/#what-collaboration-features-are-important-to-you)\n\nStart using MotherDuck now!\n\n[Try 21 Days Free](https://motherduck.com/get-started/)\n\nGet Started\n\n![blog subscription icon](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fblog-subscription-icon.67ccd5ae.png&w=828&q=75)\n\n### Subscribe to motherduck blog\n\nE-mail\n\nSubscribe to other MotherDuck Updates\n\nSubmit\n\n## PREVIOUS POSTS\n\n[![The Small Data Manifesto](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2F1200_x_628_Main_13fd1eb091.png&w=3840&q=75)](https://motherduck.com/blog/small-data-manifesto/)\n\n[2024/07/18 - Sheila Sitaram, MotherDuck team](https://motherduck.com/blog/small-data-manifesto/)\n\n### [The Small Data Manifesto](https://motherduck.com/blog/small-data-manifesto)\n\nRead through the key principles and ethos behind the Small Data movement. Small data and AI is more powerful than you think. Data and AI that was once \"Big\" can now be handled by a single machine.\n\n[![DuckDB Tutorial For Beginners](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fgetting_started_duckdb_thumbnail_70b197b1ab.png&w=3840&q=75)](https://motherduck.com/blog/duckdb-tutorial-for-beginners/)\n\n[2024/10/31 - Mehdi Ouazza, Ryan Boyd](https://motherduck.com/blog/duckdb-tutorial-for-beginners/)\n\n### [DuckDB Tutorial For Beginners](https://motherduck.com/blog/duckdb-tutorial-for-beginners)\n\nGet up to speed quickly with DuckDB, including installation, VSCode workflow integration and your first SQL analytics project.\n\n[View all](https://motherduck.com/blog/)\n\nAuthorization Response",
  [2m  â”‚[0m     "numLines": 97,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 97
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [94mâ”Œâ”€ ğŸ¤– AGENT MESSAGE[0m
  [94mâ”‚[0m Now let me search for more specific information about what a database is in MotherDuck and details about shares:
  [94mâ””â”€[0m

  [96mğŸ”§ TOOL:[0m Grep â†’ CREATE DATABASE|database.*MotherDuck

  [96mğŸ”§ TOOL:[0m Grep â†’ snapshot|read-only|attach.*share
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "mode": "files_with_matches",
  [2m  â”‚[0m   "filenames": [
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/why-did-we-raise-now-ceo-backstage-call.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/why-dont-data-producers-pay-attention-to-how-their-data-is-used-downstream.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/working-with-sql-with-your-favorite-editor-check-this.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/understanding-ducklake-a-table-format-with-a-modern-architecture.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/unfinished-business-re-inventing-modern-data-tools.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/using-sql-in-your-data-lake-with-duckdb-iceberg-dbt-and-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/what-can-postgres-learn-from-duckdb-pgconfdev-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/what-if-sql-queries-returned-results-instantly.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/whats-new-in-data-small-data-big-impact.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/where-data-science-meets-shrek-how-buzzfeed-uses-ai.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/speed-querying-stackoverflow-data-with-duckdb-ft-michael-hunger.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/sql-ide-safari-harlequin-in-your-terminal.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/stay-in-flow-with-motherducks-instant-sql.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/the-bad-the-good-and-the-ugly-navigating-the-new-waves-of-machine-learning-ft-adi-polak.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/the-death-of-big-data-and-why-its-time-to-think-small-jordan-tigani-ceo-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/the-power-of-wasm-for-analytics-duckdb-in-the-browser.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/the-surprising-birth-of-duckdb-ft-co-creator-hannes-muhleisen.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/no-sql-standard-for-7-years.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/pg_duckdb-ducking-awesome-analytics-in-postgres.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/pg_duckdb-postgres-analytics-just-got-faster-with-duckdb.md"
  [2m  â”‚[0m   ],
  [2m  â”‚[0m   "numFiles": 20,
  [2m  â”‚[0m   "appliedLimit": 20
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "mode": "files_with_matches",
  [2m  â”‚[0m   "filenames": [
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/understanding-ducklake-a-table-format-with-a-modern-architecture.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/bringing-duckdb-to-the-cloud-dual-execution-explained.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/data-teams.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/duckdb-users.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/pricing.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/what-is-a-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/app-developers.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/secure-startup-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/self-service-analytics-startups.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/fix-slow-bi-dashboards.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/ducklake-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/acid-transactions-sql.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/layers-multi-tenant-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/dominik-moritz.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/streaming-oracle-to-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/spark-ducklake-getting-started.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/separating-storage-compute-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/read-scaling-preview.md"
  [2m  â”‚[0m   ],
  [2m  â”‚[0m   "numFiles": 20,
  [2m  â”‚[0m   "appliedLimit": 20
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [96mğŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_33e1e0xk/.kurt/sources/motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md

  [96mğŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_33e1e0xk/.kurt/sources/motherduck.com/product/data-teams.md
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_33e1e0xk/.kurt/sources/motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md",
  [2m  â”‚[0m     "content": "---\ntitle: differential-storage-building-block-for-data-warehouse\ncontent_type: blog\nsource_url: https://motherduck.com/blog/differential-storage-building-block-for-data-warehouse\nindexed_at: '2025-11-25T19:58:02.042118'\ncontent_hash: 6d519f6ce6440660\nhas_narrative: true\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n[GO BACK TO BLOG](https://motherduck.com/blog/)\n\n# Differential Storage: A Key Building Block For A DuckDB-Based Data Warehouse\n\n2024/03/11 - 11 min read\n\nBY\n\n[Joseph Hwang](https://motherduck.com/authors/joseph-hwang/)\n\n[DuckDB](https://duckdb.org/) is portable, easy to use, and ducking fast! We at MotherDuck put our money where our beaks are and embarked on a [journey](https://notoriousplg.substack.com/p/nplg-10523-a-new-way-to-monetize) to build a new type of [serverless data warehouse](https://motherduck.com/product/) based on DuckDB. This means extending DuckDB beyond its design as an embedded, local, single-player analytics database, and turning it into a multi-tenant, collaborative, secure, and scalable service.\n\nToday we\u2019d like to talk about Differential Storage, a key infrastructure-level enabler of new capabilities and stronger semantics for MotherDuck users. Thanks to Differential Storage, features like efficient [data sharing](https://motherduck.com/docs/key-tasks/sharing-data/sharing-overview/) and [zero-copy clone](https://motherduck.com/docs/sql-reference/motherduck-sql-reference/create-database/) are now available in MotherDuck. Moreover, Differential Storage unlocks other features, like snapshots, branching and time travel which we\u2019ll release in the coming months.\n\n## The Need To Extend DuckDB\n\nFolks over at DuckDB Labs, the team behind DuckDB, have a strong [conviction](https://duckdb.org/why_duckdb) for what DuckDB is - a powerful in-process analytics database. Crucially, they have an equally strong conviction for what _vanilla_ DuckDB is not - a central collaborative data warehouse.\n\nWe decided at MotherDuck to implement a new copy-on-write storage solution named Differential Storage to solve a number of problems that arise when running DuckDB as a central collaborative data warehouse, such as:\n\n- DuckDB is not meant to scale to a single writer and multiple concurrent readers across many hosts. A DuckDB instance assumes that the underlying database file never changes unless it itself changes it. This is a challenging limitation when building a multi-user data warehouse which may want to support a higher degree of concurrency. Differential Storage enables us to efficiently materialize recent snapshots of a given database, allowing us to implement real-time read replicas of the database for concurrent readers.\n- DuckDB will randomly overwrite ranges of the database file. This precludes us from utilizing an object store (such as S3) as our underlying storage system and limits us to systems that support random, in-place modification (such as [Amazon EFS](https://aws.amazon.com/efs/)). If possible, we would strongly prefer utilizing an object store for the base layer of our storage system, for both scalability and cost reasons. Differential Storage allows us to represent the database state as a series of immutable snapshot layer files, which can be stored in an object store. This enables us to build a tiered storage system that offloads the bulk of the data to an object store.\n- DuckDB does not yet support a number of general collaboration and backup/restore features such as time travel (or backup/restore), database snapshotting, and database forking. Differential Storage allows us to implement these features in an extremely efficient and fast manner, without duplicating any data.\n\nThe rest of this blogpost will dive into the actual implementation of Differential Storage and how it enables us to solve these problems.\n\n## How Does Differential Storage Work?\n\nDifferential Storage is implemented as a FUSE driver ( [FUSE](https://en.wikipedia.org/wiki/Filesystem_in_Userspace) is a framework for implementing userspace file systems) that provides a file-system interface to DuckDB. Thus DuckDB interacts with files stored in Differential Storage just as it would with files on any other file system, this provides a very clear interface between the two systems. Because of this we were able to implement Differential Storage without modifying any DuckDB code.\n\nWith Differential Storage, databases in MotherDuck are now represented as an ordered sequence of \u201clayers.\u201d Each layer corresponds to a point in time (a checkpoint) and stores differences relative to the prior checkpoint.\u00a0 Since each layer stores differences between that checkpoint and prior layers, we call this system \u201cDifferential Storage.\u201d\n\nDifferential Storage allows us to store many point-in-time versions of a database, without needing to duplicate the data that those versions have in common. That same capability makes it possible to efficiently store many copies (or clones, forks, branches, whatever term you like) of a database. This by itself gives us a coarse implementation of time-travel (at checkpoint granularity), where we can instantly re-materialize a database at the point of any prior checkpoint.\n\nBut we can do even better by exposing per-commit granularity snapshots of the database. We provide this full-fidelity time-travel by also keeping a redo-log of the commits that occurred between checkpoints, which can be applied to the corresponding base snapshot to reach the target point-in-time.\n\nBefore we deep dive into the different request flows for Differential Storage (read, write, fork, etc.) - it would be helpful to define some key concepts:\n\n- **Database:** A single DuckDB database. DuckDB currently stores the entire database in a single file.\n- **Database File:** The file used by DuckDB to store the contents of a database.\n- **WAL File:** The file used by DuckDB to track new commits to a database. These commits may have not been applied to the database file yet. This happens on checkpoint.\n- **Snapshot:** The state of a Database at some point in time. Today Differential Storage generates snapshots at each DuckDB checkpoint. A snapshot is composed of a sequence of snapshot layers.\n- **Snapshot layer**: Stores the new data written between checkpoints.\n- **Active snapshot layer file:** The append-only file used by Differential Storage to store the new data being written to the logical Database File. This file will become the newest snapshot layer on checkpoint.\n\nIn the following diagram - you can see the logical database file spanning some range. The logical database file is the file that DuckDB sees and interacts with. Note that the logical database file does not correspond to an actual single, physical file, but is instead composed of a sequence of snapshot layers (from 4 -> 1), as well as an active snapshot layer representing the set of writes that have occurred since the last checkpoint.\n\nDifferential Storage will load the current snapshot and the corresponding sequence of snapshot layer metadata for a given database before it begins performing read/write operations on it. The database snapshot and snapshot layer metadata is persisted in a separate OLTP database system.\n\n![im01](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fdiff01_1292257937.png&w=3840&q=75)\n\nThe following sections will trace through how Differential Storage performs some common operations: read, write, checkpoint, snapshot, and fork.\n\n### Read\n\nWhen DuckDB attempts to read some range of bytes from the logical database file, Differential Storage will split up the total read range into subranges and loop through them. For each subrange, Differential Storage will find and read from the newest snapshot layer (starting from the active snapshot layer) that contains the sub-range. It\u2019s important to use the newest snapshot layer, because this layer represents the most recent bytes written to the logical database file for that given subrange.\n\nIn the following diagram, we see that the read for range \\[start, end\\] ends up being split into 3 separate reads across snapshot layers 3, 2, and 4.\n\n![im2](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fdiff02_b096353512.png&w=3840&q=75)\n\n### Write\n\nWhen DucKDB writes data to a random offset in the database file, Differential Storage appends the data to the end of the active snapshot layer file. Differential Storage writes in an append-only fashion so that the generated snapshot layer files are contiguous. Also by relying only on appends, we open the possibility to switching to an append-only storage system in the future. But because DuckDB writes to random offsets in the database file, Differential Storage must actively track of the mapping between the offset of writes into the logical database file -> their offsets into the physical active snapshot layer file.\n\nThis mapping logic is demonstrated by the following diagram. In this example, DuckDB has written the following byte ranges in the following order since the last checkpoint:\n\n- Range 1: 200 bytes from \\[400, 600\\]\n- Range 2: 100 bytes from \\[0, 100\\]\n- Range 3: 300 bytes from \\[1000, 1300\\]\n\nThese bytes are appended to the active snapshot layer file in the order in which they occur:\n\n- Range 1: 200 bytes from \\[0, 200\\]\n- Range 2: 100 bytes from \\[200, 300\\]\n- Range 3: 300 bytes from \\[300, 600\\]\n\nNow if DuckDB attempts to write 50 bytes to the database file from range \\[575, 625\\]:\n\n1. Differential Storage sees a write request of 50 bytes from \\[575, 625\\]\n2. Differential Storage appends the 50 bytes to the end of the active snapshot layer file at range \\[600, 650\\]\n3. Differential tracks that the logical database file byte range \\[575, 625\\] is mapped to the byte range \\[600, 650\\] on the physical active snapshot layer file\n\n![im5](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fdiff05_f99683177b.png&w=3840&q=75)\n\n### Checkpoint\n\nA DuckDB checkpoint will trigger Differential Storage to perform a snapshot. A DuckDB checkpoint will apply all commits recorded in the WAL to the database file. This means that once a checkpoint completes, DuckDB can load a database from just the current database file without having to access the WAL to perform WAL replay.\n\nTo perform a snapshot, Differential Storage has to upgrade the current active snapshot layer to become the newest snapshot layer. Differential Storage does this by transactionally recording the newly upgraded snapshot layer and snapshot (containing this new snapshot layer), and updating the database to point at this new snapshot. Once this is complete, Differential Storage will open a new active snapshot layer file and WAL file for accepting new writes.\n\n![im1](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimage1_23b42bd0c0.png&w=3840&q=75)\n\n### Snapshot\n\nBecause all the previous snapshot layers are stored, it is an inexpensive metadata-only operation to materialize previous snapshots, which are simply subsequences of the current snapshot\u2019s snapshot layers. The following diagram demonstrates how Differential Storage can easily time-travel to the state of the database file two snapshots ago by loading a snapshot composed of layers 3 -> 1.\n\n![im3](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fdiff03_58830ced0a.png&w=3840&q=75)\n\n### Fork\n\nNow that we have the ability to easily materialize a fixed snapshot of the current database by selecting a subsequence of the snapshot layers, we can implement \u201cforking\u201d a database by applying a different set of changes (represented as snapshot layers) on top of one of its previous snapshots. The following diagram demonstrates how we can implement database forking (CREATE DATABASE Y FROM X) without performing any data copies.\n\n![im4](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fdiff04_a965346006.png&w=3840&q=75)\n\n## Enabling New Capabilities\n\nThe primary property of Differential Storage that enables a number of new features and optimizations is that past snapshot layer files (and thus snapshots) are immutable. Some of the most important new features and capabilities are:\n\n- Zero-copy snapshots and forks\n- Time travel\n- Data tiering\n- Improved cacheability\n\n#### Zero-Copy Snapshots and Forks\n\nStarting today, zero-copy snapshots and forks are available to all users of MotherDuck. Operations `CREATE DATABASE <name> FROM <name>` and `CREATE SHARE <share> FROM <database>` are now metadata-only operations, creating zero-copy forks of the source databases.\n\nIn coming months we will be releasing a complete suite of git-style operations on databases, such as BRANCH, RESYNC, COMMIT, DIFF, and ROLLBACK.\n\n#### Time Travel\n\nAs previously mentioned in this blogpost, Differential Storage enables MotherDuck to easily materialize previous snapshots of a database. This capability will enable MotherDuck to provide powerful time-travel and backup/restore capabilities in a fast and inexpensive manner. Stay tuned, as time travel features are on MotherDuck\u2019s near-term roadmap!\n\n#### Improved Cacheability\n\nBecause snapshot layer files are immutable it becomes quite easy to cache snapshot files. This drastically improves the efficiency of database sharing and opens the door for a number of performance and efficiency optimizations.\n\n#### Data Tiering\n\nToday MotherDuck initially writes the active snapshot layer files to EFS. But because snapshot and WAL files become immutable post-snapshot, it is possible to swap them out to a cheaper object store (such as S3) post-snapshot. This setup results in EFS acting as a fast, SSD-based write cache in front of S3. This provides MotherDuck the ability to quickly commit new writes to EFS, while batching together larger amounts of data for writing to S3.\n\n## Conclusion\n\nMotherDuck has implemented a new storage solution, Differential Storage, that solves a number of challenges of running DuckDB as a central collaborative data warehouse, around concurrency, performance, scalability, and unlocking new user capabilities for both collaboration and backup/restore.\n\nWe just rolled out this feature last week on MotherDuck - so we encourage you to try out our new [zero-copy clone capability](https://motherduck.com/docs/sql-reference/motherduck-sql-reference/create-database/)! We will continue rolling out exciting new features (as mentioned above) in the near future!\n\n## Start Quacking\n\nMotherDuck is on a mission to make analytics Ducking awesome for every kind of user:\n\n- If you\u2019re using DuckDB currently, just run `attach md:`, and your DuckDB instance suddenly becomes MotherDuck-supercharged.\n- If you\u2019re a data enthusiast, check out MotherDuck\u2019s Web UI with breakthrough features like [FixIt](https://motherduck.com/blog/introducing-fixit-ai-sql-error-fixer/) and [Column Explorer](https://motherduck.com/blog/introducing-column-explorer/) delighting and simplifying long-standing workflow problems.\n- If you\u2019re an application developer, there is no better way to build data applications than with MotherDuck!\n\nCome [try our product for free](https://motherduck.com/), join [our Slack](https://slack.motherduck.com/) for a chat, or [shoot us a note](mailto:info@motherduck.com)!\n\n### TABLE OF CONTENTS\n\n[The Need To Extend DuckDB](https://motherduck.com/blog/differential-storage-building-block-for-data-warehouse/#the-need-to-extend-duckdb)\n\n[How Does Differential Storage Work?](https://motherduck.com/blog/differential-storage-building-block-for-data-warehouse/#how-does-differential-storage-work)\n\n[Enabling New Capabilities](https://motherduck.com/blog/differential-storage-building-block-for-data-warehouse/#enabling-new-capabilities)\n\n[Conclusion](https://motherduck.com/blog/differential-storage-building-block-for-data-warehouse/#conclusion)\n\n[Start Quacking](https://motherduck.com/blog/differential-storage-building-block-for-data-warehouse/#start-quacking)\n\nStart using MotherDuck now!\n\n[Try 21 Days Free](https://motherduck.com/get-started/)\n\nGet Started\n\n![blog subscription icon](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fblog-subscription-icon.67ccd5ae.png&w=828&q=75)\n\n### Subscribe to motherduck blog\n\nE-mail\n\nSubscribe to other MotherDuck Updates\n\nSubmit\n\n## PREVIOUS POSTS\n\n[![This Month in the DuckDB Ecosystem: February 2024](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Ffebruary_2024_ed8035295a.jpg&w=3840&q=75)](https://motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024/)\n\n[2024/03/01 - Ryan Boyd](https://motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024/)\n\n### [This Month in the DuckDB Ecosystem: February 2024](https://motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024)\n\nDuckDB Monthly: Featuring DuckDB 0.10.0, Christophe Oudar, new (free) book chapters, DuckCon videos and more!\n\n[![DuckDB Tutorial For Beginners](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fgetting_started_duckdb_thumbnail_70b197b1ab.png&w=3840&q=75)](https://motherduck.com/blog/duckdb-tutorial-for-beginners/)\n\n[2024/10/31 - Mehdi Ouazza, Ryan Boyd](https://motherduck.com/blog/duckdb-tutorial-for-beginners/)\n\n### [DuckDB Tutorial For Beginners](https://motherduck.com/blog/duckdb-tutorial-for-beginners)\n\nGet up to speed quickly with DuckDB, including installation, VSCode workflow integration and your first SQL analytics project.\n\n[View all](https://motherduck.com/blog/)\n\nAuthorization Response",
  [2m  â”‚[0m     "numLines": 212,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 212
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_33e1e0xk/.kurt/sources/motherduck.com/product/data-teams.md",
  [2m  â”‚[0m     "content": "---\ntitle: data-teams\ncontent_type: event\nsource_url: https://motherduck.com/product/data-teams/\nindexed_at: '2025-11-25T20:15:54.686252'\ncontent_hash: 4d65f51b153fa81e\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n# The data warehouse that helps you fly faster\n\nDual execution with local processing and cloud scale\n\n[Get Started](https://app.motherduck.com/?auth_flow=signup)\n\nLEARN MORE\n\n![YouTube video preview](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fproduct-hero-thumbnail.5d94bd17.png&w=3840&q=75)\n\nWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuck\n\n## Give power back to analysts\n\nSay goodbye to competing for central resources and knocking elbows with your teammates and their huge transformation jobs. With the efficiency of DuckDB, the data warehouse is finally personal, with user-level configuration and plenty of room to stretch your wings.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fown-compute-duckling.21ec2aa8.png&w=3840&q=75)\n\n### Each user gets their own compute instance \u201cduckling\u201d\n\nMotherDuck\u2019s per-user tenancy model enables teams to configure each org member individually. By default, each user in an Organization, or team, has their own dedicated, serverless isolated runtime. CPU visibility is provided per-user for simple, straightforward cost attribution and usage auditing.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpush-work-down.8973aec7.png&w=3840&q=75)\n\n### Push work down to the client\n\nMotherDuck turns users\u2019 laptops into local, easy-to-use execution nodes. DuckDB\u2019s unique portability enables teams to work locally and in the cloud with the same database. Since queries process closer to where data is stored, local compute is saved for analytical processing.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsticky-give-power-to-analysts.bf614167.png&w=1920&q=75)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsticky-give-power-to-analysts.bf614167.png&w=1920&q=75)\n\n## Boost productivity\n\nMotherDuck\u2019s features and UI are designed with data teams in mind. From taking in a birds\u2019-eye view of your data with Column Explorer, to writing SQL queries with FixIt, our notebook-like interface ensures your data explorations are smooth sailing, and we\u2019re constantly making improvements to keep you in the flow.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fui-tooling-with-ai.122fe6da.png&w=3840&q=75)\n\n### AI-enabled UI and workflows\n\nAs the primary work surface for many analysts, our mission is to make MotherDuck\u2019s UI your preferred place to quickly hone in on the data that matters. Stay focused on getting answers quickly and editing complex SQL queries auto-magically with [FixIt](https://motherduck.com/blog/introducing-fixit-ai-sql-error-fixer/). Alternatively, use the [Column Explorer](https://motherduck.com/blog/introducing-column-explorer/)\u2019s automated sparklines and summary stats to hone your analysis. Once added to your data toolkit, we think you\u2019ll take to it like a duck to water.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsql-and-python-support.ffedea07.png&w=3840&q=75)\n\n### Versatile SQL and Python Support\n\nMotherDuck builds on DuckDB\u2019s portable nature and allows you to integrate it directly into your data analysis workflows. With comprehensive support for enhanced and traditional SQL, users do not have to compromise on query readability, even in a Python environment. You can even run Python scripts and Jupyter notebooks or transfer data between DuckDB and pandas dataframes. For additional flexibility, DuckDB also has a dataframe-style API, giving SQL and Python users something to quack about.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fmodern-duck-stack.db3b122e.png&w=3840&q=75)\n\n### Backed by the modern duck stack\n\nMotherDuck complements and [integrates with your existing data stack](https://www.motherduck.com/ecosystem). Thanks to DuckDB\u2019s momentum, our flock of partners is ready to ensure your analytics workflows take flight with local and remote queries. Many of our partners already support DuckDB, and some even use it in their core product as a cache or batch processing engine. For DuckDB users, getting started is as easy as executing `\u2018.open md:\u2019` in the CLI.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsticky-boost-productivity.62e709b6.png&w=1920&q=75)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsticky-boost-productivity.62e709b6.png&w=1920&q=75)\n\n## MotherDuck UI\n\nSee it in action!\n\n![MotherDuck UI Video Preview](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fmotherduck-ui-video-thumbnail.83e89e71.png&w=3840&q=75)\n\n### Query, Upload, share\n\nJoin MotherDuck Co-founder, Ryan Boyd, for a tour of the MotherDuck UI and see how you can:\n\n- Query data from the public\\_data share\n- Get a bird\u2019s eye view of your data with the [Column Explorer](https://motherduck.com/blog/introducing-column-explorer/), and see how result sets are stored in DuckDB running in the browser to enable faster filtering and pivoting\n- Upload data from the local machine to MotherDuck\n- Write basic analytic queries and use [FixIt](https://motherduck.com/blog/introducing-fixit-ai-sql-error-fixer/) to catch SQL syntax errors\n- Share uploaded data with colleagues\n\n## Not just for small data\n\nMotherDuck takes advantage of DuckDB\u2019s portable, embeddable architecture to deliver analytics virtually anywhere. While DuckDB is best known for its efficiency and suitability for small datasets and in-memory processing, it is powerful enough to efficiently handle a wide range of data sizes and types. Customers are using MotherDuck with many terabytes of data to streamline their workflow and maintain high performance.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fefficient-but-not-lightweight.96773547.png&w=3840&q=75)\n\n### DuckDB\u2019s feather-light Efficiency Punches above its weight\n\nMotherDuck is built on DuckDB\u2019s highly performant architecture, designed for analytical workloads where low latency query performance is crucial. Data is stored in a columnar, vectorized format that streamlines query execution and uses CPU and memory more efficiently for analytics than any transactional database.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Funique-architecture.37f69384.png&w=3840&q=75)\n\n### Unique architecture handles large scale\n\nYour laptop isn\u2019t just a dumb terminal. It\u2019s as fast, or faster, than a state-of-the-art cloud data warehouse. MotherDuck\u2019s unique architecture takes advantage of this untapped and rapidly improving processing power at your fingertips with a [dual execution query engine](https://motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud/). By making full use of advances in hardware and network speeds to reclaim unused compute on users\u2019 local machines, MotherDuck routes each stage of query processing to the optimal location across your local machine, the cloud, or by splitting a single query across both where needed before combining and returning end results to the user.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsticky-not-just-small-data.aee42ee7.png&w=1920&q=75)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsticky-not-just-small-data.aee42ee7.png&w=1920&q=75)\n\n## Features\n\n[![Cloud database storage feature](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ffeature-cloud.3e9c0a0a.png&w=640&q=75)\\\\\n**Cloud database storage** \\\\\nManage your DuckDB database catalog in the cloud for easy scaling and collaboration.\\\\\n\\\\\nMore Details](https://motherduck.com/product/data-teams/cloud-database-storage/)\n\n[![SQL analytics engine feature](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ffeature-analytics.f04308e0.png&w=640&q=75)\\\\\n**SQL analytics engine** \\\\\nEfficiently run the same SQL queries on data stored locally, in MotherDuck or in your data lake.\\\\\n\\\\\nMore Details](https://motherduck.com/product/data-teams/sql-analytics-engine/)\n\n[![Simplified database sharing feature](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ffeature-db.11e966ef.png&w=640&q=75)\\\\\n**Simplified database sharing** \\\\\nCreate a shareable snapshot of your data, which your colleagues can easily attach and query in MotherDuck.\\\\\n\\\\\nMore Details](https://motherduck.com/product/data-teams/simplified-database-sharing/)\n\n[![Dual query execution feature](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ffeature-query.28419698.png&w=640&q=75)\\\\\n**Dual query execution** \\\\\nUse idle compute on your laptop in concert with the cloud to increase speed and lower cost.\\\\\n\\\\\nMore Details](https://motherduck.com/product/data-teams/dual-query-execution/)\n\n[![Notebook-like UI feature](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ffeature-ui.c08b01e4.png&w=1080&q=75)\\\\\n**Notebook-like UI** \\\\\nUse the web to browse the data catalog, write SQL, filter and sort results and share data.\\\\\n\\\\\nMore Details](https://motherduck.com/product/data-teams/notebook-like-ui/)\n\n[![Strong DuckDB ecosystem feature](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ffeature-ecosystem.0ab95f7c.png&w=640&q=75)\\\\\n**Strong DuckDB ecosystem** \\\\\nUse with 25+ tools in the modern data stack for import, orchestration and business intelligence.\\\\\n\\\\\nMore Details](https://motherduck.com/product/data-teams/strong-duckdb-ecosystem/)\n\n## Architecture\n\nManaged DuckDB-in-the-cloud\n\n## Ducking simple cloud data warehouse pricing\n\nBlazing fast analytics without flyaway costs\n\n[Learn more](https://motherduck.com/product/pricing/)\n\n## Ecosystem\n\nModern Duck Stack\n\n### CLOUD DATA WAREHOUSE\n\n### Sources\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpostgres-sql.d737f4f5.png&w=750&q=75)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Famazon-s3.72386dfc.png&w=640&q=75)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsalesforce.35d52b31.png&w=384&q=75)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fstripe.2160e881.png&w=384&q=75)\n\n[**Business Intelligence**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ftableau.0ec523e2.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpower-bi.f3563826.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fomni.cb7aa381.png&w=384&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fmetabase.5f8fe44e.png&w=640&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Business+Intelligence) [**Ingestion**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ffivetran.26f3817d.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fairbyte.8371d2f0.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Festuary.babad369.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlthub.e9892b97.png&w=384&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Ingestion) [**Data Science & AI**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fhex.275dad7d.png&w=256&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fjupyter.2a6af3de.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fcolab.30ab10af.png&w=384&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fmarimo.b699c73d.png&w=640&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Data+Science+%26+AI) [**Reverse ETL**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fcensus.352f1d69.png&w=640&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Reverse+ETL) [**Transformation**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdbt.fd2184d1.png&w=384&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ftobiko.d0e3d1e5.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsql-mesh.6fceb012.png&w=640&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Transformation) [**Dev Tools**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdatagrip.f48eba23.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpuppy-graph.848400c6.png&w=750&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdagster.e1970a7c.png&w=640&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Dev+Tools)\n\n[**Orchestration**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fairflow.7f70081a.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdagster.e1970a7c.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fprefect.fd6371b3.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fkestra.aa10acfc.png&w=640&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Orchestration)\n\n[**Data Quality**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fmonte-carlo.2143f962.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsecoda.9b7e86fb.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsoda.59e5aa02.png&w=384&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fgreat-expectations.c544f1ef.png&w=640&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Data+Quality)\n\n## Case Studies\n\nBringing MotherDuck into our data stack has been a game changer. We're reducing friction and supercharging our dev and ops experience by leveraging the DuckDB interoperability across local and cloud.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\n![Ravi Chandra's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fravi_chandra_photo_7db3a4c457.jpg&w=3840&q=75)\n\nRavi Chandra\n\nCTO at Dexibit\n\nBringing MotherDuck into our data stack has been a game changer. We're reducing friction and supercharging our dev and ops experience by leveraging the DuckDB interoperability across local and cloud.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\nInstant SQL in MotherDuck will save me the misery of having to try and wrangle SQL in my BI tool where iteration speed can be very slow. This lets me get the data right earlier in the process and with faster feedback than waiting for a chart to render, or having to clear an analytics cache.\n\n[DashFuel](https://www.getdashfuel.com/)\n\n![Mike McClannahan's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fmike_e96491a8eb.jpeg&w=3840&q=75)\n\nMike McClannahan\n\nCTO, DashFuel\n\nInstant SQL in MotherDuck will save me the misery of having to try and wrangle SQL in my BI tool where iteration speed can be very slow. This lets me get the data right earlier in the process and with faster feedback than waiting for a chart to render, or having to clear an analytics cache.\n\n[DashFuel](https://www.getdashfuel.com/)\n\nMotherDuck is the GOAT\n\n[READ MORE](https://motherduck.com/case-studies/reflex-careers-gig-economy-retail/)\n\n![Nate Hamm's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimage_15820c5f78.png&w=3840&q=75)\n\nNate Hamm\n\nSr. Software Developer at Reflex\n\nMotherDuck is the GOAT\n\n[READ MORE](https://motherduck.com/case-studies/reflex-careers-gig-economy-retail/)\n\nThe histograms in the MotherDuck UI speed up my workflow a ton because I don't have to aggregate a bunch of stuff to verify my data, I can just do a SELECT \\* and look at the histograms even if I'm querying 10M rows.\n\n[READ MORE](https://motherduck.com/case-studies/gardyn/)\n\n![Rob Teeuwen's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2F1689248039646_d0c68f49b7.jpeg&w=3840&q=75)\n\nRob Teeuwen\n\nData Scientist at Gardyn\n\nThe histograms in the MotherDuck UI speed up my workflow a ton because I don't have to aggregate a bunch of stuff to verify my data, I can just do a SELECT \\* and look at the histograms even if I'm querying 10M rows.\n\n[READ MORE](https://motherduck.com/case-studies/gardyn/)\n\nMotherDuck\u2019s integration with Tableau Cloud unlocks familiar Business Intelligence at the speed of DuckDB, supercharged by MotherDuck\u2019s powerful cloud technology.\n\n[READ MORE](https://motherduck.com/case-studies/dosomething-non-profit-tco-cost-savings/)\n\n![Dave Crusoe's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2F1515814825678_e2e8b2e5e7.jpeg&w=3840&q=75)\n\nDave Crusoe\n\nVP of Product & Engineering at DoSomething\n\nMotherDuck\u2019s integration with Tableau Cloud unlocks familiar Business Intelligence at the speed of DuckDB, supercharged by MotherDuck\u2019s powerful cloud technology.\n\n[READ MORE](https://motherduck.com/case-studies/dosomething-non-profit-tco-cost-savings/)\n\nMotherDuck has allowed us to build a state-of-the-art data warehouse with limited resources, enabling high data quality at a minimal cost. Our data warehouse has a < 2-minute latency, and our teams love the near real-time updates to customer behavior.\n\n[THENA](https://www.thena.ai/)\n\n![Unmukt Raizada's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2FUnmukt_549d410ae2.jpeg&w=3840&q=75)\n\nUnmukt Raizada\n\nCo-founder at Thena\n\nMotherDuck has allowed us to build a state-of-the-art data warehouse with limited resources, enabling high data quality at a minimal cost. Our data warehouse has a < 2-minute latency, and our teams love the near real-time updates to customer behavior.\n\n[THENA](https://www.thena.ai/)\n\nMotherDuck proving once again they are not constrained by what is easy or common. Instant SQL will not only enable complex query construction for those who find the task daunting (everyone?), it'll help past me communicate with future me.\n\n[DashFuel](https://www.getdashfuel.com/)\n\n![SJ Browne's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fsj_contemplating_6411ae5dcf.jpg&w=3840&q=75)\n\nSJ Browne\n\nSoftware Engineer at DashFuel\n\nMotherDuck proving once again they are not constrained by what is easy or common. Instant SQL will not only enable complex query construction for those who find the task daunting (everyone?), it'll help past me communicate with future me.\n\n[DashFuel](https://www.getdashfuel.com/)\n\nMotherDuck with DuckDB was by far the fastest of the OLAP platforms we evaluated - both in the cloud and run on our developer's machines - bridging price and performance and greatly increasing productivity.\n\n[FINQORE](https://www.finqore.com/)\n\n![Jim O\u2019Neill's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fjim_oneil_photo_930c637f49.jpg&w=3840&q=75)\n\nJim O\u2019Neill\n\nCTO and Co-founder at FinQore\n\nMotherDuck with DuckDB was by far the fastest of the OLAP platforms we evaluated - both in the cloud and run on our developer's machines - bridging price and performance and greatly increasing productivity.\n\n[FINQORE](https://www.finqore.com/)\n\nMoving to MotherDuck, a billed by-the-second cloud offering is a no-brainer for us, considering the elegance and efficiency of a single node system compared to traditional OLAP solutions.\n\n[ATM.COM](https://atm.com/)\n\n![Nico Ritschel's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fnico_ritschel_photo_41ba132b33.jpg&w=3840&q=75)\n\nNico Ritschel\n\nDirector of Engineering at atm.com\n\nMoving to MotherDuck, a billed by-the-second cloud offering is a no-brainer for us, considering the elegance and efficiency of a single node system compared to traditional OLAP solutions.\n\n[ATM.COM](https://atm.com/)\n\nWhen I realized that MotherDuck would be a lot more affordable, with similar performance to the more prominent players, there was some skepticism from executives because they didn't believe it was possible for MotherDuck to be better and cheaper than MySQL\u2014but it is.\n\n[READ MORE](https://motherduck.com/case-studies/gardyn/)\n\n![Rob Teeuwen's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2F1689248039646_d0c68f49b7.jpeg&w=3840&q=75)\n\nRob Teeuwen\n\nData Scientist at Gardyn\n\nWhen I realized that MotherDuck would be a lot more affordable, with similar performance to the more prominent players, there was some skepticism from executives because they didn't believe it was possible for MotherDuck to be better and cheaper than MySQL\u2014but it is.\n\n[READ MORE](https://motherduck.com/case-studies/gardyn/)\n\nI just onboarded some non-technical users to MotherDuck, and I can\u2019t imagine having done so in a different system with this level of ease and lack of intimidation. Between the \u2018Filter\u2019 button, Column Explorer, and the FROM syntax - they feel empowered to answer many of their own questions! \ud83d\ude42\n\n[READ MORE](https://motherduck.com/blog/dosomething-motherduck-data-warehouse-ROI/)\n\n![Sahil Gupta's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fsahil_portrait_2b3bc22414.png&w=3840&q=75)\n\nSahil Gupta\n\nSenior Data Engineer at dosomething.org\n\nI just onboarded some non-technical users to MotherDuck, and I can\u2019t imagine having done so in a different system with this level of ease and lack of intimidation. Between the \u2018Filter\u2019 button, Column Explorer, and the FROM syntax - they feel empowered to answer many of their own questions! \ud83d\ude42\n\n[READ MORE](https://motherduck.com/blog/dosomething-motherduck-data-warehouse-ROI/)\n\nMotherDuck is insanely performant, and there\u2019s no infrastructure to manage. The cost of experimentation is incredibly low \u2014 which means we can afford to ask more questions and build more features, faster.\n\n[READ MORE](https://motherduck.com/case-studies/kultura-capital/)\n\n![Kristov Paulus's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2FScreenshot_2025_05_08_at_10_29_30_AM_ac663c67b9.png&w=3840&q=75)\n\nKristov Paulus\n\nFounder, Chief Investment Officer at Kultura Capital\n\nMotherDuck is insanely performant, and there\u2019s no infrastructure to manage. The cost of experimentation is incredibly low \u2014 which means we can afford to ask more questions and build more features, faster.\n\n[READ MORE](https://motherduck.com/case-studies/kultura-capital/)\n\nBringing MotherDuck into our data stack has been a game changer. We're reducing friction and supercharging our dev and ops experience by leveraging the DuckDB interoperability across local and cloud.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\n![Ravi Chandra's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fravi_chandra_photo_7db3a4c457.jpg&w=3840&q=75)\n\nRavi Chandra\n\nCTO at Dexibit\n\nBringing MotherDuck into our data stack has been a game changer. We're reducing friction and supercharging our dev and ops experience by leveraging the DuckDB interoperability across local and cloud.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\nInstant SQL in MotherDuck will save me the misery of having to try and wrangle SQL in my BI tool where iteration speed can be very slow. This lets me get the data right earlier in the process and with faster feedback than waiting for a chart to render, or having to clear an analytics cache.\n\n[DashFuel](https://www.getdashfuel.com/)\n\n![Mike McClannahan's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fmike_e96491a8eb.jpeg&w=3840&q=75)\n\nMike McClannahan\n\nCTO, DashFuel\n\nInstant SQL in MotherDuck will save me the misery of having to try and wrangle SQL in my BI tool where iteration speed can be very slow. This lets me get the data right earlier in the process and with faster feedback than waiting for a chart to render, or having to clear an analytics cache.\n\n[DashFuel](https://www.getdashfuel.com/)\n\nMotherDuck is the GOAT\n\n[READ MORE](https://motherduck.com/case-studies/reflex-careers-gig-economy-retail/)\n\n![Nate Hamm's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimage_15820c5f78.png&w=3840&q=75)\n\nNate Hamm\n\nSr. Software Developer at Reflex\n\nMotherDuck is the GOAT\n\n[READ MORE](https://motherduck.com/case-studies/reflex-careers-gig-economy-retail/)\n\nThe histograms in the MotherDuck UI speed up my workflow a ton because I don't have to aggregate a bunch of stuff to verify my data, I can just do a SELECT \\* and look at the histograms even if I'm querying 10M rows.\n\n[READ MORE](https://motherduck.com/case-studies/gardyn/)\n\n![Rob Teeuwen's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2F1689248039646_d0c68f49b7.jpeg&w=3840&q=75)\n\nRob Teeuwen\n\nData Scientist at Gardyn\n\nThe histograms in the MotherDuck UI speed up my workflow a ton because I don't have to aggregate a bunch of stuff to verify my data, I can just do a SELECT \\* and look at the histograms even if I'm querying 10M rows.\n\n[READ MORE](https://motherduck.com/case-studies/gardyn/)\n\nMotherDuck\u2019s integration with Tableau Cloud unlocks familiar Business Intelligence at the speed of DuckDB, supercharged by MotherDuck\u2019s powerful cloud technology.\n\n[READ MORE](https://motherduck.com/case-studies/dosomething-non-profit-tco-cost-savings/)\n\n![Dave Crusoe's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2F1515814825678_e2e8b2e5e7.jpeg&w=3840&q=75)\n\nDave Crusoe\n\nVP of Product & Engineering at DoSomething\n\nMotherDuck\u2019s integration with Tableau Cloud unlocks familiar Business Intelligence at the speed of DuckDB, supercharged by MotherDuck\u2019s powerful cloud technology.\n\n[READ MORE](https://motherduck.com/case-studies/dosomething-non-profit-tco-cost-savings/)\n\nMotherDuck has allowed us to build a state-of-the-art data warehouse with limited resources, enabling high data quality at a minimal cost. Our data warehouse has a < 2-minute latency, and our teams love the near real-time updates to customer behavior.\n\n[THENA](https://www.thena.ai/)\n\n![Unmukt Raizada's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2FUnmukt_549d410ae2.jpeg&w=3840&q=75)\n\nUnmukt Raizada\n\nCo-founder at Thena\n\nMotherDuck has allowed us to build a state-of-the-art data warehouse with limited resources, enabling high data quality at a minimal cost. Our data warehouse has a < 2-minute latency, and our teams love the near real-time updates to customer behavior.\n\n[THENA](https://www.thena.ai/)\n\nAuthorization Response",
  [2m  â”‚[0m     "numLines": 503,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 503
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [94mâ”Œâ”€ ğŸ¤– AGENT MESSAGE[0m
  [94mâ”‚[0m Let me search for more specific information about what a database is and how shares work:
  [94mâ””â”€[0m

  [96mğŸ”§ TOOL:[0m Glob â†’ **/*simplified*sharing*.md

  [96mğŸ”§ TOOL:[0m Grep â†’ database.*owned|owned.*database|CREATE DATABASE
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "mode": "files_with_matches",
  [2m  â”‚[0m   "filenames": [
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/duckdb-users.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/secure-startup-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/modern-data-warehouse-playbook.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/ducklake-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/spark-ducklake-getting-started.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/getting-started-gis-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/from-data-lake-to-lakehouse-duckdb-portable-catalog.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md"
  [2m  â”‚[0m   ],
  [2m  â”‚[0m   "numFiles": 10,
  [2m  â”‚[0m   "appliedLimit": 10
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "filenames": [],
  [2m  â”‚[0m   "durationMs": 630,
  [2m  â”‚[0m   "numFiles": 0,
  [2m  â”‚[0m   "truncated": false
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [96mğŸ”§ TOOL:[0m Glob â†’ **/product/*sharing*.md

  [96mğŸ”§ TOOL:[0m Grep â†’ attach.*share|share.*attach
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "filenames": [],
  [2m  â”‚[0m   "durationMs": 237,
  [2m  â”‚[0m   "numFiles": 0,
  [2m  â”‚[0m   "truncated": false
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "mode": "files_with_matches",
  [2m  â”‚[0m   "filenames": [
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/data-teams.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/duckdb-users.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/app-developers.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/dominik-moritz.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/search-using-duckdb-part-3.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/separating-storage-compute-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/read-scaling-preview.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/redshift-files-hunt-for-big-data.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/how-to-extract-analytics-from-bluesky.md"
  [2m  â”‚[0m   ],
  [2m  â”‚[0m   "numFiles": 10,
  [2m  â”‚[0m   "appliedLimit": 10
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [96mğŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_33e1e0xk/.kurt/sources/motherduck.com/product/duckdb-users.md
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_33e1e0xk/.kurt/sources/motherduck.com/product/duckdb-users.md",
  [2m  â”‚[0m     "content": "---\ntitle: duckdb-users\ncontent_type: product_page\nsource_url: https://motherduck.com/product/duckdb-users/\nindexed_at: '2025-11-25T20:15:52.565114'\ncontent_hash: dfb4ed9cd3383b9d\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n# local + Cloud analytics,  backed by the same database\n\nA duckdb-powered data warehouse for production grade analytics\n\n[Get Started](https://motherduck.com/get-started/)\n\nLEARN MORE\n\nWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuck\n\n## Transform Solo DuckDB Into a Collaborative Powerhouse\n\nDuckDB's in-process nature means your data stays trapped on your machine. MotherDuck eliminates this limitation with a simple \"md:\" prefix.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fshare-data-not-files.db8baefd.png&w=3840&q=75)\n\n### Share Data, Not Files\n\nNo more exporting files or managing S3 buckets to share your work. Create database shares with specific team members while maintaining the familiar DuckDB experience.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fmultiple-users-one-database.0b9d7dc7.png&w=3840&q=75)\n\n### Multiple Users, One Database\n\nEnable simultaneous access for Data Engineers, Analytics teams, and Scientists to the same datasets. Each user gets their own dedicated compute instance \u201cduckling\u201d for concurrent queries without conflicts.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsticky-bring-the-flock-together.be57c6e9.png&w=2048&q=75)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsticky-bring-the-flock-together.be57c6e9.png&w=2048&q=75)\n\n## Local Speed with Cloud-Scale Production Power\n\nEnjoy the best of both worlds with a seamless dev/prod workflow for your data. Develop locally for immediate feedback, then deploy identical workloads to the cloud with zero code changes.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Frapid-iteration-zero-cost.ff94f539.png&w=3840&q=75)\n\n### Rapid Iteration at Zero Cost\n\nExperiment locally with lightning-fast feedback cycles without spending a dime. When your solution is ready, your exact same queries work in the cloud by simply adding \"md:\" to your connection.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ftest-safely-deploy-confidently.ed329fbf.png&w=3840&q=75)\n\n### Test Safely, Deploy Confidently\n\nPrototype complex data transformations without risking expensive cloud resources. This local dev, cloud prod model ensures what works locally will perform at scale in production.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fship-data-solutions-faster.bdfdd521.png&w=3840&q=75)\n\n### Ship Data Solutions Faster\n\nEliminate the friction between development and deployment environments. Your team can innovate with quick local tests and push proven solutions to cloud production seamlessly.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsticky-scalable-node-architecture.91c200dd.png&w=1920&q=75)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsticky-scalable-node-architecture.91c200dd.png&w=1920&q=75)\n\n## Familiar Interface with Intelligent Superpowers\n\nMotherDuck maintains the DuckDB interface you love while adding thoughtful, AI-backed intelligent assistance. Experience enhanced productivity with features designed for SQL experts and business users.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fvisual-insights-at-a-glance.60ec6358.png&w=3840&q=75)\n\n### Visual Insights at a Glance\n\nBeautiful visualizations help you understand complex data patterns immediately. MotherDuck's design affordances make exploration intuitive while preserving the power of DuckDB's analytical capabilities.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fautomatic-error-correction.fe59afe0.png&w=3840&q=75)\n\n### Automatic Error Correction\n\n\"Fix It\" repairs common syntax errors with a single click, eliminating frustration from missing commas or quotes. This intelligent assistance ensures everyone on your team can work productively with SQL, regardless of expertise level.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fnatural-language-to-sql.72331bc3.png&w=3840&q=75)\n\n### Natural Language to SQL\n\nNever written SQL before? Non-technical team members can contribute with \"PROMPT QUERY\" turning plain English into correct SQL. This feature democratizes data access by removing the barrier of SQL syntax knowledge.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsticky-ergonomic-and-effortless.b3f51a46.png&w=3840&q=75)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsticky-ergonomic-and-effortless.b3f51a46.png&w=3840&q=75)\n\n## Features\n\n[![Cloud database storage feature](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ffeature-cloud.3e9c0a0a.png&w=640&q=75)\\\\\n**Cloud database storage** \\\\\nManage your DuckDB database catalog in the cloud for easy scaling and collaboration.\\\\\n\\\\\nMore Details](https://motherduck.com/product/duckdb-users/cloud-database-storage/)\n\n[![SQL analytics engine feature](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ffeature-analytics.f04308e0.png&w=640&q=75)\\\\\n**SQL analytics engine** \\\\\nEfficiently run the same SQL queries on data stored locally, in MotherDuck or in your data lake.\\\\\n\\\\\nMore Details](https://motherduck.com/product/duckdb-users/sql-analytics-engine/)\n\n[![Simplified database sharing feature](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ffeature-db.11e966ef.png&w=640&q=75)\\\\\n**Simplified database sharing** \\\\\nCreate a shareable snapshot of your data, which your colleagues can easily attach and query in MotherDuck.\\\\\n\\\\\nMore Details](https://motherduck.com/product/duckdb-users/simplified-database-sharing/)\n\n[![Dual query execution feature](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ffeature-query.28419698.png&w=640&q=75)\\\\\n**Dual query execution** \\\\\nUse idle compute on your laptop in concert with the cloud to increase speed and lower cost.\\\\\n\\\\\nMore Details](https://motherduck.com/product/duckdb-users/dual-query-execution/)\n\n[![Notebook-like UI feature](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ffeature-ui.c08b01e4.png&w=1080&q=75)\\\\\n**Notebook-like UI** \\\\\nUse the web to browse the data catalog, write SQL, filter and sort results and share data.\\\\\n\\\\\nMore Details](https://motherduck.com/product/duckdb-users/notebook-like-ui/)\n\n[![Strong DuckDB ecosystem feature](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ffeature-ecosystem.0ab95f7c.png&w=640&q=75)\\\\\n**Strong DuckDB ecosystem** \\\\\nUse with 25+ tools in the modern data stack for import, orchestration and business intelligence.\\\\\n\\\\\nMore Details](https://motherduck.com/product/duckdb-users/strong-duckdb-ecosystem/)\n\n## Architecture\n\nManaged DuckDB-in-the-cloud\n\n## Ecosystem\n\nModern Duck Stack\n\n### CLOUD DATA WAREHOUSE\n\n### Sources\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpostgres-sql.d737f4f5.png&w=750&q=75)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Famazon-s3.72386dfc.png&w=640&q=75)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsalesforce.35d52b31.png&w=384&q=75)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fstripe.2160e881.png&w=384&q=75)\n\n[**Business Intelligence**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ftableau.0ec523e2.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpower-bi.f3563826.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fomni.cb7aa381.png&w=384&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fmetabase.5f8fe44e.png&w=640&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Business+Intelligence) [**Ingestion**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ffivetran.26f3817d.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fairbyte.8371d2f0.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Festuary.babad369.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlthub.e9892b97.png&w=384&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Ingestion) [**Data Science & AI**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fhex.275dad7d.png&w=256&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fjupyter.2a6af3de.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fcolab.30ab10af.png&w=384&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fmarimo.b699c73d.png&w=640&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Data+Science+%26+AI) [**Reverse ETL**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fcensus.352f1d69.png&w=640&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Reverse+ETL) [**Transformation**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdbt.fd2184d1.png&w=384&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ftobiko.d0e3d1e5.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsql-mesh.6fceb012.png&w=640&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Transformation) [**Dev Tools**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdatagrip.f48eba23.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpuppy-graph.848400c6.png&w=750&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdagster.e1970a7c.png&w=640&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Dev+Tools)\n\n[**Orchestration**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fairflow.7f70081a.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdagster.e1970a7c.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fprefect.fd6371b3.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fkestra.aa10acfc.png&w=640&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Orchestration)\n\n[**Data Quality**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fmonte-carlo.2143f962.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsecoda.9b7e86fb.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsoda.59e5aa02.png&w=384&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fgreat-expectations.c544f1ef.png&w=640&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Data+Quality)\n\n## Case Studies\n\nMotherDuck\u2019s innovative approach to managing data and providing easy-to-use tooling has allowed us to expand our application use cases (e.g., getting data into the client's browser) and offer more value to our customers.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\n![Ravi Chandra's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fravi_chandra_photo_7db3a4c457.jpg&w=3840&q=75)\n\nRavi Chandra\n\nCTO at Dexibit\n\nMotherDuck\u2019s innovative approach to managing data and providing easy-to-use tooling has allowed us to expand our application use cases (e.g., getting data into the client's browser) and offer more value to our customers.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\nWe can create an instance per customer easily as opposed to Postgres, where it\u2019s a hassle to create and manage that many instances. We've now got these new levers for performance scaling because we can split and store the data and query efficiently as needed. If we need to handle a load spike or a huge amount of queries, we can spin up more ducklings on demand.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\n![Ravi Chandra's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fravi_chandra_photo_7db3a4c457.jpg&w=3840&q=75)\n\nRavi Chandra\n\nCTO at Dexibit\n\nWe can create an instance per customer easily as opposed to Postgres, where it\u2019s a hassle to create and manage that many instances. We've now got these new levers for performance scaling because we can split and store the data and query efficiently as needed. If we need to handle a load spike or a huge amount of queries, we can spin up more ducklings on demand.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\nOur data pipelines used to take eight hours. Now they're taking eight minutes, and I see a world where they take eight seconds. This is why we made the big bet on DuckDB and MotherDuck. It's only possible with DuckDB and MotherDuck.\n\n[READ MORE](https://motherduck.com/case-studies/finqore/)\n\n![Jim O\u2019Neill's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fjim_oneil_photo_930c637f49.jpg&w=3840&q=75)\n\nJim O\u2019Neill\n\nCo-founder and CTO at FinQore\n\nOur data pipelines used to take eight hours. Now they're taking eight minutes, and I see a world where they take eight seconds. This is why we made the big bet on DuckDB and MotherDuck. It's only possible with DuckDB and MotherDuck.\n\n[READ MORE](https://motherduck.com/case-studies/finqore/)\n\nWith MotherDuck, it only took an hour to get an app up and running, which was pretty cool. It uses 18 million rows of data, but once it\u2019s loaded, we have all this interactivity right on the website. And since it's all coming from MotherDuck, we can create a shareable snapshot of our data that others can attach to and query.\n\n[READ MORE](https://motherduck.com/case-studies/dominik-moritz/)\n\n![Dominik Moritz's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fdominik_berlin_f8a31170af.jpg&w=3840&q=75)\n\nDominik Moritz\n\nProfessor at Carnegie Mellon University\n\nWith MotherDuck, it only took an hour to get an app up and running, which was pretty cool. It uses 18 million rows of data, but once it\u2019s loaded, we have all this interactivity right on the website. And since it's all coming from MotherDuck, we can create a shareable snapshot of our data that others can attach to and query.\n\n[READ MORE](https://motherduck.com/case-studies/dominik-moritz/)\n\nMotherDuck\u2019s innovative approach to managing data and providing easy-to-use tooling has allowed us to expand our application use cases (e.g., getting data into the client's browser) and offer more value to our customers.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\n![Ravi Chandra's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fravi_chandra_photo_7db3a4c457.jpg&w=3840&q=75)\n\nRavi Chandra\n\nCTO at Dexibit\n\nMotherDuck\u2019s innovative approach to managing data and providing easy-to-use tooling has allowed us to expand our application use cases (e.g., getting data into the client's browser) and offer more value to our customers.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\nWe can create an instance per customer easily as opposed to Postgres, where it\u2019s a hassle to create and manage that many instances. We've now got these new levers for performance scaling because we can split and store the data and query efficiently as needed. If we need to handle a load spike or a huge amount of queries, we can spin up more ducklings on demand.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\n![Ravi Chandra's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fravi_chandra_photo_7db3a4c457.jpg&w=3840&q=75)\n\nRavi Chandra\n\nCTO at Dexibit\n\nWe can create an instance per customer easily as opposed to Postgres, where it\u2019s a hassle to create and manage that many instances. We've now got these new levers for performance scaling because we can split and store the data and query efficiently as needed. If we need to handle a load spike or a huge amount of queries, we can spin up more ducklings on demand.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\nOur data pipelines used to take eight hours. Now they're taking eight minutes, and I see a world where they take eight seconds. This is why we made the big bet on DuckDB and MotherDuck. It's only possible with DuckDB and MotherDuck.\n\n[READ MORE](https://motherduck.com/case-studies/finqore/)\n\n![Jim O\u2019Neill's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fjim_oneil_photo_930c637f49.jpg&w=3840&q=75)\n\nJim O\u2019Neill\n\nCo-founder and CTO at FinQore\n\nOur data pipelines used to take eight hours. Now they're taking eight minutes, and I see a world where they take eight seconds. This is why we made the big bet on DuckDB and MotherDuck. It's only possible with DuckDB and MotherDuck.\n\n[READ MORE](https://motherduck.com/case-studies/finqore/)\n\nWith MotherDuck, it only took an hour to get an app up and running, which was pretty cool. It uses 18 million rows of data, but once it\u2019s loaded, we have all this interactivity right on the website. And since it's all coming from MotherDuck, we can create a shareable snapshot of our data that others can attach to and query.\n\n[READ MORE](https://motherduck.com/case-studies/dominik-moritz/)\n\n![Dominik Moritz's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fdominik_berlin_f8a31170af.jpg&w=3840&q=75)\n\nDominik Moritz\n\nProfessor at Carnegie Mellon University\n\nWith MotherDuck, it only took an hour to get an app up and running, which was pretty cool. It uses 18 million rows of data, but once it\u2019s loaded, we have all this interactivity right on the website. And since it's all coming from MotherDuck, we can create a shareable snapshot of our data that others can attach to and query.\n\n[READ MORE](https://motherduck.com/case-studies/dominik-moritz/)\n\nMotherDuck\u2019s innovative approach to managing data and providing easy-to-use tooling has allowed us to expand our application use cases (e.g., getting data into the client's browser) and offer more value to our customers.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\n![Ravi Chandra's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fravi_chandra_photo_7db3a4c457.jpg&w=3840&q=75)\n\nRavi Chandra\n\nCTO at Dexibit\n\nMotherDuck\u2019s innovative approach to managing data and providing easy-to-use tooling has allowed us to expand our application use cases (e.g., getting data into the client's browser) and offer more value to our customers.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\nWe can create an instance per customer easily as opposed to Postgres, where it\u2019s a hassle to create and manage that many instances. We've now got these new levers for performance scaling because we can split and store the data and query efficiently as needed. If we need to handle a load spike or a huge amount of queries, we can spin up more ducklings on demand.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\n![Ravi Chandra's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fravi_chandra_photo_7db3a4c457.jpg&w=3840&q=75)\n\nRavi Chandra\n\nCTO at Dexibit\n\nWe can create an instance per customer easily as opposed to Postgres, where it\u2019s a hassle to create and manage that many instances. We've now got these new levers for performance scaling because we can split and store the data and query efficiently as needed. If we need to handle a load spike or a huge amount of queries, we can spin up more ducklings on demand.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\n## Get in Touch\n\nWe\u2019d love to learn more about what you\u2019re building. A Product Expert will fly right back to you with resources to help you take flight.\n\nFirst Name\n\nLast Name\n\nE-mail\n\nCompany\n\nLeave us a message.\n\nThis site is protected by reCAPTCHA and the Google [Privacy Policy](https://policies.google.com/privacy) and [Terms of Service](https://policies.google.com/terms) apply.\n\nSubmit\n\n![Duck looking up](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fduck-looking-up.1c763865.png&w=3840&q=75)\n\nAuthorization Response\n\nreCAPTCHA\n\nRecaptcha requires verification.\n\n[Privacy](https://www.google.com/intl/en/policies/privacy/) \\- [Terms](https://www.google.com/intl/en/policies/terms/)\n\nprotected by **reCAPTCHA**\n\n[Privacy](https://www.google.com/intl/en/policies/privacy/) \\- [Terms](https://www.google.com/intl/en/policies/terms/)",
  [2m  â”‚[0m     "numLines": 403,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 403
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [94mâ”Œâ”€ ğŸ¤– AGENT MESSAGE[0m
  [94mâ”‚[0m Now let me search for more specific information about creating and managing shares and databases:
  [94mâ””â”€[0m

  [96mğŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_33e1e0xk/.kurt/sources/motherduck.com/blog/csv-files-persist-duckdb-solution.md
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_33e1e0xk/.kurt/sources/motherduck.com/blog/csv-files-persist-duckdb-solution.md",
  [2m  â”‚[0m     "content": "---\ntitle: csv-files-persist-duckdb-solution\ncontent_type: blog\nsource_url: https://motherduck.com/blog/csv-files-persist-duckdb-solution\nindexed_at: '2025-11-25T19:57:13.232430'\ncontent_hash: 28f2997ebdb99804\nhas_code_examples: true\nhas_step_by_step: true\nhas_narrative: true\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n[GO BACK TO BLOG](https://motherduck.com/blog/)\n\n# Why CSV Files Won\u2019t Die and How DuckDB Conquers Them\n\n2025/02/04 - 9 min read\n\nBY\n\n[Mehdi Ouazza](https://motherduck.com/authors/mehdi-ouazza/)\n\nI've been working in the data field for a decade, across various companies, and one constant challenge that\u2019s almost unavoidable is dealing with CSV files.\n\nYes, there are far more efficient formats, such as [Parquet](https://motherduck.com/learn-more/why-choose-parquet-table-file-format/), which avoid schema nightmares thanks to their typing, but CSV files persist for many reasons:\n\n- They\u2019re easy to edit and read, requiring no dependencies\u2014just open the file.\n- They\u2019re universal: many services still exchange data in CSV format.\n- Want to download data from social media or your CRM? CSV.\n- Need transaction history from your bank? CSV.\n\nHowever, this simplicity comes with its own set of challenges, especially if you want to process CSVs without breaking pipelines or pulling your hair out.\n\nFortunately, DuckDB has an exceptional CSV parser. The team behind it invested heavily in building their own, and in this post, I\u2019ll show you a real-world example where I had to parse multiple CSV files. I\u2019ll also share some SQL tricks and demonstrate how smoothly everything worked using DuckDB and MotherDuck, resulting in a ready-to-query database.\n\nThe cherry on top? The final output is a database containing all Stack Overflow survey responses from the past seven years. Stick around if you\u2019re curious about extracting insights or querying the data yourself!\n\n## The biggest challenges when reading CSVs\n\nIn my opinion, there are four significant challenges when working with CSV files:\n\n1. **Schema Management**\n2. **Row-Level Errors**\n3. **Encoding Issues**\n\nThese challenges become even more complex when handling multiple CSVs that need to be read or joined to each other.\n\nLet\u2019s see how we address these issues with Stack Overflow survey data.\n\n## About the Dataset\n\nEach year, Stack Overflow publishes the results of their developer survey, including raw data in\u2014you guessed it\u2014CSV format. These files are available on their website: [https://survey.stackoverflow.co/](https://survey.stackoverflow.co/).\n\nHere\u2019s an example of how the dataset is organized:\n\n```css\nCopy code\n\n\u251c\u2500\u2500 raw\n\u2502   \u251c\u2500\u2500 2011 Stack Overflow Survey Results.csv\n\u2502   \u251c\u2500\u2500 2012 Stack Overflow Survey Results.csv\n\u2502   \u251c\u2500\u2500 2013 Stack Overflow Survey Responses.csv\n\u2502   \u251c\u2500\u2500 2014 Stack Overflow Survey Responses.csv\n\u2502   \u251c\u2500\u2500 2015 Stack Overflow Developer Survey Responses.csv\n\u2502   \u251c\u2500\u2500 2016 Stack Overflow Survey Results\n\u2502   \u2502   \u251c\u2500\u2500 2016 Stack Overflow Survey Responses.csv\n\u2502   \u2502   \u2514\u2500\u2500 READ_ME_-_The_Public_2016_Stack_Overflow_Developer_Survey_Results.txt\n\u2502   \u251c\u2500\u2500 stack-overflow-developer-survey-2017\n\u2502   \u2502   \u251c\u2500\u2500 DeveloperSurvey2017QuestionaireCleaned.pdf\n\u2502   \u2502   \u251c\u2500\u2500 README_2017.txt\n\u2502   \u2502   \u251c\u2500\u2500 survey_results_public.csv\n\u2502   \u2502   \u2514\u2500\u2500 survey_results_schema.csv\n\u2502   \u251c\u2500\u2500 stack-overflow-developer-survey-2018\n\u2502   \u2502   \u251c\u2500\u2500 Developer_Survey_Instrument_2018.pdf\n\u2502   \u2502   \u251c\u2500\u2500 README_2018.txt\n\u2502   \u2502   \u251c\u2500\u2500 survey_results_public.csv\n\u2502   \u2502   \u2514\u2500\u2500 survey_results_schema.csv\n\u2502   \u251c\u2500\u2500 stack-overflow-developer-survey-2019\n\u2502   \u2502   \u251c\u2500\u2500 README_2019.txt\n\u2502   \u2502   \u251c\u2500\u2500 so_survey_2019.pdf\n\u2502   \u2502   \u251c\u2500\u2500 survey_results_public.csv\n\u2502   \u2502   \u2514\u2500\u2500 survey_results_schema.csv\n[..]\n```\n\nKey observations:\n\n1. **Schema Changes Over the Years**\n\n\nSome questions and their formats evolve annually, making it difficult to standardize across years.\n2. **Pre-2016 Format**\n\n\nEach column represents a question, with names like:\n\n`What Country or Region do you live in?, How old are you?, How many years of IT/Programming experience do you have?, ...`\n\nAdditional challenges include:\n\n\u2022 Column names with unusual characters.\n\n\u2022 Querying such column names can be tedious.\n\nFrom 2017 onward, Stack Overflow improved the exports by separating:\n\n\u2022 A file containing the answers (columns with clean names for each question).\n\n\u2022 A schema file (.csv) that maps question codes to full question text.\n\nTo keep things manageable, I focused on datasets from 2017 onward.\n\n## Manual cleaning over automation\n\nWe\u2019ve all wasted hours trying to automate tasks that could have been done manually in minutes. This is a common trap for data engineers. Sometimes, quick manual cleanup is the most efficient approach.\n\nHere\u2019s what I did:\n\n\u2022 Placed all CSVs in a single folder.\n\n\u2022 Renamed files by adding the corresponding year as a prefix (e.g., `<year>_<file_name>`).\n\n\u2022 Ensured column names in schema files were consistent (e.g., renamed name to qname where needed).\n\nThese steps took less than five minutes and saved me headaches later. Not everything needs to be automated!\n\n## Loading the CSVs\n\nNow for the exciting part: loading the data. DuckDB supports glob patterns for loading multiple files. For complex structures like [Hive partitions](https://duckdb.org/docs/data/partitioning/hive_partitioning.html), it works seamlessly too.\n\nHere\u2019s the core query for loading survey results:\n\n```sql\nCopy code\n\nCREATE OR REPLACE TABLE stackoverflow_survey.survey_results AS\n    SELECT\n        * EXCLUDE (filename),\n        substring(parse_filename(filename), 1, 4) as year,\n    FROM read_csv_auto(\n        'data_2017_2024/*survey_results*.csv',\n        union_by_name=true,\n        filename=true)\n```\n\n**Breakdown:**\n\n1. We `CREATE` a table based on a `SELECT` statement.\n2. We select all columns but `EXCLUDE` the filename. This is a path of the containing file; we get this one by enabling `filename=true`.\n3. We parse the `filename` to get only the year. As we have a convention on the file name to prefix by `<year>`, we take the first four chars and create a `year` column\n4. We use the glob pattern to only load `*survey_results*` as a single table (we'll do another query for the `survey_schemas`)\n\nAlright, let's run this one... \ud83d\ude4f\n\n```sql\nCopy code\n\nduckdb.duckdb.ConversionException: Conversion Error: CSV Error on Line: 35365\nOriginal Line: 35499,I am a developer by profession,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA\nError when converting column \"Hobbyist\". Could not convert string \"NA\" to 'BOOLEAN'\n\nColumn Hobbyist is being converted as type BOOLEAN\nThis type was auto-detected from the CSV file.\nPossible solutions:\n* Override the type for this column manually by setting the type explicitly, e.g. types={'Hobbyist': 'VARCHAR'}\n* Set the sample size to a larger value to enable the auto-detection to scan more values, e.g. sample_size=-1\n* Use a COPY statement to automatically derive types from an existing table.\n\n  file = ./2017_2024_schema/2020_survey_results_public.csv\n  delimiter = , (Auto-Detected)\n  quote = \" (Auto-Detected)\n  escape = \" (Auto-Detected)\n  new_line = \\n (Auto-Detected)\n  header = true (Auto-Detected)\n  skip_rows = 0 (Auto-Detected)\n  comment = \\0 (Auto-Detected)\n  date_format =  (Auto-Detected)\n  timestamp_format =  (Auto-Detected)\n  null_padding = 0\n  sample_size = 20480\n  ignore_errors = false\n  all_varchar = 0\n```\n\nBad news, it didn't successfully parse the CSVs. But the GREAT news is that we have an excellent log error!\n\nWe know :\n\n- On which line we have an issue\n- A proper error message `Could not convert string \"NA\" to 'BOOLEAN'`\n- Possibles solutions\n\nThis saves so much time! Sometimes, just one row can mess up the whole process, and if the error message isn\u2019t clear, you\u2019re stuck guessing what went wrong. You might even end up throwing out your CSV or trying random fixes over and over.\n\nFor us, increasing the sample\\_size fixed the problem right away. \ud83d\udc4d\n\n## Wrapping up and automate the rest\n\nWith the initial query successful, the next steps were to:\n\n1. Repeat the process for schema files.\n2. Add row count checks to ensure no data was lost during merging of the CSVs\n\nHere's a generic function to wrap the query we saw and run them depending on the pattern name of the files (either for `results` or `schemas`).\n\n```python\nCopy code\n\nCSV_DIR = './data_2017_2024'\n\n# Global configuration\nFILE_CONFIGS = [\\\n    {'pattern': 'schema', 'table': 'survey_schemas'},\\\n    {'pattern': 'public', 'table': 'survey_results'}\\\n]\n\ndef process_survey_files(csv_dir: str) -> None:\n    \"\"\"\n    Process Stack Overflow survey CSV files and load them into DuckDB tables\n    \"\"\"\n    con = duckdb.connect('stackoverflow_survey.db')\n\n    for config in FILE_CONFIGS:\n        logging.info(f\"Processing {config['pattern']} files...\")\n        con.execute(f\"\"\"\n            CREATE OR REPLACE TABLE stackoverflow_survey.{config['table']} AS\n            SELECT\n                * EXCLUDE (filename),\n                substring(parse_filename(filename), 1, 4) as year,\n            FROM read_csv_auto(\n                '{csv_dir}/*{config['pattern']}*.csv',\n                union_by_name=true,\n                filename=true,\n                sample_size=-1\n            )\n        \"\"\")\n\n        # Log row count\n        count = con.execute(f\"SELECT COUNT(*) FROM stackoverflow_survey.{config['table']}\").fetchone()[0]\n        logging.info(f\"Loaded {count} rows into {config['table']}\")\n\n        # Log unique years\n        years = con.execute(f\"SELECT DISTINCT year FROM stackoverflow_survey.{config['table']} ORDER BY year\").fetchall()\n        logging.info(f\"{config['table']} years: {[year[0] for year in years]}\")\n\n    con.close()\n```\n\nFinally, we added another function to check row count and make sure we didn't lose any rows during the process :\n\n```python\nCopy code\n\ndef verify_row_counts(csv_dir: str) -> None:\n    \"\"\"\n    Verify that the sum of individual file counts matches the merged table counts\n    \"\"\"\n    con = duckdb.connect('stackoverflow_survey.db')\n\n    for config in FILE_CONFIGS:\n        pattern = config['pattern']\n        table = config['table']\n\n        logging.info(f\"\\nVerifying {pattern} files counts...\")\n        individual_counts = 0\n\n        for filename in os.listdir(csv_dir):\n            if pattern in filename and filename.endswith('.csv'):\n                file_path = os.path.join(csv_dir, filename)\n                count = con.execute(f\"SELECT COUNT(*) FROM read_csv_auto('{file_path}')\").fetchone()[0]\n                logging.info(f\"{filename}: {count} rows\")\n                individual_counts += count\n\n        merged_count = con.execute(f\"SELECT COUNT(*) FROM stackoverflow_survey.{table}\").fetchone()[0]\n        logging.info(f\"Individual {pattern} files total: {individual_counts}\")\n        logging.info(f\"Merged {table} total: {merged_count}\")\n\n        assert individual_counts  merged_count, f\"{pattern} row count mismatch: {individual_counts} != {merged_count}\"\n\n    con.close()\n    logging.info(\"\u2705 All row counts verified successfully!\")\n```\n\n## Sharing the dataset\n\nNow that I have a DuckDB database containing both tables (results and schemas), the only thing left is to share it! Let's see how that works with MotherDuck.\n\nI\u2019m using the DuckDB CLI, but this could also be part of a Python script. It\u2019s just four simple commands:\n\n```sql\nCopy code\n\nduckdb\nD ATTACH 'stackoverflow_survey.db'\nD ATTACH 'md:'\nD CREATE DATABASE cloud_stackoverflow_survey FROM stackoverflow_survey;\nD CREATE SHARE FROM cloud_stackoverflow_survey;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                            share_url                            \u2502\n\u2502                             varchar                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 md:_share/sample_data/23b0d623-1361-421d-ae77-125701d471e6      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n1. We attach the local DuckDB database with `ATTACH` command.\n2. We connect to MotherDuck using `ATTACH 'md';`. Note that I have my [`motherduck_token`](https://motherduck.com/docs/key-tasks/authenticating-and-connecting-to-motherduck/authenticating-to-motherduck/#authentication-using-an-access-token) stored in an `ENV`.\n3. We upload the database to MotherDuck using the `CREATE DATABASE x FROM x`\n4. We create a public share so that anyone can start querying!\n\nTo make it even easier for MotherDuck users, I put this one in the existing demo database [`sample_data`](https://motherduck.com/docs/getting-started/sample-data-queries/datasets/), which is attached by default for any users.\n\n## Querying the dataset\n\nThis dataset offers plenty of opportunities to uncover insights, but I\u2019ll wrap up this blog with a simple query that wasn\u2019t included in the original StackOverflow study.\n\nI wanted to explore the average happiness score of people based on their work location (remote, in-person, or hybrid).\n\n```sql\nCopy code\n\nSELECT RemoteWork,\n       AVG(CAST(JobSat AS DOUBLE)) AS AvgJobSatisfaction,\n       COUNT(*) AS RespondentCount\nFROM sample_data.stackoverflow_survey.survey_results\nWHERE JobSat NOT IN ('NA')\n  AND RemoteWork NOT IN ('NA')\n  AND YEAR='2024'\nGROUP BY ALL;\n```\n\nand the results :\n\n```sql\nCopy code\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              RemoteWork              \u2502 AvgJobSatisfaction \u2502 RespondentCount \u2502\n\u2502               varchar                \u2502       double       \u2502      int64      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 In-person                            \u2502  6.628152818991098 \u2502            5392 \u2502\n\u2502 Remote                               \u2502  7.072592992884806 \u2502           11103 \u2502\n\u2502 Hybrid (some remote, some in-person) \u2502  6.944303596894311 \u2502           12622 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nTwo interesting takeaways: remote and ybrid workers make up the majority of survey responses, and on average, they seem to be happier too!\n\nCheck out [our documentation](https://motherduck.com/docs/getting-started/sample-data-queries/stackoverflow-survey/) if you want to explore this dataset further.\n\nIn the meantime, get ready to tackle future CSV challenges with ease\u2014DuckDB and MotherDuck (start for [free!](https://motherduck.com/get-started/)) have got you covered!\n\n* * *\n\n### Why DuckDB\u2019s CSV Parser is Special\n\n- [https://duckdb.org/2023/10/27/csv-sniffer.html](https://duckdb.org/2023/10/27/csv-sniffer.html)\n- [https://duckdb.org/2024/12/05/csv-files-dethroning-parquet-or-not.html](https://duckdb.org/2024/12/05/csv-files-dethroning-parquet-or-not.html)\n- [Why CSVs Still Matter: The Indispensable File Format](https://youtu.be/I07qV2hij4E?si=DjCapBT3eg5UWLdn)\n\n### TABLE OF CONTENTS\n\n[The biggest challenges when reading CSVs](https://motherduck.com/blog/csv-files-persist-duckdb-solution/#the-biggest-challenges-when-reading-csvs)\n\n[About the Dataset](https://motherduck.com/blog/csv-files-persist-duckdb-solution/#about-the-dataset)\n\n[Manual cleaning over automation](https://motherduck.com/blog/csv-files-persist-duckdb-solution/#manual-cleaning-over-automation)\n\n[Loading the CSVs](https://motherduck.com/blog/csv-files-persist-duckdb-solution/#loading-the-csvs)\n\n[Wrapping up and automate the rest](https://motherduck.com/blog/csv-files-persist-duckdb-solution/#wrapping-up-and-automate-the-rest)\n\n[Sharing the dataset](https://motherduck.com/blog/csv-files-persist-duckdb-solution/#sharing-the-dataset)\n\n[Querying the dataset](https://motherduck.com/blog/csv-files-persist-duckdb-solution/#querying-the-dataset)\n\nStart using MotherDuck now!\n\n[Try 21 Days Free](https://motherduck.com/get-started/)\n\nGet Started\n\n![blog subscription icon](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fblog-subscription-icon.67ccd5ae.png&w=828&q=75)\n\n### Subscribe to motherduck blog\n\nE-mail\n\nSubscribe to other MotherDuck Updates\n\nSubmit\n\n## PREVIOUS POSTS\n\n[![DuckDB Ecosystem: January 2025](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fnewsletter_a65cff5430.png&w=3840&q=75)](https://motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025/)\n\n[2025/01/10 - Simon Sp\u00e4ti](https://motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025/)\n\n### [DuckDB Ecosystem: January 2025](https://motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025)\n\nDuckDB Monthly #25: PyIceberg, 0$ data distribution and more!\n\n[![Local dev and cloud prod for faster dbt development](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2FLocal_Dev_Cloud_Prod_083b07b92e.png&w=3840&q=75)](https://motherduck.com/blog/dual-execution-dbt/)\n\n[2025/01/16 - Jacob Matson](https://motherduck.com/blog/dual-execution-dbt/)\n\n### [Local dev and cloud prod for faster dbt development](https://motherduck.com/blog/dual-execution-dbt)\n\nSpark the Joy of beautiful local development workflows with MotherDuck & dbt\n\n[View all](https://motherduck.com/blog/)\n\nAuthorization Response",
  [2m  â”‚[0m     "numLines": 418,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 418
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [94mâ”Œâ”€ ğŸ¤– AGENT MESSAGE[0m
  [94mâ”‚[0m This is excellent! Now I have comprehensive information about databases and shares. Let me write the answer to the specified file:
  [94mâ””â”€[0m

  [96mğŸ”§ TOOL:[0m Write â†’ /tmp/answer_without_kg_8.md
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "create",
  [2m  â”‚[0m   "filePath": "/tmp/answer_without_kg_8.md",
  [2m  â”‚[0m   "content": "<3977 chars>",
  [2m  â”‚[0m   "structuredPatch": [],
  [2m  â”‚[0m   "originalFile": null
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [94mâ”Œâ”€ ğŸ¤– AGENT MESSAGE[0m
  [94mâ”‚[0m I've completed the task. Here's a summary of what I found:
  [94mâ”‚[0m 
  [94mâ”‚[0m **Key Differences Between a MotherDuck Database and a Share:**
  [94mâ”‚[0m 
  [94mâ”‚[0m 1. **Database**: A cloud-hosted DuckDB database you own with full read/write access. It uses MotherDuck's Differential Storage system for persistent storage and can be modified directly.
  [94mâ”‚[0m 
  [94mâ”‚[0m 2. **Share**: A read-only, zero-copy snapshot of a database distributed via a secret URL. Recipients can query but cannot modify the data. Created using `CREATE SHARE FROM <database>`.
  [94mâ”‚[0m 
  [94mâ”‚[0m The main distinctions are:
  [94mâ”‚[0m - **Ownership**: Databases are owned; shares are derived
  [94mâ”‚[0m - **Permissions**: Databases are read/write; shares are read-only  
  [94mâ”‚[0m - **Purpose**: Databases for storage/manipulation; shares for distribution/collaboration
  [94mâ”‚[0m - **Data duplication**: Shares create no data copies thanks to Differential Storage
  [94mâ”‚[0m 
  [94mâ”‚[0m The answer has been written to `/tmp/answer_without_kg_8.md` with full source attribution from 5 relevant files in the `.kurt/sources/` directory.
  [94mâ””â”€[0m

  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ğŸ“Š TURN 1 METRICS
     Tokens: 7,585 | Cost: $0.7299
     Cumulative: 7,585 tokens | $0.7299
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  âœ… TASK COMPLETE
     Reason: llm: The agent's message is a summary of findings and indicates task completion without soliciting further input from the user.

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ âœ… SESSION COMPLETE
â•‘    Turns: 1 | Tools: 18 | Duration: 119.0s
â•‘    Tokens: 7,585 | Cost: $0.7299
â•‘    Stop reason: Task completed (no follow-up questions)
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   ğŸ§  Running LLM judge evaluation...
   ğŸ§  LLM Judge score: 0.99
