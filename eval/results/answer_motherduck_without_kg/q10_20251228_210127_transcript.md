# Scenario: answer_motherduck_without_kg

**Status**: âœ… PASSED
**Timestamp**: 20251228_210127

**Duration**: 90.12 seconds
**Tokens Used**: 0

---

## Conversation


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ SCENARIO: answer_motherduck_without_kg
   Answer MotherDuck questions by searching sources directly (no KG)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”


ğŸ” Verifying .claude installation...
   âœ“ .claude folder exists at /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_vh0v__to/.claude
   âœ“ Skills: 0 found
   âœ“ Commands: 0 found

ğŸ” Filtering to questions: [10]

ğŸ§ª Running 1 of 10 question(s) defined in questions_motherduck.yaml


======================================================================
â“ Question 10/10
...What DuckDB versions does MotherDuck currently support?
======================================================================


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ’¬ QUESTION 10
â”‚ Answer this question by searching through the .kurt/sources/ directory:

...What DuckDB versions does MotherDuck currently support?

Required Steps:
1. Search for relevant markdown files in .kurt/sources/ using glob and grep
2. Read the most relevant files (aim for 3-5 most relevant sources)
3. As you read each file, keep track of:
   - The file path
   - The file title/name
   - Key information extracted from that file
4. Synthesize a comprehensive answer based on the information found
5. Write your answer to: /tmp/answer_without_kg_10.md

IMPORTANT - Your answer MUST have this structure:
```markdown
# Answer

[Your comprehensive answer here, drawing from the sources you read]

## Sources

List each source file you actually read and used, showing the EXACT LOCAL FILE PATH:
- .kurt/sources/motherduck.com/[path/to/file.md] - Brief description of key information used from this file
- .kurt/sources/motherduck.com/[path/to/file.md] - Brief description of key information used from this file
[etc.]

DO NOT use URLs or document titles as links. Show the actual file path you read with the Read tool.
```

The Sources section is MANDATORY - you must list every file you read to answer the question.

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ§¹ Clearing Claude Code context for clean scenario start...
   âœ“ Context cleared


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ ğŸ”„ TURN 1
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  [96mğŸ”§ TOOL:[0m Grep â†’ DuckDB.*version|version.*DuckDB|supported.*version|version.*support

  [96mğŸ”§ TOOL:[0m Grep â†’ duckdb_version|DuckDB version
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "mode": "files_with_matches",
  [2m  â”‚[0m   "filenames": [
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/from-core-to-custom-unlocking-new-possibilities-with-duckdb-extensions.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/hack-night.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pg-duckdb-release.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/making-pyspark-code-faster-with-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-congratulates-duckdb-1.0-release.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-duckdb-dbt.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/galileo-world-geospatial.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/faster-ducks.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/fix-outdated-llm-documentation-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-cognee-sql-analytics-graph-rag.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-dbt-e2e-data-engineering-project-part-2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-app-generator.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-duckdb-141-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/authors/jacob-matson.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/authors/jelte-fennema-nio.md"
  [2m  â”‚[0m   ],
  [2m  â”‚[0m   "numFiles": 19
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "mode": "files_with_matches",
  [2m  â”‚[0m   "filenames": [
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/simple-way-to-convert-csv-and-parquet-files.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/local-dev-cloud-prod-with-dagster-and-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/faster-data-pipelines-development-with-mcp-and-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/from-core-to-custom-unlocking-new-possibilities-with-duckdb-extensions.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-tutorial-for-beginners.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/bringing-duckdb-to-the-cloud-dual-execution-explained.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/a-new-paradigm-for-data-visualization-with-just-sql-markdown.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/quacking-around-the-web.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/why-choose-parquet-table-file-format.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/product-analytics-motherduck-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/duckdb-python-quickstart-part1.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/duckdb-python-quickstart-part2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/ducklake-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/hack-night.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/index.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/acid-transactions-sql.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/bigquery-alternative-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/command line.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/data build tool (dbt).md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/data model.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/7-Zip.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/CLI.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/finqore.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/community-and-open-source.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/the-future-of-bi-bi-as-code-duckdb-impact.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/streaming-oracle-to-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/search-using-duckdb-part-1.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/python-duckdb-vs-dataframe-libraries.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/redshift-files-hunt-for-big-data.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pg_duckdb-postgresql-extension-for-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pg-duckdb-release.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pgduckdb-beta-release-duckdb-postgres.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/making-pyspark-code-faster-with-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-congratulates-duckdb-1.0-release.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-duckdb-dbt.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/galileo-world-geospatial.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/getting-started-ducklake-table-format.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/getting-started-gis-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/git-for-data-part-1.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/faster-ducks.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/fix-outdated-llm-documentation-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/from-data-lake-to-lakehouse-duckdb-portable-catalog.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-the-great-federator.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-tutorial-for-beginners.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-two.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-september-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-six.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-nine.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-cognee-sql-analytics-graph-rag.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-dbt-e2e-data-engineering-project-part-2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-engineering-toolkit-essential-tools.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/csv-files-persist-duckdb-solution.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-app-generator.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/analyze-x-data-nodejs-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-duckdb-13-on-motherduck-cdw.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-duckdb-141-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/15-companies-duckdb-in-prod.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/authors/jacob-matson.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/authors/jelte-fennema-nio.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/about-us.md"
  [2m  â”‚[0m   ],
  [2m  â”‚[0m   "numFiles": 73
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [96mğŸ”§ TOOL:[0m Grep â†’ v1\.[0-9]+|0\.[0-9]+\.[0-9]+|1\.[0-9]+\.[0-9]+|supported.*DuckDB|DuckDB.*support

  [96mğŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_vh0v__to/.kurt/sources/motherduck.com/blog/announcing-duckdb-141-motherduck.md

  [96mğŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_vh0v__to/.kurt/sources/motherduck.com/blog/announcing-duckdb-13-on-motherduck-cdw.md
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_vh0v__to/.kurt/sources/motherduck.com/blog/announcing-duckdb-141-motherduck.md",
  [2m  â”‚[0m     "content": "---\ntitle: announcing-duckdb-141-motherduck\ncontent_type: blog\nsource_url: https://motherduck.com/blog/announcing-duckdb-141-motherduck\nindexed_at: '2025-11-25T19:56:19.062696'\ncontent_hash: cb38b5b6d8d7bc42\nhas_code_examples: true\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n[GO BACK TO BLOG](https://motherduck.com/blog/)\n\n# DuckDB 1.4.1 and DuckLake 0.3 Land in MotherDuck: New SQL Syntax, Iceberg Interoperability, and Performance Gains\n\n2025/10/09 - 5 min read\n\nBY\n\n[Alex Monahan](https://motherduck.com/authors/alex-monahan/)\n,\n[Garrett O'Brien](https://motherduck.com/authors/garrett-obrien/)\n\nOne of the most exciting things about DuckDB as a technology is just how quickly it improves. It\u2019s hard not to be excited about supporting a major release, but we are _especially_ excited about this one. We\u2019re thrilled to share that MotherDuck now supports DuckDB version 1.4.1 and DuckLake version 0.3.\n\n**DuckDB 1.4.0** introduced landmark features, including the MERGE statement, VARIANT type, and a completely rewritten sorting engine. **DuckDB 1.4.1** builds on that foundation with important bugfixes and additional improvements. MotherDuck now supports the latest 1.4.1 version. While you can continue using your current version of DuckDB, we encourage you to [upgrade your DuckDB clients to 1.4.1](https://duckdb.org/docs/installation/?version=stable&environment=cli&platform=macos&download_method=package_manager) as soon as you can.\n\nOn the DuckLake side, MotherDuck now supports **DuckLake 0.3**. DuckLake 0.3 introduces the DuckLake `CHECKPOINT` function that makes table maintenance automatic, plus interoperability with Iceberg and native support for spatial geometry types.\n\nRead on for our favorite highlights from these releases, and check out the DuckDB blogs on [1.4.0](https://duckdb.org/2025/09/16/announcing-duckdb-140.html) and [1.4.1](https://duckdb.org/2025/10/07/announcing-duckdb-141.html) for all the details.\n\n## DuckLake 0.3: Iceberg Interoperability, Simplified Maintenance, and Spatial Data Support\n\n### Iceberg Interoperability\n\nThanks to the DuckDB `iceberg` extension, migrating your Iceberg data lake to MotherDuck-managed DuckLake just got a lot easier. On the migration path, you\u2019ll find an integrated, cloud-scale lakehouse that maintains support for tools that only speak Iceberg.\n\nYou can now copy directly from Iceberg to DuckLake as part of a migration, or from DuckLake to Iceberg to continue using your favorite Iceberg-only tools.\n\n### DuckLake Checkpoint: Maintenance Made Easy\n\nThe new `CHECKPOINT` statement combines all the maintenance operations you need into a single, simple command. Configure it once, and it automatically runs operations in sequential order:\n\n- Flushes inlined data\n- Compacts small files created by multi-threaded writes\n- Rewrites files with many deletions\n- Cleans up orphaned files\n\nNo more juggling multiple maintenance commands\u2014just call `CHECKPOINT` and DuckLake handles the rest:\n\n```sql\nCopy code\n\nATTACH 'ducklake:my_ducklake.ducklake' AS my_ducklake;\nUSE my_ducklake;\nCHECKPOINT;\n```\n\n### Spatial Geometry Types\n\nDuckLake 0.3 introduces native support for geometry data types, allowing users to take advantage of the DuckDB `spatial` extension\u2019s functionality in DuckLake. This opens up powerful new use cases for geospatial analytics directly on your data lake\u2013see the [DuckLake documentation](https://ducklake.select/docs/stable/specification/data_types#geometry-types) for a list of supported types.\n\n### MERGE INTO: Upserts for Data Lakes\n\nDuckLake 0.3 now fully supports the `MERGE INTO` statement, bringing elegant upsert capabilities to your data lake tables without requiring primary keys or indexes. This is a game-changer for incremental data pipelines and slowly changing dimensions.\n\nAs an example:\n\n```sql\nCopy code\n\n-- Update existing records and insert new ones\nWITH new_stocks(item_id, volume) AS (VALUES (20, 2200), (30, 1900))\nMERGE INTO ducklake_table.Stock\nUSING new_stocks USING (item_id)\nWHEN MATCHED THEN UPDATE SET balance = balance + volume\nWHEN NOT MATCHED THEN INSERT VALUES (new_stocks.item_id, new_stocks.volume)\nRETURNING merge_action, *;\n```\n\n`MERGE` also supports complex conditions and `DELETE` operations, making it perfect for real-world data engineering workflows. `MERGE` operations are efficient and work seamlessly with time travel, versioning, and all other DuckLake features. This gives you OLAP-optimized upsert performance on data lake storage:\n\n```sql\nCopy code\n\nWITH deletes(item_id, delete_threshold) AS (VALUES (10, 3000))\n    MERGE INTO Stock USING deletes USING (item_id)\n    WHEN MATCHED AND balance < delete_threshold THEN DELETE;\nFROM Stock;\n```\n\n### Smarter Write Performance\n\nDuckLake 0.3 speeds up write performance by allowing each thread to write separate files, which can be compacted later using the checkpoint function. This parallelization dramatically improves throughput for bulk inserts while keeping your table organized.\n\n### Additional DuckLake 0.3 Features\n\n- [**Snapshot tracking**](https://github.com/duckdb/ducklake/pull/350): New `current_snapshot()` function for easier snapshot management\n- [**Orphaned file cleanup**](https://github.com/duckdb/ducklake/pull/398): The `ducklake_delete_orphaned_files()` function removes files no longer tracked by DuckLake. Includes a `dry_run` parameter for testing\n- [**Intelligent data file rewriting**](https://github.com/duckdb/ducklake/pull/393) **:** Automatically identifies and rewrites files with many deletions for optimal performance on your current snapshot\n\n## DuckDB 1.4: MERGE Statement, VARIANT Type, and Performance\n\n### MERGE INTO: Upserts Without Primary Keys\n\nDuckDB 1.4.0 adds full support for the `MERGE` statement, giving you a clean, standard SQL way to handle upserts without requiring primary keys or indexes.\n\nHere's a simple example:\n\n```sql\nCopy code\n\nCREATE TABLE Stock(item_id INTEGER, balance INTEGER);\nINSERT INTO Stock VALUES (10, 2200), (20, 1900);\n\nWITH new_stocks(item_id, volume) AS (VALUES (20, 2200), (30, 1900))\n    MERGE INTO Stock\n        USING new_stocks USING (item_id)\n    WHEN MATCHED\n        THEN UPDATE SET balance = balance + volume\n    WHEN NOT MATCHED\n        THEN INSERT VALUES (new_stocks.item_id, new_stocks.volume)\n    RETURNING merge_action, *;\n```\n\n`MERGE` also supports complex conditions and `DELETE` operations, and it works seamlessly with DuckLake 0.3.\n\n### Blazing Fast Sorting: Rewritten from the Ground Up\n\nDuckDB 1.4.0 introduced a completely new sorting implementation that delivers often 2x or better performance improvements while using significantly less memory and scaling better across multiple threads.\n\nThe new k-way merge sort reduces data movement, adapts to pre-sorted data, and powers not just `ORDER BY` clauses but also window functions and list sorting operations. Your most intensive analytical queries just got dramatically faster \u2013 [read the DuckDB blog for more detail](https://www.google.com/url?q=https://duckdb.org/2025/09/24/sorting-again.html&sa=D&source=docs&ust=1759859043223938&usg=AOvVaw1v0Tkh7BSjXrL6K4duBp19).\n\n## Additional SQL Features\n\n### VARIANT type for semi-structured data\n\nThe new `VARIANT` type provides fast processing of JSON and other semi-structured data, with support for reading `VARIANT` types from Parquet files, including shredded encodings.\n\n### FILL window function for interpolation\n\nThe new `FILL()` window function makes it easy to interpolate missing values:\n\n```sql\nCopy code\n\nFROM (VALUES (1, 1), (2, NULL), (3, 42)) t(c1, c2)\nSELECT fill(c2) OVER (ORDER BY c1) f;\n-- Result: 1, 21, 42\n```\n\n## Huge Thanks to the DuckDB Team and Community\n\nIt\u2019s incredibly _fun_ to work with a technology that improves so fast, and we\u2019re so grateful to the entire DuckDB community. [DuckDB 1.4](https://duckdb.org/2025/09/16/announcing-duckdb-140.html) wouldn't be possible without the outstanding work from the DuckDB team and over 90 contributors who made more than 3,500 commits since version 1.3.2.\n\nIf you\u2019re curious about what else shipped in 1.4, head on over to the [DuckDB site](https://duckdb.org/2025/09/16/announcing-duckdb-140.html) and take a gander for yourself. And if you\u2019d like to run DuckDB-powered analytics at cloud scale, spin up a [free trial of MotherDuck](https://app.motherduck.com/?auth_flow=signup&_gl=1*1qteo2d*_gcl_au*MTI1MTE1Nzg3OS4xNzU1MTA4Mjk0*_ga*MTkwNjI1NTM3NS4xNzU1MTA4Mjk0*_ga_L80NDGFJTP*czE3NTk4MTM4MDAkbzE3OCRnMCR0MTc1OTgxMzgwMCRqNjAkbDAkaDE0MjU5MDU5Mzg.) or join our [community Slack](https://slack.motherduck.com/).\n\nLet's get quacking! \ud83e\udd86\n\n### TABLE OF CONTENTS\n\n[DuckLake 0.3: Iceberg Interoperability, Simplified Maintenance, and Spatial Data Support](https://motherduck.com/blog/announcing-duckdb-141-motherduck/#ducklake-03-iceberg-interoperability-simplified-maintenance-and-spatial-data-support)\n\n[DuckDB 1.4: MERGE Statement, VARIANT Type, and Performance](https://motherduck.com/blog/announcing-duckdb-141-motherduck/#duckdb-14-merge-statement-variant-type-and-performance)\n\n[Additional SQL Features](https://motherduck.com/blog/announcing-duckdb-141-motherduck/#additional-sql-features)\n\n[Huge Thanks to the DuckDB Team and Community](https://motherduck.com/blog/announcing-duckdb-141-motherduck/#huge-thanks-to-the-duckdb-team-and-community)\n\nStart using MotherDuck now!\n\n[Try 21 Days Free](https://motherduck.com/get-started/)\n\nGet Started\n\n![blog subscription icon](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fblog-subscription-icon.67ccd5ae.png&w=828&q=75)\n\n### Subscribe to motherduck blog\n\nE-mail\n\nSubscribe to other MotherDuck Updates\n\nSubmit\n\n## PREVIOUS POSTS\n\n[![DuckDB Ecosystem: September 2025](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2FThree_items_Duck_DB_Ecosystem_3_72ab709f58.png&w=3840&q=75)](https://motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025/)\n\n[2025/09/09 - Simon Sp\u00e4ti](https://motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025/)\n\n### [DuckDB Ecosystem: September 2025](https://motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025)\n\nDuckDB Monthly #33: DuckDB 58\u00d7 faster spatial joins, pg\\_duckdb 1.0, and 79% Snowflake cost savings\n\n[![MotherDuck is Landing in Europe! Announcing our EU Region](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.us-east-1.amazonaws.com%2Fassets%2Fimg%2Feu_launch_blog_b165ff2751.png&w=3840&q=75)](https://motherduck.com/blog/motherduck-in-europe/)\n\n[2025/09/24 - Garrett O'Brien, Sheila Sitaram](https://motherduck.com/blog/motherduck-in-europe/)\n\n### [MotherDuck is Landing in Europe! Announcing our EU Region](https://motherduck.com/blog/motherduck-in-europe)\n\nServerless analytics built on DuckDB, running entirely in the EU.\n\n[View all](https://motherduck.com/blog/)\n\nAuthorization Response",
  [2m  â”‚[0m     "numLines": 210,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 210
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_vh0v__to/.kurt/sources/motherduck.com/blog/announcing-duckdb-13-on-motherduck-cdw.md",
  [2m  â”‚[0m     "content": "---\ntitle: announcing-duckdb-13-on-motherduck-cdw\ncontent_type: blog\nsource_url: https://motherduck.com/blog/announcing-duckdb-13-on-motherduck-cdw\nindexed_at: '2025-11-25T19:56:52.346338'\ncontent_hash: 0960a8687cbd6e92\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n[GO BACK TO BLOG](https://motherduck.com/blog/)\n\n# DuckDB 1.3 Lands in MotherDuck: Performance Boosts, Even Faster Parquet, and Smarter SQL\n\n2025/06/01 - 5 min read\n\nBY\n\n[Sheila Sitaram](https://motherduck.com/authors/sheila-sitaram/)\n\nWe\u2019re excited to share that **DuckDB 1.3.0 is now available in MotherDuck**, bringing a wave of performance and usability upgrades to make everyday SQL and analytics faster, friendlier, and more efficient.\n\nA major release, [DuckDB 1.3.0](https://github.com/duckdb/duckdb/releases/tag/v1.3.0) improves performance in real-world scenarios with faster queries, updated SQL syntax, and smarter handling for Parquet files.\n\nRead on for our favorite highlights from this release.\n\n## Even Better Real-World Query Performance\n\n### A New TRY() expression for safer queries\n\nIf you\u2019re ingesting messy data sources or writing resilient data pipelines, the `TRY ()` [function](https://duckdb.org/2025/05/21/announcing-duckdb-130.html#try-expression) offers **more graceful handling for bad data** by returning `NULL` values instead of errors on problematic rows.\n\n### Pushdown of inequality conditions into joins\n\nA huge win for **incremental dbt models** and other workloads that rely on join conditions, DuckDB and MotherDuck [users can expect much better performance](https://github.com/duckdb/duckdb/pull/17317) when filtering.\n\n### Pushdown of arbitrary expressions into scans\n\nDuckDB can now **push down more types of filter expressions directly into scans**, [reducing the amount of data that needs to be processed downstream](https://github.com/duckdb/duckdb/pull/17213) to deliver up to 30X faster queries in these scenarios.\n\n## Blazing Fast Parquet Reads and Writes\n\nWith DuckDB 1.3.0, Parquet files are more efficient overall. While Parquet reads are even faster thanks to optimizations around caching, materialization, and read performance, Parquet writes are also faster due to a smarter use of multithreaded exports, improved compression mechanisms, and rowgroup merges.\n\n### Late materialization\n\nDuckDB now [defers fetching columns until absolutely necessary](https://github.com/duckdb/duckdb/pull/17325), resulting in **3\u201310x faster reads** for queries with `LIMIT`.\n\n### ~15% average speedup on reads\n\nGeneral **read performance is significantly improved** due to [new efficiency scan and filter improvements](https://github.com/duckdb/duckdb/pull/16315), even without late materialization.\n\n### 30%+ faster write throughput\n\nMajor improvements to **multithreaded Parquet export performance** result in [even faster writes](https://github.com/duckdb/duckdb/pull/16243).\n\n### Better compression for large strings\n\nLarge strings can now be [dictionary-compressed](https://github.com/duckdb/duckdb/pull/17061), resulting in **reduced file sizes** and performance boosts.\n\n### Smarter rowgroup combining\n\n**Smaller rowgroups from multiple threads** are now [merged at the time of write](https://github.com/duckdb/duckdb/pull/17036), resulting in more efficient Parquet files.\n\n## Performance Wins Big and Small\n\nThe release of 1.3.0 isn\u2019t just about headline features: It also includes performance boosts across the stack, from aggregations and string scans to CTEs, smarter algorithms, lower memory usage, and better parallelism.\n\n### Here are 12 performance highlights that caught our attention:\n\n- [2x faster Top-N for large `LIMIT` queries:](https://github.com/duckdb/duckdb/pull/17141) If you\u2019re working with up to 250K rows, Top N is now faster than sorting!\n\n- [3x fewer memory allocations in aggregations:](https://github.com/duckdb/duckdb/pull/16849) Improvements to string hashing and aggregation internals reduce memory pressure and lower contention, leading to more efficient execution of queries like `COUNT(DISTINCT)` at scale.\n\n- [~25% faster performance for large hash table creation:](https://github.com/duckdb/duckdb/pull/16301) The parallelism strategy has been refined to avoid excessive task splitting, leading to better memory access patterns and faster hash table initialization during large joins.\n\n- [20x faster `UNNEST` and `UNPIVOT` for small lists:](https://github.com/duckdb/duckdb/pull/16210) DuckDB now processes multiple lists at once and eliminates unnecessary copying to deliver better performance for common patterns like unpivoting a few columns.\n\n- [30\u201340% faster `RANGE` based window functions:](https://github.com/duckdb/duckdb/pull/16765) Parallelized task processing across hash groups and reduced lock contention during execution now lead to smoother, more efficient performance.\n\n- [7x faster conversion to Python object columns:](https://github.com/duckdb/duckdb/pull/16431) Optimized Python object conversion due to skipping intermediate steps to speed up performance for object columns and scalar UDFs.\n\n- [5\u201325% faster LIKE '%text%' and CONTAINS string scans:](https://github.com/duckdb/duckdb/pull/16484) Unified and optimized DuckDB\u2019s implementation using `memchr` for early match detection to speed up substring searches across the board.\n\n- [Faster list-of-list creation:](https://github.com/duckdb/duckdb/pull/17063) Improved performance when constructing nested lists, boosting speed for transformation pipelines that rely on complex list structures.\n\n- [Reduced memory contention in hash joins:](https://github.com/duckdb/duckdb/pull/16172) Introduced parallel `memset` for initializing large join tables, eliminating single-threaded bottlenecks and improving performance on multi-core systems.\n\n- [Faster recursive CTEs and complex subqueries performance:](https://github.com/duckdb/duckdb/pull/17294) Adopted a new top-down subquery decorrelation strategy, unlocking better optimization for nested queries and improved performance for recursive CTEs.\n\n- [Improved performance and support for JSON-heavy queries:](https://github.com/duckdb/duckdb/pull/16729) More parallelism in `UNION ALL` and resolution of multiple JSON edge cases, for better handling.\n\n- [Faster decoding of short FSST compressed strings:](https://github.com/duckdb/duckdb/pull/16508) Optimized decoding for inlined strings by skipping unnecessary copying, resulting in ~15% speedups without performance regressions on longer strings.\n\n\nAll these optimizations add up to one thing: even faster queries without lifting a finger.\n\n## What This Means for MotherDuck Users\n\nIf you're using MotherDuck, DuckDB 1.3 is already live. Your dbt models, dashboards, and notebooks will feel snappier right away.\n\nWhile you can continue using your current version of DuckDB, we encourage you to [upgrade your DuckDB clients to 1.3.0](https://duckdb.org/docs/installation/?version=stable&environment=cli&platform=macos&download_method=package_manager) as soon as you can to take advantage of the fixes and performance improvements.\n\nCurious what version you\u2019re on? Run this simple query to take a look:\n\n```csharp\nCopy code\n\nSELECT version();\n```\n\n## Huge Thanks to the DuckDB Team\n\nAt MotherDuck, we\u2019re proud to support the best of DuckDB\u2019s powerfully efficient query engine as a managed cloud service so you can easily manage a fleet of DuckDB instances and collaborate with your team. [DuckDB 1.3.0](https://duckdb.org/2025/05/21/announcing-duckdb-130.html) wouldn\u2019t be possible without the incredible engineering work from the DuckDB team and contributors from the broader community and ecosystem.\n\nIf you have feedback or questions, join our [Community Slack](https://slack.motherduck.com/) or reach out directly in the MotherDuck UI or [online](https://motherduck.com/contact-us/product-expert/). We\u2019re eager to hear your feedback so we can help you move faster from question to insight and build a ducking awesome product that best supports your workflow.\n\nHappy querying - let\u2019s get quacking!\n\n### TABLE OF CONTENTS\n\n[Even Better Real-World Query Performance](https://motherduck.com/blog/announcing-duckdb-13-on-motherduck-cdw/#even-better-real-world-query-performance)\n\n[Blazing Fast Parquet Reads and Writes](https://motherduck.com/blog/announcing-duckdb-13-on-motherduck-cdw/#blazing-fast-parquet-reads-and-writes)\n\n[Performance Wins Big and Small](https://motherduck.com/blog/announcing-duckdb-13-on-motherduck-cdw/#performance-wins-big-and-small)\n\n[What This Means for MotherDuck Users](https://motherduck.com/blog/announcing-duckdb-13-on-motherduck-cdw/#what-this-means-for-motherduck-users)\n\n[Huge Thanks to the DuckDB Team](https://motherduck.com/blog/announcing-duckdb-13-on-motherduck-cdw/#huge-thanks-to-the-duckdb-team)\n\nStart using MotherDuck now!\n\n[Try 21 Days Free](https://motherduck.com/get-started/)\n\nGet Started\n\n![blog subscription icon](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fblog-subscription-icon.67ccd5ae.png&w=828&q=75)\n\n### Subscribe to motherduck blog\n\nE-mail\n\nSubscribe to other MotherDuck Updates\n\nSubmit\n\n## PREVIOUS POSTS\n\n[![Breaking the Excel-SQL Barrier: Leveraging DuckDB's Excel Extension](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2FBreaking_Excel_SQL_barrier_d4e2cf549e.png&w=3840&q=75)](https://motherduck.com/blog/duckdb-excel-extension/)\n\n[2025/05/27 - Jacob Matson](https://motherduck.com/blog/duckdb-excel-extension/)\n\n### [Breaking the Excel-SQL Barrier: Leveraging DuckDB's Excel Extension](https://motherduck.com/blog/duckdb-excel-extension)\n\nNow in MotherDuck & DuckDB, its never been easier to join in your data from spreadsheet sources.\n\n[![A Duck Walks into a Lake](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2FA_duck_walks_into_a_lake_1_9e9dc6ec88.png&w=3840&q=75)](https://motherduck.com/blog/ducklake-motherduck/)\n\n[2025/05/28 - Jordan Tigani](https://motherduck.com/blog/ducklake-motherduck/)\n\n### [A Duck Walks into a Lake](https://motherduck.com/blog/ducklake-motherduck)\n\nDuckDB introduces a new table format, what does it mean for the future of data lakes ?\n\n[View all](https://motherduck.com/blog/)\n\nAuthorization Response",
  [2m  â”‚[0m     "numLines": 172,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 172
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "mode": "files_with_matches",
  [2m  â”‚[0m   "filenames": [
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/using-sql-in-your-data-lake-with-duckdb-iceberg-dbt-and-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/whats-new-in-data-small-data-big-impact.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/why-and-how-we-integrated-duckdb-motherduck-with-gooddata.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/pg_duckdb-postgres-analytics-just-got-faster-with-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/faster-data-pipelines-development-with-mcp-and-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/ibis-one-library-to-query-any-backend.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-run-dbt-build-with-sub-second-execution-times.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-tutorial-for-beginners.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-dbt-accelerating-the-developer-experience-with-local-power.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-motherduck-for-beginners-your-ultimate-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/data-teams.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/react-components-testing.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/what-is-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/what-is-OLAP.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/why-choose-parquet-table-file-format.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/product-analytics-motherduck-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/secure-startup-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/sql-group-by-examples-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/star-schema-data-warehouse-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/fix-slow-bi-dashboards.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/hybrid-analytics-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/modern-data-warehouse-playbook.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/partitioned-writes-parquet-ducklake.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/duckdb-python-quickstart-part1.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/duckdb-python-quickstart-part2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/duckdb-vs-sqlite-databases.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/ducklake-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/hack-night.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/acid-transactions-sql.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/columnar-storage-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/filter.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/storage.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/window functions.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/column.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/SQLAlchemy.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/MotherDuck extension.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/Common Table Expressions (CTEs).md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/DuckDB CLI.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/DuckDB.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/EXPLAIN clause.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/INSERT statement.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/JSON.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/ALTER TABLE statement.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/duckdb-book-summary-chapter2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/duckdb-book-summary-chapter4.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/duckdb-news.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/why-web-developers-should-care-about-analytical-databases.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/careers.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/the-future-of-bi-bi-as-code-duckdb-impact.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/vector-technologies-ai-data-stack.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/streamlining-ai-agents-duckdb-rag-solutions.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/six-reasons-duckdb-slaps.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/solving-advent-code-duckdb-dbt.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/search-using-duckdb-part-1.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/search-using-duckdb-part-2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/separating-storage-compute-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/python-duckdb-vs-dataframe-libraries.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pg_duckdb-postgresql-extension-for-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pg-duckdb-release.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pgduckdb-beta-release-duckdb-postgres.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/postgres-duckdb-options.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-open-for-all-with-series-b.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-union-orchestration.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-ai-sql-fixit-inline-editing-features.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-congratulates-duckdb-1.0-release.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-dbt-pipelines.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-duckdb-dbt.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/log-processing-savings-bacalhau-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/introducing-motherduck-for-business-analytics.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/json-log-analysis-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/google-sheets-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/getting-started-ducklake-table-format.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/getting-started-gis-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/faster-ducks.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/fix-outdated-llm-documentation-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/from-data-lake-to-lakehouse-duckdb-portable-catalog.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-wasm-in-browser.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/ducklake-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/estuary-streaming-cdc-replication.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/fabi-ai-llm-prompt-analysis.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-text2sql-llm.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-the-great-federator.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-tutorial-for-beginners.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-versus-pandas-versus-polars.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-three.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-enterprise-5-key-categories.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-excel-extension.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-september-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-seven.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-six.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-nine.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-june-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-eight.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-eleven.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-august-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-december-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-110-hidden-gems.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-cognee-sql-analytics-graph-rag.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-dbt-e2e-data-engineering-project-part-2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-engineer-highlights-PyConDE-2023.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-engineering-toolkit-essential-tools.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-engineers-answer-10-top-reddit-questions.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/building-data-applications-with-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/building-motherduck-partner-ecosystem.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/cidr-paper-hybrid-query-processing-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/csv-files-persist-duckdb-solution.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/big-data-is-dead.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/bigquery-to-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-ducklake-support-motherduck-preview.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-motherduck-general-availability-data-warehousing-with-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/analyze-sqlite-databases-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/analyze-x-data-nodejs-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-duckdb-13-on-motherduck-cdw.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-duckdb-141-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/15-companies-duckdb-in-prod.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/analyze-data-in-azure-with-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/analyze-json-data-using-sql.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/authors/sheila-sitaram.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/authors/simon-spati.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/authors/ryan-boyd.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/authors/marcos-ortiz.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/authors/garrett-obrien.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/authors/alex-monahan.md"
  [2m  â”‚[0m   ],
  [2m  â”‚[0m   "numFiles": 155
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [96mğŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_vh0v__to/.kurt/sources/motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw.md

  [96mğŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_vh0v__to/.kurt/sources/motherduck.com/blog/motherduck-congratulates-duckdb-1.0-release.md

  [96mğŸ”§ TOOL:[0m Grep â†’ currently support|supported DuckDB|DuckDB.*support|1\.0|1\.1|1\.2
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_vh0v__to/.kurt/sources/motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw.md",
  [2m  â”‚[0m     "content": "---\ntitle: announcing-duckdb-12-on-motherduck-cdw\ncontent_type: blog\nsource_url: https://motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw\nindexed_at: '2025-11-25T19:56:52.249690'\ncontent_hash: ffbbc98f7f85afe2\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n[GO BACK TO BLOG](https://motherduck.com/blog/)\n\n# MotherDuck Now Supports DuckDB 1.2: Faster, Friendlier, Better Performance\n\n2025/02/05 - 4 min read\n\nBY\n\n[Sheila Sitaram](https://motherduck.com/authors/sheila-sitaram/)\n\nMotherDuck support for [DuckDB 1.2](https://duckdb.org/2025/02/05/announcing-duckdb-120.html) has arrived, and with it comes a wave of improvements that make analytics in your data warehouse faster and more intuitive. We\u2019re always excited to see how DuckDB pushes the boundaries of performance and usability, and the 1.2 release delivers on both fronts.\n\nWhether you\u2019re crunching CSVs, writing SQL, or optimizing complex queries, DuckDB 1.2 brings major enhancements to help you work more efficiently, and we\u2019re proud to support it from the outset. Our early support for DuckDB 1.2 is possible due to the helpful collaboration with the DuckDB community as we tested and verified the upcoming release.\n\nThis blog highlights key improvements in performance, the SQL experience, CSV handling, and scalability.\n\n## Performance Gains That Matter\n\nPerformance has always been a strength of DuckDB, and 1.2 takes it to new heights. Several core enhancements boost query speed, particularly for common real-world use cases.\n\n### Even Faster Top N Queries\n\nSorting and retrieving the **top N** records in a dataset is a frequent operation in analytics. DuckDB 1.2 now **leverages a heap-based approach** to make Top N queries faster. That means dashboards, ranking reports, and percentile calculations all see noticeable performance gains.\n\n### Long Strings, Now Compressed\n\nIf you work with datasets containing long string values, DuckDB 1.2 introduces **ZSTD-based string compression**, resulting in better compression and faster write speeds. For MotherDuck users, this translates to faster reads and more efficient storage.\n\n### Aggregation Speed-Ups\n\nGrouping and summarizing large datasets is now faster thanks to **partition-aware aggregation** and other **hash table optimizations**. For example, aggregations on Hive-partitioned datasets now benefit from better data locality, leading to major efficiency improvements.\n\n## A Friendlier SQL Experience\n\nDuckDB 1.2 improvements aren\u2019t just about efficiency gains: 1.2 also introduces improvements that make SQL more intuitive and expressive.\n\n### More Expressive Column Selection\n\nNew shorthand syntax makes it easier to select and rename columns on the fly:\n\n- `SELECT * LIKE '%name%'` lets you select only columns matching a pattern\n- `SELECT * RENAME` allows renaming multiple columns inline\n- Column aliases before expressions improve readability, e.g., `SELECT new_col: x + 1, another: x + 2`\n\n### Better Handling of Boolean Aggregations\n\nPreviously, summing a Boolean column required wrapping it in a `CASE WHEN` statement. Now, you can directly sum a Boolean column with `SUM(price > 50)`, making queries both cleaner and faster.\n\n### Improved Auto-Completion and CLI Experience\n\nWriting SQL is easier than ever with a more intelligent autocomplete engine that provides context-aware suggestions. Plus, the DuckDB CLI gets a fresh upgrade with **syntax highlighting and thousands-separator support** for better readability.\n\n## Better CSV Handling and Excel File Support\n\nReading CSV files remains one of the most common tasks in data analysis, and DuckDB 1.2 makes it even faster and more memory-efficient. Compression and filter pushdown optimizations speed up ingestion, while improved error handling makes dealing with messy data smoother than before.\n\nMany enterprises still rely heavily on Excel files and handling them in DuckDB has traditionally been done through the [spatial extension](https://duckdb.org/docs/guides/file_formats/excel_import.html). Although not technically part of DuckDB 1.2, we want to highlight the newly-improved [Excel extension](https://github.com/duckdb/duckdb-excel), which now provides support for reading and writing Excel files. It works great with MotherDuck's [Dual Execution](https://motherduck.com/docs/key-tasks/running-hybrid-queries/) query engine, enabling Excel files to be read on your local DuckDB client and referenced in your SQL queries so you can upload local data to MotherDuck or `JOIN` with MotherDuck tables in the cloud.\n\n## More Robustness & Scalability\n\nReliability matters, and DuckDB 1.2 includes several robustness improvements that directly benefit MotherDuck users:\n\n- **Fixes for concurrent checkpoints**, improving stability under heavy workloads\n- **Better handling of WAL recovery**, ensuring data integrity in case of crashes\n- **Optimistic writes in more scenarios**, reducing contention in high-concurrency environments\n- **Larger-than-memory UPDATEs, DELETEs and Window Functions**, reducing the reliance on memory and enabling working with even larger-sized datasets\n\n## Whats Next?\n\nDuckDB 1.2 brings meaningful improvements across the board, making it faster, friendlier, and more scalable. At MotherDuck, we\u2019re thrilled to see these optimizations in action, delivering even better performance for our users. Whether you're handling CSVs, running analytical queries, or writing SQL with ease, DuckDB 1.2 makes the experience smoother and more powerful.\n\n### TABLE OF CONTENTS\n\n[Performance Gains That Matter](https://motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw/#performance-gains-that-matter)\n\n[A Friendlier SQL Experience](https://motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw/#a-friendlier-sql-experience)\n\n[Better CSV Handling and Excel File Support](https://motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw/#better-csv-handling-and-excel-file-support)\n\n[More Robustness & Scalability](https://motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw/#more-robustness-scalability)\n\n[Whats Next?](https://motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw/#whats-next)\n\nStart using MotherDuck now!\n\n[Try 21 Days Free](https://motherduck.com/get-started/)\n\nGet Started\n\n![blog subscription icon](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fblog-subscription-icon.67ccd5ae.png&w=828&q=75)\n\n### Subscribe to motherduck blog\n\nE-mail\n\nSubscribe to other MotherDuck Updates\n\nSubmit\n\n## PREVIOUS POSTS\n\n[![Local dev and cloud prod for faster dbt development](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2FLocal_Dev_Cloud_Prod_083b07b92e.png&w=3840&q=75)](https://motherduck.com/blog/dual-execution-dbt/)\n\n[2025/01/16 - Jacob Matson](https://motherduck.com/blog/dual-execution-dbt/)\n\n### [Local dev and cloud prod for faster dbt development](https://motherduck.com/blog/dual-execution-dbt)\n\nSpark the Joy of beautiful local development workflows with MotherDuck & dbt\n\n[![Why CSV Files Won\u2019t Die and How DuckDB Conquers Them](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fcsvwontdie_1_9a8f8b85b5.png&w=3840&q=75)](https://motherduck.com/blog/csv-files-persist-duckdb-solution/)\n\n[2025/02/04 - Mehdi Ouazza](https://motherduck.com/blog/csv-files-persist-duckdb-solution/)\n\n### [Why CSV Files Won\u2019t Die and How DuckDB Conquers Them](https://motherduck.com/blog/csv-files-persist-duckdb-solution)\n\nLearn how you can pragmatically use DuckDB to parse any CSVs\n\n[View all](https://motherduck.com/blog/)\n\nAuthorization Response",
  [2m  â”‚[0m     "numLines": 134,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 134
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_vh0v__to/.kurt/sources/motherduck.com/blog/motherduck-congratulates-duckdb-1.0-release.md",
  [2m  â”‚[0m     "content": "---\ntitle: motherduck-congratulates-duckdb-1.0-release\ncontent_type: blog\nsource_url: https://motherduck.com/blog/motherduck-congratulates-duckdb-1.0-release\nindexed_at: '2025-11-25T19:57:46.857822'\ncontent_hash: 5a700d9ff7bfada6\nhas_narrative: true\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n[GO BACK TO BLOG](https://motherduck.com/blog/)\n\n# Congratulations to DuckDB Labs On Reaching 1.0!\n\n2024/06/03 - 4 min read\n\nBY\nMotherDuck team\n\nEarlier today, [DuckDB released version 1.0](https://duckdb.org/2024/06/03/announcing-duckdb-100), marking a key maturity milestone for the nimble yet powerful analytics database quickly taking over the world. MotherDuck would like to _quackgradulate_ DuckDB and extend our gratitude for all their hard work and support (and enabling all the duck puns)!\n\n## Why DuckDB?\n\nFor database nerds, [there\u2019s much to love about DuckDB](https://motherduck.com/duckdb-book-brief/) \u2014 [performance](https://thenewstack.io/duckdb-in-process-python-analytics-for-not-quite-big-data/), [innovation velocity](https://motherduck.com/blog/six-reasons-duckdb-slaps/), [versatility](https://duckdb.org/faq.html#why-call-it-duckdb), [ease of use](https://www.nikolasgoebel.com/2024/05/28/duckdb-doesnt-need-data.html), [rich and user-friendly SQL](https://duckdb.org/2024/03/01/sql-gymnastics.html), and [extreme portability](https://duckdb.org/why_duckdb.html#portable). Thanks to DuckDB, analytics can run virtually anywhere, liberated from the shackles of complex and expensive distributed systems. As an embedded database, it\u2019s the perfect \u2018Lego\u2019 building block that can snap into any process just by linking in a library.\n\nWhen we first learned about DuckDB two years ago, we loved it so much that we decided to start a company to turn it into a serverless cloud data warehouse. While in retrospect, this seems like an obvious duck to bet on, at the time, DuckDB was relatively unknown outside of database enthusiast and academic circles. But you could tell, even then, that they were onto something \u2014 the elegance of the design and the fervent enthusiasm of their growing user base set it apart from other databases. Moreover, their philosophy about what actually matters in data management systems deeply resonated with us at MotherDuck.\n\nThis turned out to be a prophetic choice. In the two years since we started working together, DuckDB has consistently moved up the rankings in the [DB Engines list](https://db-engines.com/en/ranking%5D). They\u2019ve gone from thousands of monthly downloads to millions. And they\u2019ve gone from being the database nobody has heard of to the one everyone is talking about.\n\n![DB Engines growth chart](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimage1_f6daf71258.png&w=3840&q=75)\n\nWith DuckDB as the key building block, MotherDuck is a [complete set of Legos](https://www.lego.com/en-us/product/millennium-falcon-75192?gclid=CjwKCAjwjeuyBhBuEiwAJ3vuoU4Ue7BPvmrfhnovXtGvA-5kp27nHkdJs9LXUCaPZjCUCrewdkOiyRoCnuQQAvD_BwE&ef_id=CjwKCAjwjeuyBhBuEiwAJ3vuoU4Ue7BPvmrfhnovXtGvA-5kp27nHkdJs9LXUCaPZjCUCrewdkOiyRoCnuQQAvD_BwE:G:s&s_kwcid=AL!790!3!!!!x!!!19930801844!&cmp=KAC-INI-GOOGUS-GO-US_GL-EN-RE-SP-BUY-CREATE-MB_ALWAYS_ON-SHOP-BP-PMAX-ALL-CIDNA00000-PMAX-MEDIUM_PRIORITY&gad_source=1), purpose-made for data teams, analytics application developers, and DuckDB users looking to supercharge and extend their favorite database to the cloud.\n\n## DuckDB Labs, Thank You!\n\nWhen we first talked to [Hannes](https://hannes.muehleisen.org/) and [Mark](https://mytherin.github.io/) about bringing DuckDB to the cloud, they were cautiously supportive of the idea. Since then, we\u2019ve built a great working relationship with the DuckDB Labs team to help achieve our shared vision of DuckDB running everywhere. We\u2019ve also created a pioneering model for building a commercial business without stifling open-source independence.\n\nWe at MotherDuck are extending DuckDB beyond its embedded confines by offering [serverless delivery](https://motherduck.com/product/), [secure sharing](https://motherduck.com/docs/key-tasks/managing-shared-motherduck-database/) and [access control](https://motherduck.com/docs/authenticating-to-motherduck/), [durable managed storage](https://motherduck.com/docs/architecture-and-capabilities/), [hybrid/dual query execution](https://motherduck.com/cidr-paper/), [a WebAssembly (Wasm) SDK](https://motherduck.com/blog/building-data-applications-with-motherduck/), and more.\n\nCrucially, thanks to the [extensibility hooks](https://duckdb.org/docs/extensions/overview.html) DuckDB provides, MotherDuck has been able to run standard DuckDB under the hood.\n\nAs DuckDB marched towards its 1.0 release, we saw DuckDB Labs\u2019 hard work firsthand to production-proof DuckDB. We appreciate the hardening, fuzzing, refactoring, and testing that has made for an impressively stable, flexible, and semantically rich data management system. Frankly, many of MotherDuck\u2019s recent improvements, including version independence and multi-statement transactions, were made possible by DuckDB Labs\u2019 collaborative efforts.\n\nWe could not have picked a better database to work with or a better group of passionate database professionals to partner with. To Hannes, Mark, and the rest of DuckDB Labs, we appreciate your continuous support, determination, and excellence.\n\nWe look forward to celebrating 2.0 and beyond with you!\n\n## DuckDB 1.0 and MotherDuck\n\nToday\u2019s release also marks the first simultaneous launch of MotherDuck with a new DuckDB version. MotherDuck already supports DuckDB 1.0; if you run a query via MotherDuck, it will run on the latest DuckDB version. What makes this possible is **Version Independence**, a feature we quietly enabled a few weeks ago that decouples clients from the version of DuckDB that we run on our servers.\n\nWhen DuckDB ships a new version, we can upgrade all the MotherDuck servers to run it in the cloud. Users don\u2019t need to do anything; they\u2019ll get access to improved performance and bug fixes. While users will need to upgrade their clients to access new features, they can now do so at their convenience.\n\n## PS: Something BIG is Coming Soon\n\nAt MotherDuck, we have also been busy, and we have some exciting news to share with you very soon.\n\nStay tuned!\n\nMeanwhile, if you\u2019re in San Francisco tonight, **June 3rd, at 6:00 pm**, [celebrate with us at our party at 111 Minna](https://motherducking-party-snowflake-summit.eventbrite.com/)\u2026 [we\u2019ll run it back on Tuesday, June 11th](https://motherducking-party-data-ai-summit.eventbrite.com/)!\n\n## Take Flight with MotherDuck\n\n### Cloud SQL Analytics Without the Overhead\n\nIf you haven\u2019t tried MotherDuck, [take flight with a 30-day trial of the Standard Plan](https://motherduck.com/) or paddle [Free Forever for small projects](https://motherduck.com/product/pricing/).\n\n### TABLE OF CONTENTS\n\n[Why DuckDB?](https://motherduck.com/blog/motherduck-congratulates-duckdb-1.0-release#why-duckdb)\n\n[DuckDB Labs, Thank You!](https://motherduck.com/blog/motherduck-congratulates-duckdb-1.0-release#duckdb-labs-thank-you)\n\n[DuckDB 1.0 and MotherDuck](https://motherduck.com/blog/motherduck-congratulates-duckdb-1.0-release#duckdb-10-and-motherduck)\n\n[PS: Something BIG is Coming Soon](https://motherduck.com/blog/motherduck-congratulates-duckdb-1.0-release#ps-something-big-is-coming-soon)\n\n[Take Flight with MotherDuck](https://motherduck.com/blog/motherduck-congratulates-duckdb-1.0-release#take-flight-with-motherduck)\n\nStart using MotherDuck now!\n\n[Try 21 Days Free](https://motherduck.com/get-started/)\n\nGet Started\n\n![blog subscription icon](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fblog-subscription-icon.67ccd5ae.png&w=828&q=75)\n\n### Subscribe to motherduck blog\n\nE-mail\n\nSubscribe to other MotherDuck Updates\n\nSubmit\n\n## PREVIOUS POSTS\n\n[![How we Saved 95% on Log Processing with Bacalhau and MotherDuck](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2FBacalhau_blog_e9a1602bb1.png&w=3840&q=75)](https://motherduck.com/blog/log-processing-savings-bacalhau-motherduck/)\n\n[2024/05/08 - Sean M. Tracey](https://motherduck.com/blog/log-processing-savings-bacalhau-motherduck/)\n\n### [How we Saved 95% on Log Processing with Bacalhau and MotherDuck](https://motherduck.com/blog/log-processing-savings-bacalhau-motherduck)\n\nWe stopped sifting our log data and started generating speedy logging insights to realize 95% in cost savings by pre-processing logs with Bacalhau and MotherDuck. How is that even possible? Let's walk through a step-by-step overview together.\n\n[![DuckDB Tutorial For Beginners](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fgetting_started_duckdb_thumbnail_70b197b1ab.png&w=3840&q=75)](https://motherduck.com/blog/duckdb-tutorial-for-beginners/)\n\n[2024/10/31 - Mehdi Ouazza, Ryan Boyd](https://motherduck.com/blog/duckdb-tutorial-for-beginners/)\n\n### [DuckDB Tutorial For Beginners](https://motherduck.com/blog/duckdb-tutorial-for-beginners)\n\nGet up to speed quickly with DuckDB, including installation, VSCode workflow integration and your first SQL analytics project.\n\n[View all](https://motherduck.com/blog/)\n\nAuthorization Response",
  [2m  â”‚[0m     "numLines": 121,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 121
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "mode": "content",
  [2m  â”‚[0m   "numFiles": 0,
  [2m  â”‚[0m   "filenames": [],
  [2m  â”‚[0m   "content": "<9934 chars>",
  [2m  â”‚[0m   "numLines": 50,
  [2m  â”‚[0m   "appliedLimit": 50
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [96mğŸ”§ TOOL:[0m Grep â†’ upgrade.*DuckDB|DuckDB client.*version|version.*client

  [96mğŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_vh0v__to/.kurt/sources/motherduck.com/glossary/MotherDuck extension.md
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_vh0v__to/.kurt/sources/motherduck.com/glossary/MotherDuck extension.md",
  [2m  â”‚[0m     "content": "---\ntitle: MotherDuck extension\ncontent_type: tutorial\nsource_url: https://motherduck.com/glossary/MotherDuck extension\nindexed_at: '2025-11-25T20:08:29.934950'\ncontent_hash: 5315c271fb5d98b9\nhas_step_by_step: true\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n# MotherDuck extension\n\n_[Back to DuckDB Data Engineering Glossary](https://motherduck.com/glossary/)_\n\nThe [MotherDuck extension](https://github.com/duckdb/duckdb/tree/master/extension/motherduck) is a component of [DuckDB](https://duckdb.org/) that enables seamless integration with the [MotherDuck](https://motherduck.com/) cloud service. This extension allows users to connect their local DuckDB instance to MotherDuck's serverless analytics platform, facilitating hybrid query execution across local and cloud environments. By using the MotherDuck extension, data professionals can leverage the power of cloud computing while maintaining the flexibility of working with data on their local machine. The extension supports features such as remote data access, synchronized schema management, and the ability to push computations to the cloud when needed, enhancing DuckDB's capabilities for handling larger datasets and more complex analytics tasks.\n\nAuthorization Response",
  [2m  â”‚[0m     "numLines": 22,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 22
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "mode": "content",
  [2m  â”‚[0m   "numFiles": 0,
  [2m  â”‚[0m   "filenames": [],
  [2m  â”‚[0m   "content": "<2817 chars>",
  [2m  â”‚[0m   "numLines": 9,
  [2m  â”‚[0m   "appliedLimit": 30
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [94mâ”Œâ”€ ğŸ¤– AGENT MESSAGE[0m
  [94mâ”‚[0m Now I have gathered enough information. Let me write the answer to the specified file.
  [94mâ””â”€[0m

  [96mğŸ”§ TOOL:[0m Write â†’ /tmp/answer_without_kg_10.md
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "create",
  [2m  â”‚[0m   "filePath": "/tmp/answer_without_kg_10.md",
  [2m  â”‚[0m   "content": "<1829 chars>",
  [2m  â”‚[0m   "structuredPatch": [],
  [2m  â”‚[0m   "originalFile": null
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [94mâ”Œâ”€ ğŸ¤– AGENT MESSAGE[0m
  [94mâ”‚[0m I've written the answer to `/tmp/answer_without_kg_10.md`. 
  [94mâ”‚[0m 
  [94mâ”‚[0m **Summary:** MotherDuck currently supports **DuckDB version 1.4.1** (as of October 2025). MotherDuck has a "Version Independence" feature that allows their servers to run the latest DuckDB version, while clients can upgrade at their convenience. The documentation shows MotherDuck has supported DuckDB versions 1.0, 1.2, 1.3, and now 1.4.1 as each was released.
  [94mâ””â”€[0m

  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ğŸ“Š TURN 1 METRICS
     Tokens: 11,266 | Cost: $0.4593
     Cumulative: 11,266 tokens | $0.4593
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  âœ… TASK COMPLETE
     Reason: llm: The agent clearly states it has gathered enough information and is proceeding to write the answer, indicating task completion rather than soliciting further input.

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ âœ… SESSION COMPLETE
â•‘    Turns: 1 | Tools: 11 | Duration: 71.3s
â•‘    Tokens: 11,266 | Cost: $0.4593
â•‘    Stop reason: Task completed (no follow-up questions)
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   ğŸ§  Running LLM judge evaluation...
   ğŸ§  LLM Judge score: 0.85
