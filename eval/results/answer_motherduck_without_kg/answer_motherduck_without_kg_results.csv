Question #,Question Text,answer_motherduck_without_kg_answer,answer_motherduck_without_kg_source_1,answer_motherduck_without_kg_source_2,answer_motherduck_without_kg_source_3,answer_motherduck_without_kg_source_4,answer_motherduck_without_kg_source_5,answer_motherduck_without_kg_source_6,answer_motherduck_without_kg_source_7,answer_motherduck_without_kg_source_8,answer_motherduck_without_kg_source_9,answer_motherduck_without_kg_source_10,answer_motherduck_without_kg_judge_overall_score,answer_motherduck_without_kg_judge_accuracy_score,answer_motherduck_without_kg_judge_completeness_score,answer_motherduck_without_kg_judge_relevance_score,answer_motherduck_without_kg_judge_clarity_score,answer_motherduck_without_kg_judge_feedback,answer_motherduck_without_kg_tokens_used,answer_motherduck_without_kg_duration_seconds
1,,"# Answer  Based on the MotherDuck documentation, **Parquet is the most efficient file format for loading data into MotherDuck**, followed by native DuckDB database files. Here's why:  ## Parquet: The Recommended Format  **Parquet is specifically optimized for analytical workloads** because it uses a compressed columnar format, which provides the best performance for large-scale aggregations. DuckDB (which powers MotherDuck) stores data in compressed columnar format internally, making Parquet a natural fit that requires minimal transformation during loading.  ### Key Efficiency Factors for Parquet:  1. **Columnar Storage**: Parquet stores data in columns rather than rows, which is ideal for analytical queries that typically scan specific columns across many rows.  2. **Built-in Compression**: The format includes efficient compression algorithms that reduce storage size and I/O requirements during data loading.  3. **Native DuckDB Support**: DuckDB can query Parquet files directly wit...",- .kurt/sources/motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md,- .kurt/sources/motherduck.com/videos/simple-way-to-convert-csv-and-parquet-files.md,- .kurt/sources/motherduck.com/blog/six-reasons-duckdb-slaps.md,- .kurt/sources/motherduck.com/blog/duckdb-tutorial-for-beginners.md,- .kurt/sources/motherduck.com/blog/python-duckdb-vs-dataframe-libraries.md,- .kurt/sources/motherduck.com/videos/how-to-efficiently-load-data-into-ducklake-with-estuary.md,,,,,,,,,,,,
2,,"# How MotherDuck Integrates with DuckDB  MotherDuck extends DuckDB to the cloud through a sophisticated integration architecture that maintains full compatibility with the open-source database while adding cloud-scale capabilities.  ## Integration Architecture  ### Three-Layer System  MotherDuck's integration is built on three core components:  1. **Client Extension**: MotherDuck integrates directly with the DuckDB ecosystem through an extension system. Users can connect their local DuckDB instance to MotherDuck with a simple command, regardless of whether they're working in the CLI, Python, JDBC, or even the browser via WebAssembly.  2. **Compute Layer**: Cloud-based queries are processed by containerized DuckDB instances called """"ducklings."""" These compute resources scale based on user needs, providing the necessary CPU and memory for analytical queries.  3. **Storage Layer**: Instead of DuckDB's native single-writer file format, MotherDuck implements a differential storage system...",,,,,,,,,,,,,,,,,,
3,,"# SQL Features from DuckDB Not Yet Supported in MotherDuck  Based on the MotherDuck documentation, there are several SQL features and capabilities from DuckDB that have limitations or are not yet fully supported in MotherDuck due to its cloud architecture. While MotherDuck maintains strong compatibility with DuckDB and uses the same engine both locally and in the cloud, some advanced features remain unavailable on the server-side.  ## Key Unsupported Features  ### 1. Multiple Simultaneous Writers  **Limitation:** MotherDuck currently **only supports one writer per database** at a time. While multiple users can read from the same shared database simultaneously, only one user can have write access.  **Why:** This is a fundamental architectural constraint of MotherDuck's storage system. Even though MotherDuck has solved the """"reading while writing"""" problem through its differential storage engine and snapshot isolation, the multiple writer problem remains unsolved.  **Impact:** Workloa...",,,,,,,,,,,,,,,,,,
4,,"# Why Queries May Run Slower on MotherDuck Than Locally  While MotherDuck extends DuckDB's powerful local analytics capabilities to the cloud, there are specific scenarios where queries may run slower on MotherDuck compared to local execution. Understanding these performance trade-offs helps you optimize your query execution strategy.  ## Network Data Transfer Overhead  The primary reason queries may run slower on MotherDuck is **network data transfer**. When a query executes remotely in the cloud, the final result set must be transferred over the network back to your local client. This introduces latency that doesn't exist with purely local execution.  ### When This Matters Most  Network overhead becomes significant when: - **Large result sets**: Queries returning millions of rows must transfer all that data over the network - **Geographic distance**: Greater distance between your location and MotherDuck's servers (currently in AWS us-east-1 and eu-central-1) increases latency - **...",,,,,,,,,,,,,,,,,,
5,,"# How to Set Up MotherDuck to Work with dbt  MotherDuck integrates seamlessly with dbt (data build tool) through the `dbt-duckdb` adapter, allowing you to perform data transformations directly within MotherDuck's cloud data warehouse. Here's a comprehensive guide to getting started.  ## Prerequisites  Before you begin, you'll need: - A MotherDuck account (sign up at [motherduck.com](https://app.motherduck.com/?auth_flow=signup)) - Python 3.x installed - Basic familiarity with dbt and SQL  ## Installation  ### 1. Install the dbt-duckdb Adapter  Install the dbt-duckdb package with MotherDuck support:  ```bash pip install dbt-duckdb[md] # or with Poetry poetry add dbt-duckdb[md] ```  The `[md]` extra installs the necessary dependencies for MotherDuck integration.  ### 2. Get Your MotherDuck Service Token  1. Sign in to your MotherDuck account 2. Click on **Settings** in the upper right corner 3. Copy your **Service Token** to your clipboard 4. Export it as an environment variable:  ```...",,,,,,,,,,,,,,,,,,
6,,"# How to Migrate Data from a Local DuckDB Database to MotherDuck  There are several methods to migrate data from a local DuckDB database to MotherDuck, ranging from simple one-command uploads to more granular table-by-table approaches.  ## Method 1: Upload Entire Local Database (Simplest)  The easiest way to migrate your local DuckDB database to MotherDuck is using a single command:  ```sql CREATE DATABASE remote_database_name FROM CURRENT_DATABASE();  -- or more generally CREATE DATABASE remote_database_name FROM '<local database name>'; ```  **Important considerations:** - The local and remote database names **must be different**, otherwise you'll get an error: `Catalog Error: error while importing share: Schema with name <local-database-name> does not exist!` - For large databases, this can take considerable time (e.g., ~1 hour for an 11GB database, transferring 15GB of data) - This method uploads all tables and data from your local database to MotherDuck  ## Method 2: Connect an...",,,,,,,,,,,,,,,,,,
7,,"# How to Join a Local CSV with an S3 Table Using MotherDuck  If you have a CSV file on your laptop and a table stored in S3, the most efficient way to join them using MotherDuck is to leverage **Dual Execution** â€” MotherDuck's innovative hybrid query execution model that intelligently minimizes data movement.  ## The Most Efficient Approach  Simply write a standard SQL join query that references both your local CSV and your S3 data:  ```sql SELECT     local.customer_id,     local.recent_purchase,     cloud.historical_data FROM read_csv('local_sales.csv') AS local JOIN read_parquet('s3://my-bucket/customer_history.parquet') AS cloud     ON local.customer_id = cloud.customer_id WHERE local.purchase_date >= '2025-01-01'; ```  ## How Dual Execution Makes This Efficient  MotherDuck's **Dual Execution** model is a hybrid query execution strategy where the optimizer intelligently decides whether to run parts of a query locally on your laptop or remotely in the MotherDuck cloud. The primary...",,,,,,,,,,,,,,,,,,
8,,"# The Difference Between a MotherDuck Database and a Share  ## MotherDuck Database  A **MotherDuck database** is a fully functional, writable database hosted in the cloud using MotherDuck's managed DuckDB service. Key characteristics include:  - **Writable**: You can create, modify, and delete tables and data - **Full Control**: Database owners have complete control over the schema and content - **Collaborative**: Multiple users can simultaneously access with dedicated compute instances (""""ducklings"""") for concurrent queries - **Cloud Storage**: Database catalog is managed in the cloud for easy scaling and collaboration - **Local + Cloud**: Can be queried both locally and in the cloud with seamless integration  ## MotherDuck Share  A **share** is a **read-only, shareable snapshot** of a MotherDuck database, purpose-built for data collaboration and ad-hoc analytics. Key characteristics include:  - **Read-Only**: Recipients can query the data but cannot modify it - **Snapshot-Based**:...",,,,,,,,,,,,,,,,,,
9,,"# MotherDuck Compute Instance Sizes  MotherDuck offers **5 distinct compute instance types** designed for different workload requirements, following a serverless architecture with per-user tenancy. Each instance type is optimized for specific use cases ranging from lightweight ad-hoc analytics to the most demanding data transformations.  ## Available Instance Types  ### 1. **Pulse** The smallest instance designed for lightweight, fully serverless analytics.  **Common use cases:** - Ad-hoc analytics tasks with datasets in MotherDuck - Building read-only workloads with high volumes of concurrent users (e.g., customer-facing analytics applications) - Situations where a larger, dedicated instance is overkill  **Billing:** Per Compute Unit (CU) second, 1 second minimum  **Pricing:** - Free plan: Up to 10 CU hours - Lite plan: $0.25 per CU hour - Business plan: $0.40 per CU hour  ### 2. **Standard** Built for common data warehouse workloads including loads and transforms.  **Common use ca...",,,,,,,,,,,,,,,,,,
10,,"# DuckDB Versions Supported by MotherDuck  Based on the MotherDuck documentation, **MotherDuck currently supports DuckDB version 1.4.1** as of October 2025.  ## Current Version Support  - **Server-side**: MotherDuck runs **DuckDB 1.4.1** on their cloud servers - **Client-side**: Users can connect with any DuckDB client version, but are encouraged to upgrade to 1.4.1 for optimal performance and access to new features  ## Version Independence  MotherDuck implemented a feature called **Version Independence** that was first enabled around June 2024 (before the DuckDB 1.0 release). This feature decouples the client version from the server version, meaning:  - When DuckDB ships a new version, MotherDuck can upgrade all servers to run it in the cloud - Users don't need to immediately upgrade their clients to benefit from performance improvements and bug fixes - Users can upgrade their clients at their convenience to access new SQL features  ## Recent Version History  MotherDuck has support...",,,,,,,,,,,,,,,,,,
