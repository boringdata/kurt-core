# Scenario: answer_motherduck_without_kg

**Status**: âœ… PASSED
**Timestamp**: 20251228_210127

**Duration**: 93.12 seconds
**Tokens Used**: 0

---

## Conversation


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸ“‹ SCENARIO: answer_motherduck_without_kg
   Answer MotherDuck questions by searching sources directly (no KG)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”


ðŸ” Verifying .claude installation...
   âœ“ .claude folder exists at /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_qjl9o6i5/.claude
   âœ“ Skills: 0 found
   âœ“ Commands: 0 found

ðŸ” Filtering to questions: [9]

ðŸ§ª Running 1 of 10 question(s) defined in questions_motherduck.yaml


======================================================================
â“ Question 9/10
...What compute instance sizes does MotherDuck offer?
======================================================================


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ðŸ’¬ QUESTION 9
â”‚ Answer this question by searching through the .kurt/sources/ directory:

...What compute instance sizes does MotherDuck offer?

Required Steps:
1. Search for relevant markdown files in .kurt/sources/ using glob and grep
2. Read the most relevant files (aim for 3-5 most relevant sources)
3. As you read each file, keep track of:
   - The file path
   - The file title/name
   - Key information extracted from that file
4. Synthesize a comprehensive answer based on the information found
5. Write your answer to: /tmp/answer_without_kg_9.md

IMPORTANT - Your answer MUST have this structure:
```markdown
# Answer

[Your comprehensive answer here, drawing from the sources you read]

## Sources

List each source file you actually read and used, showing the EXACT LOCAL FILE PATH:
- .kurt/sources/motherduck.com/[path/to/file.md] - Brief description of key information used from this file
- .kurt/sources/motherduck.com/[path/to/file.md] - Brief description of key information used from this file
[etc.]

DO NOT use URLs or document titles as links. Show the actual file path you read with the Read tool.
```

The Sources section is MANDATORY - you must list every file you read to answer the question.

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ðŸ§¹ Clearing Claude Code context for clean scenario start...
   âœ“ Context cleared


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ ðŸ”„ TURN 1
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  [96mðŸ”§ TOOL:[0m Grep â†’ instance size|compute.*size|node.*size|instance.*type

  [96mðŸ”§ TOOL:[0m Grep â†’ small|medium|large|xlarge|CPU|memory|compute
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "mode": "files_with_matches",
  [2m  â”‚[0m   "filenames": [
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/how-to-efficiently-load-data-into-ducklake-with-estuary.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/pricing.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/secure-startup-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/sql-group-by-examples-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/modern-data-warehouse-use-cases.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/index.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/big-data.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/bigquery-alternative-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/contact-us/product-expert.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/reflex-careers-gig-economy-retail.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/trunkrs-same-day-delivery-motherduck-from-redshift.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/dexibit.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/the-simple-joys-of-scaling-up.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/simplifying-iot-analytics-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/small-data-sf-recap-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/small-data-sf-recap.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/separating-storage-compute-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/redshift-files-hunt-for-big-data.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pgduckdb-beta-release-duckdb-postgres.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-ai-sql-fixit-inline-editing-features.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/just-enough-sql-for-ai.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/llm-data-pipelines-prompt-motherduck-dbt.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/introducing-motherduck-for-business-analytics.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/fix-outdated-llm-documentation-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-wasm-in-browser.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-engineers-answer-10-top-reddit-questions.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/building-data-applications-with-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-small-data-sf-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/big-data-is-dead.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-mega-giga-instance-sizes-huge-scale.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/authors/ryan-boyd.md"
  [2m  â”‚[0m   ],
  [2m  â”‚[0m   "numFiles": 34
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "mode": "files_with_matches",
  [2m  â”‚[0m   "filenames": [
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/why-csvs-still-matter-the-indispensable-file-format.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/why-did-we-raise-now-ceo-backstage-call.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/why-dont-data-producers-pay-attention-to-how-their-data-is-used-downstream.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/why-should-you-care-about-duckdb-ft-mihai-bojin.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/why-use-duckdb-in-your-data-pipelines-ft-niels-claeys.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/why-web-developers-should-care-about-analytical-databases.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/working-with-sql-with-your-favorite-editor-check-this.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/webinar/scaling-duckdb-panel-ondemand.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/understanding-ducklake-a-table-format-with-a-modern-architecture.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/unfinished-business-re-inventing-modern-data-tools.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/unleashing-duckdb-dbt-for-local-analytics-triumphs.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/unleashing-the-power-of-duckdb-for-interactive-sql-notebooks.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/using-sql-in-your-data-lake-with-duckdb-iceberg-dbt-and-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/what-can-postgres-learn-from-duckdb-pgconfdev-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/what-if-sql-queries-returned-results-instantly.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/whats-new-in-data-small-data-big-impact.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/whats-new-in-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/where-data-science-meets-shrek-how-buzzfeed-uses-ai.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/why-and-how-we-integrated-duckdb-motherduck-with-gooddata.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/spatial-data-management-with-duckdb-ft-mattforrest.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/speed-querying-stackoverflow-data-with-duckdb-ft-michael-hunger.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/sql-ide-safari-harlequin-in-your-terminal.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/stay-in-flow-with-motherducks-instant-sql.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/take-flight-with-dbt-and-duckdb-dropping-dev-warehouse-costs-to-zero.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/taming-file-zoos-data-science-with-duckdb-database-files.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/the-bad-the-good-and-the-ugly-navigating-the-new-waves-of-machine-learning-ft-adi-polak.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/the-death-of-big-data-and-why-its-time-to-think-small-jordan-tigani-ceo-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/the-future-of-bi-exploring-the-impact-of-bi-as-code-tools-with-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/the-magic-of-duckdb-extensions-for-data-engineering-and-analytics.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/the-power-of-wasm-for-analytics-duckdb-in-the-browser.md"
  [2m  â”‚[0m   ],
  [2m  â”‚[0m   "numFiles": 30,
  [2m  â”‚[0m   "appliedLimit": 30
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [96mðŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_qjl9o6i5/.kurt/sources/motherduck.com/blog/announcing-mega-giga-instance-sizes-huge-scale.md

  [96mðŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_qjl9o6i5/.kurt/sources/motherduck.com/product/pricing.md

  [96mðŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_qjl9o6i5/.kurt/sources/motherduck.com/blog/the-simple-joys-of-scaling-up.md
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_qjl9o6i5/.kurt/sources/motherduck.com/blog/announcing-mega-giga-instance-sizes-huge-scale.md",
  [2m  â”‚[0m     "content": "---\ntitle: announcing-mega-giga-instance-sizes-huge-scale\ncontent_type: blog\nsource_url: https://motherduck.com/blog/announcing-mega-giga-instance-sizes-huge-scale\nindexed_at: '2025-11-25T19:56:38.218331'\ncontent_hash: 16a72a7b2d67e0db\nhas_narrative: true\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n[GO BACK TO BLOG](https://motherduck.com/blog/)\n\n# Introducing Mega and Giga Ducklings: Scaling Up, Way Up\n\n2025/07/17 - 4 min read\n\nBY\n\n[Ryan Boyd](https://motherduck.com/authors/ryan-boyd/)\n\nAs DuckDB continues to prove it can scale from your laptop to the cloud and make even big data feel small, more of you are pushing the limits of what\u2019s possible \u2014 more complex aggregations, gnarlier joins, tighter deadlines. Jumbo ducklings got us far and are big enough for the [vast majority of customers](https://motherduck.com/blog/redshift-files-hunt-for-big-data/). While our focus is on the horizontal scale out architectures possible with [per-user tenancy](https://motherduck.com/blog/announcing-mega-giga-instance-sizes-huge-scale/#scaling-up-isnt-the-only-way), sometimes you just need a bigger hammer to get the job done.\n\nMeet our newest feathered friends: **Mega** and **Giga** ducklings.\n\n![Duckling Sizes](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fduckling_size_banner_v2_f3d99a5ff3.png&w=3840&q=75)\n\nThese new instance sizes are built for the **largest, toughest, most complex data transformations** DuckDB can handle \u2014 and then some.\n\nLike their smaller siblings, Mega and Giga instances are fully managed, ephemeral, and optimized for DuckDB. But they bring **more memory and more compute**, so your queries can go faster and finish sooner \u2014 even under serious load.\n\n## Mega ducklings: For Demanding Workloads at a Larger Scale\n\n**Mega ducklings** are designed for when your workloads have outgrown Jumbo and you need more power \u2014 not eventually, but _right now_.\n\n> **\"An extremely large instance for when you need complex transformations done quickly.\"**\n\n**Use a Mega when:**\n\n- Your queries are too complex or your data volume is too high for Jumbo to handle \u2014 especially **in crunch time**\n- You\u2019re running a **weekly job that rebuilds all your tables**, and it has to run in **minutes, not hours**\n- One customer has **10x the data** of everyone else, and they still expect subsecond response times\n\nUnder the hood, Mega unlocks more **in-memory execution**, handles larger joins and aggregations without spilling, whether you\u2019re reading from your MotherDuck storage, Parquet files or your shiny new DuckLake.\n\n## Giga ducklings: When Nothing Else Will Work\n\n**Giga ducklings** are our largest instance sizes, purpose-built for **the toughest of transformations**.\n\n> **\"Largest instances enable the toughest of transformations to run faster.\"**\n\n**Request a Giga when:**\n\n- Your data workload is **so complex or so massive** that nothing else will work\n- You\u2019re running a **one-time job to restate revenue for the last 10 years** \u2014 and it needs to be correct and fast\n- You need a growth path **beyond Mega**, because your **data volume and complexity just grew 10x**\n\nGiga gives DuckDB an environment with maximum compute and memory \u2014 ideal for **very complex joins**, **deeply nested CTEs**, and **long-range analytical backfills**. It\u2019s not for every job \u2014 but when you need it, you _really_ need it.\n\n## Scaling up isn't the only way\n\nScaling up to larger instance sizes (ducklings) is only one of the [many ways MotherDuck scales data warehousing workloads](https://motherduck.com/blog/scaling-duckdb-with-ducklings/).\n\nMost data warehouses are built as monoliths, where every user in the organization shares the same data warehouse compute resources. These monoliths often begin to crack under high concurrency. At the core of MotherDuck's architecture is [per-user tenancy](https://motherduck.com/blog/scaling-duckdb-with-ducklings/#how-is-a-duckling-different-from-a-standard-data-warehouse-instance), in which each user (or customer, in the case of customer-facing analytics) gets their own duckling that's configurable in size. So you might use one of the new Mega instances for some complicated transformations in your data pipelines, but still rely upon Standard instances to serve most of your users. Each instance is provisioned on demand and managed for you.\n\nThere may be cases where per-user tenancy isn't as natural. For example, [business intelligence (BI) tools](https://motherduck.com/ecosystem/?category=Business+Intelligence) typically share a single database connection but then may have dozens of users running queries at the same time. This would ordinarily break the \"one-user-per-duckling\" pattern.\n\nMotherDuck\u2019s [read scaling](https://motherduck.com/docs/key-tasks/authenticating-and-connecting-to-motherduck/read-scaling/) is designed for these types of cases \u2013 providing an extra boost in compute through horizontal scaling and maintaining the pattern of \u201cone-user-per-duckling!\u201d\n\n## Available on the Business Plan\n\nThese new duckling sizes are available on the instance plan. Megas are completely self-serve. If you want access to Gigas, please [quack with us](https://motherduck.com/contact-us/product-expert/?a=get-gigas) about what you're building.\n\n### TABLE OF CONTENTS\n\n[Mega ducklings: For Demanding Workloads at a Larger Scale](https://motherduck.com/blog/announcing-mega-giga-instance-sizes-huge-scale/#mega-ducklings-for-demanding-workloads-at-a-larger-scale)\n\n[Giga ducklings: When Nothing Else Will Work](https://motherduck.com/blog/announcing-mega-giga-instance-sizes-huge-scale/#giga-ducklings-when-nothing-else-will-work)\n\n[Scaling up isn't the only way](https://motherduck.com/blog/announcing-mega-giga-instance-sizes-huge-scale/#scaling-up-isnt-the-only-way)\n\n[Available on the Business Plan](https://motherduck.com/blog/announcing-mega-giga-instance-sizes-huge-scale/#available-on-the-business-plan)\n\nStart using MotherDuck now!\n\n[Try 21 Days Free](https://motherduck.com/get-started/)\n\nGet Started\n\n![blog subscription icon](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fblog-subscription-icon.67ccd5ae.png&w=828&q=75)\n\n### Subscribe to motherduck blog\n\nE-mail\n\nSubscribe to other MotherDuck Updates\n\nSubmit\n\n## PREVIOUS POSTS\n\n[![The Data Engineer Toolkit: Infrastructure, DevOps, and Beyond](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fthumb_de_50b9010e13.png&w=3840&q=75)](https://motherduck.com/blog/data-engineering-toolkit-infrastructure-devops/)\n\n[2025/07/03 - Simon Sp\u00e4ti](https://motherduck.com/blog/data-engineering-toolkit-infrastructure-devops/)\n\n### [The Data Engineer Toolkit: Infrastructure, DevOps, and Beyond](https://motherduck.com/blog/data-engineering-toolkit-infrastructure-devops)\n\nA comprehensive guide to advanced data engineering tools covering everything from SQL engines and orchestration platforms to DevOps, data quality, AI workflows, and the soft skills needed to build production-grade data platforms.\n\n[![This Month in the DuckDB Ecosystem: July 2025](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2FThree_items_Duck_DB_Ecosystem_2_32a9339cef.png&w=3840&q=75)](https://motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025/)\n\n[2025/07/08 - Simon Sp\u00e4ti](https://motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025/)\n\n### [This Month in the DuckDB Ecosystem: July 2025](https://motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025)\n\nDuckDB Monthly #31: Kafka Integration, Browser-Based Analytics, and Lake Format Innovations\n\n[View all](https://motherduck.com/blog/)\n\nAuthorization Response",
  [2m  â”‚[0m     "numLines": 124,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 124
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_qjl9o6i5/.kurt/sources/motherduck.com/product/pricing.md",
  [2m  â”‚[0m     "content": "---\ntitle: pricing\ncontent_type: product_page\nsource_url: https://motherduck.com/product/pricing/\nindexed_at: '2025-11-25T20:16:03.158148'\ncontent_hash: 62844ce7682cbcb5\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n# Simple, straightforward cloud data warehouse pricing\n\nDitch your overengineered cloud data warehouse for blazing fast analytics!\n\n![Free plan's illustration](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpricing-plan-free.35076c86.png&w=3840&q=75)\n\nFree\n\n$0NO CREDIT CARD\nREQUIRED\n\nA soft landing for dabbling and experimenting with MotherDuck\n\n[Get Started](https://app.motherduck.com/?auth_flow=signup)\n\n- Up to 5 Members\n- Up to 10GB of Storage\n- Pragmatic, AI-Backed UI\n\nSQL \u2018FixIt\u2019\n\nResolve common SQL errors with thoughtful, in-line suggestions\n[Learn more](https://motherduck.com/docs/key-tasks/writing-sql-with-ai/#automatically-fix-sql-errors-in-the-webui)\n\n\n\nto keep you in the flow\n\n- Community SupportSelf-serve via Slack\n\n- Up to 10 Compute Unit Hours\n\n![Business plan's illustration](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpricing-plan-business.f2750d2a.png&w=3840&q=75)\n\nBusiness\n\n$100PER ORG\n/ MONTH + USAGE\n\nProduction analytics and BI workloads without the maintenance overhead\n\n[Try 21 days FREE](https://app.motherduck.com/?auth_flow=signup)\n\n- Unlimited Members\n- Unlimited Storage\n\nPay as you go for unlimited storage\n\n- Pragmatic, AI-Backed UI +\n\nAI Functions\n\nSingle call and bulk AI functions, including prompt() and embedding()\n[Learn more](https://motherduck.com/docs/about-motherduck/billing/)\n\n- Priority Support\n\nFaster access to MotherDuck experts with an [expedited response SLA](https://motherduck.com/support-policy/)\n\n\n\nFor production-grade workloads\n\n- 5 Compute\n\nInstance Types\n\nBalance speed and performance for serverless scale and per-user tenancy\n[Learn more](https://motherduck.com/product/pricing/#instance-types)\n\n\n\n+\n\nRead Scaling\n\nEnable up to 16 read scaling replicas, each backed by its own instance\n[Learn more](https://motherduck.com/docs/key-tasks/authenticating-and-connecting-to-motherduck/read-scaling/)\n\n\n[SEE INSTANCE TYPES](https://motherduck.com/product/pricing/#instance-types)\n\n![Lite plan's illustration](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpricing-plan-lite.f629c933.png&w=3840&q=75)\n\nLite\n\n$25PER ORG\n/ MONTH + USAGE\n\nPerfect for individuals and small teams looking for their first data warehouse\n\n[Get Started](https://app.motherduck.com/?auth_flow=signup)\n\n- Up to 5 Members\n- Unlimited Storage\n\nPay as you go for unlimited storage\n\n- Pragmatic, AI-Backed UI +\n\nAI Functions\n\nSingle call and bulk AI functions, including prompt() and embedding()\n[Learn more](https://motherduck.com/docs/about-motherduck/billing/)\n\n- Standard SupportPerfect for getting started\n\n- 2 Compute\n\nInstance Types\n\nBalance speed and performance for serverless scale and per-user tenancy\n[Learn more](https://motherduck.com/product/pricing/#instance-types)\n\n\n\nPay as you go for Unlimited Compute\n\n\n[SEE INSTANCE TYPES](https://motherduck.com/product/pricing/#instance-types)\n\nLooking for an annual plan?\n[Get in touch](https://motherduck.com/contact-us/product-expert/)\n\n![Annual plan illustration](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpricing-annual-plan.aef751c8.png&w=3840&q=75)\n\nMoving to MotherDuck, a billed by-the-second cloud offering is a no-brainer for us, considering the elegance and efficiency of a single node system compared to traditional OLAP solutions.\n\nNico Ritschel\n\nDirector of Engineering @ atm.com\n\n![Nico Ritschel](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fatm-logo.e3612038.png&w=828&q=75)\n\nMotherDuck is insanely performant, and there\u2019s no infrastructure to manage. The cost of experimentation is incredibly low \u2014 which means we can afford to ask more questions and build more features, faster.\n\nKristov Paulus\n\nFounder, CIO @ Kultura Capital\n\n![Kristov Paulus](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fkultura-logo.77e389a5.png&w=640&q=75)\n\nMoving to MotherDuck, a billed by-the-second cloud offering is a no-brainer for us, considering the elegance and efficiency of a single node system compared to traditional OLAP solutions.\n\nNico Ritschel\n\nDirector of Engineering @ atm.com\n\n![Nico Ritschel](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fatm-logo.e3612038.png&w=828&q=75)\n\nMotherDuck is insanely performant, and there\u2019s no infrastructure to manage. The cost of experimentation is incredibly low \u2014 which means we can afford to ask more questions and build more features, faster.\n\nKristov Paulus\n\nFounder, CIO @ Kultura Capital\n\n![Kristov Paulus](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fkultura-logo.77e389a5.png&w=640&q=75)\n\nMoving to MotherDuck, a billed by-the-second cloud offering is a no-brainer for us, considering the elegance and efficiency of a single node system compared to traditional OLAP solutions.\n\nNico Ritschel\n\nDirector of Engineering @ atm.com\n\n![Nico Ritschel](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fatm-logo.e3612038.png&w=828&q=75)\n\nMotherDuck is insanely performant, and there\u2019s no infrastructure to manage. The cost of experimentation is incredibly low \u2014 which means we can afford to ask more questions and build more features, faster.\n\nKristov Paulus\n\nFounder, CIO @ Kultura Capital\n\n![Kristov Paulus](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fkultura-logo.77e389a5.png&w=640&q=75)\n\n## Compare Plans\n\nJust four elements: Storage, Compute, AI, and Platform Access.\n\nRegion\n\nUSA (N. Virginia): us-east-1\n\nPLANS\n\nFree\n\n**$0** No credit card required\n\n[Get Started](https://app.motherduck.com/?auth_flow=signup)\n\nBusiness\n\n**$100** per org / month + Usage\n\n[Try 21 days free](https://app.motherduck.com/?auth_flow=signup)\n\nLite\n\n**$25** per org / month + Usage\n\n[Get Started](https://app.motherduck.com/?auth_flow=signup)\n\n[Get Started for Free](https://app.motherduck.com/?auth_flow=signup)\n\nMotherDuck Data WarehouseData\n\nWarehouse\n\nMotherDuck Data WarehouseData\n\nWarehouse\n\nOrg. Members\n\nCollaborate and share data securely with org members in your organization, including users and service accounts\n\nUp to 5\n\nUnlimited\n\nUp to 5\n\nPlatform Access\n\nPlatform access covers MotherDuck support and AI-backed UI functions for members and service accounts in your Org\n[Learn more](https://motherduck.com/docs/about-motherduck/billing/pricing/#ai-function-pricing)\n\n$0\n\n$100 per org\n\n$25 per org\n\nAI Functions\n\nFor single call and bulk AI functions, including prompt() and embedding()\n[Learn more](https://motherduck.com/docs/about-motherduck/billing/)\n\nUI functions only\n\n$1.00 per AI Unit\n\n$1.00 per AI Unit\n\nStorage\n\nCost effective storage\n\nUp to 10GB\n\n$0.08 per GB per month\n\n$0.08 per GB per month\n\nCompute\n\nA selection of instances for all your analytics needs\n[Learn more](https://motherduck.com/product/pricing/#instance-types)\n\n1 Instance type:\n\nOptimize your workload's underlying compute resources\n\n5 Instance types:\n\nOptimize your workload's underlying compute resources\n\n2 Instance types:\n\nOptimize your workload's underlying compute resources\n\nPulse\n\nFor lightweight, fully serverless analytics\nBilled per Compute Unit (CU) second, 1 second minimum\n[Learn more](https://motherduck.com/product/pricing/#instance-types)\n\n(Pay on-demand)\n\nUp to 10 CU hours\n\n$0.40 per CU hour\n\n$0.25 per CU hour\n\nStandard\n\nFor everyday tasks and balanced performance\nBilled per second, 60 second minimum\n[Learn more](https://motherduck.com/product/pricing/#instance-types)\n\n(Pay per instance)\n\n$1.80 per hour\n\n$1.20 per hour\n\nJumbo\n\nFor predictable performance on heavy workloads\nBilled per second, 60 second minimum\n[Learn more](https://motherduck.com/product/pricing/#instance-types)\n\n(Pay per instance)\n\n$3.60 per hour\n\nMega\n\nFor demanding jobs at an even larger scale\nBilled per second, 5 minute minimum\n[Learn more](https://motherduck.com/product/pricing/#large-instance-types)\n\n(Pay per instance)\n\n$10.80 per hour\n\nGiga\n\nFor the largest and toughest workloads\nBilled per second, 10 minute minimum\n[Learn more](https://motherduck.com/product/pricing/#large-instance-types)\n\n(Pay per instance)\n\n[Contact Us](https://motherduck.com/contact-us/product-expert/)\n\nRead Scaling\n\nEnable up to 16 read-scaling replicas, each backed by its own instance, for BI dashboards and read-only use cases\n[Learn more](https://motherduck.com/docs/key-tasks/authenticating-and-connecting-to-motherduck/read-scaling/)\n\nQuery History\n\nA consolidated view of all queries run across your organization.\n[Learn more](https://motherduck.com/docs/sql-reference/motherduck-sql-reference/md_information_schema/query_history/)\n\nDual Execution\n\nIncredibly efficient queries, shared across local and cloud compute\n[Learn more](https://motherduck.com/docs/concepts/architecture-and-capabilities/#dual-execution)\n\nWorkflow and CollaborationWorkflow\n\nWorkflow and CollaborationWorkflow\n\nInstant SQL\n\nBuild and debug faster with\nzero-latency query results\n[Learn more](https://motherduck.com/blog/introducing-instant-sql/)\n\nFixIt\n\nResolve SQL errors with in-line fixes\n[Learn more](https://motherduck.com/docs/getting-started/interfaces/motherduck-quick-tour/#writing-sql-with-confidence-using-fixit-and-edit)\n\nColumn Explorer\n\nInstantly visualize the columns\nof your tables and result sets.\n[Learn more](https://motherduck.com/docs/getting-started/interfaces/motherduck-quick-tour/#diving-into-your-data-with-column-explorer)\n\nDatabase Sharing\n\nShare zero-copy snapshots\nfor easier collaboration\n[Learn more](https://motherduck.com/docs/key-tasks/sharing-data/sharing-overview/)\n\nSecurity And ComplianceSecurity &\n\nCompliance\n\nSecurity And ComplianceSecurity &\n\nCompliance\n\nSOC2 Type II\n\nFull compliance with SOC 2 Type II\n[Learn more](https://motherduck.com/trust-and-security/#Compliance)\n\nGDPR Compliance\n\nGeneral Data Protection Regulation (GDPR) compliant\n[Learn more](https://motherduck.com/trust-and-security/#Compliance)\n\nPrivate Link\n\nSecure, private connectivity through the AWS network\n\n\\+ Paid Add On\n\nHIPAA BAA\n\nAvailable on request\n[Contact us](https://motherduck.com/contact-us/product-expert/) for more details\n\nAvailable on request\n\nSupport\n\nSupport\n\nHuman-First SupportSupport\n\nReal people who are ready to help you in a dedicated space for your MotherDuck questions\n\nCommunity\n\nVia the [Slack Community](https://slack.motherduck.com/)\n\nPriority\n\nFaster access to MotherDuck experts with an [expedited response SLA](https://motherduck.com/support-policy/)\n\nStandard\n\nFull access to MotherDuck experts with a [standard response SLA](https://motherduck.com/support-policy/)\n\nIn-App Expert ChatIn-App\n\nExpert Chat\n\nChat with product experts directly\nfrom the MotherDuck UI\n\n## Serverless Instances\n\nMotherDuck\u2019s [per-user tenancy model](https://motherduck.com/product/data-teams/) gives each Org member an isolated instance in one of five types to enable individual, user-level configuration.Multiple read scaling replicas can also be added to handle extra load from concurrent users.\n\n![Pulse Instance type illustration](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Finstance-type-illus-pulse.8c39b9cc.png&w=3840&q=75)\n\n### Pulse\n\nOur smallest instance, perfect for ad-hoc analytics tasks\n\nCommonly used when...\n\n- Doing ad-hoc analytics tasks with datasets in MotherDuck\n- Building read-only workloads with high volumes of concurrent users like customer-facing analytics applications\n- A larger, dedicated instance is overkill for the task at hand\n\nIncluded Plans:\n\nFreeLiteBusiness\n\n![Standard Instance type illustration](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Finstance-type-illus-standard.3d0ae9e9.png&w=3840&q=75)\n\n### Standard\n\nBuilt to handle common data warehouse workloads, including loads and transforms\n\nCommonly used when...\n\n- Performing typical data engineering tasks like data ingest and dbt transformations\n- Running dbt jobs that have multiple transformations in parallel\n- Building out standard data pipelines before moving to production and scaling up\n\nIncluded Plans:\n\nFreeLiteBusiness\n\n![Jumbo Instance type illustration](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Finstance-type-illus-jumbo.b77c7bca.png&w=3840&q=75)\n\n### Jumbo\n\nFor larger data warehouse workloads with many transformations or complex aggregations\n\nCommonly used when...\n\n- Query complexity, data volume, and the number of transformations are too high for the Standard instance\n- Performing complex joins and aggregations on growing datasets using event stream data or nested JSON with changing schemas\n- Running faster with your workloads\n\nIncluded Plans:\n\nFreeLiteBusiness\n\nAnd for even heavier workloads...\n\n![Mega Instance type illustration](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Finstance-type-illus-mega.cd4cd44f.png&w=3840&q=75)\n\n### Mega\n\nAn extremely large instance for when you need complex transformations done quickly\n\nCommonly used when...\n\n- Queries are too complex or data volumes too high for Jumbo instances to handle in crunch time\n- Running a weekly job that rebuilds all of your tables and it has to run in minutes, not hours\n- One customer has 10x the amount of data as others and you want to deliver same speed\n\nIncluded Plans:\n\nFreeLiteBusiness\n\n![Giga Instance type illustration](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Finstance-type-illus-giga.3228dda6.png&w=3840&q=75)\n\n### Giga\n\nLargest instances enable the toughest transformations to run faster\n\nCommonly used when...\n\n- Your data workload is so complex that nothing else will work\n- Running a one-time job to go back and restate revenue for the last 10 years at a large company\n- You need a growth path beyond Mega for when your data volume and complexity grows 10x\n\n[Contact Us](https://motherduck.com/contact-us/product-expert/)\n\n## flock together with 40+ integration partners\n\n![Hex](https://motherduck.com/_next/static/media/hex-logo.f94f1afa.png)\n\n![Dbt](https://motherduck.com/_next/static/media/dbt-logo.5fd68952.png)\n\n![Omni](https://motherduck.com/_next/static/media/omni-logo.28efaf09.png)\n\n![Airflow](https://motherduck.com/_next/static/media/airflow-logo.aa9b0b7a.png)\n\n![Fivetran](https://motherduck.com/_next/static/media/fivetran-logo.e1839559.png)\n\n![Superset](https://motherduck.com/_next/static/media/superset-logo.ba9ddb48.png)\n\n![Tableau](https://motherduck.com/_next/static/media/tableau-logo.5d1e2634.png)\n\n![Airbyte](https://motherduck.com/_next/static/media/airbyte-logo.8ec3c7fc.png)\n\n![PowerBI](https://motherduck.com/_next/static/media/power-bi-logo.ca8fb520.png)\n\n![Dagster](https://motherduck.com/_next/static/media/dagster-logo.c48c5136.png)\n\n[EXPLORE ECOSYSTEM](https://motherduck.com/ecosystem/)\n\n![Extensive Ecosystem illustration](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fextensive-ecosystem-illus.9113fad6.png&w=3840&q=75)\n\n## Built for humans, powered by ducks\n\nMotherDuck\u2019s strategic partnership with DuckDB Labs brings the fast improving efficiencies of DuckDB\u2019s query engine from local machines to the cloud as a managed service. Working closely with the DuckDB Labs team has helped us co-create a shared vision for the future of blazing fast analytics. Together, we are committed to cutting-edge innovation in service of ergonomic, radically streamlined analytics workflows.\n\n[LEARN MORE](https://motherduck.com/about-us/)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpricing-info-built-for-humans.ad49af55.png&w=3840&q=75)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpricing-info-built-for-humans.ad49af55.png&w=3840&q=75)\n\n## Support with a heart\n\nGreat technology deserves a remarkable customer experience to match. We believe a thoughtful, human-first approach to delivering great support is as important as building great products. Our Customer team genuinely cares about your success and strives to act as an extension of your own team.\n\n[LEARN MORE](https://motherduck.com/customer-support/)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpricing-info-support-with-hearth.bdef3120.png&w=3840&q=75)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpricing-info-support-with-hearth.bdef3120.png&w=3840&q=75)\n\n## Trusted security standards\n\nKeeping your data safe and secure in the MotherDuck nest is our top priority. Our robust security and privacy program uses a defense in-depth strategy to protect your most valuable business assets and fortify trust. MotherDuck is SOC 2 Type II and GDPR compliant, with full reports and HIPAA BAAs available on request for [Business Plan](https://motherduck.com/product/pricing/#info-table) customers.\n\n[LEARN MORE](https://motherduck.com/trust-and-security/#Compliance)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpricing-info-gold-standard.a6afcacd.png&w=1920&q=75)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpricing-info-gold-standard.a6afcacd.png&w=1920&q=75)\n\n## FAQS\n\n### What is a MotherDuck Organization?\n\nIn MotherDuck, an Organization (Org for short) is a team of users. Each Org has member limits aligned to your pricing plan. Accounts for team members and service accounts will count towards the Org members included in your pricing plan.\n\n### How does MotherDuck calculate and meter compute hours?\n\nDepending on the Instance Type, MotherDuck meters compute on demand or per-instance.\n\nThe Pulse instance is an on-demand, auto-scaling instance that is metered on a per-query basis. We measure the amount of CPU and memory usage over time as a Compute Unit (CU). Pulse has a minimum of 1 CU second per query.\n\nStandard, Jumbo, Mega, and Giga instances are metered per second an instance is running, with variable compute costs based on the pricing plan and selected Instance Type. They start up quickly, within ~200 ms, and continue running for 60 seconds once the last query completes.\n\nLarger Mega and Giga instances take up to a few minutes to start up and have a cooldown period of 5 and 10 minutes, respectively.\n\n### What is MotherDuck\u2019s storage minimum, and how is it calculated and metered?\n\nMotherDuck uses cloud object storage. Usage is metered on the size of compressed data stored on-disk.\n\nTo provide data recoverability, MotherDuck charges for 7 days\u2019 worth of fail-safe data stored and meters on a per-day basis. Any data that is mutated or deleted will be retained for 7 days.\n\nMotherDuck does not charge you for: Data managed by you in your own object storage bucket, data stored on your laptop, or MotherDuck-managed data used to provide zero-copy clones called [shares](https://motherduck.com/docs/key-tasks/sharing-data/sharing-overview/) and associated data sharing features.\n\n### How are AI Units measured and metered?\n\n1 AI Unit = $1.00\n\nPlease refer to the [Documentation](https://motherduck.com/docs/about-motherduck/billing/pricing/) for a detailed overview of how AI units burn down against [SQL Assistant](https://motherduck.com/docs/category/sql-assistant/) and [Bulk AI Functions](https://motherduck.com/docs/about-motherduck/billing/pricing/).\n\nPaid Plan customers have full access to [FixIt](https://motherduck.com/docs/key-tasks/writing-sql-with-ai/#how-fixit-works), MotherDuck\u2019s in-line suggestions to help resolve common SQL errors, and usage-based pricing for [SQL Assistant](https://motherduck.com/docs/category/sql-assistant/) and [Bulk AI Functions](https://motherduck.com/docs/about-motherduck/billing/pricing/).\n\nFree Plan users have full access to [FixIt](https://motherduck.com/docs/key-tasks/writing-sql-with-ai/#how-fixit-works) and limited access to our [SQL Assistant Functions](https://motherduck.com/docs/category/sql-assistant/).\n\n### In which cloud regions is MotherDuck available?\n\nMotherDuck is currently available in the [AWS us-east-1 and AWS eu-central-1 regions](https://motherduck.com/docs/concepts/architecture-and-capabilities/). We have plans to expand to additional regions as part of our roadmap and encourage you to upvote ( [US-West](https://motherduck.canny.io/feature-requests/p/us-west-region)) or add other desired regions to [Canny](https://motherduck.canny.io/feature-requests).\n\n### Can I use MotherDuck in two cloud regions simultaneously?\n\nEach MotherDuck Organization is currently scoped to a single cloud region that must be chosen at Org creation when signing up.\n\n### Is there an on-premises version of MotherDuck?\n\nNo - MotherDuck is a managed cloud service.\n\n### Does MotherDuck have a free trial?\n\nEvery new account gets a free 21-day trial with full access to all of MotherDuck\u2019s features. We also offer a Free Plan with 10 GB of storage and 10 Compute Unit (CU) hours per month.\n\n### Does MotherDuck have an annual plan?\n\nYes - teams who are interested in an annual contract have the option to pre-commit to a level of MotherDuck usage. To learn more, please connect with our [Sales team](https://motherduck.com/contact-us/product-expert/).\n\n### How does MotherDuck protect my data?\n\nMotherDuck is committed to protecting customer data, honoring your global privacy rights, and securing the data you provide to us through the use of our products. We build our platform using best practices for highly available, scalable, and secure cloud applications, and we regularly monitor and assess our program to ensure that it meets or exceeds compliance and regulatory requirements. For more information and details about our privacy and security programs, please visit our [Trust & Security](https://motherduck.com/trust-and-security/#Compliance) page.\n\n### Does MotherDuck have academic discounts for schools or students?\n\nWe do not currently have any discounts for schools or students. Anyone is welcome to use MotherDuck\u2019s Free Plan.\n\n### Does MotherDuck offer a discount for non-profits?\n\nWe do not currently have any discounts for non-profits. Anyone is welcome to use MotherDuck\u2019s Free Plan.\n\n### What is your refund policy?\n\nPlease refer to MotherDuck\u2019s [Terms of Service](https://motherduck.com/terms-of-service/) for more information. If you have additional questions, please reach out to our [Customer team](https://motherduck.com/contact-us/support/) for assistance.\n\n![MotherDuck logo](https://motherduck.com/_next/static/media/md-simple-logo.00372b77.png)\n\n### Try Motherduck now\n\nGet started for free,\nshare data with the whole flock as you grow.\n\n[Try 21 Days Free](https://app.motherduck.com/?auth_flow=signup)\n\nAuthorization Response",
  [2m  â”‚[0m     "numLines": 661,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 661
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_qjl9o6i5/.kurt/sources/motherduck.com/blog/the-simple-joys-of-scaling-up.md",
  [2m  â”‚[0m     "content": "---\ntitle: the-simple-joys-of-scaling-up\ncontent_type: blog\nsource_url: https://motherduck.com/blog/the-simple-joys-of-scaling-up\nindexed_at: '2025-11-25T19:57:39.118108'\ncontent_hash: 81e451eafe18b744\nhas_narrative: true\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n[GO BACK TO BLOG](https://motherduck.com/blog/)\n\n# The Simple Joys of Scaling Up\n\n2023/05/11 - 16 min read\n\nBY\n\n[Jordan Tigani](https://motherduck.com/authors/jordan-tigani/)\n\nIn the quest to handle their Big Data problems, software and hardware architects have been pursuing divergent strategies for the last 20 years. While software folks have been busy re-writing their code to scale out to multiple machines, hardware folks have been cramming more and more transistors and cores into a single chip so you can do more work on each machine.\n\nAs anyone who has had a programming interview can attest, if you have a linear progression and an exponential progression the exponential will dominate. Scale-out lets you scale linearly with cost. But Moore\u2019s Law compounds exponentially with time, meaning if you do nothing for a few years you can scale up and get orders of magnitude improvements. In two decades, transistor density has increased by 1000x; something that might have taken thousands of machines in 2002 could be done today in just one.\n\n![image transistors](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimage4_cf8be8744b.png%3Fupdated_at%3D2023-05-10T16%3A48%3A35.141Z&w=3840&q=75)_Image by Our World In Data, [https://ourworldindata.org/moores-law](https://ourworldindata.org/moores-law)_\n\nAfter such a dramatic increase in hardware capability, we should ask ourselves, \u201cDo the conditions that drove our scaling challenges in 2003 still exist?\u201d After all, we\u2019ve made our systems far more complex and added a lot of overhead. Is it all still necessary? If you can do the job on a single machine, isn\u2019t that going to be a better alternative?\n\nThis post will dig into why scale-out became so dominant, take a look at whether those rationales still hold, and then explore some advantages of scale-up architecture.\n\n## Why did we scale out in the first place?\n\nFirst, a little bit of context. Twenty years ago, Google was running into scaling problems as they were trying to crawl and index the entire web. The typical way of dealing with this would have been to buy pricier machines. Unfortunately, they didn\u2019t have a lot of money at the time and, regardless of cost, they were still going to hit limits as \u201cweb-scale\u201d went through its own exponential growth progression.\n\nIn order to be able to index every website everywhere, Google invented a new model for computation; by applying functional programming and distributed systems algorithms, they achieved almost infinite scale without requiring the purchase of \u201cbig iron\u201d hardware. Instead of bigger computers, they could just tie together a lot of small computers with clever software. This was \u201cscaling out\u201d to more machines instead of \u201cscaling up\u201d to bigger ones.\n\nGoogle published a series of three papers in rapid succession that changed the way people build and scale software systems. These papers were\u00a0 [GFS](https://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf) (2003) which tackled storage, [MapReduce](https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf) (2004) which handled computation, and [BigTable](https://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf) (2006) which had the rudiments of a database.\n\nDoug Cutting, who implemented the techniques in these papers and released them as open source, [said](https://www.zdnet.com/article/hadoop-creator-google-is-living-a-few-years-in-the-future-and-sending-the-rest-of-us-messages/), \u201cGoogle is living a few years in the future and sending the rest of us messages.\u201d (Unfortunately, Google didn\u2019t get very far in the time travel business, having devoted much of their development efforts to their bug-ridden [Goat Teleporter](https://bugs.chromium.org/p/chromium/issues/detail?id=31482).)\n\nReading the MapReduce paper for the first time, I felt like Google had created a whole new way of thinking. I joined Google in 2008, hoping to be a part of that magic. Shortly thereafter, I started working on productizing their scale-out query engine [Dremel](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36632.pdf), which became BigQuery.\n\nIt is difficult to overstate the impact of the architectural change heralded by the scale-out revolution. If you\u2019re building \u201cserious\u201d infrastructure, these days, you have to scale out via a complex distributed system. This has led to popularization of new techniques for consensus protocols, new ways of deploying software, and more comfort with relaxed consistency. Scale up was limited to legacy code bases that clung to their single-node architectures.\n\n## My workload couldn\u2019t _possibly_ fit on one machine \\[\u274c\\]\n\nThe first and primary rationale for scaling out is that people believe they need multiple machines to handle their data. In a long [post](https://motherduck.com/blog/big-data-is-dead/), I argued that \u201cBig Data is Dead,\u201d or, specifically, that data sizes tend to be smaller than people think, that workloads tend to be smaller still, and that a lot of data never gets used. If you don\u2019t have \u201cBig Data,\u201d then you almost certainly don\u2019t need scale-out architectures. I won\u2019t rehash those same arguments here.\n\nI can start with a simple chart, which shows how much bigger AWS instances have gotten over time. Widely-available machines now have 128 cores and a terabyte of RAM. That\u2019s the same amount of cores as a Snowflake XL instance, with four times the memory.\n\n![image 2](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimage7_65330fe4d2.png%3Fupdated_at%3D2023-05-18T11%3A12%3A23.376Z&w=3840&q=75)\n\nThe Dremel [paper](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36632.pdf), written in 2008, included some benchmarks running a 3,000 node Dremel system against an 87 TB dataset. Today you can get equivalent performance on a single machine.\n\nAt the time, Dremel\u2019s capabilities seemed impossible without indexes or pre-computed results; everyone else in the database world was trying to avoid table scans, but they said, \u201cNah, we\u2019re just going to do table scans really fast and turn every query into a table scan.\u201d By throwing huge numbers of machines at problems, they were able to achieve performance that seemed like black magic. Fifteen years later, we can get similar performance without resorting to any magic at all, or even a distributed architecture.\n\nIn the [appendix](https://motherduck.com/blog/the-simple-joys-of-scaling-up/#appendix-dremel-in-a-box), I walk through the math to show that it would be possible to achieve this level of performance in a single node. This chart shows various resources and how they compare to what would be needed to achieve equivalent performance from the paper. Higher bars are better.\n\n![image 3](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimage1_ab5f68748b.png%3Fupdated_at%3D2023-05-18T11%3A12%3A23.608Z&w=3840&q=75)\n\nIn this we see that one machine can achieve performance of the 3,000 node Dremel cluster under \u201chot\u201d and \u201cwarm\u201d cache conditions. This is reasonable given that many scale-out systems, like Snowflake, rely on local SSD for cache in order to get good performance. If the data was \u201ccold\u201d (in an object store like S3) we could still achieve the requisite performance, but we\u2019d need a different instance type to do so.\n\n## I could scale up but larger machines are too expensive \\[\u274c\\]\n\nScaling up used to mean dramatically increasing your costs. Want a machine that is twice as powerful? It might have cost you several times as much.\n\nIn the cloud, everything gets run on virtual machines that are small slices of much larger servers. Most people don\u2019t pay much attention to how big these are, because there are few workloads that need the whole machine. But these days, the physical hardware capacities are massive, often having core counts in the hundreds and memory in the terabytes.\n\nIn the cloud, you don\u2019t need to pay extra for a \u201cbig iron\u201d machine because you\u2019re already running on one. You just need a bigger slice. Cloud vendors don\u2019t charge proportionally more for a larger slice, so your cost per unit of compute doesn\u2019t change if you\u2019re working on a tiny instance or a giant one.\n\nIt is easiest to think about the problem in terms of cost to achieve a given level of performance. In the past, larger servers were more expensive per unit of compute power. Nowadays, in the modern cloud, the price for a given amount of compute on AWS is constant until you hit a very large size.\n\n![image 4](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimage8_b30d4e394a.png%3Fupdated_at%3D2023-05-18T11%3A12%3A23.391Z&w=3840&q=75)\n\nThe other advantage that you have in the cloud is that you don\u2019t need to keep spare hardware around. That\u2019s your cloud provider\u2019s job. If your server crashes, AWS will respawn your workload in a new machine; you might not even notice. They\u2019re also constantly refurbishing the datacenter hardware, and a lot of important improvements get done without any work on your part.\n\nCloud architectures also enable separation of storage and compute, which means that compute instances often store very little data. This means that in the event of a failure, a replacement can be spun up very quickly since you don\u2019t have to reload any data. This can reduce the need for a hot standby.\n\n## Scaling out is more reliable \\[ **\u2014**\\]\n\nScale out architectures are generally considered to be more reliable; they are designed to be able to keep running despite lots of different types of failures. However, scale out systems haven\u2019t significantly improved reliability, and you can get good enough reliability from scaling up.\n\nAvailability in the cloud is often dominated by external factors; someone fat-fingers a configuration and resizes a cluster to 0 (this happened briefly in BigQuery several years ago), network routing gets messed up (the cause of historical multi-service Google outage), the auth service you rely upon is down, etc. Actual SLA performance can be dominated by these factors, which can cause correlated failures when failures happen across multiple systems and products.\n\nAs a rough rule of thumb, cloud scale-out databases and analytics providers offer a 4-9s SLA (99.99% availability). On the other hand, people running their own scale-up systems have been holding themselves to at least that threshold of availability for a long time. Many banks and other enterprises have 5- and 6- 9 mission critical systems that are being run on scale-up hardware.\n\nReliability is also about durability as well as availability. One of the knocks against scale-up systems was that in the event of a failure, you needed to have a replica of the data somewhere. Separation of storage and compute basically solves this problem. Once the final destination for storage is not in the same machine where you perform the compute, you don\u2019t have to worry about the lifetime of the machine running the compute.\u00a0 The basic shared disk infrastructure supplied by cloud vendors, like EBS or Google Persistent Disk, leverages highly-durable storage under the covers so that applications can get high degrees of durability without needing to be modified.\n\n## How to stop worrying and love the single node\n\nSo we\u2019ve seen that the three main arguments for scale out \u2013 scalability, cost, and reliability \u2013 are not as compelling as they might have been decades ago. There are also some benefits of scaling up, that seem to have been forgotten, that we\u2019ll discuss here.\n\n### KISS: Keep it Simple, Stupid \\[\u2705\\]\n\nSimplicity. Scale out systems are significantly more difficult to build, deploy, and maintain. As much as engineers love to debate the merits of Paxos vs RAFT, or CRDTs, it is hard to argue that these things don\u2019t make the system significantly more complex to build and maintain. Mere mortals have a hard time reasoning about these systems, how they work, what happens when they fail, and how to recover.\n\nHere is a [network diagram](https://en.wikipedia.org/wiki/Paxos_(computer_science)) from Wikipedia describing the \u201csimple\u201d path of the Paxos distributed consensus algorithm, showing no failures. If you are building a distributed database and want to handle writes to more than one node, you\u2019ll need to build something like this:\n\n![image 5](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimage6_e2158026fb.png%3Fupdated_at%3D2023-05-10T13%3A39%3A01.526Z&w=3840&q=75)\n\nThe actual protocol here is not as important as the fact that this is the simplest case of one of the more basic algorithms for distributed consensus. Engineering millenia have gone into implementing these algorithms. On a single node system, these algorithms are generally unnecessary.\n\nBuilding software for distributed systems is just harder than building on a single node. Distributed databases need to worry about shuffling data between nodes for joins, and aligning data to particular nodes. Single-node systems are dramatically simpler; to do a join you just create a hash table and share pointers. There are no independent failures that you have to recover from.\n\nThe downsides of complexity aren\u2019t just felt by the programmers building the systems themselves. Abstractions leak, so things like eventual consistency, storage partitioning, and failure domains need to be handled by developers and end users. The CAP theorem is real, so users of distributed systems will need to make active tradeoffs between consistency, availability, and what to do when you get network failures.\n\nDeploying and maintaining single node systems are generally a lot easier. They are up or they are down. The more moving parts you have, the greater the number of things that can go wrong and the higher the likelihood. Single nodes have one place to look for problems, and the problems they have are easier to diagnose.\n\n## Perf: The Final Frontier \\[\u2705\\]\n\nGiven a choice between faster or slower, nearly everyone will choose faster. Single node systems have important performance advantages over distributed systems. If you just think about it in a vacuum, adding a network hop is going to be strictly slower than avoiding one. When you add things like consistency protocols, this impact can get much worse. A single node database can commit a transaction in a millisecond, whilst a distributed one might take tens or hundreds of milliseconds.\n\nWhile distributed systems can improve overall throughput when the system is network bound, they also generate significant additional network usage for non-trivial work. For example, if two distributed datasets need to be joined, if they haven\u2019t been carefully co-partitioned, data shuffling will add considerable latency. There really isn\u2019t a viable way to make arbitrary distributed joins as fast as they are on a single node system.\n\nTo show an example of why a distributed architecture is going to have limitations on performance, take a look at BigQuery\u2019s stylized architecture diagram:\n\n![image bq](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimage2_4e74a3051f.png%3Fupdated_at%3D2023-05-10T13%3A39%3A01.485Z&w=3840&q=75)_Image by Google Cloud, [https://cloud.google.com/bigquery/docs/storage\\_overview](https://cloud.google.com/bigquery/docs/storage_overview)_\n\nThe petabit network that connects everything may sound fast, but it is still a bottleneck because so many operations need to move data across the network. Most non-trivial queries are network bound. A single node system would need to move far less data since there is no need to do a shuffle.\n\n## Waiting for Mr Moore\n\nWe looked at the rationales behind scaling out and saw that they are much weaker than they had been in the past.\n\n1. **\u274cCapacity**. Modern single-node systems are huge and can handle almost any workload.\n2. **\u274cReliability**. Scaling out doesn\u2019t necessarily lead to more robust systems.\n3. **\u2014 Cost**. Cloud vendors don\u2019t charge more per core for larger VM sizes so cost is a wash.\n\nWe also talked about some of the benefits of scale up:\n\n1. **\u2705Simplicity**. Simple systems are easier to build, operate, and improve.\n2. **\u2705Performance**. A distributed system will almost always display higher latency, especially tail latency, than a single node system.\n\nLet\u2019s say you\u2019re not convinced, and you need to scale out. But what about in 5 years, when machines are an order of magnitude bigger?\n\nWe\u2019re ready for a new generation of systems that take advantage of single-node performance. Innovation will move faster, and you\u2019ll be able to focus on actually solving problems rather than in coordinating complex distributed systems.\n\n## Appendix Dremel in a box\n\nThis appendix compares the benchmark results from the Dremel paper with running a similar workload on a single large machine on modern hardware. While it would be nice to have a practical outcome to demonstrate it, it is easy to argue with benchmark configurations and whether something is actually a fair comparison. Instead, we\u2019ll show that modern hardware should be up to the challenge.\n\nThe [paper](https://research.google/pubs/pub36632/) authors ran on a 3,000 node Dremel cluster. For the record, this much hardware in BigQuery would cost you more than $1M a year. We\u2019ll compare it to an [i4i.metal](https://instances.vantage.sh/aws/ec2/i4i.metal) instance in AWS that costs $96k a year, has 128 cores and 1T of RAM. We\u2019ll use this to run a side-by side bake-off.\n\nHere is a snippet from the paper that shows the computation that they ran to benchmark against MapReduce:\n\n![image appendix](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimage7_8fb68e3179.png%3Fupdated_at%3D2023-05-10T13%3A39%3A02.686Z&w=3840&q=75)![image appendix](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimage4_d23fcac4e3.png%3Fupdated_at%3D2023-05-18T11%3A19%3A04.246Z&w=3840&q=75)\n\nIn the Dremel paper, the main performance result showed being able to do a scan and aggregation query over 85B records in about 20 seconds, reading half a terabyte of data. This was orders of magnitude faster than MapReduce-based systems. It was also far beyond what you could do in more traditional scale-up systems at the time.\n\nIn order to match the level of performance in the paper, you\u2019d need to be able to scan 4.5B rows and 25GB of data per second.\n\n### CPU\n\nSingleStore has an old blog post and demo showing that they can scan more than 3B rows per second per core, which would mean that on a machine the size of our I4i you\u2019d be able process 384 B rows per second, almost two orders of magnitude more than we need to match Dremel. Even if it takes 50x more processing power to count the words in a text field, we still have a comfortable buffer.\n\n### Memory\n\nMemory bandwidth on a single server is likely going to be in the TB/s, so that likely isn\u2019t an issue. As long as the data is staged in memory, we should have no problem at all reading 500 GB in 20 seconds. The columns used in the query would take up half of the memory in the machine, so if we have those pre-cached, we\u2019d still have half a terabyte of memory in order to do the processing or to store inactive cache. However, this feels like cheating, since it relies on having the exact columns needed in the query cached in memory ahead of time.\n\n### Local Disk\n\nWhat if the data that we need were stored on the local SSD? Many databases, Snowflake, for example, use local SSD as staging locations for hot data. The I4i servers have a total 30TB of NVMe SSD, which means we can fit 30 times more in the cache on SD than we could in memory, and 60 times more than we need for this query. It doesn\u2019t seem unreasonable that the active columns in this query would be cached in the SSD under a reasonable caching policy.\n\nIf capacity isn\u2019t an issue, what about bandwidth? NVMe drives are fast, but are they fast enough? The 8 disks in these instances can do a total 160k IOPS per second, with a maximum size of 256KB for each operation. This means we can read 40 GB/second, which is more than the 25 we need. It isn\u2019t a whole lot of headroom, but it should still work.\n\n### Object Store\n\nFinally, what if we wanted to do it \u201ccold,\u201d where none of the data was cached? After all, one of the benefits of Dremel was that it could read data directly from object storage. Here is where we\u2019re going to run into a limitation; the I4i instance only has 75 Gigabits/sec of networking capacity, or roughly 9 GB/s. That\u2019s about a third of what we\u2019d need to be able to read directly from object storage.\n\nThere are instances that have much higher memory bandwidth; the TRN1 instances have 8 100-gigabit network adapters. This means you can do 100 GB/sec, significantly higher than our requirements. It would be reasonable to assume that these 100 Gb NICs will be more widely deployed in the future and make it to additional instance types.\n\nWe acknowledge that just because you have hardware available in a machine doesn\u2019t mean that it is all uniformly accessible and that performance increases linearly with CPU count. Operating systems aren\u2019t always great at handling numbers of cores, locks scale poorly, and software needs to be written very carefully to avoid hitting a wall.\n\nThe point here isn\u2019t to make claims about the relative efficiencies of various systems; after all, this benchmark was performed 15 years ago. However, it should hopefully demonstrate that workloads that operate over a dataset nearing 100 TB are now reasonable to run on a single instance.\n\nStart using MotherDuck now!\n\n[Try 21 Days Free](https://motherduck.com/get-started/)\n\nGet Started\n\n![blog subscription icon](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fblog-subscription-icon.67ccd5ae.png&w=828&q=75)\n\n### Subscribe to motherduck blog\n\nE-mail\n\nSubscribe to other MotherDuck Updates\n\nSubmit\n\n## PREVIOUS POSTS\n\n[![Data Engineer's Highlights from PyCon DE 2023](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fpycon_de_0_49ea2be764.jpg&w=3840&q=75)](https://motherduck.com/blog/data-engineer-highlights-PyConDE-2023/)\n\n[2023/05/04 - Mehdi Ouazza](https://motherduck.com/blog/data-engineer-highlights-PyConDE-2023/)\n\n### [Data Engineer's Highlights from PyCon DE 2023](https://motherduck.com/blog/data-engineer-highlights-PyConDE-2023)\n\nData Engineer's Highlights from PyCon DE 2023\n\n[![DuckDB Tutorial For Beginners](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fgetting_started_duckdb_thumbnail_70b197b1ab.png&w=3840&q=75)](https://motherduck.com/blog/duckdb-tutorial-for-beginners/)\n\n[2024/10/31 - Mehdi Ouazza, Ryan Boyd](https://motherduck.com/blog/duckdb-tutorial-for-beginners/)\n\n### [DuckDB Tutorial For Beginners](https://motherduck.com/blog/duckdb-tutorial-for-beginners)\n\nGet up to speed quickly with DuckDB, including installation, VSCode workflow integration and your first SQL analytics project.\n\n[View all](https://motherduck.com/blog/)\n\nAuthorization Response",
  [2m  â”‚[0m     "numLines": 217,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 217
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [94mâ”Œâ”€ ðŸ¤– AGENT MESSAGE[0m
  [94mâ”‚[0m I now have comprehensive information on MotherDuck's compute instance sizes. Let me also check if there's additional documentation on ducklings/scaling:
  [94mâ””â”€[0m

  [96mðŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_qjl9o6i5/.kurt/sources/motherduck.com/blog/scaling-duckdb-with-ducklings.md
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_qjl9o6i5/.kurt/sources/motherduck.com/blog/scaling-duckdb-with-ducklings.md",
  [2m  â”‚[0m     "content": "---\ntitle: scaling-duckdb-with-ducklings\ncontent_type: blog\nsource_url: https://motherduck.com/blog/scaling-duckdb-with-ducklings\nindexed_at: '2025-11-25T19:57:17.009614'\ncontent_hash: 31a47966ffadbd25\nhas_narrative: true\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n[GO BACK TO BLOG](https://motherduck.com/blog/)\n\n# How MotherDuck Scales DuckDB in the Cloud vertically and horizontally\n\n2025/04/16 - 5 min read\n\nBY\n\n[Ryan Boyd](https://motherduck.com/authors/ryan-boyd/)\n\nIn the very first days of MotherDuck as a company, back before the co-founders had even met in person to kick off the company in mid-2022, we realized we needed a name to call the DuckDB instances we were running on behalf of users in the cloud. The idea behind the name MotherDuck, in the first place, was that we were marshaling a flock of DuckDB instances. What does a _mother_ duck manage? \"Ducklings\", of course. The name stuck, and MotherDuck's DuckDB instances became Ducklings.\n\n## How is a Duckling different from a standard Data Warehouse instance?\n\nMost data warehouses are built as monoliths, where every user in the organization shares the same data warehouse compute resources. Unless this warehouse is over-provisioned (calling all admins with 3XL instances out there!), it often begins to crack under high concurrency. Many analysts know the pain of trying to run a query while someone else is running a giant report, and having their workload slow to a crawl.\n\n![legacy_data_warehouse.png](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Flegacy_data_warehouse_fcd5053295.png&w=3840&q=75)\n\n## Per-user Tenancy for Internal Analytics / BI\n\nMotherDuck\u2019s approach with Ducklings is very different. Instead of all users sharing the same instance, each user gets their own Duckling which handles their workload and automatically shuts down if not being used.\n\n![motherduck_data_warehouse.png](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fmotherduck_data_warehouse_e933633b2e.png&w=3840&q=75)\n\nAnd, of course, all users are accessing a consistent view of the data warehouse shared either throughout the organization or with individual users in the org.\n\n## Vertical Scaling: Configurable per-user\n\nIs your CEO complaining that _they_ need more compute? Each Duckling can be scaled up or down to meet the needs of the user.\n\nMotherDuck [has three Duckling sizes](https://motherduck.com/product/pricing/): Pulse, Standard and Jumbo.\n\n![duckling_sizes.png](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fduckling_sizes_dc9bc51fe2.png&w=3840&q=75)\n\n_Author\u2019s note: We have a multi-terabyte data warehouse at MotherDuck and our CEO, Jordan, is able to use the smallest Ducklings, called Pulses to understand what is going on in the business every day_\n\n![duckling_size_example.png](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fduckling_size_example_8a972f4865.png&w=3840&q=75)\n\n## Horizontal Read Scaling: Configurable per-user\n\nSometimes the data warehouse doesn't know the identity of the end users. For example, BI tools typically share a single database connection but then may have dozens of users running queries at the same time. This would ordinarily break the \"one-user-per-duckling\" pattern.\n\nMotherDuck\u2019s [read scaling](https://motherduck.com/docs/key-tasks/authenticating-and-connecting-to-motherduck/read-scaling/) is designed for these types of cases \u2013 providing an extra boost in compute through horizontal scaling and maintaining the pattern of \u201cone-user-per-duckling!\u201d\n\n![duckling_read_scaling.png](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fduckling_read_scaling_64da81363c.png&w=3840&q=75)\n\n## Duckling-powered Customer-facing Analytics\n\nCustomer-facing analytics use cases have different requirements than an analytics stack built to power your internal data teams. It often starts with a simple customer ask \u2013 eg \u201cI want to see a dashboard of revenue trends\u201d \u2013 which engineering implements on top of the transactional database (like Postgres). Eventually, with more customer demands and growth, your transactional database is on fire. You\u2019re spending all day experimenting with different indexes or blocked by an eng team that owns database configuration and you\u2019re searching for an analytics solution.\n\n![traditional_app.png](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Ftraditional_app_641d5f371e.png&w=3840&q=75)\n\nMotherDuck\u2019s per-user tenancy model is especially powerful for these types of applications. Each customer can have their own Duckling(s) with isolated data, mitigating many types of security concerns with multitenant databases. Since each user has their own Duckling(s), you can rid yourself of scale anxiety and know that MotherDuck will always be ready to handle new customers as fast as your sales team can sign deals.\n\n![data_app_scaling_motherduck.png](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fdata_app_scaling_motherduck_f7a1861ed4.png&w=3840&q=75)\n\nAs we saw with the internal data analytics use case, you can configure the Duckling size per customer, enabling you to offer higher levels of service and scale to your most important customers.\n\n## Scaling from your Duckling back to the Laptop\n\nHistorically, laptops were extremely under-powered and you needed to scale to the cloud to get fast compute resources. With laptops now being as powerful as supercomputers of yesteryear, we still scale to the cloud for 24x7 availability, sharing/collaboration, and centralized data management, but the powerful chips on our laps are underutilized.\n\nWith MotherDuck, you can scale your workloads back to your laptop to take advantage of local compute power and zero-latency in combination with the power offered by your cloud-based Duckling. This happens automatically in the MotherDuck UI to enable the quick aggregation and filtering of data in the Column Explorer. The MotherDuck SQL query planner automatically decides whether to bring the compute to the data or the data to the compute. We call this [Dual Execution](https://motherduck.com/docs/key-tasks/running-hybrid-queries/) and we wrote a [CIDR paper](https://www.cidrdb.org/cidr2024/papers/p46-atwal.pdf) on this technology (formerly called hybrid query execution).\n\nAs you build your own applications, you can decide whether to take advantage of client-side compute and zero latency queries using Dual Execution, or have all the compute happen on MotherDuck\u2019s servers.\n\n## Go launch your flock of Ducklings\n\nMotherDuck makes it easy to scale from megabytes to terabytes with a combination of per-user Duckling tenancy, vertical scaling to more powerful Ducklings, horizontal scaling to more Ducklings and dual execution. These scaling techniques enable the super-efficient DuckDB SQL engine to power internal data analytics as well as customer-facing analytics with ease.\n\n[Try MotherDuck today](https://app.motherduck.com/?auth_flow=signup) with our 21-day free trial. And, if you want to learn more about how others (including Okta and smallpond) are scaling data workloads using DuckDB, watch our [recent panel of experts discussing scale](https://motherduck.com/webinar/scaling-duckdb-panel-ondemand/).\n\n> \"We've now got these new levers for performance scaling because we can split and store the data and query efficiently as needed. If we need to handle a load spike or a huge amount of queries, we can spin up more ducklings on demand.\"\n>\n> [Ravi Chandra, CTO @ Dexibit](https://motherduck.com/case-studies/dexibit/)\n\n### TABLE OF CONTENTS\n\n[How is a Duckling different from a standard Data Warehouse instance?](https://motherduck.com/blog/scaling-duckdb-with-ducklings/#how-is-a-duckling-different-from-a-standard-data-warehouse-instance)\n\n[Per-user Tenancy for Internal Analytics / BI](https://motherduck.com/blog/scaling-duckdb-with-ducklings/#per-user-tenancy-for-internal-analytics-bi)\n\n[Vertical Scaling: Configurable per-user](https://motherduck.com/blog/scaling-duckdb-with-ducklings/#vertical-scaling-configurable-per-user)\n\n[Horizontal Read Scaling: Configurable per-user](https://motherduck.com/blog/scaling-duckdb-with-ducklings/#horizontal-read-scaling-configurable-per-user)\n\n[Duckling-powered Customer-facing Analytics](https://motherduck.com/blog/scaling-duckdb-with-ducklings/#duckling-powered-customer-facing-analytics)\n\n[Scaling from your Duckling back to the Laptop](https://motherduck.com/blog/scaling-duckdb-with-ducklings/#scaling-from-your-duckling-back-to-the-laptop)\n\n[Go launch your flock of Ducklings](https://motherduck.com/blog/scaling-duckdb-with-ducklings/#go-launch-your-flock-of-ducklings)\n\nStart using MotherDuck now!\n\n[Try 21 Days Free](https://motherduck.com/get-started/)\n\nGet Started\n\n![blog subscription icon](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fblog-subscription-icon.67ccd5ae.png&w=828&q=75)\n\n### Subscribe to motherduck blog\n\nE-mail\n\nSubscribe to other MotherDuck Updates\n\nSubmit\n\n## PREVIOUS POSTS\n\n[![Close the Loop: Faster Data Pipelines with MCP, DuckDB & AI](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fmcp_blog_e4bfe2279d.png&w=3840&q=75)](https://motherduck.com/blog/faster-data-pipelines-with-mcp-duckdb-ai/)\n\n[2025/04/15 - Mehdi Ouazza](https://motherduck.com/blog/faster-data-pipelines-with-mcp-duckdb-ai/)\n\n### [Close the Loop: Faster Data Pipelines with MCP, DuckDB & AI](https://motherduck.com/blog/faster-data-pipelines-with-mcp-duckdb-ai)\n\nHow the MCP can accelerate data engineering workflows by connecting AI copilots directly to data tools like DuckDB\n\n[![Streaming in the Fast Lane: Oracle CDC to MotherDuck Using Estuary](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2FEstuary_blog_new_4509d479b7.png&w=3840&q=75)](https://motherduck.com/blog/streaming-oracle-to-motherduck/)\n\n[2025/04/17 - Emily Lucek](https://motherduck.com/blog/streaming-oracle-to-motherduck/)\n\n### [Streaming in the Fast Lane: Oracle CDC to MotherDuck Using Estuary](https://motherduck.com/blog/streaming-oracle-to-motherduck)\n\nDucks and estuaries go together. So it\u2019s no surprise that MotherDuck, a cloud data warehouse, pairs well with Estuary, a data pipeline platform.\n\n[View all](https://motherduck.com/blog/)\n\nAuthorization Response",
  [2m  â”‚[0m     "numLines": 144,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 144
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [94mâ”Œâ”€ ðŸ¤– AGENT MESSAGE[0m
  [94mâ”‚[0m Now I have all the information needed. Let me write the answer:
  [94mâ””â”€[0m

  [96mðŸ”§ TOOL:[0m Write â†’ /tmp/answer_without_kg_9.md
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "create",
  [2m  â”‚[0m   "filePath": "/tmp/answer_without_kg_9.md",
  [2m  â”‚[0m   "content": "<4267 chars>",
  [2m  â”‚[0m   "structuredPatch": [],
  [2m  â”‚[0m   "originalFile": null
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [94mâ”Œâ”€ ðŸ¤– AGENT MESSAGE[0m
  [94mâ”‚[0m I've searched through the MotherDuck sources and written a comprehensive answer to `/tmp/answer_without_kg_9.md`.
  [94mâ”‚[0m 
  [94mâ”‚[0m **Summary of findings:**
  [94mâ”‚[0m 
  [94mâ”‚[0m MotherDuck offers **5 compute instance sizes** (called "Ducklings"):
  [94mâ”‚[0m 
  [94mâ”‚[0m 1. **Pulse** - Smallest, serverless, pay-per-query (CU-based)
  [94mâ”‚[0m 2. **Standard** - For typical data engineering workloads ($1.20-1.80/hr)
  [94mâ”‚[0m 3. **Jumbo** - For larger workloads with complex aggregations ($3.60/hr, Business plan only)
  [94mâ”‚[0m 4. **Mega** - For demanding jobs at large scale ($10.80/hr, Business plan only)
  [94mâ”‚[0m 5. **Giga** - Largest instances for toughest transformations (Contact sales, Business plan only)
  [94mâ”‚[0m 
  [94mâ”‚[0m The Free and Lite plans have access to 1-2 instance types respectively, while the Business plan has access to all 5 types.
  [94mâ””â”€[0m

  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ðŸ“Š TURN 1 METRICS
     Tokens: 2,128 | Cost: $0.3981
     Cumulative: 2,128 tokens | $0.3981
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  âœ… TASK COMPLETE
     Reason: llm: The agent has presented a summary of findings without asking for any user input, indicating task completion rather than a request for continuation.

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ âœ… SESSION COMPLETE
â•‘    Turns: 1 | Tools: 7 | Duration: 75.6s
â•‘    Tokens: 2,128 | Cost: $0.3981
â•‘    Stop reason: Task completed (no follow-up questions)
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   ðŸ§  Running LLM judge evaluation...
   ðŸ§  LLM Judge score: 0.25
