# Scenario: answer_motherduck_without_kg

**Status**: âœ… PASSED
**Timestamp**: 20251228_210127

**Duration**: 110.27 seconds
**Tokens Used**: 0

---

## Conversation


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ SCENARIO: answer_motherduck_without_kg
   Answer MotherDuck questions by searching sources directly (no KG)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”


ğŸ” Verifying .claude installation...
   âœ“ .claude folder exists at /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_cpnchk8w/.claude
   âœ“ Skills: 0 found
   âœ“ Commands: 0 found

ğŸ” Filtering to questions: [6]

ğŸ§ª Running 1 of 10 question(s) defined in questions_motherduck.yaml


======================================================================
â“ Question 6/10
...How do I migrate data from a local DuckDB database to MotherDuck?
======================================================================


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ’¬ QUESTION 6
â”‚ Answer this question by searching through the .kurt/sources/ directory:

...How do I migrate data from a local DuckDB database to MotherDuck?

Required Steps:
1. Search for relevant markdown files in .kurt/sources/ using glob and grep
2. Read the most relevant files (aim for 3-5 most relevant sources)
3. As you read each file, keep track of:
   - The file path
   - The file title/name
   - Key information extracted from that file
4. Synthesize a comprehensive answer based on the information found
5. Write your answer to: /tmp/answer_without_kg_6.md

IMPORTANT - Your answer MUST have this structure:
```markdown
# Answer

[Your comprehensive answer here, drawing from the sources you read]

## Sources

List each source file you actually read and used, showing the EXACT LOCAL FILE PATH:
- .kurt/sources/motherduck.com/[path/to/file.md] - Brief description of key information used from this file
- .kurt/sources/motherduck.com/[path/to/file.md] - Brief description of key information used from this file
[etc.]

DO NOT use URLs or document titles as links. Show the actual file path you read with the Read tool.
```

The Sources section is MANDATORY - you must list every file you read to answer the question.

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ§¹ Clearing Claude Code context for clean scenario start...
   âœ“ Context cleared


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ ğŸ”„ TURN 1
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  [96mğŸ”§ TOOL:[0m Grep â†’ migrate.*DuckDB|DuckDB.*migrate|local.*MotherDuck|migration

  [96mğŸ”§ TOOL:[0m Grep â†’ attach|ATTACH.*md:

  [96mğŸ”§ TOOL:[0m Grep â†’ upload.*database|import.*data
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "mode": "files_with_matches",
  [2m  â”‚[0m   "filenames": [
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/using-sql-in-your-data-lake-with-duckdb-iceberg-dbt-and-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-motherduck-for-beginners-your-ultimate-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/bringing-duckdb-to-the-cloud-dual-execution-explained.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/data-teams.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/duckdb-users.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/privacy-policy.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/app-developers.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/fix-slow-bi-dashboards.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/partitioned-writes-parquet-ducklake.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/dominik-moritz.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/the-future-of-bi-bi-as-code-duckdb-impact.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/vibe-coding-sql-cursor.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/sql-keyboard-shortcuts-for-joyful-querying.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/spark-ducklake-getting-started.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/search-using-duckdb-part-3.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/separating-storage-compute-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/python-duckdb-vs-dataframe-libraries.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/read-scaling-preview.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/redshift-files-hunt-for-big-data.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pg to motherduck at motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/postgres-duckdb-options.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-kestra-etl-pipelines.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-union-orchestration.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/local-duckdb-ui-visual-data-analysis.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/how-to-extract-analytics-from-bluesky.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/getting-started-ducklake-table-format.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/from-data-lake-to-lakehouse-duckdb-portable-catalog.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/effortless-etl-unstructured-data-unstructuredio-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/estuary-streaming-cdc-replication.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-1.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-the-great-federator.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-tutorial-for-beginners.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-three.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-enterprise-5-key-categories.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-excel-extension.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-on-edge-raspberry-pi.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-july-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/dual-execution-dbt.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-dashboard-e2e-data-engineering-project-part-3.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-engineering-toolkit-essential-tools.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-warehouse-feature-roundup-dec-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-warehouse-feature-roundup-nov-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/csv-files-persist-duckdb-solution.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/bigquery-to-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-duckdb-snippet-sets-with-motherduck-sharing-databases.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-ducklake-support-motherduck-preview.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/analyze-sqlite-databases-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-duckdb-141-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/15-companies-duckdb-in-prod.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/MotherDuck-Visualize-Embeddings-Marimo.md"
  [2m  â”‚[0m   ],
  [2m  â”‚[0m   "numFiles": 66
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "mode": "files_with_matches",
  [2m  â”‚[0m   "filenames": [
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/whats-new-in-data-small-data-big-impact.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/pg_duckdb-postgres-analytics-just-got-faster-with-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/local-dev-cloud-prod-with-dagster-and-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-run-dbt-build-with-sub-second-execution-times.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-tutorial-for-beginners.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/ai-powered-bi-can-llms-really-generate-your-dashboards-ft-michael-driscoll.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/quacking-around-the-web.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/react-components-testing.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/what-is-a-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/why-choose-parquet-table-file-format.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/no-etl-query-raw-files.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/pandas-dataframes-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/partitioned-writes-parquet-ducklake.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/duckdb-vs-sqlite-databases.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/ducklake-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/data-warehouse-tco.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/index.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/acid-transactions-sql.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/big-data.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/result.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/auto inference.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/ENUM.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/AI.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/CLI.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/duckdb-book-summary-chapter2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/finqore.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/gardyn.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/community-and-open-source.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/why-web-developers-should-care-about-analytical-databases.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/the-future-of-bi-bi-as-code-duckdb-impact.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/the-simple-joys-of-scaling-up.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/vector-technologies-ai-data-stack.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/streaming-oracle-to-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/summer-data-engineering-roadmap.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/small-data-sf-recap.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/small-data-sf-workshops-agenda.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/search-using-duckdb-part-2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/semantic-layer-duckdb-tutorial.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/separating-storage-compute-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/redshift-files-hunt-for-big-data.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pg_duckdb-postgresql-extension-for-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pg-duckdb-release.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pgduckdb-beta-release-duckdb-postgres.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/preswald-health-data-analysis.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-window-functions-in-sql.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/new-collaboration-sharing-motherduck-data-warehouse-organization-auto-join.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/perf-is-not-enough.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-reflections-sigmod-pods-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-union-orchestration.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/just-enough-sql-for-ai.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/log-processing-savings-bacalhau-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/introducing-instant-sql.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/introducing-motherduck-for-business-analytics.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/json-log-analysis-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/how-to-extract-analytics-from-bluesky.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/getting-started-gis-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/git-for-data-part-1.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/flight-sql-vs-rest-vs-jdbc.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/from-data-lake-to-lakehouse-duckdb-portable-catalog.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/ducklake-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-1.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-text2sql-llm.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-enterprise-5-key-categories.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-excel-extension.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/dosomething-motherduck-data-warehouse-ROI.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-engineers-answer-10-top-reddit-questions.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/building-motherduck-partner-ecosystem.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/cidr-paper-hybrid-query-processing-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/csv-files-persist-duckdb-solution.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/big-data-is-dead.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-ducklake-support-motherduck-preview.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-series-seed-and-a.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/15-companies-duckdb-in-prod.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/analyze-json-data-using-sql.md"
  [2m  â”‚[0m   ],
  [2m  â”‚[0m   "numFiles": 83
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "mode": "files_with_matches",
  [2m  â”‚[0m   "filenames": [
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/using-sql-in-your-data-lake-with-duckdb-iceberg-dbt-and-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/whats-new-in-data-small-data-big-impact.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/stay-in-flow-with-motherducks-instant-sql.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/pg_duckdb-postgres-analytics-just-got-faster-with-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/simple-way-to-convert-csv-and-parquet-files.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/is-bi-too-big-for-small-data.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/local-dev-cloud-prod-with-dagster-and-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/faster-data-pipelines-development-with-mcp-and-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/from-curiosity-to-impact-how-dosomething-democratized-data.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-run-dbt-build-with-sub-second-execution-times.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-tutorial-for-beginners.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-motherduck-for-beginners-your-ultimate-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/bringing-duckdb-to-the-cloud-dual-execution-explained.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/cultivating-growth-how-gardyn-scaled-its-data-operations-with-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/trust-and-security.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/data-teams.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/duckdb-users.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/quacking-around-the-web.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/react-components-testing.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/what-is-a-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/what-is-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/local-dev-cloud-prod-dagster-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/privacy-policy.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/app-developers.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/product-analytics-motherduck-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/secure-startup-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/star-schema-data-warehouse-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/web-assembly.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/fix-slow-bi-dashboards.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/hybrid-analytics-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/modern-data-warehouse-playbook.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/no-etl-query-raw-files.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/pandas-dataframes-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/duckdb-python-quickstart-part1.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/duckdb-python-quickstart-part2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/duckdb-struct-nested-data.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/ducklake-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/diagnose-fix-slow-queries.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/index.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/acid-transactions-sql.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/big-data.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/bigquery-alternative-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/columnar-storage-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/MotherDuck extension.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/ALTER TABLE statement.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/ecosystem/tasman.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/ecosystem/marimo.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/ecosystem/corail.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/ecosystem.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/layers-multi-tenant-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/trunkrs-same-day-delivery-motherduck-from-redshift.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/udisc-motherduck-sports-management.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/community-and-open-source.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/candidate-privacy.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/atm-com-analytics-costs-sql-expressibility.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/dominik-moritz.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/vibe-coding-sql-cursor.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/streaming-oracle-to-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/small-data-manifesto.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/small-data-sf-recap.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/search-using-duckdb-part-2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/scaling-duckdb-with-ducklings.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pg_duckdb-postgresql-extension-for-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/postgres-duckdb-options.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-vercel-marketplace-native-integration.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-kestra-etl-pipelines.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-open-for-all-with-series-b.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-union-orchestration.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/local-duckdb-ui-visual-data-analysis.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/log-processing-savings-bacalhau-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/introducing-instant-sql.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/json-log-analysis-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/getting-started-ducklake-table-format.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/getting-started-gis-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/faster-data-pipelines-with-mcp-duckdb-ai.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/from-data-lake-to-lakehouse-duckdb-portable-catalog.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/ducklake-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/effortless-etl-unstructured-data-unstructuredio-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-1.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-text2sql-llm.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-the-great-federator.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-enterprise-5-key-categories.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-on-edge-raspberry-pi.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-nine.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-october-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-june-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-march-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-april-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/dual-execution-dbt.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-dbt-e2e-data-engineering-project-part-2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-engineering-toolkit-essential-tools.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-engineers-answer-10-top-reddit-questions.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/building-data-applications-with-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/cidr-paper-hybrid-query-processing-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/csv-files-persist-duckdb-solution.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/big-data-is-dead.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/bigquery-to-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-motherduck-general-availability-data-warehousing-with-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-duckdb-12-on-motherduck-cdw.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-duckdb-141-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/15-companies-duckdb-in-prod.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/authors/jacob-matson.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/authors/mehdi-ouazza.md"
  [2m  â”‚[0m   ],
  [2m  â”‚[0m   "numFiles": 117
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [94mâ”Œâ”€ ğŸ¤– AGENT MESSAGE[0m
  [94mâ”‚[0m Let me search for more specific terms related to migrating data to MotherDuck:
  [94mâ””â”€[0m

  [96mğŸ”§ TOOL:[0m Grep â†’ copy.*to.*md:|CREATE.*OR.*REPLACE|share.*database|sync.*local

  [96mğŸ”§ TOOL:[0m Grep â†’ getting.started|quickstart|beginners|tutorial
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "mode": "files_with_matches",
  [2m  â”‚[0m   "filenames": [
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/using-sql-in-your-data-lake-with-duckdb-iceberg-dbt-and-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/pg_duckdb-postgres-analytics-just-got-faster-with-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckfooding-at-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-motherduck-for-beginners-your-ultimate-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/duckdb-users.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/secure-startup-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/self-service-analytics-startups.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/hybrid-analytics-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/duckdb-python-quickstart-part1.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/hack-night.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/API.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/dexibit.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/spark-ducklake-getting-started.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/search-using-duckdb-part-3.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/separating-storage-compute-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/read-scaling-preview.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/redshift-files-hunt-for-big-data.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/scaling-duckdb-with-ducklings.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pg to motherduck at motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pg-duckdb-release.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pgduckdb-beta-release-duckdb-postgres.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/new-collaboration-sharing-motherduck-data-warehouse-organization-auto-join.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/open-lakehouse-stack-duckdb-table-formats.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/perf-is-not-enough.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-congratulates-duckdb-1.0-release.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-duckdb-dbt.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/just-enough-sql-for-ai.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/json-log-analysis-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/google-sheets-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/how-to-extract-analytics-from-bluesky.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/getting-started-ducklake-table-format.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/from-data-lake-to-lakehouse-duckdb-portable-catalog.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/estuary-streaming-cdc-replication.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-1.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/fabi-ai-llm-prompt-analysis.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-two.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-excel-extension.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-dashboard-e2e-data-engineering-project-part-3.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-engineering-toolkit-essential-tools.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-warehouse-feature-roundup-dec-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-warehouse-feature-roundup-nov-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/building-motherduck-partner-ecosystem.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/csv-files-persist-duckdb-solution.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/big-data-is-dead.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/bigquery-to-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-duckdb-snippet-sets-with-motherduck-sharing-databases.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-mega-giga-instance-sizes-huge-scale.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/analyze-json-data-using-sql.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/MotherDuck-Visualize-Embeddings-Marimo.md"
  [2m  â”‚[0m   ],
  [2m  â”‚[0m   "numFiles": 57
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "mode": "files_with_matches",
  [2m  â”‚[0m   "filenames": [
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/understanding-ducklake-a-table-format-with-a-modern-architecture.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/using-sql-in-your-data-lake-with-duckdb-iceberg-dbt-and-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/whats-new-in-data-small-data-big-impact.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/where-data-science-meets-shrek-how-buzzfeed-uses-ai.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/stay-in-flow-with-motherducks-instant-sql.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/the-future-of-bi-exploring-the-impact-of-bi-as-code-tools-with-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/the-magic-of-duckdb-extensions-for-data-engineering-and-analytics.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/one-data-tool-with-all-its-dependencies-duckdb-and-extensions.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/pg_duckdb-postgres-analytics-just-got-faster-with-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/querying-data-from-s3-with-3-lines-in-your-terminal.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/simple-way-to-convert-csv-and-parquet-files.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/is-duckdb-the-secret-to-unlocking-your-gis-potential.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/local-dev-cloud-prod-with-dagster-and-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/faster-data-pipelines-development-with-mcp-and-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/from-core-to-custom-unlocking-new-possibilities-with-duckdb-extensions.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/getting-started-with-motherduck-webinar.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/how-to-efficiently-load-data-into-ducklake-with-estuary.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-run-dbt-build-with-sub-second-execution-times.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-tutorial-for-beginners.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-vs-pandas-vs-polars-for-python-devs.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-dataviz-end-to-end-data-engineering-project-33.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-dbt-end-to-end-data-engineering-project-23.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-motherduck-for-beginners-your-ultimate-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/duckdb-python-end-to-end-data-engineering-project-13.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/bringing-duckdb-to-the-cloud-dual-execution-explained.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/build-bigger-with-small-ai-running-small-models-locally.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/cultivating-growth-how-gardyn-scaled-its-data-operations-with-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/data-visualisation-tools-with-duckdb-motherduck-hexpreset.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/a-new-paradigm-for-data-visualization-with-just-sql-markdown.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos/an-evolving-dag-for-the-llm-world-julia-schottenstein-of-langchain-at-small-data-sf-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/sql-duckdb-book-form.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/videos.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/data-teams.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/postgres-integration.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product/pricing.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/what-is-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/why-choose-parquet-table-file-format.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/product.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/product-analytics-motherduck-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/reduce-cloud-data-warehouse-costs-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/reduce-snowflake-costs-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/secure-startup-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/self-service-analytics-startups.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/sql-group-by-examples-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/hybrid-analytics-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/no-etl-query-raw-files.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/pandas-dataframes-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/partitioned-writes-parquet-ducklake.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/duckdb-python-quickstart-part1.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/duckdb-python-quickstart-part2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/duckdb-struct-nested-data.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/duckdb-vs-sqlite-databases.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/ducklake-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/data-lake-vs-data-warehouse-vs-lakehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/hack-night.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/index.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/bigquery-alternative-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/learn-more/cloud-data-warehouse-startup-guide.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/filter.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/relational API.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/relational object.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/result.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/time-series.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/window functions.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/auto inference.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/column.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/command line.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/data engineering.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/data load tool (dlt).md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/data model.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/data pipeline.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/data type.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/data visualization.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/dataset.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/SQL analytics.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/SQLAlchemy.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/Java programming language.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/JavaScript programming language.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/Julia programming language.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/Jupyter notebooks.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/MotherDuck extension.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/Online Analytical Processing (OLAP).md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/Pandas DataFrames.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/PIVOT clause.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/Python.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/S3 bucket.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/SELECT statement.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/Common Table Expressions (CTEs).md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/Dagster.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/DB-API.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/DuckDB CLI.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/DuckDB.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/ENUM.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/ETL.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/EXPLAIN clause.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/Go programming language.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/INSERT statement.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/JSON.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/getting-started-with-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/7-Zip.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/ALTER TABLE statement.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/C/C++.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/CLI.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/glossary/CSV.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/ecosystem/sqlmesh.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/events.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/ecosystem/langchain.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/ecosystem/marimo.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/ecosystem/meltano.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/ecosystem/dagster.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/ecosystem/dbt.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/ecosystem/airflow.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/customer-support.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/duckdb-book-brief.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/duckdb-book-summary-chapter2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/duckdb-book-summary-chapter3.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/duckdb-book-summary-chapter4.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/reflex-careers-gig-economy-retail.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/why-web-developers-should-care-about-analytical-databases.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/case-studies/dominik-moritz.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/taming-wild-csvs-with-duckdb-data-engineering.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/the-future-of-bi-bi-as-code-duckdb-impact.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/the-simple-joys-of-scaling-up.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/unstructured-analysis-tensorlake-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/vibe-coding-sql-cursor.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/why-learn-sql-in-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/sql-embeddings-for-semantic-meaning-in-text-and-rag.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/sql-keyboard-shortcuts-for-joyful-querying.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/sql-llm-prompt-function-gpt-models.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/streaming-data-to-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/streamlining-ai-agents-duckdb-rag-solutions.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/summer-data-engineering-roadmap.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/tableau-cloud-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/six-reasons-duckdb-slaps.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/small-data-manifesto.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/small-data-sf-recap.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/small-data-sf-workshops-agenda.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/spark-ducklake-getting-started.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/search-using-duckdb-part-1.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/search-using-duckdb-part-2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/search-using-duckdb-part-3.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/secoda-motherduck-integration-modern-duck-stack.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/semantic-layer-duckdb-tutorial.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/python-duckdb-vs-dataframe-libraries.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/read-scaling-preview.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/redshift-files-hunt-for-big-data.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pg to motherduck at motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pg_duckdb-postgresql-extension-for-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pg-duckdb-release.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pg-mooncake-columnstore.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pgduckdb-beta-release-duckdb-postgres.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/postgres-duckdb-options.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/preswald-health-data-analysis.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/pushing-geo-boundaries-with-motherduck-geobase.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-vercel-marketplace-native-integration.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-window-functions-in-sql.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/new-collaboration-sharing-motherduck-data-warehouse-organization-auto-join.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/perf-is-not-enough.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-kestra-etl-pipelines.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-open-for-all-with-series-b.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-union-orchestration.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/making-pyspark-code-faster-with-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-ai-sql-fixit-inline-editing-features.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-congratulates-duckdb-1.0-release.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-dbt-pipelines.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-duckdb-dbt.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/motherduck-headquarters-seattle-opening.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/just-enough-sql-for-ai.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/llm-data-pipelines-prompt-motherduck-dbt.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/local-duckdb-ui-visual-data-analysis.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/log-processing-savings-bacalhau-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/introducing-column-explorer.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/introducing-fixit-ai-sql-error-fixer.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/json-log-analysis-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/google-sheets-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/guide-to-coalesce-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/galileo-world-geospatial.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/geospatial-for-beginner-duckdb-spatial-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/getting-started-ducklake-table-format.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/getting-started-gis-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/flight-sql-vs-rest-vs-jdbc.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/from-data-lake-to-lakehouse-duckdb-portable-catalog.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-wasm-in-browser.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/effortless-etl-unstructured-data-unstructuredio-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/estuary-streaming-cdc-replication.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-1.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/exploring-stackoverflow-with-duckdb-on-motherduck-2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/fabi-ai-llm-prompt-analysis.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-python-e2e-data-engineering-project-part-1.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-text2sql-llm.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-the-great-federator.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-tutorial-for-beginners.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-two.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-enterprise-5-key-categories.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-excel-extension.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-on-edge-raspberry-pi.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-puppygraph-graph-model-on-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-one.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-september-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-september-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-seven.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-six.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-ten.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-may-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-nine.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-november-2023.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-november-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-november-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-october-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-january-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-july-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-june-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-march-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-eight.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-eleven.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-february-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-february-2025.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-january-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-april-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-august-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-ecosystem-newsletter-december-2023.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/dual-execution-dbt.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-110-hidden-gems.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-cognee-sql-analytics-graph-rag.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-dashboard-e2e-data-engineering-project-part-3.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/duckdb-dbt-e2e-data-engineering-project-part-2.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-engineer-highlights-PyConDE-2023.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-engineering-toolkit-essential-tools.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-engineering-toolkit-infrastructure-devops.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-warehouse-feature-roundup-oct-2024.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/differential-storage-building-block-for-data-warehouse.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/building-motherduck-partner-ecosystem.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/csv-files-persist-duckdb-solution.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/data-app-generator.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/bigquery-to-duckdb-motherduck.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-duckdb-snippet-sets-with-motherduck-sharing-databases.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/announcing-motherduck-general-availability-data-warehousing-with-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/analyze-sqlite-databases-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/analyze-x-data-nodejs-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/15-companies-duckdb-in-prod.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/analyze-data-in-azure-with-duckdb.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/analyze-json-data-using-sql.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/blog/MotherDuck-Visualize-Embeddings-Marimo.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/authors/simon-spati.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/authors/ryan-boyd.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/authors/mehdi-ouazza.md",
  [2m  â”‚[0m     ".kurt/sources/motherduck.com/authors/adithya-krishnan.md"
  [2m  â”‚[0m   ],
  [2m  â”‚[0m   "numFiles": 252
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [94mâ”Œâ”€ ğŸ¤– AGENT MESSAGE[0m
  [94mâ”‚[0m I found several relevant files. Let me read the most relevant ones about getting started with MotherDuck and migrating data:
  [94mâ””â”€[0m

  [96mğŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_cpnchk8w/.kurt/sources/motherduck.com/getting-started-with-motherduck.md

  [96mğŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_cpnchk8w/.kurt/sources/motherduck.com/videos/duckdb-motherduck-for-beginners-your-ultimate-guide.md

  [96mğŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_cpnchk8w/.kurt/sources/motherduck.com/videos/bringing-duckdb-to-the-cloud-dual-execution-explained.md

  [96mğŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_cpnchk8w/.kurt/sources/motherduck.com/product/duckdb-users.md
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_cpnchk8w/.kurt/sources/motherduck.com/getting-started-with-motherduck.md",
  [2m  â”‚[0m     "content": "---\ntitle: getting-started-with-motherduck\ncontent_type: event\nsource_url: https://motherduck.com/getting-started-with-motherduck\nindexed_at: '2025-11-25T20:36:55.713062'\ncontent_hash: eca528b7b79fabc6\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n# Product Demo: Getting Started with MotherDuck\n\n## Join us for a live demo to learn how to get started with MotherDuck, the cloud SQL analytics data warehouse extending DuckDB to the cloud.\n\nMotherDuck is now Generally Available! In this session, MotherDuck Co-Founder Ryan Boyd and Product Expert Nathaniel Thompson will show you how to maximize MotherDuck's analytics and collaboration features to take flight with your analytics workloads and applications.\n\n### Tuesday, June 18th @ 10AM PDT\n\nRegister now. We're looking forward to seeing you there!\n\n![Getting Started with MotherDuck](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2FGetting_Started_with_MD_437c0d3476.png&w=3840&q=75)\n\nGetting Started with MotherDuck\n\n## Getting Started with MotherDuck\n\nEmail address \\*\n\nNext\n\nAlready registered?Join here\n\nAuthorization Response",
  [2m  â”‚[0m     "numLines": 37,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 37
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_cpnchk8w/.kurt/sources/motherduck.com/videos/duckdb-motherduck-for-beginners-your-ultimate-guide.md",
  [2m  â”‚[0m     "content": "---\ntitle: duckdb-motherduck-for-beginners-your-ultimate-guide\ncontent_type: event\nsource_url: https://motherduck.com/videos/duckdb-motherduck-for-beginners-your-ultimate-guide\nindexed_at: '2025-11-25T20:44:57.276294'\ncontent_hash: 9ac8939ea24395a7\nhas_code_examples: true\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n[BACK TO VIDEOS](https://motherduck.com/videos/)\n\nDuckDB & MotherDuck for Beginners: Your Ultimate Guide - YouTube\n\n[Photo image of MotherDuck](https://www.youtube.com/channel/UCC0AT6XjO_ebWIifTDp5REg?embeds_referring_euri=https%3A%2F%2Fmotherduck.com%2F)\n\nMotherDuck\n\n10.8K subscribers\n\n[DuckDB & MotherDuck for Beginners: Your Ultimate Guide](https://www.youtube.com/watch?v=WYV8hvJOAQE)\n\nMotherDuck\n\nSearch\n\nWatch later\n\nShare\n\nCopy link\n\nInfo\n\nShopping\n\nTap to unmute\n\nIf playback doesn't begin shortly, try restarting your device.\n\nMore videos\n\n## More videos\n\nYou're signed out\n\nVideos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.\n\nCancelConfirm\n\nShare\n\nInclude playlist\n\nAn error occurred while retrieving sharing information. Please try again later.\n\n[Why am I seeing this?](https://support.google.com/youtube/answer/9004474?hl=en)\n\n[Watch on](https://www.youtube.com/watch?v=WYV8hvJOAQE&embeds_referring_euri=https%3A%2F%2Fmotherduck.com%2F)\n\n0:00\n\n0:00 / 36:27\n\n\u2022Live\n\n\u2022\n\nYouTube\n\n# DuckDB & MotherDuck for Beginners: Your Ultimate Guide\n\n2025/02/21\n\n## Why DuckDB is Revolutionizing Data Analytics\n\nDuckDB has experienced explosive growth in popularity, with download statistics showing remarkable adoption rates, particularly in the Python ecosystem. This open-source analytical database is designed to handle everything from quick data exploration to complex data pipelines, and it's already trusted by multiple companies in production environments.\n\n## Understanding the Small and Medium Data Revolution\n\nThe tech industry has long operated under the assumption that analytics requires big data infrastructure. However, this paradigm is being challenged by three key insights:\n\n1. **Most workloads aren't big data**: According to data from AWS Redshift and other cloud analytical databases, approximately 83% of users work with query sizes up to 1TB, and 94% work with data below 10TB.\n\n2. **Modern hardware is incredibly powerful**: Today's single machines can handle up to 24TB of memory on AWS, making distributed systems unnecessary for most use cases.\n\n3. **Distributed systems are expensive**: They require significant IO network traffic for coordination, and the development experience is considerably more complex.\n\n\nDuckDB capitalizes on these realities by enabling users to work with large datasets on a single machine, whether locally on a laptop or in the cloud via a scale-up strategy.\n\n## How DuckDB Works: The In-Process Advantage\n\nDuckDB is an open-source, in-process analytical database written in C++, designed as a single self-contained binary with all dependencies included. This architecture sets it apart from traditional databases.\n\n### Traditional Database Architecture\n\nDatabases typically fall into two categories:\n\n- **OLTP (Online Transaction Processing)**: Databases like PostgreSQL and MySQL, optimized for handling transactions with small datasets. Query times typically range from 1-10 milliseconds.\n\n- **OLAP (Online Analytical Processing)**: Databases like BigQuery and Snowflake, built for analytical queries processing large datasets. Query times can range from 100 milliseconds to several minutes.\n\n\nMost traditional databases use a client-server architecture where the database runs as a separate process, and applications connect to it through SQL queries.\n\n### The In-Process Revolution\n\nIn-process databases run directly within the application process itself. While SQLite pioneered this approach for OLTP workloads, DuckDB introduces something new: an in-process OLAP database optimized for analytical workloads.\n\nThis design enables DuckDB to:\n\n- Run on virtually any platform (laptops to cloud workflows)\n- Integrate seamlessly with any programming language\n- Execute in web browsers via WebAssembly\n- Eliminate network overhead for local operations\n\n## Getting Started with DuckDB\n\n### Installation and Basic Usage\n\nDuckDB can be installed through various methods:\n\n- Direct binary download for CLI usage\n- Package managers (Homebrew for macOS)\n- Language-specific packages (Python, R, Java, etc.)\n\nThe CLI provides a powerful interface for data exploration:\n\n```sql\nCopy code\n\n-- Simple query reading from S3\nFROM 's3://bucket/path/to/file.parquet' LIMIT 5;\n```\n\n### Key Features in Action\n\n**Friendly SQL Dialect**: DuckDB extends standard SQL with productivity enhancements, such as the FROM-first syntax shown above.\n\n**Automatic File Format Detection**: DuckDB automatically detects and handles various file formats including Parquet, CSV, JSON, Iceberg, and Delta Lake.\n\n**Extension System**: DuckDB's functionality is modular through extensions. Core extensions (like HTTPFS for S3 access) are auto-loaded when needed, while community extensions can be installed manually.\n\n## Data Persistence and the DuckDB File Format\n\nBy default, DuckDB operates in-memory, but it offers powerful persistence options:\n\n### Creating and Managing Databases\n\n```sql\nCopy code\n\n-- Attach or create a database\nATTACH 'mydatabase.ddb';\n\n-- Create a table from a query\nCREATE TABLE mytable AS SELECT * FROM source_data;\n```\n\n### The DuckDB File Format\n\nDuckDB's native file format (.ddb or .db) is:\n\n- Self-contained (all tables and metadata in one file)\n- ACID-compliant\n- Highly compressed\n- Optimized for analytical workloads\n\n### Exporting Data\n\nDuckDB supports seamless data export:\n\n```sql\nCopy code\n\n-- Export to CSV\nCOPY (SELECT * FROM mytable) TO 'output.csv';\n```\n\n## Managing Secrets and Authentication\n\nDuckDB includes a comprehensive secret management system for secure cloud access:\n\n```sql\nCopy code\n\n-- Create temporary secret using AWS credential chain\nCREATE SECRET (\n    TYPE S3,\n    PROVIDER credential_chain\n);\n```\n\nThis approach supports:\n\n- AWS SSO authentication\n- Temporary and persistent secrets\n- Multiple cloud providers\n- Secure credential storage\n\n## Scaling to the Cloud with MotherDuck\n\nMotherDuck supercharges DuckDB by transforming it from a single-player to a multiplayer analytics experience. The integration is remarkably simple:\n\n### Connecting to MotherDuck\n\n```sql\nCopy code\n\n-- Connect to MotherDuck with one command\nATTACH 'md:';\n```\n\nAuthentication requires only a MotherDuck token, which can be set as an environment variable.\n\n### Key MotherDuck Features\n\n**Dual Execution**: MotherDuck enables intelligent query execution, automatically determining whether to run computations locally or in the cloud based on data location and query requirements.\n\n**Database Sharing**: Create and share cloud databases with simple commands:\n\n```sql\nCopy code\n\n-- Create a share\nCREATE SHARE myshare FROM mydatabase;\n```\n\n**Performance Benefits**: Leveraging cloud infrastructure provides:\n\n- High-bandwidth connections to cloud storage\n- Elimination of local network bottlenecks\n- Seamless collaboration features\n\n### Cloud Storage Integration\n\nMotherDuck dramatically improves performance when querying cloud storage. In benchmarks, queries that take 11 seconds locally can complete in just 2 seconds when leveraging MotherDuck's cloud infrastructure and network proximity to storage.\n\n## The Complete Analytics Toolkit\n\nDuckDB and MotherDuck together provide:\n\n- **Simplicity**: One-command installation and cloud connection\n- **Flexibility**: Run anywhere from browsers to cloud environments\n- **Performance**: Lightning-fast analytical queries on small to medium datasets\n- **Integration**: Native support for numerous file formats and cloud providers\n- **Collaboration**: Easy data sharing and team workflows\n\nWhether you're analyzing data on your laptop, scaling computations in the cloud, or building production data pipelines, DuckDB offers a modern approach to analytics that challenges traditional big data assumptions while delivering exceptional performance and developer experience.\n\n...SHOW MORE\n\n## Related Videos\n\n[![\"Data-based: Going Beyond the Dataframe\" video thumbnail](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.us-east-1.amazonaws.com%2Fassets%2Fimg%2FData_based_f32745b461.png&w=3840&q=75)](https://motherduck.com/videos/going-beyond-the-dataframe/)\n\n[2025-11-20](https://motherduck.com/videos/going-beyond-the-dataframe/)\n\n### [Data-based: Going Beyond the Dataframe](https://motherduck.com/videos/going-beyond-the-dataframe)\n\nLearn how to turbocharge your Python data work using DuckDB and MotherDuck with Pandas. We walk through performance comparisons, exploratory data analysis on bigger datasets, and an end-to-end ML feature engineering pipeline.\n\nWebinar\n\nPython\n\nAI, ML and LLMs\n\n[![\"Empowering Data Teams: Smarter AI Workflows with Hex & MotherDuck\" video thumbnail](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.us-east-1.amazonaws.com%2Fassets%2Fimg%2FHex_Webinar_778e3959e4.png&w=3840&q=75)](https://motherduck.com/videos/smarter-ai-workflows-with-hex-motherduck/)\n\n[2025-11-14](https://motherduck.com/videos/smarter-ai-workflows-with-hex-motherduck/)\n\n### [Empowering Data Teams: Smarter AI Workflows with Hex & MotherDuck](https://motherduck.com/videos/smarter-ai-workflows-with-hex-motherduck)\n\nAI isn't here to replace data work, it's here to make it better. Watch this webinar to see how Hex and MotherDuck build AI workflows that prioritize context, iteration, and real-world impact.\n\nWebinar\n\nAI, ML and LLMs\n\n[![\"Lies, Damn Lies, and Benchmarks\" video thumbnail](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.us-east-1.amazonaws.com%2Fassets%2Fimg%2FLies_Damn_Lies_and_Benchmarks_Thumbnail_404db1bf46.png&w=3840&q=75)](https://motherduck.com/videos/lies-damn-lies-and-benchmarks/)\n\n[2025-10-31](https://motherduck.com/videos/lies-damn-lies-and-benchmarks/)\n\n### [Lies, Damn Lies, and Benchmarks](https://motherduck.com/videos/lies-damn-lies-and-benchmarks)\n\nWhy do database benchmarks so often mislead? MotherDuck CEO Jordan Tigani discusses the pitfalls of performance benchmarking, lessons from BigQuery, and why your own workload is the only benchmark that truly matters.\n\nStream\n\nInterview\n\n[View all](https://motherduck.com/videos/)\n\nAuthorization Response",
  [2m  â”‚[0m     "numLines": 301,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 301
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_cpnchk8w/.kurt/sources/motherduck.com/videos/bringing-duckdb-to-the-cloud-dual-execution-explained.md",
  [2m  â”‚[0m     "content": "---\ntitle: bringing-duckdb-to-the-cloud-dual-execution-explained\ncontent_type: tutorial\nsource_url: https://motherduck.com/videos/bringing-duckdb-to-the-cloud-dual-execution-explained\nindexed_at: '2025-11-25T20:45:20.295187'\ncontent_hash: ab4030806c409492\nhas_narrative: true\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n[BACK TO VIDEOS](https://motherduck.com/videos/)\n\nBringing DuckDB to the Cloud: Dual Execution Explained - YouTube\n\n[Photo image of MotherDuck](https://www.youtube.com/channel/UCC0AT6XjO_ebWIifTDp5REg?embeds_referring_euri=https%3A%2F%2Fmotherduck.com%2F)\n\nMotherDuck\n\n10.8K subscribers\n\n[Bringing DuckDB to the Cloud: Dual Execution Explained](https://www.youtube.com/watch?v=2eVNm4A8sLw)\n\nMotherDuck\n\nSearch\n\nWatch later\n\nShare\n\nCopy link\n\nInfo\n\nShopping\n\nTap to unmute\n\nIf playback doesn't begin shortly, try restarting your device.\n\nMore videos\n\n## More videos\n\nYou're signed out\n\nVideos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.\n\nCancelConfirm\n\nShare\n\nInclude playlist\n\nAn error occurred while retrieving sharing information. Please try again later.\n\n[Watch on](https://www.youtube.com/watch?v=2eVNm4A8sLw&embeds_referring_euri=https%3A%2F%2Fmotherduck.com%2F)\n\n0:00\n\n0:00 / 1:08:11\n\n\u2022Live\n\n\u2022\n\nYouTubeQuack & CodeMotherDuck Features\n\n# Bringing DuckDB to the Cloud: Dual Execution Explained\n\n2024/06/28\n\nBringing DuckDB's analytical power to the cloud requires more than just running it on a server. While DuckDB excels at processing data on a local machine, the dynamics of data analysis change when dealing with cloud-scale data, collaboration, and shared resources. This shift introduces challenges around [security](https://motherduck.com/learn-more/secure-startup-data-warehouse/), concurrent access, and performance, which is where a purpose-built cloud architecture becomes essential.\n\nMotherDuck, a modern cloud data warehouse, is built on DuckDB to solve these challenges. It extends DuckDB\u2019s capabilities without forking the open source project, creating a hybrid system that intelligently balances local and cloud computing. In a conversation with MotherDuck founding engineer Stephanie, she explained the architecture and the innovative query model, known as **dual execution**, that makes this possible.\n\n* * *\n\n## The MotherDuck Architecture: Beyond Hosted DuckDB\n\nA common misconception is that MotherDuck is simply DuckDB hosted in the cloud. The reality is a more sophisticated system designed to overcome the limitations of using a locally-optimized engine in a distributed environment. MotherDuck\u2019s architecture is built on three key components and a core philosophy of not forking DuckDB.\n\nInstead of maintaining a separate version, MotherDuck leverages DuckDB\u2019s powerful **extension system**. This allows MotherDuck to add new capabilities at multiple layers, including the SQL parser, optimizer, and storage interface, while staying current with the latest open source DuckDB releases. This tight integration means users benefit from the rapid innovation of the DuckDB community almost immediately.\n\nThe architecture can be broken down into three main layers:\n\n1. **The Client Extension**: This is how MotherDuck integrates with the DuckDB ecosystem. Whether a user is working in the CLI, a Python script, or a JDBC connection, a simple `ATTACH` command connects their local DuckDB instance to the MotherDuck cloud. This extension is even used to run DuckDB in the browser via WASM for the MotherDuck UI, enabling client-side processing to reduce latency and cloud compute costs.\n2. **The Compute Layer**: In the cloud, queries are processed by containerized DuckDB instances, fondly called \"ducklings.\" These compute resources are scaled based on user needs, providing the necessary CPU and memory to handle complex analytical queries on large datasets.\n3. **The Storage Layer**: DuckDB's native file format is optimized for a single writer on a local file system. This model is not well-suited for the cloud, where multiple users need to read and write to the same database concurrently. To solve this, MotherDuck implemented a differential storage system that maps a logical database file to append-only snapshot layers in cloud object storage. This design is cloud-friendly, enabling efficient in-place updates and forming the foundation for features like database sharing and time travel.\n\n* * *\n\n## Enabling Collaboration with Database Sharing and Secure Credentials\n\nThis unique architecture transforms DuckDB from a \"single-player\" tool into a collaborative \"multiplayer\" platform. One of the most significant advantages is **database sharing**. Instead of emailing SQL scripts or passing around large database files, team members within the same organization can grant query access to their databases. This streamlines collaboration, ensuring everyone works from a consistent and up-to-date version of the data.\n\nSecurity is another critical aspect of any cloud data platform. MotherDuck provides a **centralized Secret Manager**, co-designed with the DuckDB team. Users can create persistent, encrypted secrets for accessing external data sources like AWS S3, Google Cloud Storage, or Delta Lake. Once a secret is created in MotherDuck, it can be reused across different clients and sessions without needing to expose or reconfigure credentials on each local machine.\n\n* * *\n\n## Understanding Dual Execution\n\nThe most innovative feature of MotherDuck's architecture is its **dual execution model**. This is a hybrid query execution strategy where the optimizer intelligently decides whether to run parts of a query locally on the client or remotely in the MotherDuck cloud. The primary goal is to minimize data movement and leverage compute where it makes the most sense.\n\nThe process was demonstrated with a query joining two tables. When both tables reside in a MotherDuck database, the query is executed entirely in the cloud. An `EXPLAIN` plan for this query reveals that all operators, from the table scans to the final join, are marked as **remote**. The only local operation is downloading the final result set to the client.\n\nThe real power of dual execution becomes apparent when a query involves both local and cloud data. In the demonstration, one of the remote tables was copied to a local Parquet file. The query was then modified to join this local file with the table that remained in the cloud.\n\nThe `EXPLAIN` plan for this new query showed a mix of local and remote operations. The scan of the Parquet file and its associated processing happened **locally**, leveraging the user's machine. The scan of the cloud table happened **remotely** on MotherDuck's compute. The system then efficiently transferred only the necessary intermediate data to complete the join. This hybrid approach avoids needlessly uploading the local file to the cloud or downloading the entire remote table, resulting in faster and more efficient queries.\n\n* * *\n\n## Taking Control with Manual Execution Overrides\n\nWhile MotherDuck's optimizer is designed to make the most efficient choice automatically, some situations require manual control. For this, users can use the `md_run` parameter within scan functions like `read_parquet()` or `read_csv()`.\n\nBy setting `md_run = 'local'`, a user can force the scan of a remote S3 file to be executed on their local client. This involves downloading the data, which might be desirable if the data needs to be processed near the user's location or if they prefer using local credentials. Conversely, setting `md_run = 'remote'` forces the operation to run in the MotherDuck cloud.\n\nThis control is especially useful for performance tuning. A direct comparison showed that querying a 2GB Parquet file on S3 was significantly faster when executed remotely in MotherDuck (25 seconds) compared to a local DuckDB client that had to first download the data (36 seconds). By pushing the computation to the data's location, MotherDuck minimizes network I/O and delivers results more quickly.\n\n* * *\n\n## A Symbiotic Future for Local and Cloud Analytics\n\nMotherDuck's architecture is a thoughtful extension of DuckDB's core principles, adapting its local-first power for the demands of the cloud. The dual execution model provides a flexible and efficient bridge between a user's laptop and cloud data, optimizing workloads in a way that pure-cloud or pure-local systems cannot.\n\nThis relationship is symbiotic. As the largest production user of DuckDB, MotherDuck continuously pushes the engine to its limits, uncovering opportunities for improvement and contributing enhancements back to the open source project. This collaboration ensures that both DuckDB and MotherDuck will continue to evolve, offering a powerful and seamless analytical experience that spans from local exploration to cloud-scale production.\n\n...SHOW MORE\n\n## Related Videos\n\n[![\"Escaping Catalog Hell: A Guide to Iceberg, DuckDB & the Data Lakehouse\" video thumbnail](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Ficeberg_video_thumbnail_adfdabe3d6.jpg&w=3840&q=75)\\\\\n\\\\\n46:26](https://motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse/)\n\n[2025-06-12](https://motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse/)\n\n### [Escaping Catalog Hell: A Guide to Iceberg, DuckDB & the Data Lakehouse](https://motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse)\n\nBuilding a data stack means choosing between easy SaaS and complex open-source. Apache Iceberg is a middle ground, but its catalog is a hurdle. New tools now simplify using Iceberg with DuckDB to create a flexible, local data lakehouse.\n\nMotherDuck Features\n\n[![\"Instant SQL Mode - Real Time Feedback to Make SQL Data Exploration Fly\" video thumbnail](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2FG_Se_B_Sox_AW_Fg_HD_f4fddaa9ab.jpg&w=3840&q=75)](https://motherduck.com/videos/instant-sql-mode-real-time-feedback-to-make-sql-data-exploration-fly/)\n\n[2025-04-23](https://motherduck.com/videos/instant-sql-mode-real-time-feedback-to-make-sql-data-exploration-fly/)\n\n### [Instant SQL Mode - Real Time Feedback to Make SQL Data Exploration Fly](https://motherduck.com/videos/instant-sql-mode-real-time-feedback-to-make-sql-data-exploration-fly)\n\nHamilton Ulmer shares insights from MotherDuck's Instant SQL Mode, exploring how real-time query result previews eliminate the traditional write-run-debug cycle through client-side parsing and DuckDB-WASM caching.\n\nSQL\n\nTalk\n\nMotherDuck Features\n\n[![\"DuckDB: Run dbt build with sub-second execution times\" video thumbnail](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2FScreenshot_2025_03_26_at_3_40_16_PM_c6e3a8096f.png&w=3840&q=75)\\\\\n\\\\\n24:06](https://motherduck.com/videos/duckdb-run-dbt-build-with-sub-second-execution-times/)\n\n[2025-03-13](https://motherduck.com/videos/duckdb-run-dbt-build-with-sub-second-execution-times/)\n\n### [DuckDB: Run dbt build with sub-second execution times](https://motherduck.com/videos/duckdb-run-dbt-build-with-sub-second-execution-times)\n\nWhether you're new to DuckDB or looking to optimize your workflows, this session will provide practical insights to help you leverage its full potential.\n\nYouTube\n\nData Pipelines\n\ndbt\n\nMotherDuck Features\n\n[View all](https://motherduck.com/videos/)\n\nAuthorization Response",
  [2m  â”‚[0m     "numLines": 184,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 184
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_cpnchk8w/.kurt/sources/motherduck.com/product/duckdb-users.md",
  [2m  â”‚[0m     "content": "---\ntitle: duckdb-users\ncontent_type: product_page\nsource_url: https://motherduck.com/product/duckdb-users/\nindexed_at: '2025-11-25T20:15:52.565114'\ncontent_hash: dfb4ed9cd3383b9d\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n# local + Cloud analytics,  backed by the same database\n\nA duckdb-powered data warehouse for production grade analytics\n\n[Get Started](https://motherduck.com/get-started/)\n\nLEARN MORE\n\nWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuckWhy MotherDuck\n\n## Transform Solo DuckDB Into a Collaborative Powerhouse\n\nDuckDB's in-process nature means your data stays trapped on your machine. MotherDuck eliminates this limitation with a simple \"md:\" prefix.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fshare-data-not-files.db8baefd.png&w=3840&q=75)\n\n### Share Data, Not Files\n\nNo more exporting files or managing S3 buckets to share your work. Create database shares with specific team members while maintaining the familiar DuckDB experience.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fmultiple-users-one-database.0b9d7dc7.png&w=3840&q=75)\n\n### Multiple Users, One Database\n\nEnable simultaneous access for Data Engineers, Analytics teams, and Scientists to the same datasets. Each user gets their own dedicated compute instance \u201cduckling\u201d for concurrent queries without conflicts.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsticky-bring-the-flock-together.be57c6e9.png&w=2048&q=75)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsticky-bring-the-flock-together.be57c6e9.png&w=2048&q=75)\n\n## Local Speed with Cloud-Scale Production Power\n\nEnjoy the best of both worlds with a seamless dev/prod workflow for your data. Develop locally for immediate feedback, then deploy identical workloads to the cloud with zero code changes.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Frapid-iteration-zero-cost.ff94f539.png&w=3840&q=75)\n\n### Rapid Iteration at Zero Cost\n\nExperiment locally with lightning-fast feedback cycles without spending a dime. When your solution is ready, your exact same queries work in the cloud by simply adding \"md:\" to your connection.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ftest-safely-deploy-confidently.ed329fbf.png&w=3840&q=75)\n\n### Test Safely, Deploy Confidently\n\nPrototype complex data transformations without risking expensive cloud resources. This local dev, cloud prod model ensures what works locally will perform at scale in production.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fship-data-solutions-faster.bdfdd521.png&w=3840&q=75)\n\n### Ship Data Solutions Faster\n\nEliminate the friction between development and deployment environments. Your team can innovate with quick local tests and push proven solutions to cloud production seamlessly.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsticky-scalable-node-architecture.91c200dd.png&w=1920&q=75)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsticky-scalable-node-architecture.91c200dd.png&w=1920&q=75)\n\n## Familiar Interface with Intelligent Superpowers\n\nMotherDuck maintains the DuckDB interface you love while adding thoughtful, AI-backed intelligent assistance. Experience enhanced productivity with features designed for SQL experts and business users.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fvisual-insights-at-a-glance.60ec6358.png&w=3840&q=75)\n\n### Visual Insights at a Glance\n\nBeautiful visualizations help you understand complex data patterns immediately. MotherDuck's design affordances make exploration intuitive while preserving the power of DuckDB's analytical capabilities.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fautomatic-error-correction.fe59afe0.png&w=3840&q=75)\n\n### Automatic Error Correction\n\n\"Fix It\" repairs common syntax errors with a single click, eliminating frustration from missing commas or quotes. This intelligent assistance ensures everyone on your team can work productively with SQL, regardless of expertise level.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fnatural-language-to-sql.72331bc3.png&w=3840&q=75)\n\n### Natural Language to SQL\n\nNever written SQL before? Non-technical team members can contribute with \"PROMPT QUERY\" turning plain English into correct SQL. This feature democratizes data access by removing the barrier of SQL syntax knowledge.\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsticky-ergonomic-and-effortless.b3f51a46.png&w=3840&q=75)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsticky-ergonomic-and-effortless.b3f51a46.png&w=3840&q=75)\n\n## Features\n\n[![Cloud database storage feature](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ffeature-cloud.3e9c0a0a.png&w=640&q=75)\\\\\n**Cloud database storage** \\\\\nManage your DuckDB database catalog in the cloud for easy scaling and collaboration.\\\\\n\\\\\nMore Details](https://motherduck.com/product/duckdb-users/cloud-database-storage/)\n\n[![SQL analytics engine feature](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ffeature-analytics.f04308e0.png&w=640&q=75)\\\\\n**SQL analytics engine** \\\\\nEfficiently run the same SQL queries on data stored locally, in MotherDuck or in your data lake.\\\\\n\\\\\nMore Details](https://motherduck.com/product/duckdb-users/sql-analytics-engine/)\n\n[![Simplified database sharing feature](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ffeature-db.11e966ef.png&w=640&q=75)\\\\\n**Simplified database sharing** \\\\\nCreate a shareable snapshot of your data, which your colleagues can easily attach and query in MotherDuck.\\\\\n\\\\\nMore Details](https://motherduck.com/product/duckdb-users/simplified-database-sharing/)\n\n[![Dual query execution feature](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ffeature-query.28419698.png&w=640&q=75)\\\\\n**Dual query execution** \\\\\nUse idle compute on your laptop in concert with the cloud to increase speed and lower cost.\\\\\n\\\\\nMore Details](https://motherduck.com/product/duckdb-users/dual-query-execution/)\n\n[![Notebook-like UI feature](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ffeature-ui.c08b01e4.png&w=1080&q=75)\\\\\n**Notebook-like UI** \\\\\nUse the web to browse the data catalog, write SQL, filter and sort results and share data.\\\\\n\\\\\nMore Details](https://motherduck.com/product/duckdb-users/notebook-like-ui/)\n\n[![Strong DuckDB ecosystem feature](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ffeature-ecosystem.0ab95f7c.png&w=640&q=75)\\\\\n**Strong DuckDB ecosystem** \\\\\nUse with 25+ tools in the modern data stack for import, orchestration and business intelligence.\\\\\n\\\\\nMore Details](https://motherduck.com/product/duckdb-users/strong-duckdb-ecosystem/)\n\n## Architecture\n\nManaged DuckDB-in-the-cloud\n\n## Ecosystem\n\nModern Duck Stack\n\n### CLOUD DATA WAREHOUSE\n\n### Sources\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpostgres-sql.d737f4f5.png&w=750&q=75)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Famazon-s3.72386dfc.png&w=640&q=75)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsalesforce.35d52b31.png&w=384&q=75)\n\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fstripe.2160e881.png&w=384&q=75)\n\n[**Business Intelligence**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ftableau.0ec523e2.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpower-bi.f3563826.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fomni.cb7aa381.png&w=384&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fmetabase.5f8fe44e.png&w=640&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Business+Intelligence) [**Ingestion**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ffivetran.26f3817d.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fairbyte.8371d2f0.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Festuary.babad369.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlthub.e9892b97.png&w=384&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Ingestion) [**Data Science & AI**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fhex.275dad7d.png&w=256&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fjupyter.2a6af3de.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fcolab.30ab10af.png&w=384&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fmarimo.b699c73d.png&w=640&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Data+Science+%26+AI) [**Reverse ETL**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fcensus.352f1d69.png&w=640&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Reverse+ETL) [**Transformation**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdbt.fd2184d1.png&w=384&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ftobiko.d0e3d1e5.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsql-mesh.6fceb012.png&w=640&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Transformation) [**Dev Tools**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdatagrip.f48eba23.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpuppy-graph.848400c6.png&w=750&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdagster.e1970a7c.png&w=640&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Dev+Tools)\n\n[**Orchestration**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fairflow.7f70081a.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdagster.e1970a7c.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fprefect.fd6371b3.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fkestra.aa10acfc.png&w=640&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Orchestration)\n\n[**Data Quality**\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fmonte-carlo.2143f962.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsecoda.9b7e86fb.png&w=640&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fsoda.59e5aa02.png&w=384&q=75)\\\\\n\\\\\n![](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fgreat-expectations.c544f1ef.png&w=640&q=75)\\\\\n\\\\\nMORE INFO](https://motherduck.com/ecosystem/?category=Data+Quality)\n\n## Case Studies\n\nMotherDuck\u2019s innovative approach to managing data and providing easy-to-use tooling has allowed us to expand our application use cases (e.g., getting data into the client's browser) and offer more value to our customers.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\n![Ravi Chandra's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fravi_chandra_photo_7db3a4c457.jpg&w=3840&q=75)\n\nRavi Chandra\n\nCTO at Dexibit\n\nMotherDuck\u2019s innovative approach to managing data and providing easy-to-use tooling has allowed us to expand our application use cases (e.g., getting data into the client's browser) and offer more value to our customers.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\nWe can create an instance per customer easily as opposed to Postgres, where it\u2019s a hassle to create and manage that many instances. We've now got these new levers for performance scaling because we can split and store the data and query efficiently as needed. If we need to handle a load spike or a huge amount of queries, we can spin up more ducklings on demand.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\n![Ravi Chandra's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fravi_chandra_photo_7db3a4c457.jpg&w=3840&q=75)\n\nRavi Chandra\n\nCTO at Dexibit\n\nWe can create an instance per customer easily as opposed to Postgres, where it\u2019s a hassle to create and manage that many instances. We've now got these new levers for performance scaling because we can split and store the data and query efficiently as needed. If we need to handle a load spike or a huge amount of queries, we can spin up more ducklings on demand.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\nOur data pipelines used to take eight hours. Now they're taking eight minutes, and I see a world where they take eight seconds. This is why we made the big bet on DuckDB and MotherDuck. It's only possible with DuckDB and MotherDuck.\n\n[READ MORE](https://motherduck.com/case-studies/finqore/)\n\n![Jim O\u2019Neill's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fjim_oneil_photo_930c637f49.jpg&w=3840&q=75)\n\nJim O\u2019Neill\n\nCo-founder and CTO at FinQore\n\nOur data pipelines used to take eight hours. Now they're taking eight minutes, and I see a world where they take eight seconds. This is why we made the big bet on DuckDB and MotherDuck. It's only possible with DuckDB and MotherDuck.\n\n[READ MORE](https://motherduck.com/case-studies/finqore/)\n\nWith MotherDuck, it only took an hour to get an app up and running, which was pretty cool. It uses 18 million rows of data, but once it\u2019s loaded, we have all this interactivity right on the website. And since it's all coming from MotherDuck, we can create a shareable snapshot of our data that others can attach to and query.\n\n[READ MORE](https://motherduck.com/case-studies/dominik-moritz/)\n\n![Dominik Moritz's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fdominik_berlin_f8a31170af.jpg&w=3840&q=75)\n\nDominik Moritz\n\nProfessor at Carnegie Mellon University\n\nWith MotherDuck, it only took an hour to get an app up and running, which was pretty cool. It uses 18 million rows of data, but once it\u2019s loaded, we have all this interactivity right on the website. And since it's all coming from MotherDuck, we can create a shareable snapshot of our data that others can attach to and query.\n\n[READ MORE](https://motherduck.com/case-studies/dominik-moritz/)\n\nMotherDuck\u2019s innovative approach to managing data and providing easy-to-use tooling has allowed us to expand our application use cases (e.g., getting data into the client's browser) and offer more value to our customers.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\n![Ravi Chandra's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fravi_chandra_photo_7db3a4c457.jpg&w=3840&q=75)\n\nRavi Chandra\n\nCTO at Dexibit\n\nMotherDuck\u2019s innovative approach to managing data and providing easy-to-use tooling has allowed us to expand our application use cases (e.g., getting data into the client's browser) and offer more value to our customers.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\nWe can create an instance per customer easily as opposed to Postgres, where it\u2019s a hassle to create and manage that many instances. We've now got these new levers for performance scaling because we can split and store the data and query efficiently as needed. If we need to handle a load spike or a huge amount of queries, we can spin up more ducklings on demand.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\n![Ravi Chandra's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fravi_chandra_photo_7db3a4c457.jpg&w=3840&q=75)\n\nRavi Chandra\n\nCTO at Dexibit\n\nWe can create an instance per customer easily as opposed to Postgres, where it\u2019s a hassle to create and manage that many instances. We've now got these new levers for performance scaling because we can split and store the data and query efficiently as needed. If we need to handle a load spike or a huge amount of queries, we can spin up more ducklings on demand.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\nOur data pipelines used to take eight hours. Now they're taking eight minutes, and I see a world where they take eight seconds. This is why we made the big bet on DuckDB and MotherDuck. It's only possible with DuckDB and MotherDuck.\n\n[READ MORE](https://motherduck.com/case-studies/finqore/)\n\n![Jim O\u2019Neill's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fjim_oneil_photo_930c637f49.jpg&w=3840&q=75)\n\nJim O\u2019Neill\n\nCo-founder and CTO at FinQore\n\nOur data pipelines used to take eight hours. Now they're taking eight minutes, and I see a world where they take eight seconds. This is why we made the big bet on DuckDB and MotherDuck. It's only possible with DuckDB and MotherDuck.\n\n[READ MORE](https://motherduck.com/case-studies/finqore/)\n\nWith MotherDuck, it only took an hour to get an app up and running, which was pretty cool. It uses 18 million rows of data, but once it\u2019s loaded, we have all this interactivity right on the website. And since it's all coming from MotherDuck, we can create a shareable snapshot of our data that others can attach to and query.\n\n[READ MORE](https://motherduck.com/case-studies/dominik-moritz/)\n\n![Dominik Moritz's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fdominik_berlin_f8a31170af.jpg&w=3840&q=75)\n\nDominik Moritz\n\nProfessor at Carnegie Mellon University\n\nWith MotherDuck, it only took an hour to get an app up and running, which was pretty cool. It uses 18 million rows of data, but once it\u2019s loaded, we have all this interactivity right on the website. And since it's all coming from MotherDuck, we can create a shareable snapshot of our data that others can attach to and query.\n\n[READ MORE](https://motherduck.com/case-studies/dominik-moritz/)\n\nMotherDuck\u2019s innovative approach to managing data and providing easy-to-use tooling has allowed us to expand our application use cases (e.g., getting data into the client's browser) and offer more value to our customers.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\n![Ravi Chandra's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fravi_chandra_photo_7db3a4c457.jpg&w=3840&q=75)\n\nRavi Chandra\n\nCTO at Dexibit\n\nMotherDuck\u2019s innovative approach to managing data and providing easy-to-use tooling has allowed us to expand our application use cases (e.g., getting data into the client's browser) and offer more value to our customers.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\nWe can create an instance per customer easily as opposed to Postgres, where it\u2019s a hassle to create and manage that many instances. We've now got these new levers for performance scaling because we can split and store the data and query efficiently as needed. If we need to handle a load spike or a huge amount of queries, we can spin up more ducklings on demand.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\n![Ravi Chandra's photo](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fravi_chandra_photo_7db3a4c457.jpg&w=3840&q=75)\n\nRavi Chandra\n\nCTO at Dexibit\n\nWe can create an instance per customer easily as opposed to Postgres, where it\u2019s a hassle to create and manage that many instances. We've now got these new levers for performance scaling because we can split and store the data and query efficiently as needed. If we need to handle a load spike or a huge amount of queries, we can spin up more ducklings on demand.\n\n[READ MORE](https://motherduck.com/case-studies/dexibit/)\n\n## Get in Touch\n\nWe\u2019d love to learn more about what you\u2019re building. A Product Expert will fly right back to you with resources to help you take flight.\n\nFirst Name\n\nLast Name\n\nE-mail\n\nCompany\n\nLeave us a message.\n\nThis site is protected by reCAPTCHA and the Google [Privacy Policy](https://policies.google.com/privacy) and [Terms of Service](https://policies.google.com/terms) apply.\n\nSubmit\n\n![Duck looking up](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fduck-looking-up.1c763865.png&w=3840&q=75)\n\nAuthorization Response\n\nreCAPTCHA\n\nRecaptcha requires verification.\n\n[Privacy](https://www.google.com/intl/en/policies/privacy/) \\- [Terms](https://www.google.com/intl/en/policies/terms/)\n\nprotected by **reCAPTCHA**\n\n[Privacy](https://www.google.com/intl/en/policies/privacy/) \\- [Terms](https://www.google.com/intl/en/policies/terms/)",
  [2m  â”‚[0m     "numLines": 403,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 403
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [94mâ”Œâ”€ ğŸ¤– AGENT MESSAGE[0m
  [94mâ”‚[0m These are helpful. Let me search for more specific content about uploading/copying local data to MotherDuck and the tutorial for beginners:
  [94mâ””â”€[0m

  [96mğŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_cpnchk8w/.kurt/sources/motherduck.com/blog/duckdb-tutorial-for-beginners.md

  [96mğŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_cpnchk8w/.kurt/sources/motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud.md
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_cpnchk8w/.kurt/sources/motherduck.com/blog/duckdb-tutorial-for-beginners.md",
  [2m  â”‚[0m     "content": "---\ntitle: duckdb-tutorial-for-beginners\ncontent_type: tutorial\nsource_url: https://motherduck.com/blog/duckdb-tutorial-for-beginners\nindexed_at: '2025-11-25T19:57:39.343742'\ncontent_hash: 9666dd2fd1ca1c68\nhas_code_examples: true\nhas_step_by_step: true\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n[GO BACK TO BLOG](https://motherduck.com/blog/)\n\n# DuckDB Tutorial For Beginners\n\n2024/10/31 - 12 min read\n\nBY\n\n[Mehdi Ouazza](https://motherduck.com/authors/mehdi-ouazza/)\n,\n[Ryan Boyd](https://motherduck.com/authors/ryan-boyd/)\n\nIf you haven't had the chance to get up to speed with DuckDB, this tutorial is for you! We'll go over the essentials, from installation to workflow, getting to know the command-line interface (CLI), and diving into your first analytics project. If are too lazy to read, I also made a video for this tutorial.\n\nDuckDB Tutorial For Beginners In 12 min - YouTube\n\n[Photo image of MotherDuck](https://www.youtube.com/channel/UCC0AT6XjO_ebWIifTDp5REg?embeds_referring_euri=https%3A%2F%2Fmotherduck.com%2F)\n\nMotherDuck\n\n10.8K subscribers\n\n[DuckDB Tutorial For Beginners In 12 min](https://www.youtube.com/watch?v=ZX5FdqzGT1E)\n\nMotherDuck\n\nSearch\n\nWatch later\n\nShare\n\nCopy link\n\nInfo\n\nShopping\n\nTap to unmute\n\nIf playback doesn't begin shortly, try restarting your device.\n\nFull screen is unavailable. [Learn More](https://support.google.com/youtube/answer/6276924)\n\nMore videos\n\n## More videos\n\nYou're signed out\n\nVideos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.\n\nCancelConfirm\n\nShare\n\nInclude playlist\n\nAn error occurred while retrieving sharing information. Please try again later.\n\n[Why am I seeing this?](https://support.google.com/youtube/answer/9004474?hl=en)\n\n[Watch on](https://www.youtube.com/watch?v=ZX5FdqzGT1E&embeds_referring_euri=https%3A%2F%2Fmotherduck.com%2F)\n\n0:00\n\n0:00 / 11:26\n\n\u2022Live\n\n\u2022\n\nLet's start quacking some code!\n\nEditor's note: this tutorial was originally published 2023-04-26 by Mehdi and has been updated by Ryan to reflect advancements in DuckDB.\n\n\n## What is DuckDB?\n\nDuckDB is an in-process SQL [OLAP](https://motherduck.com/learn-more/what-is-OLAP/) database, which means it is a database optimized for analytics and runs within the same process as the application using it. This unique feature allows DuckDB to offer the advantages of a database without the complexities of managing one. But, as with any software concept, the best way to learn is to dive in and get your hands dirty.\n\nWe\u2019ll be showing examples using the DuckDB command-line client (CLI), but you can also use DuckDB from within Python, R, and other languages, or any tool supporting JDBC or ODBC drivers. There is a community-contributed selection of example queries and code for many of these languages on the [DuckDB Snippets](https://duckdbsnippets.com/) website.\n\n_In the below snippets, any code example prefixed with `$` means that it\u2019s a bash command. Otherwise we assume that these would run within a DuckDB process, which uses a `D` prompt._\n\n## Installation\n\nInstalling DuckDB is a breeze. Visit the [DuckDB documentation](https://duckdb.org/docs/installation/index) and download the binary for your operating system.\n\nFor MacOS and Windows users, you can leverage package managers to make the DuckDB CLI directly available in your PATH, simplifying upgrades and installations.\n\nTo install DuckDB on MacOS using Homebrew, run the following command:\n\n```bash\nCopy code\n\n$ brew install duckdb\n```\n\nTo install DuckDB on Windows using winget, run the following command:\n\n```bash\nCopy code\n\nC:\\> winget install DuckDB.cli\n```\n\nYou can now launch DuckDB by simply calling the `duckdb` CLI command.\n\n```jsx\nCopy code\n\n$ duckdb\nv1.0.0 1f98600c2c\nEnter \".help\" for usage hints.\nConnected to a transient in-memory database.\nUse \".open FILENAME\" to reopen on a persistent database.\nD\n```\n\n## Workflow with VSCode\n\nTo follow along with our exploration of DuckDB, check out this [GitHub repository](https://github.com/mehd-io/duckdb-playground-tutorial). I recommend working with an editor, a SQL file, and sending commands to the terminal for a lightweight setup. This approach offers visibility on all commands, enables you to safely version control them, and allows you to leverage formatting tools and AI friends like Copilot.\n\nIn our example, we'll use Visual Studio Code (VSCode). To configure a custom shortcut to send commands from the editor to the terminal, open the keyboard shortcuts JSON file and add a key binding to the following command :\n\n```jsx\nCopy code\n\n{\n    \"key\": \"shift+enter\",\n    \"command\": \"workbench.action.terminal.runSelectedText\"\n}\n```\n\nOf course, this workflow can be pretty easily replicated with any editor or IDE!\n\n### Data Persistence with DuckDB: Overview\n\nBy default, DuckDB is an in-memory process and won't persist any data. To demonstrate this, let's create a simple table based on a query result:\n\n```sql\nCopy code\n\n$ duckdb\nD CREATE TABLE ducks AS SELECT 3 AS age, 'mandarin' AS breed;\nFROM ducks;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  age  \u2502  breed   \u2502\n\u2502 int32 \u2502 varchar  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     3 \u2502 mandarin \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nThis query creates and populates a \"ducks\" table. However, if we exit the CLI and reopen it, the table will be gone.\n\nUnlike standard SQL, the query above uses the `FROM` statement without any `SELECT *` statement. This is a neat shortcut in DuckDB and there are plenty more [DuckDB SQL shortcuts](https://duckdb.org/2022/05/04/friendlier-sql.html)!\n\n\n### Data Persistence with DuckDB: Creating a Database\n\nTo persist data, you have two options:\n\n1. Provide a path to a database file when starting DuckDB. The file can have any extension, but common choices are `.db`, `.duckdb`, or `.ddb`. If no database exists at the specified path, DuckDB will create one.\n\n\n```bash\nCopy code\n\n\n$ duckdb /data/myawesomedb.db\n```\n\n\nYou can also launch DuckDB with a database in read-only mode to avoid modifying the database:\n\n\n```bash\nCopy code\n\n\n$ duckdb -readonly /data/myawesomedb.db\n```\n\n2. If DuckDB is already running, use the `attach` command to connect to a database at the specified file path.\n\n\n```arduino\nCopy code\n\n\nATTACH DATABASE '/path/to/your/database.db' AS mydb;\n```\n\n\nThe database file uses DuckDB's custom single-file format (all tables are included), which supports transactional ACID compliance and stores data in a compressed columnar format for optimal aggregation performance. DuckDB is [regularly adding](https://duckdb.org/2022/10/28/lightweight-compression.html) new compression algorithms to improve performance.\n\nWhile the DuckDB team often improves the file format with new releases, it is [backward compatible](https://duckdb.org/docs/internals/storage.html) as of DuckDB 1.0, meaning that new releases are able to read files produced by early releases of DuckDB.\n\nIf you use MotherDuck as your cloud data warehouse, it automatically manages the DuckDB databases for you, so you create a MotherDuck database using the familiar [`CREATE DATABASE`](https://motherduck.com/docs/sql-reference/motherduck-sql-reference/create-database/) SQL statement.\n\n## Reading and Displaying Data\n\nNext, let's explore reading and writing data in CSV and Parquet formats. We'll use a small dataset from Kaggle containing daily Netflix Top 10 Movie/TV Show data for the United States from 2020 to March 2022.\n\nTo load the CSV dataset, use the [read\\_csv\\_auto](https://duckdb.org/docs/data/csv/overview#read_csv_auto-function) command, which infers the schema and detects the delimiter. You can also use the `read_csv` command and pass the schema and delimiter as parameters.\n\n```sql\nCopy code\n\nSELECT * FROM read_csv_auto('path/to/your/file.csv');\n```\n\nWhen you use this command, the dataset is read, but an actual table is not created in your DuckDB database. To create a table, use a `CREATE TABLE x AS` (CTAS) statement:\n\n```sql\nCopy code\n\nCREATE TABLE netflix_top10 AS SELECT * FROM read_csv_auto('path/to/your/file.csv');\n```\n\nTo write data to a CSV file, use the `COPY` command and specify the delimiter. For Parquet files, simply specify the file format:\n\n```sql\nCopy code\n\nCOPY ./data/netflix_top10.csv TO 'path/to/your/output/file.csv' WITH (FORMAT 'CSV', DELIMITER ',');\nCOPY ./data/netflix_top10.csv TO 'path/to/your/output/file.parquet' WITH (FORMAT 'PARQUET');\n```\n\nTo read data from a Parquet file, use the `read_parquet` command:\n\n```sql\nCopy code\n\nSELECT * FROM read_parquet('path/to/your/file.parquet');\n```\n\nDuckDB supports a wide variety of different file formats, including the native DuckDB database file used above, CSV, [JSON](https://motherduck.com/blog/analyze-json-data-using-sql/), Parquet, [Iceberg](https://motherduck.com/docs/integrations/file-formats/apache-iceberg/), [Delta Lake](https://motherduck.com/docs/integrations/file-formats/delta-lake/) and more. You can read these files from your local filesystem, a http endpoint or a cloud blob store like AWS S3, Cloudflare R2, Azure Blob Storage or Google Cloud Storage.\n\n## Display Modes, Output Options\n\nDuckDB CLI offers various ways to enhance your experience by customizing the data display and output options.\n\nYou can use the `.mode` command to change the appearance of tables returned in the terminal output. For instance, if you are dealing with long nested JSON, you can change the mode to `line` or `JSON` to have a better view of your data.\n\n```jsx\nCopy code\n\n.mode line\nSELECT * FROM './data/sales.json';\nsales_data = [{'order_id': 1, 'customer': {'id': 101, 'name': John Doe, 'email': john.doe@example.com}, 'items': [{'product_id': 301, 'product_name': Laptop, 'quantity': 1, 'price': 1200}, {'product_id': 302, 'product_name': Mouse, 'quantity': 1, 'price': 25}], 'total_amount': 1225, 'date': 2023-03-24}, {'order_id': 2, 'customer': {'id': 102, 'name': Jane Smith, 'email': jane.smith@example.com}, 'items': [{'product_id': 303, 'product_name': Keyboard, 'quantity': 1, 'price': 50}, {'product_id': 304, 'product_name': Monitor, 'quantity': 1, 'price': 200}], 'total_amount': 250, 'date': 2023-03-25}]\n```\n\nNext to that, you can output elsewhere the data by redirecting the terminal output to a file.\n\nLet\u2019s say you would like to output the result to a Markdown file, you can set the display mode to Markdown with `.mode markdown`. Combine this with the `.output` or `.once` command to write the result directly to a specific file. The `.output` command writes all the output of the different results you run, while `.once` does it just once.\n\n```lua\nCopy code\n\n.mode markdown\n.output myfile.md\n```\n\n## Running Commands and Exiting\n\nDuckDB CLI allows you to run a SQL statement and exit using the `-c` option parameter. For example, if you use a `SELECT` statement to read a Parquet file:\n\n```jsx\nCopy code\n\n$ duckdb -c \"SELECT * FROM read_parquet('path/to/your/file.parquet');\"\n```\n\nThis feature is lightweight, fast, and easy. You can even build your own [bash functions](https://duckdbsnippets.com/snippets/6/quickly-convert-a-csv-to-parquet-bash-function) using the DuckDB CLI for various operations on CSV/Parquet files, such as converting a CSV to Parquet.\n\nDuckDB also offers flags for configuration that you can fine-tune, such as setting the thread count, memory limits, ordering of null values and more. You can find the full list of flag options and their current values from the `duckdb_settings()` table function.\n\n```csharp\nCopy code\n\nFROM duckdb_settings();\n```\n\n## Working with Extensions\n\nExtensions are like packages that you can install within DuckDB to enjoy specific feature. DuckDB supports a number of core extensions. Not all are included by default, but DuckDB has a mechanism for remote extension installation. To view the available core extensions, execute the following statement:\n\n```csharp\nCopy code\n\nFROM duckdb_extensions();\n```\n\nTo install an extension, such as the popular `httpfs` extension that allows reading/writing remote files over HTTPS and S3, use the `INSTALL` command followed by the extension name. Once installed, DuckDB downloads the extension to the `$HOME/.duckdb/` folder (modifiable by setting the `extension_directory` parameter).\n\nNext, load the extension in the DuckDB process with the `LOAD` command.\n\n```ini\nCopy code\n\nINSTALL httpfs;\nLOAD httpfs;\n```\n\nDuckDB supports autoloading of the core extensions, so you often do not need to manually load these. As an example. if you read from a CSV file with a \\`https://\\` scheme, the \\`httpfs\\` extensionwill be autoloaded.\n\n\nIf you're using a third-party extension or your own extension not bundled by default, set the `allow_unsigned_extensions` flag to `True`, or use the `-unsigned` flag parameter when launching DuckDB.\n\n```jsx\nCopy code\n\n$ duckdb -unsigned\n```\n\nExtensions are powerful and versatile. You can create your own using the [template](https://github.com/duckdb/extension-template) provided by the DuckDB Labs team to kickstart your extension development journey.\n\nThere is now a [Community Extensions repository](https://duckdb.org/docs/extensions/community_extensions.html) for you to share any custom extensions with the wider DuckDB community for easy installation.\n\n## First analytics project\n\nWe have the mentioned Netflix dataset hosted on a public AWS S3 bucket. In this simple project, we will answer the most existential question : what were people in the US binge-watching during the COVID lockdown?\n\nAs the data is sitting on AWS S3, we\u2019ll start by installing the extension httpfs.\n\n```jsx\nCopy code\n\n-- Install extensions\nINSTALL httpfs;\nLOAD httpfs;\n-- Minimum configuration for loading S3 dataset if the bucket is public\nSET s3_region='us-east-1';\n```\n\nWe can now read our dataset :\n\n```jsx\nCopy code\n\nD CREATE TABLE netflix AS SELECT * FROM read_parquet('s3://us-prd-motherduck-open-datasets/netflix/netflix_daily_top_10.parquet');\nFROM netflix;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   As of    \u2502 Rank  \u2502 Year to Date Rank \u2502 \u2026 \u2502 Days In Top 10 \u2502 Viewership Score \u2502\n\u2502    date    \u2502 int64 \u2502      varchar      \u2502   \u2502     int64      \u2502      int64       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 2020-04-01 \u2502     1 \u2502 1                 \u2502 \u2026 \u2502              9 \u2502               90 \u2502\n\u2502 2020-04-01 \u2502     2 \u2502 2                 \u2502 \u2026 \u2502              5 \u2502               45 \u2502\n\u2502 2020-04-01 \u2502     3 \u2502 3                 \u2502 \u2026 \u2502              9 \u2502               76 \u2502\n\u2502 2020-04-01 \u2502     4 \u2502 4                 \u2502 \u2026 \u2502              5 \u2502               30 \u2502\n\u2502 2020-04-01 \u2502     5 \u2502 5                 \u2502 \u2026 \u2502              9 \u2502               55 \u2502\n\u2502 2020-04-01 \u2502     6 \u2502 6                 \u2502 \u2026 \u2502              4 \u2502               14 \u2502\n```\n\nFinally, getting the top watched movies as follow :\n\n```jsx\nCopy code\n\n-- Display the most popular TV Shows\nSELECT Title, max(\"Days In Top 10\") from netflix\nwhere Type='Movie'\nGROUP BY Title\nORDER BY max(\"Days In Top 10\") desc\nlimit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502             Title              \u2502 max(\"Days In Top 10\") \u2502\n\u2502            varchar             \u2502         int64         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 The Mitchells vs. The Machines \u2502                    31 \u2502\n\u2502 How the Grinch Stole Christmas \u2502                    29 \u2502\n\u2502 Vivo                           \u2502                    29 \u2502\n\u2502 365 Days                       \u2502                    28 \u2502\n\u2502 Despicable Me 2                \u2502                    27 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Copy the result to CSV\nCOPY (\nSELECT Title, max(\"Days In Top 10\") from netflix\nwhere Type='TV Show'\nGROUP BY Title\nORDER BY max(\"Days In Top 10\") desc\nlimit 5\n) TO 'output.csv' (HEADER, DELIMITER ',');\n```\n\nWhat\u2019s fun is that for both Movies and TV shows, the top 5 mostly include kids show. We all know that kids doesn\u2019t bother to see multiple time the same thing\u2026\n\nDuckDB and MotherDuck also support accessing private S3 buckets by using [`CREATE SECRET`](https://motherduck.com/docs/integrations/cloud-storage/amazon-s3/) to specify and store your credentials.\n\n## Exploring Beyond the Pond\n\nThat\u2019s it for this tutorial! If you're interested in delving deeper into DuckDB, check out these resources:\n\n- The official DuckDB docs : [https://duckdb.org/](https://duckdb.org/)\n- The DuckDB discord : [https://discord.com/invite/tcvwpjfnZx](https://discord.com/invite/tcvwpjfnZx)\n\nTo elevate your experience with DuckDB and scale it with a cloud data warehouse, explore [MotherDuck](https://motherduck.com/product/)! Dive into our [end-to-end tutorial](https://motherduck.com/docs/getting-started/e2e-tutorial) to discover the user-friendly web interface, AI-based SQL query fixing, global and organization-wide data sharing capabilities, and more.\n\nAdditionally, stay tuned to our [monthly newsletter](https://motherduck.com/duckdb-news/) and [YouTube channel](https://youtube.com/@motherduckdb/), where we'll continue to share more DuckDB-related content!\n\nKeep quacking, keep coding.\n\n!['DuckDB In Action' book cover](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fduckdb-book-full-cover.68e4f598.png&w=3840&q=75)\n\nGet your free book!\n\nE-mail\n\nSubscribe to other MotherDuck news\n\nSubmit\n\nFree Book!\n\n![blog subscription icon](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fblog-subscription-icon.67ccd5ae.png&w=828&q=75)\n\n### Subscribe to motherduck blog\n\nE-mail\n\nSubscribe to other MotherDuck Updates\n\nSubmit\n\n## PREVIOUS POSTS\n\n[![This Month in the DuckDB Ecosystem: March 2023](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fduckdb_ecosystem_monthly_feb_2023_352e669717.png&w=3840&q=75)](https://motherduck.com/blog/duckdb-ecosystem-newsletter-four/)\n\n[2023/03/23 - Marcos Ortiz](https://motherduck.com/blog/duckdb-ecosystem-newsletter-four/)\n\n### [This Month in the DuckDB Ecosystem: March 2023](https://motherduck.com/blog/duckdb-ecosystem-newsletter-four)\n\nThis month in the DuckDB Ecosystem, by Marcos Ortiz. Includes featured community member Elliana May, Python ecosystem, top links, upcoming events and more.\n\n[![This Month in the DuckDB Ecosystem: April 2023](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fduckdb_ecosystem_monthly_april_2023_bb2015c778.png&w=3840&q=75)](https://motherduck.com/blog/duckdb-ecosystem-newsletter-five/)\n\n[2023/04/17 - Marcos Ortiz](https://motherduck.com/blog/duckdb-ecosystem-newsletter-five/)\n\n### [This Month in the DuckDB Ecosystem: April 2023](https://motherduck.com/blog/duckdb-ecosystem-newsletter-five)\n\nThis month in the DuckDB Ecosystem, by Marcos Ortiz. Latest updates, including featured community member Josh Wills, upcoming events like webinars and top links.\n\n[View all](https://motherduck.com/blog/)\n\nAuthorization Response",
  [2m  â”‚[0m     "numLines": 465,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 465
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_cpnchk8w/.kurt/sources/motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud.md",
  [2m  â”‚[0m     "content": "---\ntitle: announcing-motherduck-duckdb-in-the-cloud\ncontent_type: blog\nsource_url: https://motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud\nindexed_at: '2025-11-25T19:57:33.138925'\ncontent_hash: a5ee88402c607603\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n[GO BACK TO BLOG](https://motherduck.com/blog/)\n\n# Announcing MotherDuck: Hybrid Execution Scales DuckDB from your Laptop into the Cloud\n\n2023/06/22 - 4 min read\n\nBY\nMotherDuck team\n\nDuckDB has become widely known as \u201cSQLite for Analytics\u201d \u2013 a powerful SQL analytics engine with broad adoption in development workflows, ad-hoc analytics on the laptop and embedded applications. MotherDuck wants to make it even easier to use, so we\u2019ve worked alongside the creators of DuckDB to build a cloud-based serverless analytics platform. Today is a large milestone in that journey \u2013 MotherDuck is now available by invitation.\n\nMotherDuck in 100 seconds (by a duck \ud83e\udd86) - YouTube\n\n[Photo image of MotherDuck](https://www.youtube.com/channel/UCC0AT6XjO_ebWIifTDp5REg?embeds_referring_euri=https%3A%2F%2Fmotherduck.com%2F)\n\nMotherDuck\n\n10.8K subscribers\n\n[MotherDuck in 100 seconds (by a duck \ud83e\udd86)](https://www.youtube.com/watch?list=PLIYcNkSjh-0zP7fwKzhnbx5ur1Mf80Q_p&v=BINA_ytZXMY)\n\nMotherDuck\n\nSearch\n\nWatch later\n\nShare\n\nCopy link\n\n1/1\n\nInfo\n\nShopping\n\nTap to unmute\n\nIf playback doesn't begin shortly, try restarting your device.\n\nFull screen is unavailable. [Learn More](https://support.google.com/youtube/answer/6276924)\n\nMore videos\n\n## More videos\n\nYou're signed out\n\nVideos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.\n\nCancelConfirm\n\nShare\n\nInclude playlist\n\nAn error occurred while retrieving sharing information. Please try again later.\n\n[Watch on](https://www.youtube.com/watch?list=PLIYcNkSjh-0zP7fwKzhnbx5ur1Mf80Q_p&v=BINA_ytZXMY&embeds_referring_euri=https%3A%2F%2Fmotherduck.com%2F)\n\n0:00\n\n[Previous (SHIFT+p)](https://www.youtube.com/watch?list=PLIYcNkSjh-0zP7fwKzhnbx5ur1Mf80Q_p&v=BINA_ytZXMY \"Previous (SHIFT+p)\")\n\n0:00 / 1:51\n\n\u2022Live\n\n\u2022\n\n## Hybrid execution: cloud and laptop working together\n\nData scientists, analysts, and engineers love DuckDB because it works great no matter where their data lives. Since many data professionals have powerful laptops sitting 85% idle, they often want to bring the data to their local machine to make it even more efficient to crunch, especially when performing ad hoc analysis and development. MotherDuck lets you analyze this local data locally, while still JOINing with data processed in the cloud, giving you efficient use of all your compute resources.\n\nIn the example below, the table `yellow_cab_nyc` lives in MotherDuck in the cloud, and I have a CSV on my laptop table with currency conversions. We want to see the average cost of NYC taxi trips by passenger count in different currencies by JOINing these two tables. Yes, we\u2019re seamlessly joining data on my laptop with data in the cloud!\n\n![Post asset](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fexample_hybrid_7bb8f08e2d.png&w=3840&q=75)\n\nYou can even do hybrid query execution with data stored in s3, with MotherDuck securely storing and managing your AWS credentials.\n\n![example_s3.png](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fexample_s3_d97e746203.png&w=3840&q=75)\n\nNote, these examples are part of our [sample datasets and queries](https://motherduck.com/docs/category/sample-datasets--queries/), feel free to run them yourself!\n\nYou might wonder how this works under the covers. By connecting your DuckDB instance to MotherDuck, you establish a radically different type of distributed system - one, in which one node is MotherDuck in the cloud, and another node is wherever your DuckDB lives, be it your laptop or a lambda, Python or CLI, JDBC or MotherDuck\u2019s own web app. Both nodes execute queries in concert in the most optimal way, automatically routing parts of queries to the right location.\n\n## MotherDuck includes a web notebook and Git-style Collaboration\n\nWant to run some quick SQL queries without downloading and installing DuckDB? The MotherDuck web application provides a notebook-like UI. This enables you to analyze local CSVs and parquet files, upload them and manage them alongside your other data stored in MotherDuck.\n\n![app_motherduck_beta.png](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fapp_motherduck_beta_v2_69fbe04dcf.png%3Fupdated_at%3D2023-06-21T23%3A24%3A18.647Z&w=3840&q=75)\n\nAs a DuckDB-in-the-cloud company, naturally MotherDuck embeds DuckDB in its web application using WASM. Results of your SQL queries are cached in this DuckDB instance, enabling you to instantly sort, pivot, and filter query results!\n\nWant to share your DuckDB data with colleagues? Using SQL, you can create a shareable snapshot of your data, which your colleagues can easily attach in MotherDuck.\n![example_share.png](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fexample_share_cfe1d14570.png&w=3840&q=75)\n\nThis SQL command will return a shareable URL which can then be used by your colleague to access the shared database.\n![example_attach.png](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fexample_attach_ff22a57c32.png&w=3840&q=75)\n\n## Anywhere you can Duck, you can MotherDuck\n\nDuckDB has been starred by over 10k developers on GitHub, and it might be due to the simplicity of getting up and running with a downloadable, open source analytics engine. We want to continue (and improve!) that amazing experience as we bring DuckDB to the cloud.\n\nOne way to do this is by ensuring MotherDuck works well with many of the most popular technologies in the modern data stack, including ingestion, orchestration and BI+Visualization tools.\n\n![partner-logos.png](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fpartner_logos_242d207bb6.png&w=3840&q=75)\n\nWe strive to make MotherDuck as easy to adopt as DuckDB. To that end, any DuckDB instance in the world running in Python or CLI can connect to MotherDuck with a single line of code. Suddenly, by running this command your DuckDB magically becomes supercharged by MotherDuck. Such ease of onboarding could only have been possible via close collaboration with the creators of DuckDB!\n\n![d_to_md.png](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fd_to_md_1dfe63b09b.png&w=3840&q=75)\n\n## Continuing to Make Analytics Ducking Awesome\n\nOne of the primary reasons we were driven to build a serverless analytics platform on top of DuckDB was their fast-paced innovation. Many features in DuckDB have gone from thoughts in academic papers to committed code in a few weeks.\n\nWe\u2019re launching MotherDuck now and doing weekly releases because we admire and want to emulate this speed of execution. Thanks in advance for all the feedback you can provide to make MotherDuck a better product!\n\n## Get Started\n\n[Request an invite](https://motherduck.com/) now to get started using MotherDuck, and join the flock on [slack.motherduck.com](https://slack.motherduck.com/).\n\nAnd, if you\u2019re in San Francisco next week, don\u2019t forget to [register for the MotherDuck Party](https://motherduck-party.eventbrite.com/), watch DuckDB co-creator Hannes [keynote the Data + AI conference](https://www.databricks.com/dataaisummit/session/data-ai-summit-keynote-thursday), and join MotherDuck co-founder Ryan Boyd in his [technical session](https://www.databricks.com/dataaisummit/session/if-duck-quacks-forest-and-everyone-hears-should-you-care).\n\n### TABLE OF CONTENTS\n\n[Hybrid execution: cloud and laptop working together](https://motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud/#hybrid-execution-cloud-and-laptop-working-together)\n\n[MotherDuck includes a web notebook and Git-style Collaboration](https://motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud/#motherduck-includes-a-web-notebook-and-git-style-collaboration)\n\n[Anywhere you can Duck, you can MotherDuck](https://motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud/#anywhere-you-can-duck-you-can-motherduck)\n\n[Continuing to Make Analytics Ducking Awesome](https://motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud/#continuing-to-make-analytics-ducking-awesome)\n\n[Get Started](https://motherduck.com/blog/announcing-motherduck-duckdb-in-the-cloud/#get-started)\n\nStart using MotherDuck now!\n\n[Try 21 Days Free](https://motherduck.com/get-started/)\n\nGet Started\n\n![blog subscription icon](https://motherduck.com/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fblog-subscription-icon.67ccd5ae.png&w=828&q=75)\n\n### Subscribe to motherduck blog\n\nE-mail\n\nSubscribe to other MotherDuck Updates\n\nSubmit\n\n## PREVIOUS POSTS\n\n[![This Month in the DuckDB Ecosystem: June 2023](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fthumbnail_duckdb_newsletter_1_34b0dc65cf.png&w=3840&q=75)](https://motherduck.com/blog/duckdb-ecosystem-newsletter-seven/)\n\n[2023/06/16 - Marcos Ortiz](https://motherduck.com/blog/duckdb-ecosystem-newsletter-seven/)\n\n### [This Month in the DuckDB Ecosystem: June 2023](https://motherduck.com/blog/duckdb-ecosystem-newsletter-seven)\n\nThis Month in the DuckDB Ecosystem: June 2023\n\n[![DuckDB Tutorial For Beginners](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fgetting_started_duckdb_thumbnail_70b197b1ab.png&w=3840&q=75)](https://motherduck.com/blog/duckdb-tutorial-for-beginners/)\n\n[2024/10/31 - Mehdi Ouazza, Ryan Boyd](https://motherduck.com/blog/duckdb-tutorial-for-beginners/)\n\n### [DuckDB Tutorial For Beginners](https://motherduck.com/blog/duckdb-tutorial-for-beginners)\n\nGet up to speed quickly with DuckDB, including installation, VSCode workflow integration and your first SQL analytics project.\n\n[View all](https://motherduck.com/blog/)\n\nAuthorization Response",
  [2m  â”‚[0m     "numLines": 188,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 188
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [94mâ”Œâ”€ ğŸ¤– AGENT MESSAGE[0m
  [94mâ”‚[0m Let me also read a few more files that might have more specific details on data migration:
  [94mâ””â”€[0m

  [96mğŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_cpnchk8w/.kurt/sources/motherduck.com/learn-more/hybrid-analytics-guide.md

  [96mğŸ”§ TOOL:[0m Read â†’ /var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_cpnchk8w/.kurt/sources/motherduck.com/videos/getting-started-with-motherduck-webinar.md
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_cpnchk8w/.kurt/sources/motherduck.com/learn-more/hybrid-analytics-guide.md",
  [2m  â”‚[0m     "content": "---\ntitle: hybrid-analytics-guide\ncontent_type: tutorial\nsource_url: https://motherduck.com/learn-more/hybrid-analytics-guide\nindexed_at: '2025-11-25T09:57:23.352209'\ncontent_hash: 91344eaa7ee54322\nhas_step_by_step: true\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n[BACK TO LEARN](https://motherduck.com/learn-more/)\n\n# Hybrid Analytics: Query Local & Cloud Data Instantly\n\n12 min readBY\n\n[Aditya Somani](https://motherduck.com/authors/aditya-aomani/)\n\n![Hybrid Analytics: Query Local & Cloud Data Instantly](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2FZero_latency_e8da68f055.png&w=3840&q=75)\n\nAre your analytics queries timing out in Postgres? Does your laptop grind to a halt when you try to analyze a large CSV file? If you feel caught between the memory limits of local tools and the spiraling costs of cloud data warehouses, you're not alone. The traditional divide between local development and cloud-scale analytics creates friction, slows down projects, and drains budgets.\n\nBut there is a modern, more efficient way. Imagine running complex SQL queries on a 20 GB Parquet file directly on your laptop, without a flicker of memory strain. Picture joining a local spreadsheet with a massive table in Amazon S3 using a single, elegant command. This is the reality of the **hybrid analytics workflow**, a powerful approach that unifies your local machine and the cloud into a single, unified data environment.\n\nThis guide is your definitive resource for understanding and implementing this new workflow. We'll break down the core concepts, provide practical examples, and show you how to solve the most common data bottlenecks for good. You will learn why traditional databases fail for analytics, how to analyze datasets larger than your RAM, and how the power of \"Dual Execution\" lets you instantly join local files with cloud data, all without the cost and complexity of managing a server cluster.\n\n## Why Are My Analytics Queries on Postgres & MySQL Timing Out?\n\nIf your analytical queries on a database like PostgreSQL or MySQL are consistently slow or timing out, you've hit a fundamental architectural limit. These databases are masterpieces of engineering for **[Online Transaction Processing (OLTP)](https://estuary.dev/blog/postgres-to-motherduck/)**. These are the small, fast operations that power applications, like creating a user or updating an order. However, this same design becomes a major bottleneck for **[Online Analytical Processing (OLAP)](https://en.wikipedia.org/wiki/Online_analytical_processing)**, which involves complex queries that scan and aggregate vast amounts of data.\n\nThe root of the problem is their **[row-oriented](https://en.wikipedia.org/wiki/Data_orientation)** storage model. A row-store keeps all data for a single record together on disk, which is efficient for retrieving an entire user profile. But for an analytical query that only needs to sum the `sale_amount` column across millions of rows, a row-store is forced to read every single column for every single row. This wastes an enormous amount of I/O and CPU cycles on data it doesn't need, which is the primary reason your dashboards are slow and your queries fail.\n\nThe next logical step is to move analytical workloads to a system built on a **[columnar architecture](https://motherduck.com/learn-more/columnar-storage-guide/)**. A columnar database organizes data by column, storing all values for `sale_amount` together. When your query asks for the sum of `sale_amount`, the database reads _only_ that column, greatly reducing I/O and speeding up performance by orders of magnitude. Modern analytical engines like DuckDB couple this with **[vectorized query execution](https://15721.courses.cs.cmu.edu/spring2024/notes/06-vectorization.pdf)**, a technique that processes data in large batches or \"vectors\" instead of row-by-row. This method fully utilizes modern CPU capabilities to perform a single instruction on multiple data points simultaneously, leading to large gains in computational efficiency.\n\n| Architecture | Row-Oriented (OLTP) | Column-Oriented (OLAP) |\n| --- | --- | --- |\n| **Primary Use Case** | Application backends, frequent small updates. | Business intelligence, data analytics, large scans. |\n| **Data Storage** | All data for a single record is stored together. | All data for a single column is stored together. |\n| **Query Example** | `SELECT * FROM users WHERE user_id = 123;` (Fast) | `SELECT SUM(sale_amount) FROM sales;` (Slow) |\n| **Best For** | Fast writes and single-record lookups. | Fast aggregations and filtering on specific columns. |\n\nBy offloading analytics to a purpose-built columnar engine, you let your transactional database continue to excel at what it does best while your analytical queries run in a [high-speed, optimized environment](https://motherduck.com/blog/postgres-duckdb-options/).\n\n## How Can I Analyze a 20 GB Parquet File on My Laptop Without It Crashing?\n\nThe second major bottleneck for data professionals is local memory. Trying to load a 20 GB file into a traditional in-memory library like Pandas on a 16 GB laptop will almost certainly result in a `MemoryError`. This happens because these tools must load the entire dataset into your computer's RAM before they can begin processing.\n\nThe modern solution is **out-of-core processing**, a strategy where data is processed in manageable chunks directly from disk without ever being fully loaded into RAM. This is the key feature of engines like DuckDB, which uses a [streaming execution model to handle datasets far larger than your available memory](https://duckdb.org/2024/07/09/memory-management.html). If a complex operation requires more memory than is available (by default, 80% of your system's RAM), DuckDB can \"spill\" intermediate results to a temporary file on disk, ensuring your query completes without crashing.\n\nThis capability turns your laptop into a surprisingly powerful analytics workstation. With an out-of-core engine, analyzing that 20 GB file becomes straightforward. You can simply use SQL to query it directly from a Python script or Jupyter notebook.\n\n```python\nCopy code\n\nimport duckdb\n\n# This query runs out-of-core, never loading the full 20GB file into RAM.\n# DuckDB's streaming engine processes the file in chunks.\nresult = duckdb.sql(\"\"\"\n  SELECT\n      product_category,\n      AVG(sale_price) as avg_price\n  FROM read_parquet('large_sales_dataset.parquet')\n  WHERE region = 'North America'\n  GROUP BY product_category\n  ORDER BY avg_price DESC;\n\"\"\").arrow()\n\nprint(result)\n```\n\nThis simple, powerful approach allows you to perform heavy-duty data analysis on your local machine, iterating quickly without waiting for a cloud cluster to spin up or worrying about memory crashes.\n\n## How Can I Join Local CSVs with Cloud Data in a Single Query?\n\nThis is where the hybrid workflow really shows its strength. Joining a local CSV of fresh sales data with a historical customer table in an S3 bucket has traditionally been a major challenge. The problem is \"data gravity,\" since it's [slow and expensive to move large amounts of data](https://motherduck.com/learn-more/no-etl-query-raw-files/). A naive query would have to either upload your entire local file to the cloud or download the entire cloud table to your laptop, both of which are very inefficient.\n\nMotherDuck solves this with an innovative query planner called **Dual Execution**. It treats your laptop and the MotherDuck cloud as two nodes in a single distributed system. When you run a hybrid query, the planner intelligently breaks it down and pushes computation to where the data lives, minimizing data transfer.\n\n> \"The most innovative feature of MotherDuck's architecture is its dual execution model. This is a hybrid query execution strategy where the optimizer intelligently decides whether to run parts of a query locally on the client or remotely in the MotherDuck cloud. The primary goal is to minimize data movement and leverage compute where it makes the most sense.\" - [Bringing DuckDB to the Cloud: Dual Execution Explained](https://motherduck.com/videos/bringing-duckdb-to-the-cloud-dual-execution-explained/)\n\nImagine you want to join a local CSV of new product pricing with a massive sales table in MotherDuck, but only for a specific product. Instead of moving entire tables, the Dual Execution planner does the following:\n\n1. **Local Scan:** It scans the small pricing CSV on your laptop.\n2. **Filter Locally:** It applies the filter for the specific product on your machine.\n3. **Transfer Minimal Data:** It sends only the single, filtered pricing row (a few bytes of data) to the cloud.\n4. **Join in the Cloud:** It performs the final join against the massive sales table in the MotherDuck cloud.\n\nThis process can reduce network traffic by orders of magnitude compared to traditional methods, turning a difficult query into an interactive one. You can see this in action with a simple `EXPLAIN` statement, which [shows which parts of the query run locally `(L)` and which run remotely `(R)`](https://motherduck.com/docs/key-tasks/running-hybrid-queries/).\n\n## Why Are Data Engineers So Excited About Dual-Execution Engines?\n\nData engineers are excited because dual-execution engines solve one of their biggest challenges: the \"it worked on my machine\" problem. In traditional setups, the tools and data used for local development are often completely different from the production cloud environment, leading to bugs and deployment failures.\n\nMotherDuck eliminates this by using the **exact same DuckDB engine** both locally and in the cloud. A query that works on your laptop is guaranteed to work in the cloud, creating a direct path from development to production. This greatly improves developer experience (DX) and accelerates iteration cycles.\n\nThis architecture provides three key benefits:\n\n1. **Faster Development:** Engineers can build and test pipelines with the zero-latency feedback of local development before scaling to the cloud.\n2. **Lower Costs:** By using the free, powerful compute on users' laptops and minimizing data transfer, this model significantly reduces cloud bills.\n3. **Better Collaboration:** It transforms the traditionally \"single-player\" DuckDB into a [\"multiplayer\" platform](https://motherduck.com/videos/339/bringing-duckdb-to-the-cloud-dual-execution-explained/) where teams can share databases and work from a single source of truth.\n\nThis powerful combination of local speed and cloud scale is backed by real-world success.\n\n> **[Case Study: Finqore's 60x Pipeline Acceleration](https://motherduck.com/case-studies/)**\n> Finqore, a financial technology company, was struggling with an 8-hour data pipeline built on Postgres. By migrating to a hybrid workflow with MotherDuck, they were able to use DuckDB's performance and MotherDuck's serverless scale to transform that pipeline into an **8-minute workflow**, a 60x improvement that unlocked real-time data exploration for their team.\n\n## How Can I Run SQL Analytics Without Managing Clusters?\n\nThe operational overhead of provisioning, scaling, and maintaining server clusters is a major drain on data teams. **[Serverless SQL analytics](https://motherduck.com/docs/concepts/architecture-and-capabilities/)** removes this burden entirely. Instead of managing infrastructure, you simply write and run your queries, and the platform handles the rest.\n\nThis model is not only simpler but also much more cost-effective for the \"spiky\" workloads typical of analytics. You pay only for the compute you actually use, avoiding the massive costs of idle clusters.\n\n| Feature / Scenario | Traditional Cloud Warehouse (e.g., Snowflake/BigQuery) | Hybrid Approach (Local + Serverless) |\n| --- | --- | --- |\n| **Development & Prototyping** | Billed for active compute time, even for small test queries. | **Free.** Uses local machine resources with no cloud costs. |\n| **Pricing Model** | Complex credits or per-TB scanned, which is hard to predict. | Simple, usage-based billing; pay only for queries you run. |\n| **Idle Compute** | Billed for provisioned clusters, even when idle, which can create a costly [idle tax on short-running queries](https://motherduck.com/learn-more/reduce-snowflake-costs-duckdb). | **No cost.** Serverless architecture has no idle compute. |\n| **Hardware Requirement** | Entirely reliant on expensive, provisioned cloud hardware. | Leverages powerful, existing local hardware (laptops, servers). |\n\nBy adopting a serverless, hybrid approach, you can reduce your cloud data warehouse costs while empowering your team with a faster, more flexible workflow.\n\n## What Lightweight SQL Solutions Can Be Integrated with Jupyter Notebooks?\n\nFor data scientists who work primarily in Jupyter, several excellent tools bring the power of SQL directly into the notebook environment. The most powerful option for serious analytics is the **DuckDB engine** itself. It can query Pandas DataFrames, Arrow tables, and large local files directly with full SQL support. Its performance on analytical queries is excellent in the embedded space.\n\nFor comparison, while Python's standard library includes **SQLite**, it's a row-based OLTP engine and is significantly slower than DuckDB for analytical queries. An independent benchmark found DuckDB to be **[12-35 times faster](https://motherduck.com/learn-more/duckdb-vs-sqlite-databases/)** for aggregations on a 100-million-row dataset. For any analytical task in a notebook, DuckDB is the clear choice for performance and scalability.\n\nAnother popular tool is **[JupySQL](https://jupysql.ploomber.io/)**, which provides convenient SQL \"magics\" (`%sql`, `%%sql`) that turn a notebook cell into a SQL editor. It connects to various backends, including DuckDB, making it great for quick, ad-hoc exploration.\n\n## How Can I Keep Queries on My Laptop in Sync With the Cloud?\n\nThe key to keeping local and cloud queries synchronized is **single-engine semantics**. Because MotherDuck uses the same DuckDB engine on your laptop and in the cloud, a query validated locally is guaranteed to behave identically in production. This eliminates the most common source of dev-prod drift.\n\nA modern dev-to-prod workflow combines this with tools like dbt (data build tool). An analyst can develop and test a dbt model on their laptop against local data for rapid iteration. Once validated, they can promote the model to run in the cloud against the full production dataset with a [single configuration change](https://motherduck.com/blog/dual-execution-dbt/), ensuring complete consistency. This workflow combines the speed of local development with the scale and reliability of a production cloud environment.\n\n## When Should I Not Use This Hybrid Approach?\n\nWhile the hybrid, in-process model is very useful for analytics, it's not a solution for every problem. It's crucial to understand its limitations to know when a different architecture is needed.\n\n1. **High-Concurrency Applications:** An in-process engine like DuckDB is not designed to be a client-server database serving hundreds of simultaneous application users. For powering a public-facing web application, a traditional OLTP database like PostgreSQL or a distributed SQL database is the right choice.\n2. **Real-Time, High-Volume Ingestion:** If your use case involves ingesting thousands of events per second in real-time, a specialized streaming platform or real-time OLAP database would be more suitable.\n3. **Truly Massive, Multi-Terabyte Workloads:** While DuckDB can handle surprisingly large datasets on a single node, if your active working set is in the tens or hundreds of terabytes, you've reached the scale where a distributed cloud data warehouse becomes necessary to parallelize work across a large cluster.\n\nThe beauty of the MotherDuck ecosystem is that it provides a smooth way to scale up. You can start with a local-first, hybrid workflow and, as your concurrency or data scale needs grow, easily push more of the workload to the MotherDuck cloud without changing your core tools or SQL logic.\n\n### TABLE OF CONTENTS\n\n[Why Are My Analytics Queries on Postgres & MySQL Timing Out?](https://motherduck.com/learn-more/hybrid-analytics-guide/#why-are-my-analytics-queries-on-postgres-mysql-timing-out)\n\n[How Can I Analyze a 20 GB Parquet File on My Laptop Without It Crashing?](https://motherduck.com/learn-more/hybrid-analytics-guide/#how-can-i-analyze-a-20-gb-parquet-file-on-my-laptop-without-it-crashing)\n\n[How Can I Join Local CSVs with Cloud Data in a Single Query?](https://motherduck.com/learn-more/hybrid-analytics-guide/#how-can-i-join-local-csvs-with-cloud-data-in-a-single-query)\n\n[Why Are Data Engineers So Excited About Dual-Execution Engines?](https://motherduck.com/learn-more/hybrid-analytics-guide/#why-are-data-engineers-so-excited-about-dual-execution-engines)\n\n[How Can I Run SQL Analytics Without Managing Clusters?](https://motherduck.com/learn-more/hybrid-analytics-guide/#how-can-i-run-sql-analytics-without-managing-clusters)\n\n[What Lightweight SQL Solutions Can Be Integrated with Jupyter Notebooks?](https://motherduck.com/learn-more/hybrid-analytics-guide/#what-lightweight-sql-solutions-can-be-integrated-with-jupyter-notebooks)\n\n[How Can I Keep Queries on My Laptop in Sync With the Cloud?](https://motherduck.com/learn-more/hybrid-analytics-guide/#how-can-i-keep-queries-on-my-laptop-in-sync-with-the-cloud)\n\n[When Should I Not Use This Hybrid Approach?](https://motherduck.com/learn-more/hybrid-analytics-guide/#when-should-i-not-use-this-hybrid-approach)\n\nStart using MotherDuck now!\n\n[Try 21 Days Free](https://app.motherduck.com/?auth_flow=signup)\n\nStart using MotherDuck now!\n\n[Try 21 Days Free](https://app.motherduck.com/?auth_flow=signup)\n\n## FAQS\n\n### My analytics queries on Postgres / MySQL are timing out. What\u2019s the next step up?\n\nThe next step is to move your analytical workloads from a row-oriented (OLTP) database like Postgres to a purpose-built columnar (OLAP) engine like DuckDB. Columnar engines are designed for analytics and are orders of magnitude faster for large scans and aggregations because they only read the specific columns needed for a query.\n\n### How can I analyze a 20 GB Parquet file on my laptop without it crashing?\n\nUse a query engine that supports \"out-of-core\" processing, like DuckDB. It processes data in manageable chunks directly from your disk instead of loading the entire file into RAM. This allows you to analyze datasets that are significantly larger than your computer's available memory.\n\n### Why is it so hard to join local CSVs with cloud data?\n\nThe main challenge is \"data gravity\"\u2014it's slow and expensive to move large datasets across a network. Traditional tools force you to either upload your entire local file or download the entire cloud table. A modern hybrid platform with a dual-execution engine solves this by intelligently minimizing data transfer.\n\n### Can I mix local datasets and S3 data in a single query?\n\nYes. With a hybrid analytics platform like MotherDuck, you can write a single SQL query that joins local files (e.g., CSVs) with data in cloud storage (e.g., Parquet files in S3). The system treats them as if they exist in one unified environment, abstracting away their physical location.\n\n### How can I run SQL analytics without managing clusters?\n\nAdopt a serverless SQL analytics platform. These services handle all infrastructure provisioning, scaling, and maintenance for you. You simply run your queries and pay only for the compute you use, which eliminates the high cost and operational overhead of managing idle clusters.\n\n### Why are data engineers excited about dual-execution engines?\n\nDual-execution engines solve the \"it worked on my machine\" problem by using the exact same query engine on the developer's laptop and in the cloud. This guarantees consistency, speeds up development cycles, lowers costs by leveraging local compute, and enables better team collaboration on a single source of truth.\n\n### What lightweight SQL solutions can be integrated with Jupyter notebooks?\n\nDuckDB is the leading lightweight SQL solution for Jupyter. It can be installed via pip and can directly query Pandas DataFrames, Arrow tables, and large local files with full SQL support. It is significantly faster for analytical queries than other embedded options like SQLite.\n\n### How can I keep queries on my laptop in sync with the cloud?\n\nUse a platform that offers single-engine semantics, like MotherDuck. Because it runs the same DuckDB engine locally and in the cloud, a query validated on your laptop is guaranteed to behave identically in production. This eliminates dev-prod drift and ensures consistency.\n\nAuthorization Response",
  [2m  â”‚[0m     "numLines": 212,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 212
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "text",
  [2m  â”‚[0m   "file": {
  [2m  â”‚[0m     "filePath": "/var/folders/yr/lv_0z6m15fg8llcm02_kw4m80000gn/T/kurt_eval_cpnchk8w/.kurt/sources/motherduck.com/videos/getting-started-with-motherduck-webinar.md",
  [2m  â”‚[0m     "content": "---\ntitle: getting-started-with-motherduck-webinar\ncontent_type: event\nsource_url: https://motherduck.com/videos/getting-started-with-motherduck-webinar\nindexed_at: '2025-11-25T20:44:42.911566'\ncontent_hash: 7e2a069d42290080\n---\n\nHands-on Lab: Agentic Data Engineering with MotherDuck and Ascend[December 3, 10am PT / 1pm ET](https://www.ascend.io/events/hands-on-lab-agentic-data-engineering-with-motherduck)\n\n[Motherduck home](https://motherduck.com/)\n\n[START FREE](https://app.motherduck.com/?auth_flow=signup)\n\n[BACK TO VIDEOS](https://motherduck.com/videos/)\n\n\\[Webinar\\] Getting Started with MotherDuck - YouTube\n\n[Photo image of MotherDuck](https://www.youtube.com/channel/UCC0AT6XjO_ebWIifTDp5REg?embeds_referring_euri=https%3A%2F%2Fmotherduck.com%2F)\n\nMotherDuck\n\n10.8K subscribers\n\n[\\[Webinar\\] Getting Started with MotherDuck](https://www.youtube.com/watch?v=bcU3voqZnCE)\n\nMotherDuck\n\nSearch\n\nWatch later\n\nShare\n\nCopy link\n\nInfo\n\nShopping\n\nTap to unmute\n\nIf playback doesn't begin shortly, try restarting your device.\n\nMore videos\n\n## More videos\n\nYou're signed out\n\nVideos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.\n\nCancelConfirm\n\nShare\n\nInclude playlist\n\nAn error occurred while retrieving sharing information. Please try again later.\n\n[Watch on](https://www.youtube.com/watch?v=bcU3voqZnCE&embeds_referring_euri=https%3A%2F%2Fmotherduck.com%2F)\n\n0:00\n\n0:00 / 41:41\n\n\u2022Live\n\n\u2022\n\nWebinarMotherDuck Features\n\n# Getting Started with MotherDuck Webinar\n\n2024/06/19\n\nMotherDuck co-founder Ryan Boyd and Produck Expert Nathaniel Thompson provide an overview on MotherDuck, featuring DuckDB analyst ergonomics, Column Explorer, Fixit, Tableau visualization, Python data analysis, Wasm and more.\n\n## Related Videos\n\n[![\"Data-based: Going Beyond the Dataframe\" video thumbnail](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.us-east-1.amazonaws.com%2Fassets%2Fimg%2FData_based_f32745b461.png&w=3840&q=75)](https://motherduck.com/videos/going-beyond-the-dataframe/)\n\n[2025-11-20](https://motherduck.com/videos/going-beyond-the-dataframe/)\n\n### [Data-based: Going Beyond the Dataframe](https://motherduck.com/videos/going-beyond-the-dataframe)\n\nLearn how to turbocharge your Python data work using DuckDB and MotherDuck with Pandas. We walk through performance comparisons, exploratory data analysis on bigger datasets, and an end-to-end ML feature engineering pipeline.\n\nWebinar\n\nPython\n\nAI, ML and LLMs\n\n[![\"Empowering Data Teams: Smarter AI Workflows with Hex & MotherDuck\" video thumbnail](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.us-east-1.amazonaws.com%2Fassets%2Fimg%2FHex_Webinar_778e3959e4.png&w=3840&q=75)](https://motherduck.com/videos/smarter-ai-workflows-with-hex-motherduck/)\n\n[2025-11-14](https://motherduck.com/videos/smarter-ai-workflows-with-hex-motherduck/)\n\n### [Empowering Data Teams: Smarter AI Workflows with Hex & MotherDuck](https://motherduck.com/videos/smarter-ai-workflows-with-hex-motherduck)\n\nAI isn't here to replace data work, it's here to make it better. Watch this webinar to see how Hex and MotherDuck build AI workflows that prioritize context, iteration, and real-world impact.\n\nWebinar\n\nAI, ML and LLMs\n\n[![\"Escaping Catalog Hell: A Guide to Iceberg, DuckDB & the Data Lakehouse\" video thumbnail](https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Ficeberg_video_thumbnail_adfdabe3d6.jpg&w=3840&q=75)\\\\\n\\\\\n46:26](https://motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse/)\n\n[2025-06-12](https://motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse/)\n\n### [Escaping Catalog Hell: A Guide to Iceberg, DuckDB & the Data Lakehouse](https://motherduck.com/videos/escaping-catalog-hell-a-guide-to-iceberg-duckdb-the-data-lakehouse)\n\nBuilding a data stack means choosing between easy SaaS and complex open-source. Apache Iceberg is a middle ground, but its catalog is a hurdle. New tools now simplify using Iceberg with DuckDB to create a flexible, local data lakehouse.\n\nMotherDuck Features\n\n[View all](https://motherduck.com/videos/)\n\nAuthorization Response",
  [2m  â”‚[0m     "numLines": 121,
  [2m  â”‚[0m     "startLine": 1,
  [2m  â”‚[0m     "totalLines": 121
  [2m  â”‚[0m   }
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [94mâ”Œâ”€ ğŸ¤– AGENT MESSAGE[0m
  [94mâ”‚[0m Now I have a comprehensive understanding of how to migrate data from local DuckDB to MotherDuck. Let me write the answer:
  [94mâ””â”€[0m

  [96mğŸ”§ TOOL:[0m Write â†’ /tmp/answer_without_kg_6.md
  [92m  âœ“ RESULT:[0m
  [2m  â”‚[0m {
  [2m  â”‚[0m   "type": "create",
  [2m  â”‚[0m   "filePath": "/tmp/answer_without_kg_6.md",
  [2m  â”‚[0m   "content": "<4232 chars>",
  [2m  â”‚[0m   "structuredPatch": [],
  [2m  â”‚[0m   "originalFile": null
  [2m  â”‚[0m }
  [2m  â””â”€[0m

  [94mâ”Œâ”€ ğŸ¤– AGENT MESSAGE[0m
  [94mâ”‚[0m I've written a comprehensive answer to `/tmp/answer_without_kg_6.md`. The answer covers how to migrate data from a local DuckDB database to MotherDuck, including:
  [94mâ”‚[0m 
  [94mâ”‚[0m 1. **Method 1: ATTACH Command** - The simplest approach using `ATTACH 'md:'` to connect and then copying tables
  [94mâ”‚[0m 2. **Method 2: Web UI Upload** - Using MotherDuck's notebook-like interface to upload files
  [94mâ”‚[0m 3. **Method 3: From Files** - Creating tables directly from CSV/Parquet files
  [94mâ”‚[0m 
  [94mâ”‚[0m The answer also explains key concepts like dual execution (MotherDuck's intelligent hybrid query execution), the hybrid workflow benefits, and post-migration capabilities like database sharing.
  [94mâ”‚[0m 
  [94mâ”‚[0m I used 6 source files from `.kurt/sources/motherduck.com/` to compile this comprehensive answer.
  [94mâ””â”€[0m

  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ğŸ“Š TURN 1 METRICS
     Tokens: 7,005 | Cost: $0.6649
     Cumulative: 7,005 tokens | $0.6649
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  âœ… TASK COMPLETE
     Reason: llm: The agent has clearly outlined the methods and concepts related to data migration, signaling that it has completed the task rather than seeking further input.

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ âœ… SESSION COMPLETE
â•‘    Turns: 1 | Tools: 14 | Duration: 92.6s
â•‘    Tokens: 7,005 | Cost: $0.6649
â•‘    Stop reason: Task completed (no follow-up questions)
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   ğŸ§  Running LLM judge evaluation...
   ğŸ§  LLM Judge score: 0.95
