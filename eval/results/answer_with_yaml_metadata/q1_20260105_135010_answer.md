---
sources:
  - path: .kurt/sources/motherduck.com/learn-more/why-choose-parquet-table-file-format.md
    claims_used:
      - "Apache Parquet is an open-source columnar storage file format designed for efficient data processing"
      - "Parquet efficiently manages large datasets while ensuring high performance"
      - "Parquet has superior compression and faster query performance"
      - "CSV files are a straightforward, text-based format... lacks advanced functionalities like compression and schema management, which limits its efficiency in handling large-scale datasets"
  - path: .kurt/sources/motherduck.com/videos/simple-way-to-convert-csv-and-parquet-files.md
    claims_used:
      - "CSV is a file format used for data storage"
      - "The COPY command allows for filtering and selecting specific columns"
---

# Most Efficient File Formats for Loading Data into MotherDuck

**Parquet is the most efficient file format for loading data into MotherDuck.**

## Why Parquet is Optimal

1. **Columnar Storage**: Unlike row-based formats like CSV, Parquet stores data by columns, enabling faster query performance and superior compression for large-scale analytical workloads.

2. **Efficient Compression**: Parquet leverages specialized encoding techniques such as dictionary, run-length, and delta encoding to optimize storage. These methods reduce the data footprint, translating into cost savings and improved access speeds.

3. **Predicate Pushdown and Column Pruning**: Parquet supports techniques that bring filtering and aggregation operations closer to the storage layer, reducing the amount of data that needs processing.

4. **Schema Evolution**: Parquet handles evolving data structures with ease, supporting seamless schema modifications without disrupting existing workflows.

## Comparison with Alternatives

| Format | Type | Best For | Efficiency for MotherDuck |
|--------|------|----------|--------------------------|
| **Parquet** | Columnar | Analytical workloads | **Highest** |
| Apache ORC | Columnar | Hadoop/Hive ecosystems | High |
| CSV | Row-based | Simple data exchange | Low (lacks compression, schema management) |
| Apache Avro | Row-based | Schema evolution, streaming | Moderate |

## Recommendation

For loading data into MotherDuck:
- **Use Parquet** for optimal performance on large datasets
- Convert CSV files to Parquet using DuckDB's COPY command if you receive data in CSV format
- Parquet's efficient compression minimizes I/O operations, which is especially important for cloud-based analytics
