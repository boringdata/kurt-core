---
sources:
  - claim: "dbt is a great and straightforward tool for building production-ready data pipelines with SQL"
    doc: motherduck.com/blog/duckdb-dbt-e2e-data-engineering-project-part-2.md
    lines: 27-37
  - claim: "Since DuckDB is an embedded database and just another Python library to install, we can run the computation within the same Python dbt process"
    doc: motherduck.com/blog/duckdb-dbt-e2e-data-engineering-project-part-2.md
    lines: 97-100
  - claim: "profiles.yml configuration shows dev uses local path and prod uses md: for MotherDuck"
    doc: motherduck.com/blog/duckdb-dbt-e2e-data-engineering-project-part-2.md
    lines: 306-318
  - claim: "Using md: triggers authentication with MotherDuck, which checks for a token in the motherduck_token environment variable"
    doc: motherduck.com/blog/duckdb-dbt-e2e-data-engineering-project-part-2.md
    lines: 320-321
---

# Setting Up MotherDuck with dbt

## Installation

Install the dbt-duckdb adapter with MotherDuck support using pip or Poetry:

```bash
# Using pip
pip install dbt-duckdb[md]

# Using Poetry
poetry add dbt-duckdb[md]
```

## Initialize a dbt Project

```bash
dbt init <project_name>
```

This creates the standard dbt project structure with folders for models, tests, macros, etc.

## Configure profiles.yml

The key to connecting dbt to MotherDuck is in your `profiles.yml` configuration. You can set up two targets: one for local development and one for MotherDuck (production):

```yaml
your_project_name:
  outputs:
    dev:
      type: duckdb
      path: /tmp/dbt.duckdb  # Local DuckDB file for development
    prod:
      type: duckdb
      path: "md:"  # MotherDuck connection
  target: dev
```

### Key Configuration Details

- **type**: Always set to `duckdb` for the dbt-duckdb adapter
- **path**:
  - For local development: Use a local file path (e.g., `/tmp/dbt.duckdb`)
  - For MotherDuck: Use `md:` to connect to MotherDuck cloud
  - You can also specify a database: `md:my_database`

## Authentication

MotherDuck authentication requires a token. Set the `motherduck_token` environment variable:

```bash
export motherduck_token="your_token_here"
```

You can obtain this token from your MotherDuck account settings page.

## Running dbt with MotherDuck

```bash
# Run with local DuckDB (dev target)
dbt run --target dev

# Run with MotherDuck (prod target)
dbt run --target prod
```

## Benefits of This Setup

1. **Seamless dev-to-prod transition**: Since MotherDuck is DuckDB in the cloud, SQL is fully compatible between environments
2. **Fast local iteration**: DuckDB operates in-process, allowing quick iteration since computation occurs locally within the same dbt process
3. **Zero cloud costs for development**: Using DuckDB locally eliminates cloud compute costs during development
4. **Easy testing**: You can run dbt unit tests locally without any cloud dependencies

## Working with External Data (S3)

For pipelines that read from S3, you can configure sources in `sources.yml`:

```yaml
version: 2

sources:
  - name: external_source
    meta:
      external_location: "{{ env_var('S3_PATH') }}"
    tables:
      - name: my_table
```

Use AWS credentials by calling `load_aws_credentials()` as a pre-hook in your `dbt_project.yml`.
